[{"categories":null,"content":"Arch Linux 使用 NUT 管理 UPS NUT 包含两个最重要的服务：\nnut-server：nut-server 通过驱动直接与 UPS 进行通讯，获取 UPS 的状态信息，并将这些信息提供给 nut-monitor 使用 nut-monitor：nut-monitor 定期从 nut-server 获取 UPS 的状态信息，根据这些信息对其所在的机器执行关机等操作 单服务器 + 单 UPS 这里使用的服务器是 ArchLinux（2023.10.26），UPS 是 APC BK650M2-CH\n服务器上使用 $ pacman -Sy nut 安装 nut 包\nnut-server 配置 扫描已连接的 UPS\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ sudo nut-scanner Scanning USB bus. No start IP, skipping SNMP Scanning XML/HTTP bus. No start IP, skipping NUT bus (old connect method) [nutdev1] driver = \"usbhid-ups\" port = \"auto\" vendorid = \"051D\" productid = \"0002\" product = \"Back-UPS BK650M2-CH FW:294803G -292804G\" serial = \"9B2328A00149\" vendor = \"American Power Conversion\" bus = \"001\" 在 ups.conf 配置文件中添加 UPS 的驱动和端口信息\n1 2 3 4 5 6 7 8 9 $ sudo vim /etc/nut/ups.conf ~~~ # [自定义设备名称] # driver = 连接驱动 # port = UPS 所在端口 [apcbk650m2] driver = usbhid-ups # 参考 nut-scanner 扫描的信息 port = auto # 因为使用 USB 进行的连接，选择 auto 即可 ~~~ 启动 UPS 的驱动程序服务\n1 2 3 4 5 6 7 8 9 10 # 启动 UPS 的驱动程序服务有 4 种方式，这里推荐使用第 4 种 # 按顺序依次启动 ups.conf 中配置的 UPS 的驱动程序服务 $ sudo upsdrvctl start # 按名称启动 ups.conf 中配置的 UPS 的驱动程序服务 $ sudo upsdrvctl start apcbk650m2 # 使用 nut-driver-enumerator 服务依次启动 ups.conf 中配置的 UPS 的驱动程序服务。 # nut-driver-enumerator 服务启动后，会自动为 ups.conf 中设置的所有 UPS 创建 nut-driver@\u003cupsname\u003e 服务并启动它 $ sudo systemctl enable --now nut-driver-enumerator # 只启动指定名称的 ups 的驱动服务（推荐） $ sudo systemctl enable --now nut-driver@apcbk650m2 添加一个管理员账户，nut-monitor 使用该用户连接到 nut-server，可以对 UPS 进行关机等操作\n1 2 3 4 5 6 7 8 9 10 11 $ sudo vim /etc/nut/upsd.users ~~~ # 设置一个管理员用户，可以直接在本机使用 upsc 等命令设置/查看 UPS 信息 [admin] # 密码，在之后配置监控（upsmon）时使用 password = 123456 # 只有一台机器设置为 primary 即可 upsmon = primary actions = SET # 该用户对 UPS 有 SET 权限。既其可以对 UPS 进行重启或断电等操作 instcmds = ALL # 该用户可以执行所有实例命令（Instance Commands）。实例命令通常是直接与 UPS 状态和参数有关的操作，例如获取电池电量、输入电压等。 ~~~ 设置自启动并启动 nut-server\n1 2 3 4 5 6 7 8 9 10 # 启动并自启 nut-server $ sudo systemctl enable --now nut-server # 查看 nut-server 启动状态，看是否有异常 $ systemctl status nut-server # 如果没问题使用如下命令即可获取 UPS 的状态信息 $ upsc apcbk650m2 battery.charge: 100 battery.charge.low: 10 ... ups.vendorid: 051d nut-monitor 配置 添加需要监控的 UPS 信息\n1 2 3 4 5 $ sudo vim /etc/nut/upsmon.conf ~~~ # 要监控的 UPS 信息，参数参考 upsd.users MONITOR apcbk650m2@localhost 1 admin 123456 primary ~~~ 默认配置说明\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 # 要监控 UPS 的 nut-server 信息 MONITOR apcbk650m2@localhost 1 admin 123456 primary # UPS 使用电源供电时，每 5 秒获取一次 UPS 的状态 POLLFREQ 5 # UPS 使用电池供电时，每 5 秒获取一次 UPS 的状态 POLLFREQALERT 5 # UPS 连续 15 秒处于“失效”状态，将其设置为“死亡” DEADTIME 15 # 通知用户 5 秒后关闭机器 FINALDELAY 5 # 等待 15 秒后执行 SHUTDOWNCMD 进行关机 HOSTSYNC 15 # 关机命令。下方命令表示立即关机并断开电源 SHUTDOWNCMD \"/sbin/shutdown -h +0\" # 当 UPS 需要关闭时，在 primary 模式运行的 upsmon 会创建该文件，可以在 SHUTDOWNCMD 中检查此文件，如果存在即可调用 upsdrvctl shutdown 关闭 UPS 驱动服务 POWERDOWNFLAG /etc/killpower # 当 UPS 需要更换电池时，每 12 小时会发送一次警告 RBWARNTIME 43200 # 无法访问 UPS 超过 300 秒会发送 NOCOMM 通知，直到问题被解决。 NOCOMMWARNTIME 300 # 当可用的 UPS 少于 1 个时关闭服务器 MINSUPPLIES 1 # UPS 状态在发生以下变化时会将通知写到系统日志并通过 /bin/wall 通知给已登录的用户 NOTIFYFLAG ONLINE\tSYSLOG+WALL NOTIFYFLAG ONBATT\tSYSLOG+WALL NOTIFYFLAG LOWBATT\tSYSLOG+WALL NOTIFYFLAG FSD\tSYSLOG+WALL NOTIFYFLAG COMMOK\tSYSLOG+WALL NOTIFYFLAG COMMBAD\tSYSLOG+WALL NOTIFYFLAG SHUTDOWN\tSYSLOG+WALL NOTIFYFLAG REPLBATT\tSYSLOG+WALL NOTIFYFLAG NOCOMM\tSYSLOG+WALL NOTIFYFLAG NOPARENT\tSYSLOG+WALL # UPS 状态在发生变化时发送的通知内容。%s 会被替换为 upsname@hostname NOTIFYMSG ONLINE\t\"UPS %s on line power\" NOTIFYMSG ONBATT\t\"UPS %s on battery\" NOTIFYMSG LOWBATT\t\"UPS %s battery is low\" NOTIFYMSG FSD\t\"UPS %s: forced shutdown in progress\" NOTIFYMSG COMMOK\t\"Communications with UPS %s established\" NOTIFYMSG COMMBAD\t\"Communications with UPS %s lost\" NOTIFYMSG SHUTDOWN\t\"Auto logout and shutdown proceeding\" NOTIFYMSG REPLBATT\t\"UPS %s battery needs to be replaced\" NOTIFYMSG NOCOMM\t\"UPS %s is unavailable\" NOTIFYMSG NOPARENT\t\"upsmon parent process died - shutdown impossible\" 设置自启并启动 nut-monitor\n1 $ sudo systemctl enable --now nut-monitor 编写脚本实现 UPS 使用电池供电 1 分钟后或 UPS 电池电量低时自动关闭服务器\n通过 upsmon.conf 可以发现 nut-monitor 只有在不满足 MINSUPPLIES 条件时才会自动关机。对于 UPS 使用电池供电 1 分钟后或 UPS 电池电量低（默认取决于 UPS 厂商的设置，可以通过 [自定义 UPS 的电量过低阈值](#自定义 UPS 的电量过低阈值) 进行修改）时自动关闭服务器是没有默认实现的，这可以借助 nut 提供的 NOTIFYCMD 和 upssched 来自定义脚本实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 # 修改 sudo vim /etc/nut/upsmon.conf ~~~ # nut 提供了 UPS 上电（ONLINE）通知、切换电池供电通知（ONBATT）等一系列的通知，我们可以通过自定义脚本或者使用 nut 提供的 upssched 在接收到这些通知后，对其进行定制化的操作，这里使用 upssched NOTIFYCMD /usr/bin/upssched # 设置在 UPS 上电、切换到电池供电、低电量时，将通知写入系统日志 + 将提示信息发送给已登录的用户 + 执行 NOTIFYCMD NOTIFYFLAG ONLINE SYSLOG+WALL+EXEC NOTIFYFLAG ONBATT SYSLOG+WALL+EXEC NOTIFYFLAG LOWBATT SYSLOG+WALL+EXEC ~~~ # 配置 upssched $ sudo vim /etc/nut/upssched.conf ~~~ # 当触发下面 AT ... START-TIMER timername ... 时，会将 timername 传给这个脚本并执行 # 不推荐使用默认的 /usr/bin/upssched-cmd，因为在更新 nut 后可能会重置该脚本 CMDSCRIPT /var/lib/nut/upssched/upssched-cmd # 该文件会在进程间传递通信以启动和停止计时器。要保证执行 upssched 的用户可以对其进行访问 PIPEFN /var/lib/nut/upssched/upssched.pipe # 避免 upsmod 同时调度两个时间出现竞争情况。要保证执行 upssched 的用户可以对其进行访问 LOCKFN /var/lib/nut/upssched/upssched.lock # 当 apcbk650m2@localhost（这里也可以使用 * 表示所有的 UPS。当指定特定 UPS 时，一定要用与通知时 %s 参数相同的名称，否则规则会不生效） 切换到电池供电时启动一个计时器，在 60 秒后，执行 CMDSCRIPT，并传入计时器名称 onbatt-timer。用来设置 UPS 使用电池供电 60s 后自动关闭服务器 AT ONBATT apcbk650m2@localhost START-TIMER onbatt-timer 60 # 当 apcbk650m2@localhost 在 60 秒内重新上电，关闭计时器：onbatt-timer AT ONLINE apcbk650m2@localhost CANCEL-TIMER onbatt-timer # 只要 apcbk650m2@localhost 电池电量低就执行 LOWBATT，并传入参数 lowbatt。用来设置 UPS 电池电量低时发送邮件/企微通知并关闭服务器 AT LOWBATT apcbk650m2@localhost EXECUTE lowbatt # 只要 apcbk650m2@localhost 切换到电池供电就执行 CMDSCRIPT，并传入参数 onbatt。用来设置在 UPS 切换到电池供电时发送邮件/企微通知 AT ONBATT apcbk650m2@localhost EXECUTE onbatt # 只要 apcbk650m2@localhost 重新上电就执行 CMDSCRIPT，并传入参数 online。用来设置在 UPS 重新上电时发送邮件/企微通知 AT ONLINE apcbk650m2@localhost EXECUTE online ~~~ # 创建 CMDSCRIPT 文件 $ sudo mkdir /var/lib/nut/upssched $ sudo touch /var/lib/nut/upssched/upssched-cmd /var/lib/nut/upssched/upssched.pipe /var/lib/nut/upssched/upssched.lock # 在 ArchLinux 上默认使用 nut 用户运行 nut-server 和 nut-monitor 服务，所以将文件权限给 nut 用户 $ sudo chown -R nut: /var/lib/nut/upssched $ sudo chmod -R 750 /var/lib/nut/upssched # 配置触发脚本 upssched-cmd $ sudo vim /usr/bin/upssched-cmd ~~~ case $1 in onbatt-timer) set +e # 发送通知到企微机器人 curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\nUPS 已经使用电池供电 60 秒，现在开始关闭服务器\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce set -e /usr/bin/upsmon -c fsd ;; lowbatt) set +e # 发送通知到企微机器人 curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\nUPS 电池电量低，现在开始关闭服务器\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce set -e /usr/bin/upsmon -c fsd ;; onbatt) # 发送通知到企微机器人 curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\nUPS 电源已断开，使用电池为服务器供电\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce ;; online) # 发送通知到企微机器人 curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\nUPS 电源已恢复，使用电源为服务器供电\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce ;; *) logger -t upssched-cmd \"Unrecognized command: $1\" ;; esac ~~~ 重启 nut-monitor 服务\n1 $ sudo systemctl restart nut-monitor 测试\n断开 UPS 电源\n控制台：\nBroadcast message from nut@localhost (somewhere) (Sat Nov 11 13:18:44 2023): UPS apcbk650m2@localhost on battery\n企微机器人：\nUPS 电源已断开，使用电池为服务器供电\n60s 内给 UPS 上电\n控制台：\nBroadcast message from nut@localhost (somewhere) (Sat Nov 11 13:18:59 2023): UPS apcbk650m2@localhost on line power\n企微机器人：\nUPS 电源已恢复，使用电源为服务器供电\n断开 UPS 电源 1 分钟后\n控制台：\nBroadcast message from nut@localhost (somewhere) (Sat Nov 11 13:20:44 2023): Executing automatic power-fail shutdown Broadcast message from nut@localhost (somewhere) (Sat Nov 11 13:20:44 2023): Auto logout and shutdown proceeding\n企微机器人：\nUPS 已经使用电池供电 60 秒，现在开始关闭服务器\n多服务器 + 单 UPS 这里使用的服务器是 ArchLinux（2023.10.26）和绿联私有云DX4600+，UPS 是 APC BK650M2-CH，并且 UPS 使用 USB 线连接在 ArchLinux 服务器上。这部分是在 [单服务器 + 单 UPS](#单服务器 + 单 UPS) 的基础上进行修改\nArchLinux 服务器的 IP 是 192.168.1.100，NAS 的 IP 是 192.168.1.200\nArchLinux 配置 修改 nut 运行在 netserver 模式，允许外部服务器访问 nut-server\n1 2 3 4 5 $ sudo vim /etc/nut/nut.conf ~~~ #MODE=none MODE=netserver ~~~ 设置 nut-server 的监听地址和端口\n1 2 3 4 5 $ sudo vim /etc/nut/upsd.conf ~~~ # 允许所有人通过 3493 端口访问 nut-server LISTEN 0.0.0.0 3493 ~~~ 添加防火墙规则\n1 2 3 4 # 只允许 IP 地址为 192.168.1.200（NAS 的 IP） 的服务器访问 3493 端口 $ sudo firewall-cmd --add-rich-rule=\"rule family=\"ipv4\" source address=\"192.168.1.200/32\" port port=\"3493\" protocol=\"tcp\" accept\" --permanent # 重新加载防火墙 $ sudo firewall-cmd --reload 为 NAS 添加一个新用户 ugreen，让其可以使用该用户通过 nut-monitor 从 ArchLinux 上的 nut-server 获取 UPS 的状态信息\n1 2 3 4 5 6 7 $ sudo vim /etc/nut/upsd.users ~~~ [ugreen] password = 654321 # 因为使用 ArcLinux 做主服务，所以将 ugreen 设置为 secondary 即可 upsmon = secondary ~~~ 重启 nut-server\n1 $ sudo systemctl restart nut-server 绿联私有云 DX4600+ 配置 绿联自带的“外置UPS”应用（2023.11.11）只支持使用 USB 线直连的 UPS，所以这里通过修改 nut 配置的方式设置 UPS。\n注意：使用“外置UPS”的“启用UPS”开关操作后，会对 nut 的配置文件进行修改，可能导致冲突。所以手动修改完 nut 的配置文件后，不要操作“外置UPS”的“启用UPS”开关\n开启调试功能，获取 root 密码（略），使用 ssh 进行连接 NAS\n1 $ ssh root@nas -p 922 测试 NAS 能否从 ArchLinux 上的 nut-server 获取 UPS 的状态信息\n1 2 3 4 5 $ upsc apcbk650m2@192.168.1.100:3493 battery.charge: 96 battery.charge.low: 10 ... ups.vendorid: 051d 因为绿联的系统是基于 OpenWrt 的，所以需要修改 /etc/config/nut_monitor\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 $ vim /etc/config/nut_monitor # 注意：操作“外置UPS”应用后会对该文件进行修改 ~~~ config upsmon 'upsmon' # 使用 nutmon 用户运行 upsmon option runas 'nutmon' # 设置有通知时，默认将日志写入 SYSLOG 并执行 notifycmd list defaultnotify 'EXEC+SYSLOG' option minsupplies '1' option shutdowncmd '/sbin/shutdown' option notifycmd '/usr/sbin/upssched' #config master 'master' # option upsname 'ups0' # option hostname 'localhost' # option powervalue '1' # option username 'nut' # option password 'nut' # 因为 NAS 的 upsmon 运行在 secondary 模式，所以这里配置 slave config slave 'apcbk650m2' option upsname apcbk650m2 option hostname 192.168.1.100 option 3493 option powervalue 1 option username ugreen option password 654321 ~~~ 启动另一个窗口连接 NAS，查看系统日志\n因为 Openwrt 上没有 wall 命令，所以 nut-monitor 不能把通知打印到已登录用户的控制台，所以这里通过系统日志检查 nut-monitor 是否成功连接\n1 2 # /var/log/ug_sys_log_flag 文件中存储了系统日志的实际路径 $ tail -f $(cat /var/log/ug_sys_log_flag) 启动 nut-monitor\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 启动 $ /etc/init.d/nut-monitor start # 设置开机自启动 $ /etc/init.d/nut-monitor enable # 在日志窗口可以看到如下信息，Logged into UPS apcbk650m2@192.168.1.100 即表示连接成功 Sat Nov 11 16:00:47 2023 daemon.err upsmon[28174]: 0.000034\tUPS: apcbk650m2@192.168.1.100 (slave) (power value 1) Sat Nov 11 16:00:47 2023 daemon.err upsmon[28174]: 0.000049\tdebug level is '1' Sat Nov 11 16:00:47 2023 daemon.err upsmon[28174]: 0.000313\tTrying to connect to UPS [apcbk650m2@192.168.1.100] Sat Nov 11 16:00:47 2023 daemon.err upsmon[28174]: 0.001577\tLogged into UPS apcbk650m2@192.168.1.100 # 查看状态/停止/重启 $ /etc/init.d/nut-monitor status/stop/restart 设置 NAS 自动关机\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 # 配置 upssched $ vim /etc/nut/upssched.conf ~~~ CMDSCRIPT /opt/nut/nutmon/upssched-cmd PIPEFN /opt/nut/nutmon/upssched.pipe LOCKFN /opt/nut/nutmon/upssched.lock AT ONBATT apcbk650m2@192.168.1.100 START-TIMER onbatt-timer 60 AT ONLINE apcbk650m2@192.168.1.100 CANCEL-TIMER onbatt-timer AT LOWBATT apcbk650m2@192.168.1.100 EXECUTE lowbatt AT ONBATT apcbk650m2@192.168.1.100 EXECUTE onbatt AT ONLINE apcbk650m2@192.168.1.100 EXECUTE online ~~~ # 创建 CMDSCRIPT、PIPEFN 和 LOCKFN 文件 $ mkdir -p /opt/nut/nutmon $ touch /opt/nut/nutmon/upssched-cmd /opt/nut/nutmon/upssched.pipe /opt/nut/nutmon/upssched.lock $ chown -R nutmon: /opt/nut/nutmon $ chmod -R 750 /opt/nut/nutmon # 配置触发脚本 upssched-cmd $ vim /opt/nut/upssched-cmd ~~~ #! /bin/sh case $1 in onbatt-timer) set +e # 发送通知到企微机器人 curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\nUPS 已经使用电池供电 60 秒，现在开始关闭 NAS\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce set -e # 参考绿联“外置UPS”应用自动生成的脚本进行设置 ubus call nas_svr shutdown '{\"path\":\"ugreen\"}' sleep 2 /sbin/shutdown ;; lowbatt) set +e # 发送通知到企微机器人 curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\nUPS 电池电量低，现在开始关闭 NAS\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce set -e # 参考绿联“外置UPS”应用自动生成的脚本进行设置 ubus call nas_svr shutdown '{\"path\":\"ugreen\"}' sleep 2 /sbin/shutdown ;; onbatt) # 发送通知到企微机器人 curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\nUPS 电源已断开，使用电池为 NAS 供电\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce ;; online) # 发送通知到企微机器人 curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\nUPS 电源已恢复，使用电源为 NAS 供电\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce ;; *) logger -t upssched-cmd \"Unrecognized command: $1\" ;; esac ~~~ 修改 nut-monitor 启动脚本\n因为默认的脚本会重置 /etc/nut/upssched.conf 的配置，导致自定义的配置不生效\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ cp /etc/init.d/nut-monitor /etc/init.d/nut-monitor.bak $ vim /etc/init.d/nut-monitor build_config() { ... #echo \"CMDSCRIPT /usr/bin/upssched-cmd\" \u003e /etc/nut/upssched.conf #echo \"PIPEFN /var/run/nut/upssched.pipe\" \u003e\u003e /etc/nut/upssched.conf #echo \"LOCKFN /var/run/nut/upssched.lock\" \u003e\u003e /etc/nut/upssched.conf config_load nut_server config_get delayoff ups0 offdelay #echo \"AT ONBATT * START-TIMER upsgone $delayoff\" \u003e\u003e /etc/nut/upssched.conf #echo \"AT ONLINE * CANCEL-TIMER upsgone\" \u003e\u003e /etc/nut/upssched.conf chmod 640 /etc/nut/upssched.conf chgrp $(id -gn ${runas:-root}) \"/etc/nut/upssched.conf\" } 注意：这个可能是绿联进行过修改，所以以后系统升级可能变化/被重置。\n重启 nut-monitor\n1 $ /etc/init.d/nut-monitor restart 测试\n断开 UPS 电源\nArchLinux 控制台：\nBroadcast message from nut@localhost (somewhere) (Sat Nov 11 18:35:00 2023): UPS apcbk650m2@localhost on battery\nNAS 日志：\nSat Nov 11 18:35:22 2023 daemon.err upsmon[23092]: 35.004219\tUPS apcbk650m2@192.168.1.100 on line power Sat Nov 11 18:35:02 2023 daemon.info upssched[23633]: Timer daemon started Sat Nov 11 18:35:02 2023 daemon.info upssched[23633]: New timer: onbatt-timer (60 seconds)\n企微机器人：\nUPS 电源已断开，使用电池为服务器供电 UPS 电源已断开，使用电池为 NAS 供电\n60s 内给 UPS 上电\nArchLinux 控制台：\nBroadcast message from nut@localhost (somewhere) (Sat Nov 11 18:35:20 2023): UPS apcbk650m2@localhost on line power\nNAS 日志：\nSat Nov 11 18:35:22 2023 daemon.err upsmon[23092]: 35.004219\tUPS apcbk650m2@192.168.1.100 on line power Sat Nov 11 18:35:22 2023 daemon.info upssched[23633]: Cancelling timer: onbatt-timer\n企微机器人：\nUPS 电源已断开，使用电源为服务器供电 UPS 电源已断开，使用电源为 NAS 供电\n断开 UPS 电源并等待 1 分钟后\nArchLinux 控制台：\nBroadcast message from nut@localhost (somewhere) (Sat Nov 11 18:38:35 2023): UPS apcbk650m2@localhost on battery --- 1 分钟后 --- Broadcast message from nut@localhost (somewhere) (Sat Nov 11 18:39:51 2023): Executing automatic power-fail shutdown Broadcast message from nut@localhost (somewhere) (Sat Nov 11 18:39:51 2023): Auto logout and shutdown proceeding\nNAS 日志：\nSat Nov 11 18:38:37 2023 daemon.err upsmon[23092]: 230.022973\tUPS apcbk650m2@192.168.1.100 on battery Sat Nov 11 18:38:37 2023 daemon.info upssched[32407]: Timer daemon started Sat Nov 11 18:38:37 2023 daemon.info upssched[32407]: New timer: onbatt-timer (60 seconds) --- 1 分钟后 ---- Sat Nov 11 18:39:37 2023 daemon.err upsmon[23092]: 290.026032\tUPS apcbk650m2@192.168.1.100: forced shutdown in progress\n企微机器人：\nUPS 电源已断开，使用电池为服务器供电 UPS 电源已断开，使用电池为 NAS 供电 --- 1 分钟后 --- UPS 已经使用电池供电 60 秒，现在开始关闭服务器 UPS 已经使用电池供电 60 秒，现在开始关闭 NAS\n更完整的配置 /etc/nut/upsd.conf\n1 2 3 4 5 6 7 8 9 10 NOTIFYFLAG ONLINE SYSLOG+WALL+EXEC NOTIFYFLAG ONBATT SYSLOG+WALL+EXEC NOTIFYFLAG LOWBATT SYSLOG+WALL+EXEC NOTIFYFLAG FSD SYSLOG+WALL+EXEC NOTIFYFLAG COMMOK SYSLOG+WALL+EXEC NOTIFYFLAG COMMBAD SYSLOG+WALL+EXEC NOTIFYFLAG SHUTDOWN SYSLOG+WALL+EXEC NOTIFYFLAG REPLBATT SYSLOG+WALL+EXEC NOTIFYFLAG NOCOMM SYSLOG+WALL+EXEC NOTIFYFLAG NOPARENT SYSLOG+WALL+EXEC /etc/nut/upssched.conf\n1 2 3 4 5 6 7 8 9 10 11 12 AT ONBATT apcbk650m2@localhost START-TIMER onbatt-timer 60 AT ONLINE apcbk650m2@localhost CANCEL-TIMER onbatt-timer AT ONBATT apcbk650m2@localhost EXECUTE onbatt AT ONLINE apcbk650m2@localhost EXECUTE online AT LOWBATT apcbk650m2@localhost EXECUTE lowbatt AT FSD apcbk650m2@localhost EXECUTE fsd AT COMMOK apcbk650m2@localhost EXECUTE commok AT COMMBAD apcbk650m2@localhost EXECUTE commbad AT SHUTDOWN apcbk650m2@localhost EXECUTE shutdown AT REPLBATT apcbk650m2@localhost EXECUTE replbatt AT NOCOMM apcbk650m2@localhost EXECUTE nocomm AT NOPARENT apcbk650m2@localhost EXECUTE noparent /var/lib/nut/upssched/upssched-cmd\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 #! /bin/sh case $1 in onbatt-timer) set +e # 发送通知到企微机器人 curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\nUPS 已经使用电池供电 60 秒，开始关闭服务器\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce set -e /usr/bin/upsmon -c fsd ;; onbatt) curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\n已断开 UPS 电源，使用电池为服务器供电\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce ;; online) curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\n已恢复 UPS 电源，使用电源为服务器供电\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce ;; lowbatt) set +e curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\nUPS 电池电量低，关闭服务器\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce set -e /usr/bin/upsmon -c fsd ;; fsd) ;; commok) curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\n服务器与 UPS 通讯成功\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce ;; commbad) curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\n服务器与 UPS 通讯失败\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce ;; shutdown) ;; replbatt) curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\n需要更换 UPS 电池\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce ;; nocomm) set +e curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\nUPS 不可用，关闭服务器\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce set -e /usr/bin/upsmon -c fsd ;; noparent) curl -H \"Content-Type: application/json\" -X POST -d '{\"msgtype\":\"markdown\",\"markdown\":{\"content\":\"# UPS 监控\\n服务器的 upsmon 父线程死亡\"}}' https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=74d8024d-9c5f-48eb-b1df-f4246ba245ce ;; *) logger -t upssched-cmd \"Unrecognized command: $1\" ;; esac upsmon 参数详解 参数 说明 POLLFREQ seconds 轮询 UPS 的时间间隔，默认 5 秒。间隔越小，获取的值越准确，建立的连接越多。 POLLFREQALERT seconds 在任意 UPS 使用电池供电时，轮询 UPS 的时间间隔，默认 5 秒。关系必须满足：POLLFREQALERT \u003c= POLLFREQ。可以与 POLLFREQ 一起使用，在 UPS 正常时减慢轮询速度，在 UPS 使用电池供电时，加快轮询速度。 DEADTIME seconds 与 UPS 失联 seconds 秒（默认 15 秒）后将其标记为“死亡”。如果轮询时（POLLFREQ/POLLFREQALERT）获取 UPS 状态失败，会将其标记为“失效”状态，如果它保持“失效”超过 DEADTIME 秒，则将其标记为“死亡”。推荐值：max(POLLFREQ, POLLFREQALERT) 的 3 倍 FINALDELAY seconds 在 primary 模式运行时，发送 SHUTDOWN 通知告诉 secondary 和用户 seconds 秒（默认 5 秒）后它会运行 SHUTDOWNCMD 执行关机\n在 secondary 模式运行时，通知用户 seconds 秒（默认 5 秒）后它会运行 SHUTDOWNCMD 执行关机。 HOSTSYNC seconds 在 primary 模式运行时，发送 SHUTDOWN 通知给 secondary 后，等待 seconds 秒，无论 secondary 是否有响应，primary 都执行关机。防止 secondary 长时间无响应导致 primary 永远挂起\n在 secondary 模式运行时，如果 primary 没有即时响应，secondary 会等待 seconds 秒自动关机。 MONITOR system powervalue username password type 需要监控的 UPS 信息。upsmon.conf 中必须至少有一条 MONITOR 记录。被监控的 UPS 可以不为运行 upsmon 的系统供电。\nsystem：UPS 标识符，格式：\u003cups名称\u003e[@\u003c主机名\u003e[:\u003c端口\u003e]]，默认主机名是 localhost\npowervalue：为本系统供电的电源数量。默认值为 1\nusername password type：与 upsd.users 文件中的配置相同 NOCOMMWARNTIME seconds upsmon 无法访问任何一个 UPS 超过 seconds 秒（默认 300 秒）会发送 NOCOMM 通知，直到问题被解决。 NOTIFYMSG type message upsmon 默认维护了一个通知类型和通知消息的列表，类似于：NOTIFYMSG ONLINE \"UPS %s is getting line power\"NOTIFYMSG ONBATT \"Someone pulled the plug on %s\"%s 会被自动替换为 UPS 的标识符type 的可选值有：ONLINE：UPS 使用电源供电ONBATT：UPS 使用电池供电LOWBATT：UPS 使用电池供电，并且电量不足FSD：UPS 已经被 primary 关机（FSD = \"Forced Shutdown\"）COMMOK：与 UPS 成功建立通讯COMMBAD：与 UPS 的通讯丢失SHUTDOWN：系统正在关闭中REPLBATT：UPS 的电池损坏需要更换NOCOMM：UPS 不可用（无法联系监控） NOTIFYFLAG type flag[+flag]... 当事件发生时，将消息发送到哪些地方。默认通过 /bin/wall 将消息发送给所有已登录的用户并写到系统日志示例：NOTIFYFLAG ONLINE SYSLOGNOTIFYFLAG ONBATT SYSLOG+WALL+EXECflag 的值有：SYSLOG：将消息写入系统日志WALL：将消息写入所有带 /bin/wall 的用户EXEC：执行下方的 NOTIFYCMDIGNORE：什么都不做。IGNORE 和上方的任意标志都不能在同一行上使用 NOTIFYCMD command 当任意事件通知发生时，需要执行的指令/脚本，可以在命令/脚本中从环境变量 NOTIFYTYPE 获取事件类型。只有 NOTIFYFLAG 包含 EXEC 的事件类型才会执行该 command。通常使用 NOTIFYCMD 监听 upssched POWERDOWNFLAG filename 当 UPS 需要关闭电源时，在 primary 模式下运行的 upsmon 会创建此文件。需要在 SHUTDOWNCMD 脚本中判断如果该文件存在，则调用 upsdrvctl shutdown 关闭 UPS 的驱动服务。需要关闭电源的情况可能是 UPS 电源电量达到了临界值，此时需要关闭负载然后再关闭 UPS。详情参考：Configuring automatic shutdowns for low battery events RBWARNTIME seconds 当 UPS 需要更换电池时，间隔多久触发一次 REPLBATT 通知。默认是 43200 秒（12 小时） RUN_AS_USER username upsmon 通常不会使用 root 权限启动。在编译时默认设置以 nobody 用户身份运行。但是 nobody 没有权限读取 upsmon.conf。所以建议为 upsmon 创建一个没有密码的普通新用户 nutmon，将该值设置为 nutmon，并让其对 upsmon.conf 具有可读权限（不应该有写权限）。 MINSUPPLIES num 最少有 num 个 UPS 通电才保持系统运行。默认值是 1。当有多个冗余电源时才需要修改该值。\n例如共有 4 个电源，要求其中至少有 2 个以上 UPS 通电才保持系统运行，则将该值设置为 2 SHUTDOWNCMD command 当系统需要关闭时，upsmon 执行此命令。如果它是 secondary，只要 正常的 UPS 数量 \u003c MINSUPPLIES，它就会立即执行该命令如果它是 primary，它将允许在所有 secondary 注销之后，primary 再执行该命令进行关机示例：\"/sbin/shutdown -h +0\" # 在 0 分钟后立即关闭系统并断掉电源 CERTPATH certificate file or database 如果使用 NSS 提供的 SSL 支持，设置执行数据库文件夹的路径如果使用 OpenSSL 提供的 SSL 支持，指定 PEM 格式的 CA 证书的目录。每个文件都包含一个 CA 证书，通过 CA 主题名称的哈希值进行查询 CERTIDENT certificate_name database password 当使用 NSS 提供的 SSL 支持时，设置数据库文件夹中的证书名称和访问证书所需的密码 CERTHOST hostname certificate_name certverify forcessl 当使用 NSS 提供的 SSL 支持时，为指定的服务器设置证书名称，并标识服务器证书是否经过验证以及连接是否必须安全 `CERTVERIFY 0 1` `FORCESSL 0 1` DEBUG_MIN INTEGER 设置 upsmon 的日志级别 自定义 UPS 的电量过低阈值 1 2 3 4 5 6 7 8 9 10 11 12 $ sudo vim /etc/nut/ups.conf [apcbk650m2] driver = usbhid-ups port = auto # UPS 驱动服务通常根据 battery.charge \u003c battery.charge.low 或 battery.runtime \u003c battery.runtime.low 来判断 UPS 是否电量过低 # 让 UPS 驱动服务忽略 UPS 自身报告的 battery.charge.low 或 override.battery.runtime.low 值 # 可以通过 override.battery.charge.low 和 override.battery.runtime.low 参数自定义 UPS 的低电量阈值 ignorelb # 自定义低电量阈值百分比，当 battery.charge \u003c override.battery.charge.low 时才算电量过低 override.battery.charge.low = 30 # 自定义低运行时间阈值（分钟），当 battery.runtime \u003c override.battery.runtime.low 是才算电量过低 override.battery.runtime.low = 180 参考文档：\nNetwork UPS Tools - ArchWiki [OpenWrt Wiki] NUT (Network UPS Tools) NUT manual pages upsmon.conf ","description":"","tags":["NUT","Arch Linux","Linux"],"title":"Arch Linux 使用 NUT 管理 UPS","uri":"/posts/linux/arch-linux/archlinux-network-ups-tools/"},{"categories":null,"content":"Arch Linux 使用 Docker 自建 Bitwarden 服务 在 ArchLinux（2023.10.26）上使用 Docker（24.0.7）安装 Bitwarden（2023.10.1），使用 Cloudflare Tunnel 对 Bitwarden 进行反向代理\n安装 安装过程参考官网 Install and Deploy - Linux\n安装 Docker 和 Docker Compose（略）\n新增用户\n1 2 3 4 5 6 # 新增 bitwarden 用户 $ sudo useradd -d /opt/bitwarden/ -c 'bitwarden user' -m -r -U -s /bin/bash bitwarden # 修改 bitwarden 用户密码 $ sudo passwd bitwarden # 将 bitwarden 添加到 docker 组 $ sudo usermod -aG docker bitwarden 安装 Bitwarden\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 # 切换到 bitwarden 用户 $ su - bitwarden # 切换文件夹 $ cd /opt/bitwarden # 下载安装脚本 $ curl -Lso bitwarden.sh \"https://func.bitwarden.com/api/dl/?app=self-host\u0026platform=linux\" \u0026\u0026 chmod 700 bitwarden.sh # 执行安装 $ ./bitwarden.sh install _ _ _ _ | |__ (_) |___ ____ _ _ __ __| | ___ _ __ | '_ \\| | __\\ \\ /\\ / / _` | '__/ _` |/ _ \\ '_ \\ | |_) | | |_ \\ V V / (_| | | | (_| | __/ | | | |_.__/|_|\\__| \\_/\\_/ \\__,_|_| \\__,_|\\___|_| |_| Open source password management solutions Copyright 2015-2023, 8bit Solutions LLC https://bitwarden.com, https://github.com/bitwarden =================================================== bitwarden.sh version 2023.10.1 Docker version 24.0.7, build afdd53b4e3 Docker Compose version 2.23.0 # 输入自己 Bitwarden 服务的域名，例如 bitwarden.example.com (!) Enter the domain name for your Bitwarden instance (ex. bitwarden.example.com): bitwarden.example.com # 自己 Bitwarden 的域名必须使用 https 协议，如果该域名没有设置过 SSL 证书，可以在这里使用 Let's Encrypt 签发证书，需要暴露服务器的 80 和 443 端口，同时 Bitwarden 每次重启时会自动去续签该证书。因为我的域名证书是被 Cloudflare 管理的，所以这里输入 n。 # 证书相关的问题可以参考：https://bitwarden.com/help/certificates/ (!) Do you want to use Let's Encrypt to generate a free SSL certificate? (y/n): n # 设置 Bitwarden 数据库的名称，这里默认即可 (!) Enter the database name for your Bitwarden instance (ex. vault): # 此时会去拉取镜像... # 安装 Bitwarden 需要申请 id 和 key，访问 https://bitwarden.com/host 输入邮箱获取即可 (!) Enter your installation id (get at https://bitwarden.com/host): abcdefgh-ijkl-mnop-qrst-uvwxyz12345678 (!) Enter your installation key: hHFDj3cUQeExi1j85Jui # 按照获取 key 时的选择即可 (!) Enter your region (US/EU) [US]: # 如果自己 Bitwarden 的域名已经有 SSL 证书，并且想使用这个证书，这里选 y。否则选 N (!) Do you have a SSL certificate to use? (y/N): N # 是否创建自签名的 SSL 证书。这个证书可以用来加密 Cloudflare Tunnel/Nginx 到 Bitwarden 自建服务间的通信，我这里不需要，所以选 N (!) Do you want to generate a self-signed SSL certificate? (y/N): N Generating key for IdentityServer. Generating a RSA private key ..................................++++ .......................................++++ writing new private key to 'identity.key' ----- # 根据上方证书的设置，这里也会显示不同的警告信息 !!!!!!!!!! WARNING !!!!!!!!!! You are not using a SSL certificate. Bitwarden requires HTTPS to operate. You must front your installation with a HTTPS proxy or the web vault (and other Bitwarden apps) will not work properly. Building nginx config. Building docker environment files. Building docker environment override files. Building FIDO U2F app id. Building docker-compose.yml. Installation complete # 安装成功后不急着启动，还有一些必要配置 If you need to make additional configuration changes, you can modify the settings in `./bwdata/config.yml` and then run: `./bitwarden.sh rebuild` or `./bitwarden.sh update` Next steps, run: `./bitwarden.sh start` 修改环境配置文件\nBitwarden 有两个重要的配置文件：环境变量配置文件（global.override.env）和安装配置文件（config.yml）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 $ vim /opt/bitwarden/bwdata/env/global.override.env ~~~ # 因为上方没有给 bitwarden 设置任何证书，所以这里默认是 http，手动把它改成 https globalSettings__baseServiceUri__vault=https://bitwarden.example.com ... # 设置发信邮箱信息（以企业微信为例），该邮箱用于给用户发送各种通知邮件 globalSettings__mail__replyToEmail=noreply@example.com globalSettings__mail__smtp__host=smtp.exmail.qq.com globalSettings__mail__smtp__port=465 globalSettings__mail__smtp__ssl=true globalSettings__mail__smtp__username=noreply@example.com globalSettings__mail__smtp__password=iQL6QB29SbP5UIXc8NEh # 禁止用户注册。可以在自己注册一个管理员帐号后，把这个设置为 true，不允许其他用户自行注册帐号 globalSettings__disableUserRegistration=false ... # 设置管理员邮箱，管理员可以访问管理页面 adminSettings__admins=username@example.com ~~~ 修改安装配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 $ vim /opt/bitwarden/bwdata/config.yml ~~~ # 因为上方没有给 bitwarden 设置任何证书，所以这里默认是 http，手动把它改成 https url: https://bitwarden.example.com ... # 可以修改 http 和 https 暴露在宿主机上的端口。因为 docker 默认会以 0.0.0.0:9090 的方式暴露端口，并且不受 firewalld 的控制，就会导致任意外部机器均可以访问 8080 端口，所以这里可以设置为 127.0.0.1:9090，仅将端口暴露在本地，禁止外部服务访问，然后通过 Cloudflare Tunnel/Nginx 反向代理的方式访问该端口 http_port: 127.0.0.1:9090 # 没有给 bitwarden 设置任何证书，所以不需要暴露 https 端口，设置为空即可。如果设置了证书这里需要配合证书一起使用 https_port: ... # ssl 证书相关，如果需要参照注释配置即可 ssl: false ssl_versions: ssl_ciphersuites: ssl_managed_lets_encrypt: false ssl_certificate_path: ssl_key_path: ssl_ca_path: ssl_diffie_hellman_path: ... ~~~ 重启服务\n1 2 3 4 # 修改了环境配置文件，执行 restart 即可使其生效；修改了安装配置文件，执行 rebuild 即可使其生效。 # 这里先执行 rebuild 重新创建容器，然后再启动容器 $ ./bitwarden.sh rebuild $ ./bitwarden.sh start 查看服务启动状态\n1 $ docker ps 这里应该可以看到 bitwarden-admin 和 bitwarden-sso 服务的状态是 unhealthy，bitwarden-mssql、bitwarden-web、bitwarden-attachments 的 PORTS 属性都是空， 执行 curl http://127.0.0.1:9090，会报错：502 Bad Gateway。这是因为 docker 网络管理有问题，导致 bitwarden-admin 和 bitwarden-sso 无法访问 bitwarden-mssql，bitwarden-nginx 无法访问 bitwarden-web 导致的。\nCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 795f0eb0ab19 bitwarden/nginx:2023.10.1 \"/entrypoint.sh\" 2 minutes ago Up 2 minutes (healthy) 80/tcp, 8443/tcp, 127.0.0.1:9090-\u003e8080/tcp bitwarden-nginx 855a95f54a43 bitwarden/admin:2023.10.1 \"/entrypoint.sh\" 2 minutes ago Up 2 minutes (unhealthy) 5000/tcp bitwarden-admin d1ec3b0636a6 bitwarden/mssql:2023.10.1 \"/entrypoint.sh\" 2 minutes ago Up 2 minutes (healthy) bitwarden-mssql 6c1a5872d2c6 bitwarden/sso:2023.10.1 \"/entrypoint.sh\" 2 minutes ago Up 2 minutes (unhealthy) 5000/tcp bitwarden-sso 64e3ac5a2695 bitwarden/web:2023.10.0 \"/entrypoint.sh\" 2 minutes ago Up 2 minutes (healthy) bitwarden-web c94484465d83 bitwarden/attachments:2023.10.1 \"/entrypoint.sh\" 2 minutes ago Up 2 minutes (healthy) bitwarden-attachments 3073b6d7ff8b bitwarden/notifications:2023.10.1 \"/entrypoint.sh\" 2 minutes ago Up 2 minutes (healthy) 5000/tcp bitwarden-notifications 4e808d13a45d bitwarden/events:2023.10.1 \"/entrypoint.sh\" 2 minutes ago Up 2 minutes (healthy) 5000/tcp bitwarden-events 8f7b756f74a7 bitwarden/identity:2023.10.1 \"/entrypoint.sh\" 2 minutes ago Up 2 minutes (healthy) 5000/tcp bitwarden-identity a9acec0d84e7 bitwarden/api:2023.10.1 \"/entrypoint.sh\" 2 minutes ago Up 2 minutes (healthy) 5000/tcp bitwarden-api c8157eb4ab98 bitwarden/icons:2023.10.1 \"/entrypoint.sh\" 2 minutes ago Up 2 minutes (healthy) 5000/tcp bitwarden-icons 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 查看 bitwarden-admin 的日志可以看到如下错误信息 $ docker logs bitwarden-admin ~~~ fail: Bit.Admin.HostedServices.DatabaseMigrationHostedService[0] Database unavailable for migration. Trying again (attempt #9)... Microsoft.Data.SqlClient.SqlException (0x80131904): A network-related or instance-specific error occurred while establishing a connection to SQL Server. The server was not found or was not accessible. Verify that the instance name is correct and that SQL Server is configured to allow remote connections. (provider: TCP Provider, error: 40 - Could not open a connection to SQL Server: Could not open a connection to SQL Server) at Microsoft.Data.SqlClient.TdsParser.ThrowExceptionAndWarning(TdsParserStateObject stateObj, Boolean callerHasConnectionLock, Boolean asyncClose) at Microsoft.Data.SqlClient.TdsParser.Connect(ServerInfo serverInfo, SqlInternalConnectionTds connHandler, Boolean ignoreSniOpenTimeout, Int64 timerExpire, SqlConnectionString connectionOptions, Boolean withFailover) at Microsoft.Data.SqlClient.SqlInternalConnectionTds.AttemptOneLogin(ServerInfo serverInfo, String newPassword, SecureString newSecurePassword, Boolean ignoreSniOpenTimeout, TimeoutTimer timeout, Boolean withFailover) at Microsoft.Data.SqlClient.SqlInternalConnectionTds.LoginNoFailover(ServerInfo serverInfo, String newPassword, SecureString newSecurePassword, Boolean redirectedUserInstance, SqlConnectionString connectionOptions, SqlCredential credential, TimeoutTimer timeout) at Microsoft.Data.SqlClient.SqlInternalConnectionTds.OpenLoginEnlist(TimeoutTimer timeout, SqlConnectionString connectionOptions, SqlCredential credential, String newPassword, SecureString newSecurePassword, Boolean redirectedUserInstance) at Microsoft.Data.SqlClient.SqlInternalConnectionTds..ctor(DbConnectionPoolIdentity identity, SqlConnectionString connectionOptions, SqlCredential credential, Object providerInfo, String newPassword, SecureString newSecurePassword, Boolean redirectedUserInstance, SqlConnectionString userConnectionOptions, SessionData reconnectSessionData, Boolean applyTransientFaultHandling, String accessToken, DbConnectionPool pool) at Microsoft.Data.SqlClient.SqlConnectionFactory.CreateConnection(DbConnectionOptions options, DbConnectionPoolKey poolKey, Object poolGroupProviderInfo, DbConnectionPool pool, DbConnection owningConnection, DbConnectionOptions userOptions) at Microsoft.Data.ProviderBase.DbConnectionFactory.CreatePooledConnection(DbConnectionPool pool, DbConnection owningObject, DbConnectionOptions options, DbConnectionPoolKey poolKey, DbConnectionOptions userOptions) at Microsoft.Data.ProviderBase.DbConnectionPool.CreateObject(DbConnection owningObject, DbConnectionOptions userOptions, DbConnectionInternal oldConnection) at Microsoft.Data.ProviderBase.DbConnectionPool.UserCreateRequest(DbConnection owningObject, DbConnectionOptions userOptions, DbConnectionInternal oldConnection) at Microsoft.Data.ProviderBase.DbConnectionPool.TryGetConnection(DbConnection owningObject, UInt32 waitForMultipleObjectsTimeout, Boolean allowCreate, Boolean onlyOneCheckConnection, DbConnectionOptions userOptions, DbConnectionInternal\u0026 connection) at Microsoft.Data.ProviderBase.DbConnectionPool.TryGetConnection(DbConnection owningObject, TaskCompletionSource`1 retry, DbConnectionOptions userOptions, DbConnectionInternal\u0026 connection) at Microsoft.Data.ProviderBase.DbConnectionFactory.TryGetConnection(DbConnection owningConnection, TaskCompletionSource`1 retry, DbConnectionOptions userOptions, DbConnectionInternal oldConnection, DbConnectionInternal\u0026 connection) at Microsoft.Data.ProviderBase.DbConnectionInternal.TryOpenConnectionInternal(DbConnection outerConnection, DbConnectionFactory connectionFactory, TaskCompletionSource`1 retry, DbConnectionOptions userOptions) at Microsoft.Data.ProviderBase.DbConnectionClosed.TryOpenConnection(DbConnection outerConnection, DbConnectionFactory connectionFactory, TaskCompletionSource`1 retry, DbConnectionOptions userOptions) at Microsoft.Data.SqlClient.SqlConnection.TryOpen(TaskCompletionSource`1 retry, SqlConnectionOverrides overrides) at Microsoft.Data.SqlClient.SqlConnection.Open(SqlConnectionOverrides overrides) at Microsoft.Data.SqlClient.SqlConnection.Open() at Bit.Migrator.SqlServerDbMigrator.MigrateDatabase(Boolean enableLogging, CancellationToken cancellationToken) in /home/runner/work/server/server/util/Migrator/SqlServerDbMigrator.cs:line 49 at Bit.Admin.HostedServices.DatabaseMigrationHostedService.StartAsync(CancellationToken cancellationToken) in /home/runner/work/server/server/src/Admin/HostedServices/DatabaseMigrationHostedService.cs:line 29 ClientConnectionId:00000000-0000-0000-0000-000000000000 ~~~ 解决 unhealthy 和 502 Bad Gateway\n参考：https://github.com/bitwarden/server/issues/1546\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 创建 docker-compose.override.yml 并添加以下配置 $ vim /opt/bitwarden/bwdata/docker/docker-compose.override.yml ~~~ version: '3' services: mssql: networks: - default - public web: networks: - default - public attachments: networks: - default - public ~~~ # 重启服务 $ ./bitwarden.sh restart # 查看服务，此时应该都是 healthy 状态，并且 bitwarden-mssql、bitwarden-web、bitwarden-attachments 的 PORTS 属性均不为空 $ docker ps # 请求服务，也有正确的响应结果 $ curl http://127.0.0.1:9090 访问并创建用户（略）\n禁用其它用户注册\n1 2 3 4 5 6 7 8 9 10 $ vim /opt/bitwarden/bwdata/env/global.override.env ~~~ # 禁止用户注册。可以在自己注册一个管理员帐号后，把这个设置为 true，不允许其他用户自行注册帐号 globalSettings__disableUserRegistration=false ... ~~~ # 重启服务 $ ./bitwarden.sh restart 备份恢复 备份 Bitwarden 的 Docker 容器使用卷映射将所有重要数据都保存在主机的 bwdata 文件夹，所以只需要对该文件夹进行备份即可。如果数据丢失，选择性的恢复该文件夹中的文件即可。\nbwdata 文件夹中有几个非常重要的数据：\nbwdata/env：环境变量配置，包括数据库和证书密码 bwdata/core/attachments：保管库中存储的附件 bwdata/mssql/data：数据库数据 夜间数据库备份\u0026恢复 Bitwarden 会在运行时自动对 mssql 数据库进行夜间备份，并将其存储在 bwdata/mssql/backups 文件夹保留 30 天\n获取数据库密码\n1 2 3 4 5 $ cat global.override.env ~~~ globalSettings__sqlServer__connectionString=...Password= ~~~ 离线恢复数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 进入 bitwarden-mssql 容器内部 $ docker exec -it bitwarden-mssql /bin/bash # 备份文件在容器内的该目录下 $ ls etc/bitwarden/mssql/backups vault_FULL_20201208_003243.BAK # 登录 mssql 数据库 $ /opt/mssql-tools/bin/sqlcmd -S localhost -U \u003csa\u003e -P \u003csa-password\u003e # 开始 离线恢复数据 1\u003e use master 2\u003e GO 1\u003e alter database vault set offline with rollback immediate 2\u003e GO 1\u003e restore database vault from disk='/etc/bitwarden/mssql/backups/vault_FULL_{Backup File Name}.BAK' with replace 2\u003e GO 1\u003e alter database vault set online 2\u003e GO 1\u003e exit # 退出容器 $ exit # 重启服务 $ ./bitwarden.sh restart 参考文档：\nbitwarden Install and Deploy - Linux Certificate Options Unhealthy SSo and events on Fresh 1.42.2 #1546 Backup your Hosted Data ","description":"","tags":["Linux","Arch Linux","Bitwarden"],"title":"Arch Linux 使用 Docker 自建 Bitwarden 服务","uri":"/posts/linux/arch-linux/archlinux-docker-bitwarden/"},{"categories":null,"content":"Cloudflare Zero Trust Tunnels 内网穿透 国内的宽带运营商即使给个人提供了公网 IPv4/IPv6，一般也会封掉 80、443、8080 等常用端口，并且会要求域名必须备案，因此在访问内网服务的时候必须在域名后面添加端口号。\n使用 Cloudflare（CF） 管理的域名，并使用 DDNS 将内网的 IPv6 定时更新到 CF，在开启小黄云时，可以使用 Origin Rules 将发到域名 443/80 端口的请求重写到其它端口（为了防止内网服务器暴露太多端口，可以只暴露 Nginx 的端口，然后在 Nginx 中按域名配置反向代理），这样可以解决运营商封常用端口的问题。但是因为开启了小黄云，流量会经过 CF，所以在国内的访问速度就没有直连 IPv6 的速度快。\n并且 CF 的 DNS 只支持 HTTP/HTTPS 协议的请求，同时 CF 支持的端口 也有限，所以如果有 ssh、ws、rdp、tcp 等协议就无法通过 CF DNS 的方式进行访问了。\n综上，这里有 3 种方案：\n说明 利弊 只使用 CF 的 DNS 功能，不开启小黄云 速度快、支持所有协议、域名需备案、访问需要添加端口号、运营商封锁常用端口 使用 CF 的 DNS + Origin Rules，开启小黄云 速度较慢、仅支持 HTTP/HTTPS、域名不许备案 使用 CF 的 Zero Trust Tunnels 速度较慢、支持常用的基于 TCP 的协议 服务端 在 Cloudflare Zero Trust 页面，依次点击 Access -\u003e Tunnels，并创建一个 tunnel\nTunnel 的服务端可以安装在需要穿透的内网设备上。如果内网中有多个设备需要穿透，则可以将其安装在可以访问这些设备的一个公共设备上\n安装完成后，根据所选的系统不同，会显示出不同的安装指令。但是通过这个指令安装的包是不支持使用包管理器进行更新的，所以可以通过添加 cloudflared 软件包仓库的方式，使用包管理器进行安装。参见：Cloudflare packages\n安装完成后只需要执行安装服务的指令即可\n1 $ sudo cloudflared service install eyTI5...zNNeT 将服务设置为开机自启\n1 $ sudo systemctl start --now cloudflared 客户端 对于 HTTP/HTTPS 服务只需要在 Public Hostname 中进行添加即可，设置成功后会在指定域名的 DNS 中自动添加一条指向 Cloudflare 的记录，之后使用浏览器进行访问即可。\n对于其它协议（SSH、RDP、SMB、WS、TCP 等）的服务，有两种访问方式：\ncloudflared + Public Hostname，并进行相关配置，参考：Use cases Cloudflare Warp + Private Network，参考：WARP 这里只介绍 cloudflared 的方式，所以需要先在客户端安装 cloudflared，参见：Cloudflare packages。Cloudflare Warp 方式自行查阅文档即可\nSSH 在 Tunnels 的 Public Hostname 中添加一条指向内网服务 ssh 服务的记录，例如：\nSubdomain Domain Path Type URL ssh example.com SSH localhost:22 在客户端安装好 cloudflared 后，编辑客户端的 ssh 配置文件：~/.ssh/config\nHost ssh.example.com HostName ssh.example.com ProxyCommand cloudflared access ssh --hostname %h 然后使用 ssh 进行连接即可\n1 $ ssh username@ssh.example.com RDP 在 Tunnels 的 Public Hostname 中添加一条指向内网服务 rdp 服务的记录，例如：\nSubdomain Domain Path Type URL rdp example.com RDP localhost:3389 在客户端安装 cloudflared 后，使用如下命令在本地打开一个 rdp 监听端口\n1 $ cloudflared access rdp --hostname rdp.example.com --url rdp://localhost:3389 使用 RDP 客户端连接本地的 rdp://localhost:3389 即可\nSMB 在 Tunnels 的 Public Hostname 中添加一条指向内网服务 smb 服务的记录，例如：\nSubdomain Domain Path Type URL smb example.com SMB localhost:445 在客户端安装 cloudflared 后，使用如下命令在本地打开一个 tcp 监听端口\n1 $ cloudflared access tcp --hostname smb.example.com --url localhost:8445 使用 SMB 客户端连接本地的 smb://localhost:8445 即可\nTCP 对于其它基于 tcp 的协议，配置方式与 smb 的类似\n在 Tunnels 的 Public Hostname 中添加一条指向内网服务 tcp 服务的记录，例如：\nSubdomain Domain Path Type URL tcp example.com TCP localhost:5555 在客户端安装 cloudflared 后，使用如下命令在本地打开一个 tcp 监听端口\n1 $ cloudflared access tcp --hostname tcp.example.com --url localhost:6666 此时通过本地的 6666 端口即可以访问内网中 5555 端口上的服务\nTCP 监听自启动服务 在使用 Tunnels 时，必须要让客户端上使用 cloudflared 启动的端口一直运行，这里可以通过编写 systemd服务的方式来执行这个命令，并设置其开机自启动\n编写启动脚本：/opt/cloudflared-tunnel/tunnels.sh\n1 2 3 4 5 #!/bin/bash # 让该命令后台运行 /usr/bin/cloudflared access tcp --hostname tcp.example.com --url localhost:5555 \u0026 # 记录上个命令执行的进程号 echo $! \u003e /var/run/cloudflared-tunnel.tcp.example.com.pid 编写停止脚本：/opt/cloudflared-tunnel/stop.sh\n1 2 3 #!/bin/bash # 使用进程号杀掉进程 kill `cat /var/run/cloudflared-tunnel.tcp.example.com.pid` 编写 systemd 服务文件：/opt/cloudflared-tunnel/cloudflared-tunnel.service 1 2 3 4 5 6 7 8 9 10 11 12 13 [Unit] Description = CloudFlared Tunnels Wants = network-online.target After = network-online.target [Service] User=root ExecStart = sh /opt/cloudflared-tunnel/tunnels.sh ExecStop = sh /opt/cloudflared-tunnel/stop.sh Type = forking [Install] WantedBy = multi-user.target 将 systemd 服务文件链接到 systemd 服务文件夹，使其生效，并设置服务自启动\n1 2 $ sudo ln -s /opt/cloudflared-tunnel/cloudflared-tunnel.service /usr/lib/systemd/system/cloudflared-tunnel.service $ sudo systemctl start --now cloudflared-tunnel 其它问题 在查看服务端 cloudflared 服务状态时，发现以下警告\nfailed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 2048 kiB, got: 416 kiB). 参考：UDP Buffer Sizes\n修改 sysctl 属性值\n1 2 3 4 5 # 修改配置 $ sudo sysctl net.core.rmem_max=2500000 $ sudo sysctl net.core.wmem_max=2500000 # 检查配置是否生效 $ sudo sysctl -a | grep mem_max 持久化配置可以在 /etc/sysctl.d 下创建 net.core.rwmem_max.conf\n1 2 net.core.rmem_max=2500000 net.core.wmem_max=2500000 在查看服务端 cloudflared 服务状态时，发现以下警告和错误\n1 2 3 4 WRN Failed to create new quic connection error=\"failed to dial to edge with quic: timeout: no recent network activity\" connIndex=1 event=0 ip=198.41.200.73 ERR Failed to create new quic connection error=\"failed to dial to edge with quic: timeout: no recent network activity\" ERR Failed to fetch features, default to disable error=\"lookup cfd-features.argotunnel.com on 192.168.1.1:53: read udp 192.168.1.100:51941-\u003e192.168.1.1:53: i/o timeout\" WRN Unable to lookup protocol percentage QUIC（Quick UDP Internet Connections，快速 UDP 网络连接）是由 Google 在 2013 年实现的一种建立在 UDP 之上的实验性的传输层网络传输协议。而国内的运营商可能会对基于 UDP 的连接进行阻断，所以就可能导致该服务无法使用。\n可以在 cloudflared 的 systemd 服务文件中手动指定让其使用什么协议进行通讯\n1 2 3 4 5 6 7 8 9 10 11 $ sudo vim /etc/systemd/system/cloudflared.service ~~~ # 使用 http2 ExecStart=/usr/bin/cloudflared --protocol http2 --no-autoupdate tunnel run --token eyoiO...lNy00 ~~~ ~~~ # 优先使用 quic，失败后使用 http2 ExecStart=/usr/bin/cloudflared --protocol auto --no-autoupdate tunnel run --token eyoiO...lNy00 ~~~ ","description":"","tags":["Network","Cloudflare"],"title":"Cloudflare Zero Trust Tunnels 内网穿透","uri":"/posts/network/cloudflare-zero-trust-tunnels/"},{"categories":null,"content":"Arch Linux 使用 smartmontools 监控硬盘状态 在 ArchLinux（2023.10.10）上使用 smartmontools 工具监控西部数码 HC320，这里直接将整个硬盘格式化成了 Btrfs 系统，所以后续的操作命令均使用 /dev/sda ，如果硬盘进行过分区，则需要将其换成相应的分区（例如：/dev/sda1）\n安装软件包\n1 $ sudo pacman -Sy smartmontools smartmontools 中包含 smartctl 指令，用来手动执行相关命令来查看硬盘状态；同时包含一个 smartd 服务，可以在后台定时监控硬盘状态，并可以在需要时发送邮件通知等。\n检查硬盘是否支持并启用了 SMART（Self-Monitoring, Analysis and Reporting Technology）\n1 2 3 $ sudo smartctl --info /dev/sda | grep 'SMART' SMART support is: Available - device has SMART capability. SMART support is: Enabled 如果支持（Available）但是没有启用（Enabled），则手动启用 SMART\n1 2 $sudo smartctl --smart=on /dev/sda SMART Enabled. 查看硬盘的 SMART 信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 $ sudo smartctl -A /dev/sda # 如果提示不识别磁盘类型，可以使用 --device 手动指定；使用 -n standby 可以在不唤醒硬盘的情况下查看硬盘信息 $ sudo smartctl --device=sat -n standby -A /dev/sda smartctl 7.4 2023-08-01 r5530 [x86_64-linux-6.5.7-arch1-1] (local build) Copyright (C) 2002-23, Bruce Allen, Christian Franke, www.smartmontools.org === START OF READ SMART DATA SECTION === SMART Attributes Data Structure revision number: 16 Vendor Specific SMART Attributes with Thresholds: ID# ATTRIBUTE_NAME FLAG VALUE WORST THRESH TYPE UPDATED WHEN_FAILED RAW_VALUE # 底层数据读取错误率 1 Raw_Read_Error_Rate 0x000b 100 100 016 Pre-fail Always - 0 2 Throughput_Performance 0x0005 133 133 054 Pre-fail Offline - 92 3 Spin_Up_Time 0x0007 168 168 024 Pre-fail Always - 522 (Average 445) # 启动/停止计数 4 Start_Stop_Count 0x0012 100 100 000 Old_age Always - 32 # 重映射扇区数 5 Reallocated_Sector_Ct 0x0033 100 100 005 Pre-fail Always - 0 7 Seek_Error_Rate 0x000b 100 100 067 Pre-fail Always - 0 8 Seek_Time_Performance 0x0005 128 128 020 Pre-fail Offline - 18 # 通电时间 9 Power_On_Hours 0x0012 100 100 000 Old_age Always - 54 # 主轴起旋重试次数 10 Spin_Retry_Count 0x0013 100 100 060 Pre-fail Always - 0 # 磁盘通电次数 12 Power_Cycle_Count 0x0032 100 100 000 Old_age Always - 4 192 Power-Off_Retract_Count 0x0032 100 100 000 Old_age Always - 32 193 Load_Cycle_Count 0x0012 100 100 000 Old_age Always - 32 # 温度 194 Temperature_Celsius 0x0002 127 127 000 Old_age Always - 47 (Min/Max 25/58) 196 Reallocated_Event_Count 0x0032 100 100 000 Old_age Always - 0 197 Current_Pending_Sector 0x0022 100 100 000 Old_age Always - 0 198 Offline_Uncorrectable 0x0008 100 100 000 Old_age Offline - 0 # 奇偶校验错误率 199 UDMA_CRC_Error_Count 0x000a 200 200 000 Old_age Always - 0 ID：属性 ID，通常是一个1到255之间的十进制或十六进制的数字 ATTRIBUTE_NAME：硬盘制造商定义的属性名 FLAG：属性操作标志（可以忽略） VALUE：属性的标准化值，在 1 到 253 之间。 WORST：硬盘运行过程中出现的最差值。数值越小越差，越接近 VALUE 越好 THRESH：在报告硬盘 FAILED 状态前，WORST 可以允许的最小值 TYPE：关键属性（Pre-fail），非关键属性（Oldage） UPDATED：属性的更新频率。Offline 代表磁盘执行离线测试时的时间 WHEN_FAILED：如果 VALUE \u003c= THRESH，值为 FAILING_NOW，需要尽快备份重要文件，特别是关键属性（Pre-fail）；如果 WORST \u003c= THRESH，值为 In_the_past，表示属性已经故障，但在测试时没问题；否则值为 -，表示从没故障过。 RAW_VALUE：制造商定义的原始值，从VALUE派生。有一些代表累计值或及时值，还有一些需要运算后才有意义 可以对磁盘进行一些测试\n短测试（Short）：快速检测硬盘的基本状态，包括一般错误、坏道等问题。通常只需要几分钟即可完成。 长/扩展测试（Long or Extended）：深度扫描硬盘以发现更多潜在问题，包括更小的错误、坏道、数据完整性等。通常需要更长时间来玩成。 传输测试（Conveyance）：检测硬盘在运输过程中是否受到损害。有助于发现硬盘在运送过程中是否受到了震动和冲击而导致的问题。 选择性测试（Selective）：用户可以选择性的检测硬盘的特定部分或属性，以便更具针对性的检测问题。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 查看各种检测所需的时间 $ sudo smartctl -c /dev/sda ... Short self-test routine recommended polling time: ( 2) minutes. Extended self-test routine recommended polling time: ( 804) minutes. Conveyance self-test routine recommended polling time: ( 4) minutes. ... # 执行不同的测试 $ sudo smartctl -t short /dev/sda $ sudo smartctl -t long /dev/sda $ sudo smartctl -t conveyance /dev/sda $ sudo smartctl -t select,123+345 /dev/sda # 查看测试结果 $ sudo smartctl -H /dev/sda # 查看硬盘的整体状态 $ sudosmartctl -l selftest /dev/sda # 查看最近的检查结果列表 $ sudosmartctl -x /dev/sda # 查看设备的详细信息 修改 smartd 配置文件 /etc/smartd.conf\n1 2 3 # DEVICESCAN 默认是开启的，即监控所有的设备，但是开启这个参数会导致后面自定义的配置失效，所以这里注释掉它 #DEVICESCAN /dev/disk/by-uuid/e03jd8bf-184b-41e5-a77b-1c74jdx4149 -d removable -a -o on -S on -n standby,15,q -s (S/../01/./02|L/10/25/./02) -W 4,36,48 -m username@domain.com -M exec /path/to/notify-script -M test 硬盘ID可以使用 ls -lah /dev/disk/by-uuid/ 命令查看\n-d removable：-d 用来指定磁盘类型，removable 表示这是通过 USB 连接的可移动磁盘，还可以使用 ata 或者 scsi 等\n-a：监控磁盘的所有属性信息\n-o on：[仅 ATA]启用 SMART 自动离线测试\n-S on：启用 smartd 启动时属性自动保存\n-n standby[,15,q]\n-n：用来设置定期测试哪些功率模式（OFF、SLEEP、STANDBY、IDLE、ACTIVE）的磁盘。通常，为了响应 smartd 发出的 SMART 命令，磁盘盘片会启动，这可能会导致处在低功耗模式的磁盘被激活到高功耗模式。使用该配置可以选择跳过测试处在低功耗模式的磁盘。\nnever：默认值，测试处于所有功率模式的磁盘 sleep：不测试处于 SLEEP 功率模式的硬盘 standby：不测试处于 SLEEP 或 STANDBY 功率模式的硬盘 idle：只测试处于 ACTIVE 功率模式的硬盘 15：使用正整数指定硬盘跳过测试的最大次数。这里即当磁盘跳过 15 次测试后，无论其功率模式如何，都会对其进行测试\nq：跳过定期测试时，smartd 通常会写入非正式日志消息，使用该选项抑制该消息，从而防止硬盘因此消息而旋转\n可以使用 -i 选项修改定期测试的频率，默认是 30 分钟\n1 2 # 可以修改为每 3 小时检查一次 SMARTD_ARGS=\"-i 10800\" -s (T/MM/DD/d/HH)：除了 smartd 的定期测试，还可以通过该选项自定义定时自检\n参数可以使用 (A|B|C) 的形式定义多个类型或频率的自检项目\nT：检测类型：短测试（S）、长测试（L）、传输测试（C）、离线测试（O）、选择性测试（参考 smartd.conf(5)） MM：月份，一月（01）到十二月（12） DD：日期，01 到 31 d：星期，星期一（1）到星期日（7） HH：小时，00 到 23 星期用 .，其它用 .. 来表示时间的重复\n1 2 # 每月 1 号 2 点执行短测试，每年 10 月 25 日 2 点执行长测试 (S/../01/./02|L/10/25/./02) -W 4,36,48：记录硬盘温度快速上升 4 度及以上，记录硬盘温度到达 36 度，并在硬盘温度到达 48 度时记录/通过电子邮件发出警告\n-m username-or-email：邮件通知系统用户或者指定邮箱\n-M：警告通知方式，可以包含多种，必须与 -m 结合使用。smartd 默认使用 mail 指令发送邮件\nonce：默认设置（除非用了 -s 选项）。仅针对检测到的每种类型的磁盘问题发送一封警告邮件。 always：在每次检查时，针对检测到的每种类型的磁盘问题发送额外的警告邮件。 daily：如果启用了 -s 选项，则这是默认值。针对检测到的每种类型的磁盘问题，每天发送一次额外的警告提醒电子邮件。 diminishing：针对检测到的每种类型的磁盘问题，在一天间隔后、两天间隔、四天间隔等后发送额外的警告提醒电子邮件。每个间隔的长度是前一个间隔的两倍。间隔长度将在收到 5 封警告提醒电子邮件后保持为 32 天。 test：在 smartd 启动后立即发送一封测试电子邮件 exec PATH：当 smartd 需要发送电子邮件时，运行可执行的 PATH 而不是默认的 mail 命令。PATH 必须指向可执行的二进制文件或脚本。脚本示例：/usr/share/doc/smartmontools/examplescripts/ test 和 exec PATH 结合使用可在启动 smartd 时测试邮件是否正确发送，并在出现问题时，执行自定义脚本。\n自定义通知脚本中可以使用$参数名的方式引用/设置 smartd 提供的一些环境变量\nSMARTD_MAILER：mail 命令的位置 SMARTD_DEVICE：设备名，例如 /dev/sda SMARTD_DEVICETYPE：设备类型，例如 ATA、SCSI SMARTD_DEVICESTRING：设备描述，以 SMARTD_DEVICE 开头，后面跟可选的控制器标识，例如 /dev/sda[SAT] SMARTD_DEVICEINFO：设备的标识信息。包括 smartctl -i 打印的大部分信息，但是使用单行格式 SMARTD_FAILTYPE：给出警告或消息电子邮件的原因。 Health：即将发生故障 usage：使用属性失败 SelfTest：自检失败次数增加 ErrorCount：ATA 错误日志中的错误数已增加 CurrentPendingSector：无法读取多个磁盘扇区之一，并标记为重新分配（替换为备用扇区） OfflineUncorrectableSector：在脱机测试或自检期间，无法读取一个或多个磁盘扇区 Temperature：达到温度 FailedHealthCheck：SMART 运行状况命令失败 FailedReadSmartData：读取 SMART 属性数据的命令失败 FailedReadSmartErrorLog：读取 SMART 错误日志的命令失败。 FailedReadSmartSelfTestLog：读取SMART自检日志的命令失败。 FailedOpenDevice：对设备的 open（） 命令失败。 SMARTD_ADDRESS：-m 后设置的邮件地址列表，列表中的逗号分隔符会被替换为空格 SMARTD_ADDRESS_ORIG：SMARTD_ADDRESS 的原始值 SMARTD_MESSAGE：smartd 的警告摘要信息 SMARTD_FULLMESSAGE：smartd 的详细警告信息 SMARTD_TFIRST：此类型第一个问题的时间和日期 SMARTD_TFIRSTEPOCH：自 1970.01.01 起算，SMARTD_TFIRST 的时间戳 SMARTD_PREVCNT：以前发送的消息数 SMARTD_NEXTDAYS：发送下一条消息之前的天数。在 -M once 为空，在 -M always 为 0，在 -M daily 为 1 邮件配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # 安装 s-nail msmtp msmtp-mta $ sudo pacman -Sy s-nail msmtp msmtp-mta # 配置 msmtp $ sudo touch /etc/msmtprc /var/log/msmtp $ sudo chmod 600 /etc/msmtprc /var/log/msmtp $ sudo vim /etc/msmtprc ~~~ # Set default values for all following accounts. defaults tls on tls_starttls off tls_certcheck on allow_from_override off set_from_header on logfile /var/log/msmtp # qq-mail account qq host smtp.exmail.qq.com port 465 auth login from username@qq.com user username@qq.com password pOdFLt7DoTDOqpIe # Set a default account account default: qq ~~~ # 测试发送邮件 $ printf \"Subject: 这是主题\\n\\n这是内容\" | sudo msmtp \"recipient@qq.com\" $ echo \"这是内容\" | sudo mail -s \"这是主题\" \"recipient@qq.com\" 启动 smartd 服务，并设置开机自启，此时会收到 smartd 发送的测试邮件\n1 $ sudo systemctl start --now smartd.service 参考文档：\nS.M.A.R.T. - ArchWiki msmtp - ArchWiki smartd.conf(5) - Arch manual pages ","description":"","tags":["Linux","Arch Linux"],"title":"Arch Linux 使用 smartmontools 监控硬盘状态","uri":"/posts/linux/arch-linux/archlinux-smartmontools/"},{"categories":null,"content":"使用 ACL 在 Btrfs 文件系统上配置共享文件夹的权限 场景说明 在 ArchLinux（2023.10.10） 上创建了一个共享文件夹 /path/to/share，属于 root 用户和 share 组，权限是 770，希望 share 组的用户均可以对该文件夹中的文件/文件夹具有读写权限。\n必须使用 ACL 是因为现在用户的默认 umask 是 022，即创建出文件后的权限是 755，所以组只有读权限，没有写权限。如果把 umask 设置为 002，虽然满足需求，但是用户在 /path/to/share 以外的其它文件夹创建文件时，权限也会变成 775，即属于该用户组的其它用户也能修改该用户的文件，这是不安全的。\n该场景同样适用于项目协作，例如某个项目组的成员均可以对某个目录下的所有文件进行读写，并且不会减弱自己其它文件的安全性。\n实际操作 安装 acl 软件包\n1 $ sudo pacman -Sy acl 首先需要在挂载文件时添加 acl 选项，修改 /etc/fstab 文件\n1 UUID=67b83jxf-xui3-19xj-duxl-4541f27xj4y /mnt/share btrfs defaults,acl 0 0 重载 /etc/fstab 的配置\n1 2 $ sudo systemctl daemon-reload $ sudo mount -a 检查内核是否启用了 Btrfs 的 ACL 支持\n1 2 $ zcat /proc/config.gz | grep CONFIG_BTRFS_FS_POSIX_ACL CONFIG_BTRFS_FS_POSIX_ACL=y 如果没有开启，请检查上方挂载时已添加 acl 选项，并重新挂载成功\n修改 /path/to/share 的所属组\n1 2 3 4 5 6 7 $ ll /path/to/share -rw-r--r-- 1 root root ... drwxr-xr-x 1 root root ... # 递归修改所有文件/文件夹的所属用户为 root，所属组为 share $ sudo chown -R root:share /path/to/share -rw-r--r-- 1 root share ... drwxr-xr-x 1 root share ... 为 /path/to/share 设置权限为 770\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ sudo chmod 770 /path/to/share # 对于之前存在的文件可以结合 find 命令进行修改，修改所有文件夹的组权限为 770 $ sudo chmod 770 `find /path/to/share -type d` # 修改所有文件的权限为 660，如果旧文件包含 x 权限，这里要按需修改 $ sudo chmod 660 `find /path/to/share -type f` -rw-rw---- 1 root share ... drwxrwx--- 1 root share ... # 如果文件/文件夹中包含空格会报错 $ export SAVEIFS=$IFS $ export IFS=$(echo -en \"\\n\\b\") # 修改解释器的单词分隔符，从其中删掉空格 $ sudo chmod 770 `find /path/to/share -type d` # 然后再使用带 find 的指令 $ export IFS=$SAVEIFS 为 /path/to/share 设置 SGID，使得在该目录下创建的新文件/文件夹属于 share 组，而不是创建用户的组\n1 2 3 4 5 6 $ sudo chmod g+s /path/to/share # 对于之前存在的文件夹可以结合 find 命令进行修改 $ sudo chmod g+s `find /path/to/share -type d` -rw-rw---- 1 root share ... drwxrws--- 1 root share ... 为 /path/to/share 设置 ACL 权限\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # 设置 share 组对 /path/to/share 目录有 rwx 权限，并且该目录中新建的文件/文件夹默认（d）继承父文件夹的 ACL 权限 $ sudo setfacl -m d:g:share:rwx /path/to/share # 如果文件夹内之前包括其它文件夹，配合 find 命令对已存在的文件夹进行设置 $ sudo setfacl -m d:g:share:rwx `find /path/to/share -type d` $ sudo setfacl -m g:share:rwx `find /path/to/share -type d` # 使用 getfacl 查看新/旧文件夹，最终效果是相同的 $ getfacl newfolder # file: newfolder/ # owner: root # group: share # flags: -s- user::rwx group::rwx group:share:rwx mask::rwx other::--- default:user::rwx default:group::rwx default:group:share:rwx default:mask::rwx default:other::--- # 如果文件夹内之前包含其它文件，为文件添加 ACL 权限。如果旧文件包含 x 权限，这里需要按需修改 $ sudo setfacl -m g:share:rwx `find /path/to/share -type f` $ sudo setfacl -m g::rwx `find /path/to/share -type f` $ sudo chmod g-x `find /path/to/share -type f` # 这里需要执行下 g-x，不然旧文件和新文件的 getfacl 效果不相同 # 使用 getfacl 查看新/旧文件，最终效果是相同的 $ getfacl newfile # file: newfile # owner: root # group: share user::rw- group::rwx\t#effective:rw- group:share:rwx\t#effective:rw- mask::rw- other::--- ","description":"","tags":["Linux"],"title":"使用 ACL 在 Btrfs 文件系统上配置共享文件夹的权限","uri":"/posts/linux/use-acl-set-share-permission-on-btrfs/"},{"categories":null,"content":"Arch Linux 使用 APC BK650M2-CH UPS 监控 UPS 信息 将连接线和电脑连接好，检测服务器是否识别设备\n1 2 3 $ sudo pacman -S usbutils $ lsusb | grep Uninterruptible Bus 001 Device 002: ID 051d:0002 American Power Conversion Uninterruptible Power Supply 安装 apcupsd\n1 $ sudo pacman -S apcupsd 修改 apcupsd 的配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ sudo vim /etc/apcupsd/apcupsd.conf # UPS 名称，可自定义 UPSNAME BK650M2 # 检查 UPSCABLE 和 UPSTYPE 均为 usb，DEVICE 为空 UPSCABLE usb UPSTYPE usb DEVICE # 当 UPS 处于断电模式，触发以下任意一个阈值即关闭服务器： # 1. BATTERYLEVEL：UPS 电池电量剩余 n% 后关闭系统 # 2. MINUTES：UPS 电池可用时间剩余 n 分钟后关闭系统 # 3. TIMEOUT：UPS 电源断电后 n 秒关闭服务器，0 为禁用该配置 BATTERYLEVEL 5 MINUTES 3 TIMEOUT 0 启动服务并设置开机自启\n1 $ sudo systemctl enable --now apcupsd.service 查看 UPS 信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 $ apcaccess status APC : 001,036,0854 // 版本，记录数，后面的字节数 DATE : 2023-09-29 12:27:21 +0800 // 最后更新时间 HOSTNAME : somehostname // 运行 apcupsd 的主机名 VERSION : 3.14.14 (31 May 2016) unknown // apcupsd 版本，时间，操作系统 UPSNAME : BK650M2 // UPS 名称 CABLE : USB Cable // 线缆类型 DRIVER : USB UPS Driver // 驱动类型 UPSMODE : Stand Alone // 运行模式 STARTTIME: 2023-09-29 12:27:19 +0800 // apcupsd 服务启动时间 MODEL : Back-UPS BK650M2-CH // UPS 型号 STATUS : ONLINE // UPS 状态 LINEV : 226.0 Volts // 当前输入电压 LOADPCT : 0.0 Percent // 负载占比 BCHARGE : 100.0 Percent // 电池电量百分比 TIMELEFT : 60.3 Minutes // 电池可用时间 MBATTCHG : 5 Percent // 电池电量剩余百分之多少后关闭系统 MINTIMEL : 3 Minutes // 电池可用时间剩余多少分钟后关闭系统 MAXTIME : 0 Seconds // 使用电池运行多久后关闭系统 SENSE : Low // 电压灵敏度 LOTRANS : 160.0 Volts // 最低允许输入电压 HITRANS : 278.0 Volts // 最高容许输入电压 ALARMDEL : 30 Seconds // 报警前的延迟时间 BATTV : 13.6 Volts // 电池输出电压 LASTXFER : No transfers since turnon // 自 apcupsd 启动以来，最后一次使用电池的原因 NUMXFERS : 0 // 自 apcupsd 启动以来，使用电池的次数 TONBATT : 0 Seconds // 电池当前待机时间 CUMONBATT: 0 Seconds // 自 apcupsd 启动以来，电池的累计使用时间 XOFFBATT : N/A // apcupsd 启动后最后一次使用电池的时间 SELFTEST : OK // 自 apcupsd 启动以来最后一次自测的时间 STATFLAG : 0x05000008 // UPS 状态（16 进制） SERIALNO : 8B1357G17398 // UPS 序列号 BATTDATE : 2001-01-01 // 上次更换电池的时间 NOMINV : 220 Volts // 额定输入电压 NOMBATTV : 12.0 Volts // 额定电池电压 NOMPOWER : 390 Watts // 额定功率 FIRMWARE : 294803G -292804G // UPS 固件版本 END APC : 2023-09-29 12:27:49 +0800 测试 UPS 功能 将 /etc/apcupsd/apcupsd.conf 中的 TIMEOUT 从 0 修改到 1，然后重启 apcupsd 服务\n1 2 3 4 5 $ sudo vim /etc/apcupsd/apcupsd.conf ~~~ TIMEOUT 1 ~~~ $ sudo systemctl restart apcupsd.service 拔掉 UPS 的电源，过 1 秒钟后 Linux 服务器应该会自动关机\n因为 apcupsd 默认使用 shutdown -h -H now 命令进行关机，会关闭机器但不断开电源，所以此时服务器的电源灯还是亮的\n接通 UPS 的电源，手动开启服务器，将配置文件中的 TIMEOUT 由 1 修改回 0\n1 2 3 4 5 $ sudo vim /etc/apcupsd/apcupsd.conf ~~~ TIMEOUT 0 ~~~ $ sudo systemctl restart apcupsd.service 无人值守方案 在 BIOS 里设置服务器通电后自启动\n设置 UPS 断电后立即关闭服务器\n1 2 3 4 5 $ sudo vim /etc/apcupsd/apcupsd.conf ~~~ TIMEOUT 1 ~~~ $ sudo systemctl restart apcupsd.service 修改 apcupsd 关闭服务器时的指令，让其将服务器关机并断电\n1 2 3 4 5 6 7 8 9 10 11 # 当 UPS 的状态发生变化时，apcupsd 服务会按照这个文件中的设置执行相应的指令 $ sudo vim /etc/apcupsd/apccontrol ~~~ # 修改关闭服务器时需要执行的指令 doshutdown) echo \"UPS ${2} initiated Shutdown Sequence\" | ${WALL} # ${SHUTDOWN} -h -H now \"apcupsd UPS ${2} initiated shutdown\" # 不同系统可能有不同的关机断电指令，需要自行修改 ${SHUTDOWN} now \"apcupsd UPS ${2} initiated shutdown\" ;; ~~~ 在服务器 和 UPS 之间使用智能插座进行连接\n因为这款 UPS 在断电后，需要等待 2.5 分钟左右才会自动关机，所以如果在这 2.5 分钟之内 UPS 电源被接通了，已经关机的服务器因为没有断过电，是不会自动启动的，所以就需要人工使用智能插座远程干预下\nweb 监控页面 添加要监控的主机\n1 2 3 4 5 $ sudo vim /etc/apcupsd/hosts.conf ~~~ # MONITOR hostname[:port] \"Nickname\" MONITOR 192.168.1.100 \"Local Host\" ~~~ 安装并启动 fcgiwrap\n1 2 $ sudo pacman -S fcgiwrap $ sudo systemctl start fcgiwrap.socket 配置 nginx\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 server { listen 8080; location /cgi-bin/ { # 关闭压缩，加快访问速度 gzip off; # cgi 脚本根路径，因为 location 后包含了 /cgi-bin，所以最终会去 /usr/lib/apcupsd/cgi-bin 目录查找脚本文件 root /usr/lib/apcupsd; # 主页 fastcgi_index multimon.cgi; # fcgiwrap 提供的 fastcgi 套接字 fastcgi_pass unix:/var/run/fcgiwrap.sock; # fastcgi 标准参数 include /etc/nginx/fastcgi_params; # 调整非标准参数 SCRIPT_FILENAME fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; } } 启动 nginx，通过 http://192.168.1.100:8080/cgi-bin 即可访问 Web 监控页面\napcupsd 实际上是通过启动了一个 cgi 服务实现的监控\n1 2 3 4 5 6 # 当执行 apcaccess status 命令时，它会通过这个服务获取 UPS 的信息 # 不清楚这个服务使用什么协议，使用 nginx 的 fastcgi_pass 代理这个地址会报错 # 这里可以把 NISIP 设置成 localhost 仅允许本地访问，然后使用 Nginx + fcgiwrap + firewall 实现外网访问 NETSERVER on NISIP localhost NISPORT 3551 参考文档：\nAPC UPS - ArckWiki APC UPS Daemon Manual apcupsd Network Monitoring(CGI) Programs ","description":"","tags":["Linux","Arch Linux"],"title":"Arch Linux 使用 APC BK650M2-CH UPS","uri":"/posts/linux/arch-linux/archlinux-apc-bk650m2-ch/"},{"categories":null,"content":"使用 Gradle 构建 Java 项目 概述 Gradle 是继 Maven 之后的新一代构建工具，使用 Groovy DSL 脚本文件而不是 XML 文件作为配置文件。\nGroovy 是一种基于 JVM 的开发语言，与 Java 地位相同。Groovy DSL（Domain Specific Language，领域特定语言）是 Groovy 语言的一大特性，基于该特性可以设计自己的 DSL 语法，从而简化代码的编写。Gradle 就设计了一种 Groovy DSL，因此只需要按照它的 DSL 语法进行配置即可完成项目的构建等工作。 ↩\n安装 Gradle 需要提前配置好 JDK 8 以上版本\n在官网下载压缩包并解压\n1 2 3 4 $ sudo mkdir /opt/gradle $ sudo unzip gradle-8.3-bin.zip -d /opt/gradle $ ls /opt/gradle/gradle-8.3 bin init.d lib LICENSE NOTICE README 配置环境变量\n1 export PATH=$PATH:/opt/gradle/gradle-8.3/bin 如需持久化，需要配置到文件中\n验证安装\n1 2 3 4 5 $ gradle -v ------------------------------------------------------------ Gradle 8.3 ------------------------------------------------------------ Gradle 属性配置文件 Gradle 有两个主要的配置目录：Gradle 用户主目录（Gradle User Home Directory） 和 项目根目录（Project Root Directory）\nGradle 用户主目录默认是 ~/.gradle，可以在命令行中使用 -Dgradle.user.home 参数或设置 GRADLE_USER_HOME 系统环境变量进行修改\n在 Gradle 用户主目录和项目根目录中均使用 gradle.properties 文件来存储配置。\n配置优先级：Gradle 的最终配置是命令行上设置的所有属性和 gradle.properties 文件的组合。如果在多个位置配置了相同的选项，则在以下任何位置找到的第一个选项获胜：\n命令行上使用 -D 设置的 GRADLE_USER_HOME 目录下的 gradle.properties 项目目录中的 gradle.properties，然后是其父项目目录中的，直到构建的根目录中的 Gradle 安装目录中的 gradle.properties 项目目录结构 ├── .gradle // 项目级缓存目录 │ ├── 8.2 // 版本特定的缓存（例如为了支持增量构建） │ └── ⋮ ├── build // 项目的构建目录，保存编译后的字节码、生成的 jar/war 包、测试报告等 ├── gradle │ └── wrapper // 包装器 的 jar 包和配置文件 │ ├── gradle-wrapper.jar │ └── gradle-wrapper.properties ├── src // 源码目录，与 maven 完全一致 │ ├── main │ │ ├── java │ │ └── resources │ └── test │ ├── java │ └── resources ├── subproject // 子模块 │ ├── src // 源码目录 │ └── build.gradle // 子模块的构建脚本 ├── build.gradle // 构建脚本，类似于 maven 的 pom.xml ├── gradle.properties // 项目级 Gradle 属性配置文件 ├── gradlew // 包装器启动脚本 ├── gradlew.bat // 同上，用于 Windows └── settings.gradle // 项目设置文件，定义项目及子项目的名称 Gradle Wrapper Gradle Wrapper 可以用来统一使用的 Gradle 版本，并且可以在没有 Gradle 环境的情况下运行 Gradle 项目，提高开发效率。\n在第一次使用 gradlew 命令构建 Gradle 项目时候，Gradle Wrapper 会读取 gradle-wrapper.properties 文件，从 distributionUrl 把 Gradle 的压缩包下载 到 zipStoreBase/zipStorePath 并将其解压到 distributionBase/distributionPath。之后就可以使用 gradlew 执行 gradle 的相关命令了。\n可以在 IDEA 中修改使用本地 Gradle 还是 Gradle Wrapper：\nGroovy 基本语法 Groovy 完全支持 Java 语法，即可以作为面向对象的编程语言，也可以作为脚本语言\nHelloGroovy.groovy\n1 2 3 4 5 6 7 8 // Groovy 总只有 public、proteccted、private 三种访问修饰符号。 // 默认就是 public，可以省略不写 class HelloGroovy { static void main(String[] args) { // 不需要 import 常用的包，不需要分号 println(\"Hello Groovy!\") } } HelloGroovyScript.groovy\n1 2 // 可以使用脚本语言的书写方式 println(\"Hello Groovy Script!\") 变量\n1 2 3 4 // 使用 def 定义变量，不需要指定类型，访问修饰符默认是 public def a = 1 // 可以将不同类型的值赋值给同一个变量 a = \"str\" 方法\n1 2 3 4 5 6 7 8 // 方法可以使用 def 定义，返回值和参数可以不指定类型 def add(a, b) { // 可以省略 return，默认返回方法的最后一条语句的执行结果 a + b } // 在不引起歧义的情况下可以省略方法调用时的括号 def res = add 1, 2 println res 类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class Person { def name def age def gender def speak() { println(\"balabala\") } } // 对象属性赋值的 4 种方式 def p = new Person() p.name = \"张三\" p[\"age\"] = 14 p.setGender(\"男\") // Groovy 会给没有可见性修饰符的类成员变量生成 getter 和 setter；被 final 修饰的变量不会生成 setter new Person(name: \"李四\", gender: \"女\") // 获取对象属性的 3 种方式 println(p.name) println(p[\"age\"]) println(p.getGender()) // 调用方法 p.speak() 字符串\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def str = \"我是一个变量\" def str1 = '单引号，不支持变量引用，${str}，不支持换行' println(str1) // 在不引起歧义的情况下 ${str} 也可以写成 $str def str2 = \"双引号，支持变量引用：${str}，不支持换行\" println(str2) def str3 = '''模板字符串，不支持变量引用：${str}，支持 换行''' println(str3) // java.lang.String println(str1.getClass()) // 双引号是 Groovy 中自定义的类型 org.codehaus.groovy.runtime.GStringImpl println(str2.getClass()) // java.lang.String println(str3.getClass()) 集合\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 def list = [1, 2, 3, 4] assert list instanceof List // 如果定义的集合中都是同类型的元素，即可使用 \u003c\u003c 向集合中追加元素 list \u003c\u003c 5 println(list) // [1, 2, 3, 4, 5] // 集合中也可以包含不同类型的元素 list += \"六\" println(list) // [1, 2, 3, 4, 5, 六] // 删除指定元素 list -= \"六\" println(list) // [1, 2, 3, 4, 5] // 把 list2 追加到 list 中 def list2 = [6, 7, 8] list += list2 println(list) // [1, 2, 3, 4, 5, 6, 7, 8] // 从 list1 中删除 list3 中的所有元素，并将结果赋值给 list，可以有如下三种写法 def list3 = [6, 7] list -= list3 println(list) // [1, 2, 3, 4, 5, 8] // 将 list 中角标为 5 的元素替换成 6 list[5] = 6 println(list) // [1, 2, 3, 4, 5, 6] // 可以使用负数角标从后向前获取/设置元素 println(\"list[-1] = ${list[-1]}, list[-6] = ${list[-6]}\") // list[-1] = 6, list[-7] = 1 // 弹栈和压栈 list.pop() list.push(1) // 遍历集合中的元素 list.each( // 这是一个闭包（Closure） { println(\"Item：$it\") } ) Map\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // 对于 String 类型，key 可以没有引号，value 不能没有引号 def map = [G: 'Gradle', 'J': \"Java\", \"K\": '''Kotlin''', '''S''': 'Scala'] // 添加元素，key 相同会覆盖 map \u003c\u003c [1: 2] map += [\"P\": \"Python\", \"G\": \"Groovy\"] println(map) // [G:Groovy, J:Java, K:Kotlin, S:Scala, 1:2, P:Python] // 删除元素 map -= [1: 2, \"P\": \"Python\"] println(map) // [G:Groovy, J:Java, K:Kotlin, S:Scala] map.each(// 这是一个闭包（Closure） { key, val -\u003e println(\"key: $key, val: $val\") } ) map.each(// 这是一个闭包（Closure） { entry -\u003e println(\"key: $entry.key, val: $entry.value\") } ) 闭包\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 /* * 闭包 * 定义：是一个开放的、匿名的、可以接收参数、也可以有返回值的代码块。类似于 Lambda 表达式 * 语法： { [ClosureParameters -\u003e ] statements } * 调用： * 第一步，将闭包赋值给一个变量 * 第二步，使用 变量名()、变量名.call() 方式调用 * * 闭包在实际开发中的使用：作为方法的参数使用 */ // 闭包示例 { item++ } // 有参有返回值 { -\u003e item++ } // 无参有返回值 { println it } // 不指定参数，使用隐式参数名 it，有参无返回值 { it -\u003e println it } // 指定参数 it，有参无返回值 { name -\u003e println name } // 指定参数名为 name，有参无返回值 { String x, int y -\u003e println \"hey ${x} the value is ${y}\" } // 多个参数，并指定类型和参数名 { reader -\u003e def line = reader.readLine() line.trim } // 指定参数名，有参数有返回值，包含多条语句 // 单独使用闭包 def clo = { name -\u003e println \"我是 $name\" name } def res = clo(\"张三\") println(res) res = clo.call(\"李四\") println(res) // 在定义方法时，将闭包作为形参 def method(Closure closure) { println \"method start...\" // 在方法内部可以执行传入的闭包，获取其返回值等信息 closure(); println \"method end...\" } method({ println(\"closure running...\") }) // 定义带其它参数和闭包的方法 def cal(num1, num2, Closure closure) { closure(num1, num2) } cal(1, 2, { n1, n2 -\u003e println(\"$n1 + $n2 = ${n1 + n2}\") }) // 当闭包作为方法的最后一个参数时，可以写在方法外面 cal(1, 2) { n1, n2 -\u003e println \"$n1 + $n2 = ${n1 + n2}\" } 分支结构（if / else）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 def x = false def y = false if (!x) { x = true } // 断言，如果后面的表达式的结果是 false，会报错，常用于单元测试 assert x == true if (x) { x = false } else { y = true } assert x == y if ( ... ) { ... } else if ( ... ) { ... } else { ... } 分支结构（switch / case）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def x = 'foo' // found foo // def x = \"bar\" // bar // def x = '''regg''' // reg regex // def x = 5 // list // def x = 12 // range // def x = -1.23 // negative // def x = 45 // integer // def x = 1.23 // number def result = \"\" switch (x) { case \"foo\": // 支持字符串类型 result = \"found foo\" // 支持 switch 穿透 case \"bar\": result += \"bar\" break case ~/reg*/: // x.toString() 后与 ~// 内部的正则表达式是否匹配 result = \"reg regex\" break case [4, 5, 6, 'inList']: // x 是否属于该列表 result = \"list\" break case 12..30: // x 是否是 [12, 30] 区间的整数 result = \"range\" break case { x \u003c 0 }: // 闭包，也可以写成 {it \u003c 0} result = \"negative\" break case Integer: // x instance of Integer ? result = \"integer\" break case Number: // x instance of Number ? result = \"number\" break default: result = \"default\" } println(result) // 可以使用以下格式的 switch 表达式 def person = 'Adam' def partner = switch (person) { case 'Romeo' -\u003e 'Juliet' case 'Adam' -\u003e 'Eve' case 'Antony' -\u003e 'Cleopatra' case 'Bonnie' -\u003e 'Clyde' default -\u003e 'Unknown' } println(partner) // Eve 循环语句（for）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // 多重赋值语句 def baNums = [] for (def (String u, int v) = ['bar', 42]; v \u003c 45; u++, v++) { baNums \u003c\u003c \"$u $v\" } assert baNums == ['bar 42', 'bas 43', 'bat 44'] // 迭代一个范围 for (i in 0..9) { print(\"$i \") // 0 1 2 3 4 5 6 7 8 9 } println() // 迭代一个列表 for (i in [0, 1, 2, 3, 4]) { print(\"$i \") // 0 1 2 3 4 } println() // 迭代一个数组 def array = (0..4).toArray() for (i in array) { print(\"$i \") // 0 1 2 3 4 } println() // 迭代一个 map def map = ['abc': 1, 'def': 2, 'xyz': 3] for (e in map) { print(\"$e.key: $e.value \") // abc: 1 def: 2 xyz: 3 } println() // 迭代 map 的值 for (v in map.values()) { print(\"$v \") // 1 2 3 } println() // 迭代字符串中的字符 def text = \"abc\" for (c in text) { print(\"$c \") // a b c } println() 循环语句（while / do while）\n1 // 与 Java 的 while / do while 语法相同 Gradle 项目的构建过程 Gradle 的构建包含 3 个步骤：\nInitialization：初始化阶段，依次执行 GRADEL_USER_HOME/init.gradle 和项目中的 settings.gradle 脚本，加载一些全局配置和项目信息 Configuration：配置阶段，也叫编译阶段，按照从 settings.gradle 中读取的项目信息，从根目录开始逐层执行项目的 build.gradle 脚本，创建出对应的 Task，并将这些 Task 组成一张有向无环图 Execution：执行阶段，执行上一阶段生成的 Task 图，生成 jar / war 包 可以通过修改 Gradle Task 提供的 Hook 或者自定义 Task，增强 Gradle 的构建过程。\nGradle 项目配置文件详解 项目设置脚本（settings.gradle） 1 2 3 4 5 6 7 8 // 根项目名 rootProject.name = 'gradle-demo' // 包含的子项目名称 include 'subproject01' include 'subproject02' // 包含的子项目下的子项目 include 'subproject01:subproject0101' include 'subproject01:subproject0102' 只有被 include 引入的项目才会被构建\n项目构建脚本（build.gradle） build.gradle 文件称为项目的构建脚本，每个项目都对应有一个构建脚本，每个构建脚本都与一个 org.gradle.api.Project 类型的对象相关联，在脚本中定义的属性和方法其实都是 Project 的属性和方法。\n在 build.gradle 的同级目录执行 gradle 指令，Gradle 就会开始执行该脚本来构建项目\nGradle 本身提供的项目常用属性和方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 //----- 属性 ----- // 相当于 Maven 中的 GAV group = 'org.example' name = 'project name' // 项目名是只读的，这里只做演示，实际不可修改 version = '1.0-SNAPSHOT' // 项目描述 description = 'project description' // 扩展属性 ext { springVersion = \"3.1.0.RELEASE\" emailNotification = \"build@master.org\" } //----- 方法 ----- // Project 中的方法基本都是使用闭包作为最后一个参数，所以可以将闭包写在方法后面，又因为在不引起歧义的情况下，方法的括号可以省略，所以才有了下面的这些形式 // 用于配置 Gradle 构建过程自身需要的一些信息 buildscript { } // 可以修改构建时的目录结构 sourceSets { main { java { srcDirs = ['src/main/java'] } resources { srcDirs = ['src/main/resources'] } } test { java { srcDirs = ['src/test/java'] } resources { srcDirs = ['src/test/resources'] } } } // 引入二进制插件 plugins { } // 项目依赖的仓库设置 repositories { } // 项目的依赖设置 dependencies { } // 所有项目（根项目和子项目）的公共设置 allprojects { } // 子项目的公共设置 subprojects { } // 仅针对某个项目的设置 project('projectname') { } 插件（plugins） Gradle 本身对项目的自动化构建提供提供很少的实现，所有常用的功能都是插件提供的（例如编译 Java 代码等）。\nGradle 中有两种插件类型：脚本插件 和 二进制插件。\n脚本插件就是类似于 Gradle 构建脚本的脚本文件；二进制插件通过实现 Plugin 接口或使用 Gradle DSL 的方式书写在脚本文件、项目或者 jar 包中。\n插件通常从脚本插件开始，随着代码变得更有价值，就会将其迁移到二进制插件，从而可以在多个项目之间进行共享。\n脚本插件\n可以将 builid.gradle 中的公共代码或者属性提取到单独的文件，然后在构建脚本中引入即可\n1 2 3 // 在 build.gradle 中使用 apply from 将脚本插件引入即可在 build.gradle 中使用脚本插件中的内容 // from 后可以是本地文件也可以是网络上的文件 apply from: 'xx.gradle' 二进制插件\nGradle 官方提供了许多 核心插件，例如 java、java-library；也有许多常用的 社区插件，例如 org.springframework.boot，io.spring.dependency-management\n1 2 3 4 5 6 7 8 9 plugins { // 核心插件只需要使用 id 属性进行引入即可 id 'java' // 社区插件要额外指定 version 属性 id 'org.springframework.boot' version '3.1.4' // 对于没有被托管在 https://plugins.gradle.org 上的第三方插件，需要先在 buildscript 中引入存储库和依赖 } // 也可以使用以下方式引入二进制插件 apply plugin: 'java' java-library 对 java 插件进行了一些增强，二者主要区别在于 依赖传递 方式不同，所以二选一使用即可。java 插件通常在开发业务项目时使用，java-library 通常在开发工具包或公共包时使用\n仓库（repositories） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // repositories 中可以配置多个当前项目需要使用的仓库，Gradle 会按顺序依次去各个仓库中去寻找所需的依赖 repositories { // 从本地的某个路径寻找依赖（不推荐使用） maven { url 'file:///path/to/local-repos' } // 绝对路径 maven { url \"$rootDir/lib/release\" } // 相对路径 // 从 maven 的本地仓库寻找依赖 mavenLocal() // 从阿里云镜像仓库寻找依赖 maven { url 'https://maven.aliyun.com/repository/public/' } // 从私服寻找依赖 maven { url 'https://nexus.example.org/repository/public/' } // 从 maven 远程仓库寻找依赖 mavenCentral() // 从 google 仓库查找 google() } 依赖（dependencies） 依赖方式：\n直接依赖：通过 依赖类型 + GAV 的方式\n1 2 3 4 5 6 7 implementation 'com.mysql:mysql-connector-j:8.1.0' implementation group: 'com.mysql', name: 'mysql-connector-j', version: '8.1.0' // 版本号上使用 + 或者 latest.integration 表示使用最新版本 implementation 'com.mysql:mysql-connector-j:+' implementation 'com.mysql:mysql-connector-j:latest.integration' // 版本号使用 8.+ 表示版本必须 \u003e=8.0 implementation 'com.mysql:mysql-connector-j:8.+' 项目依赖：依赖某个 Project，模块之间的依赖，被依赖的模块必须在 settings.gradle 文件中\n1 implementation project(':subproject01') 本地依赖：依赖本地某个 jar 包。具体可通过文件集合、文件树的方式指定\n1 2 implementation files('lib/mysql.jar') implementation fileTree(dir: 'lib', includes: ['*.jar'], excludes: ['mysql.jar']) 依赖下载： 当执行 build 指令时，Gradle 会自动从仓库下载对应的 jar，并应用到项目中\n依赖类型： 类似于 Maven 的 scope 标签\n依赖类型 说明 compileOnly 由 java 插件提供，适用于编译期需要而不需要打到包中的依赖。 runtimeOnly 由 java 插件提供，只在运行时需要，编译时不需要的依赖。例如 mysql 驱动。gradle \u003c 7.0 为 runtime implementation 由 java 插件提供，针对 src/main 目录，在编译和运行时都需要的依赖。gradle \u003c 7.0 为 compile testCompileOnly 由 java 插件提供，用于测试的编译期，运行时不需要的依赖 testRuntimeOnly 由 java 插件提供，用于测试的运行时，编译期不需要的依赖。gradle \u003c 7.0 为 testRuntime testImplementation 由 java 插件提供，针对 src/test 目录，在测试的编译和运行时都需要的依赖。gradle \u003c 7.0 为 testCompile api 由 java-library 插件提供，类似于 implementation，同时支持依赖的传递 compileOnlyApi 由 java-library 插件提供，类似于 compileOnly providedCompile 由 war 插件提供，编译/测试阶段需要，在运行时容器已经提供了相应支持的依赖。例如 servlet-api，jsp-api 依赖传递（implementation 和 api 的区别）：\nModel A implementation / api Model B，在编译期间 Model A 均可以调用 Model B 中的代码 如果 Model B implementation Model C，则在编译期间 Model A 中无法调用 Model C 中的代码 如果 Model B api Model C，则在编译期间 Model A 中可以调用 Model C 的 代码 在运行期间，Model B implementation / api Model C，Model A 均可以调用 Model C 中的代码 所以，通常只有在 Model A 依赖 Model B，并且 Model A 和 Model B 均需要使用 Model C 中的代码时，为了避免重复依赖，才使用 Model B api Model C，否则使用 implementation 即可。项目中大量使用 api 依赖会导致构建变慢。\n另外，与 Maven 不同，在 Gradle 中父项目中引入的依赖只对父项目生效，不会传递给子项目\n依赖版本冲突：\n1 2 3 4 5 dependencies { implementation 'com.google.guava:guava:20.0' // guice 4.2.2 依赖 guava:25.1-android implementation 'com.google.inject:guice:4.2.2' } 由于 com.google.inject:guice:4.2.2 中包含 com.google.guava:guava:25.1-android 的依赖，而我们在项目中单独引入了 com.google.guava:guava:20.0，此时在项目中就会包含 2 个不同版本的 guava 包，从而出现依赖版本冲突问题。\n当出现这种情况时，Gradle 默认会使用较新版本的依赖，即在当前项目中使用 com.google.guava:guava:25.1-android（Maven 中默认是使用最短路径上的版本）\n除了 Gradle 默认的依赖版本冲突解决方式外，Gradle 还提供了一些定制化的方式解决依赖版本冲突，但是均 不推荐 使用：\n排除依赖\n1 2 3 4 5 6 7 8 9 dependencies { implementation 'com.google.guava:guava:20.0' implementation('com.google.inject:guice:4.2.2') { // 使用以下任意一种方式将 guice 中的 guava 包排除掉，此时使用的就是 guava:20.0 版本的依赖包了 exclude group: 'com.google.guava' //exclude module: 'guava' //exclude group: 'com.google.guava', module: 'guava' } } 禁止依赖传递\n1 2 3 4 5 6 7 dependencies { implementation 'com.google.guava:guava:20.0' implementation('com.google.inject:guice:4.2.2') { // 使用这种方式会导致 guice 所依赖的所有依赖包都不会被引入到当前项目，均需要手动进行引入，否则在运行时会报错 transitive false } } 强制使用指定版本\n1 2 3 4 5 6 7 8 9 10 11 dependencies { // 在需要强制使用的依赖版本号后面添加两个叹号，此时在项目中就会使用 guava:20.0 版本 implementation 'com.google.guava:guava:20.0!!' // 或者在封包里使用 version.strictly 指定强制使用的版本号 /*implementation('com.google.guava:guava') { version { strictly '20.0' } }*/ implementation 'com.google.inject:guice:4.2.2' } 在使用上方定制化方式解决依赖版本冲突时，可以提前查看项目中有哪些版本冲突依赖：\n1 2 3 4 5 configurations.configureEach() { Configuration configuration -\u003e // 当遇到版本冲突时直接构建失败 configuration.resolutionStrategy.failOnVersionConflict() } 项目（allprojects \u0026 subprojects \u0026 project） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 当在根项目的 build.gradle 中设置了仓库和依赖等信息，这些设置信息只对根项目有效，对子项目是无效的，所以可以将其配置在 allprojects 中使其对所有项目生效 allprojects { // 需要对所有项目均生效的配置和属性均可以配置在 allprojects 中 repositories { mavenLocal() maven { url 'https://maven.aliyun.com/repository/public/' } mavenCentral() } // 在 allprojects 中的设置，会在每个项目构建时都执行一次 println \"allprojects, project name is: $project.name\" } subprojects { // 在 subprojects 中的设置，会在每个子项目构建时都执行一次 println \"subprojects, project name is: $project.name\" } // 参数可以使用项目名（subject01）或者项目路径（:subject01）的方式。 // 通过该方式，可以将所有子项目的设置都使用该方式配置在根项目的 build.gradle 中 project(':subject01') { // 添加 java 插件 apply plugin: 'java' // 尽在指定项目构建时执行一次 println \"project model-a, project name is: $project.name\" } 扩展属性（ext） 所有 Gradle 的扩展对象（包括项目，任务等）都包含扩展属性，可以在扩展属性中自定义相关配置信息，项目的扩展属性可以在它以及它子项目的构建脚本的任意位置使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // 在配置脚本中直接配置的是 Project 的扩展信息，可以在其中定义依赖的版本号等信息 ext { guavaVersion = \"20.0\" guiceVersion = \"4.2.2\" user = [ 'name': '张三', 'age' : 18 ] } dependencies { // 可以直接在 dependencies 引用 ext 中的配置 implementation \"com.google.guava:guava:$guavaVersion\" implementation \"com.google.inject:guice:$guiceVersion\" } // 也可以在构建脚本的任意位置引用 ext 中的配置 println \"ext, guavaVersion: $guavaVersion, ext.user.name: $ext.user.name\" 构建脚本（buildscript） 用于设置 Gradle 构建时本身需要的一些信息，例如引入没有被托管在 https://plugins.gradle.org 上的第三方插件，需要先在 buildscript 中引入存储库和依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 buildscript { repositories { mavenLocal() // 设置存储库 maven { url 'https://nexus.example.org/repository/public/' } mavenCentral() } dependencies { // 引入依赖 classpath 'example.org:customer-plugin:version' } } plugins { // 应用插件 id 'customer-plugin' } java 插件提供的其它常用属性和方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 使用闭包的形式设置 java 插件提供的配置 java { // 指定编译源代码的 JDK 版本 sourceCompatibility = JavaVersion.VERSION_17 // 指定生成的 .class 文件的 JDK 版本 targetCompatibility = JavaVersion.VERSION_17 // 编译源码时使用的字符集 tasks.withType(JavaCompile).configureEach { options.encoding = 'UTF-8' } // 生成 Javadoc 文档时使用的字符集 tasks.withType(Javadoc).configureEach { options.encoding = 'UTF-8' } } 项目 Gradle 属性文件（gradle.properties） 该文件中主要配置一些系统属性，环境变量，项目属性，JVM 相关配置等信息\n1 2 3 4 5 6 7 8 9 10 # java 虚拟机参数 org.gradle.jvmargs=-Xms4096m -Xmx8192m # 开启 gradle 缓存 org.gradle.caching=true # 开启并行编译 org.gradle.parallel=true # 启用新的孵化模式 org.gradle.configureondemand=true # 开启守护进程 org.gradle.daemon=true 打包和 发布 Jar 包\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 plugins { id 'java' // 引入用于发布的插件 id 'maven-publish' } java { // 添加以下代码在打包时把文档和源码一起打包 withJavadocJar() withSourcesJar() // 编译源码时使用的字符集 tasks.withType(JavaCompile).configureEach { options.encoding = 'UTF-8' } // 生成 Javadoc 文档时使用的字符集 tasks.withType(Javadoc).configureEach { options.encoding = 'UTF-8' } } publishing { // 发布物信息，即需要发布的项目信息 publications { // 发布物信息，会将当前项目的包发布到下面配置的仓库 gradleDemo(MavenPublication) { // 发布到远程仓库上包的 GAV 信息 groupId = \"org.example\" artifactId = \"gradle-demo\" version = \"1.0.0-SNAPSHOT\" from components.java } } // 配置需要将打好的包发布到哪里 repositories { // 将打好的包发布到本地仓库 mavenLocal() maven { // 自定义的名称 name = 'repo-name' // 发布到本地的某个位置 // url = layout.getBuildDirectory().dir(\"repos\") // 指定 maven 私服的 URL url = \"https://nexus.example.org/maven/public/\" // 可以将正式版本和快照版本进行分离发布 /*def releasesRepoUrl = \"https://nexus.example.org/maven/releases/\" def snapshotsRepoUrl = \"https://nexus.example.org/maven/snapshots/\" url = version.endsWith('SNAPSHOT') ? snapshotsRepoUrl : releasesRepoUrl*/ // 认证信息（可选）。为了安全可以使用 System.getenv('env_name') 的方式从系统环境变量中获取用户名和密码信息 /*credentials { username = '' password = '' }*/ } } } war 包\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 plugins { // 把插件换成 war 插件 id 'war' id 'maven-publish' } // 打 war 包不能将 javadoc 和源码一起发布 publishing { publications { gradleDemo(MavenPublication) { groupId = \"org.example\" artifactId = \"gradle-demo\" version = \"1.0.0-SNAPSHOT\" // 把 components.java 换成 components.web from components.web } } repositories { mavenLocal() maven { name = 'repo-name' url = \"https://nexus.example.org/maven/public/\" } } } 配置完成后使用 build 任务即可打包到项目的 build 文件夹；使用 publish 任务即可将包发布到指定仓库\n配置案例 普通 Java / War 项目 普通 Java 项目直接通过 IDEA 创建即可，参考 项目目录结构\n普通 War 项目需要进行一些额外操作\n在 build.gradle 中将 java 插件替换成 war\n1 2 3 4 plugins { // id 'java' id 'war' } 在 src/main 目录下添加 webapp/WEB-INFO/web.xml 文件\n1 2 3 4 5 6 7 8 9 10 src/ ├── main │ ├── java │ ├── resources │ └── webapp │ └── WEB-INF │ └── web.xml └── test ├── java └── resources 微服务项目 项目结构\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 micro/ ├── .gradle ├── gradle ├── micro-bean │ ├── src │ └── build.gradle ├── micro-common │ ├── src │ └── build.gradle ├── micro-service │ ├── micro-service-order │ │ ├── src │ │ │ ├── main │ │ │ │ ├── java │ │ │ │ │ └── org.example.MicroServiceOrderApplication.java │ │ │ │ └── resources │ │ │ │ └── application.yaml │ │ │ └── test │ │ └── build.gradle │ ├── micro-service-user │ │ ├── src │ │ │ ├── main │ │ │ │ ├── java │ │ │ │ │ └── org.example.MicroServiceUserApplication.java │ │ │ │ └── resources │ │ │ │ └── application.yaml │ │ │ └── test │ │ └── build.gradle │ └── build.gradle ├── build.gradle ├── gradle.properties ├── gradlew ├── gradlew.bat ├── settings.gradle └── versions.gradle // 配置依赖统一版本管理的脚本插件 gradle.properties\n1 2 3 4 5 6 7 8 9 10 # java 虚拟机参数 org.gradle.jvmargs=-Xms4096m -Xmx8192m # 开启 gradle 缓存 org.gradle.caching=true # 开启并行编译 org.gradle.parallel=true # 启用新的孵化模式 org.gradle.configureondemand=true # 开启守护进程 org.gradle.daemon=true settings.gradle\n1 2 3 4 5 6 7 8 rootProject.name = 'micro' include 'micro-common' include 'micro-bean' include 'micro-service' include 'micro-service:micro-service-order' findProject(':micro-service:micro-service-order')?.name = 'micro-service-order' include 'micro-service:micro-service-user' findProject(':micro-service:micro-service-user')?.name = 'micro-service-user' versions.gradle\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ext { // 因为项目中已经借助 SpringBoot 使用了统一依赖管理，所以只需要将 SpringBoot 没有管理的依赖在这个文件中进行管理即可 versions = [ 'springBoot' : '3.1.4', 'springCloud' : '2022.0.4', 'springCloudAlibaba': '2021.0.4.0', 'fastjson2' : '2.0.40', 'mybatisPlus' : '3.5.3.2', 'druid' : '1.2.19', 'jjwt' : '0.12.0', ] dependencies = [ 'fastjson2' : \"com.alibaba.fastjson2:fastjson2:${versions.fastjson2}\", 'mybatis-plus-boot-starter': \"com.baomidou:mybatis-plus-boot-starter:${versions.mybatisPlus}\", 'druid' : \"com.alibaba:druid:${versions.druid}\", 'jjwt' : \"io.jsonwebtoken:jjwt-api:${versions.jjwt}\", ] } build.gradle\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 buildscript { // 引入 versions.gradle 中的信息 apply from: 'versions.gradle' repositories { mavenCentral() } dependencies { // SpringBoot 项目必须同时引入 org.springframework.boot 和 io.spring.dependency-management 插件，而二者不同版本间存在兼容性问题 // spring-boot-gradle-plugin 插件根据指定的 SpringBoot 版本，自动引入 boot 插件和对应版本的 dependency-management 插件 // dependency-management 用于管理依赖版本，类似于 maven 中的 spring-boot-starter-parent classpath \"org.springframework.boot:spring-boot-gradle-plugin:$versions.springBoot\" } } // 根项目的描述信息 description = 'root project' // 对所有项目都生效的配置 allprojects { apply plugin: 'java' apply plugin: 'maven-publish' // 所有项目都有相同的组和版本信息 group = 'org.example' version = '1.0-SNAPSHOT' // 设置 java 插件编译时 java { // 打包和发布时包含源码包和 javadoc 包 withSourcesJar() withJavadocJar() // 指定编译源代码的 JDK 版本 sourceCompatibility = JavaVersion.VERSION_17 // 指定生成的 .class 文件的 JDK 版本 targetCompatibility = JavaVersion.VERSION_17 // 编译源码时使用的字符集 tasks.withType(JavaCompile).configureEach { options.encoding = 'UTF-8' } // 生成 Javadoc 文档时使用的字符集 tasks.withType(Javadoc).configureEach { options.encoding = 'UTF-8' } } // 所有项目都使用相同的 maven 仓库 repositories { mavenLocal() mavenCentral() } // 所有项目都需要引入的依赖 dependencies { testImplementation 'org.junit.jupiter:junit-jupiter' } // 发布配置 publishing { publications { mavenJava(MavenPublication) { // 设置发布包的 GAV 信息 groupId = \"${project.group}\" artifactId = \"${project.name}\" version = \"${project.version}\" from components.java // 因为使用了 SpringBoot 等的依赖版本管理，在依赖版本管理或项目中包含使用动态版本方式设置的依赖，所以通过以下方式在打包发布时，使用与本地运行时版本相同的依赖包 // 参考：https://docs.gradle.org/8.4/userguide/publishing_maven.html#publishing_maven:resolved_dependencies versionMapping { usage('java-api') { fromResolutionOf('runtimeClasspath') } usage('java-runtime') { fromResolutionResult() } } } } repositories { mavenLocal() maven { name = 'repo-name' url = 'https://nexus.example.org/maven/public/' } } } } // 所有子项目的设置 subprojects { // 均使用 dependency-management 进行统一的依赖管理 apply plugin: 'io.spring.dependency-management' // dependencyManagement 版本统一管理，类似于 maven 中的 dependencyManagement 标签， dependencyManagement { dependencies { // 遍历 versions.gradle 中的依赖信息，将其添加到 dependencyManagement.dependencies 中 for (dep in rootProject.ext.dependencies) { dependency dep.value } } // 引入 SpringBoot、Spring Cloud、Spring Alibaba 提供的 BOM 信息 // BOM（Bill Of Materials，材料清单）本身也是一个 POM 格式的文件，在其中使用 dependencyManagement 标签管理组件所需依赖的版本信息 imports { // Gradle 会依次从多个 mavenBom 中获取依赖的版本信息，如果多个 mavenBom 中都定义了该依赖的版本信息，则最后一个 mavenBom 中的将会生效 mavenBom \"org.springframework.boot:spring-boot-dependencies:$rootProject.ext.versions.springBoot\" mavenBom \"org.springframework.cloud:spring-cloud-dependencies:$rootProject.ext.versions.springCloud\" mavenBom \"com.alibaba.cloud:spring-cloud-alibaba-dependencies:$rootProject.ext.versions.springCloudAlibaba\" } } } // 对每个子项目的单独配置，可以将其放到各个子项目自己的 build.gradle 文件中 project(':micro-bean') { apply plugin: 'java-library' description '存放数据表对应的实体类' } project(':micro-common') { apply plugin: 'java-library' description '公共模块' dependencies { // 公共模块提供公共的代码、工具、依赖包等给依赖它的模块使用，所以需要使用 api 引入依赖的方式将依赖传递给依赖公共模块的模块 api 'com.alibaba.fastjson2:fastjson2' api 'com.mysql:mysql-connector-j' api 'com.alibaba:druid' api 'com.baomidou:mybatis-plus-boot-starter' api 'io.jsonwebtoken:jjwt-api' api 'org.springframework.cloud:spring-cloud-starter-openfeign' api 'com.alibaba.cloud:spring-cloud-starter-alibaba-sentinel' api 'com.alibaba.cloud:spring-cloud-starter-alibaba-nacos-discovery' } } project(':micro-service') { description '存放各个微服务模块' // 配置 micro-service 模块下的所有子模块 subprojects { // 因为微服务是一个可运行的 SpringBoot 项目，所以引入 SpringBoot 的插件 apply plugin: 'org.springframework.boot' // 编写 SpringBoot 配置文件时可以有提示信息 configurations { compileOnly { extendsFrom annotationProcessor } } dependencies { annotationProcessor 'org.springframework.boot:spring-boot-configuration-processor' // service 中已经是编写 Controller 层的代码了，所以一般不会有其它模块使用到她的依赖包了，所以使用 implementation 引入依赖即可 implementation 'org.springframework.boot:spring-boot-starter-web' implementation project(':micro-bean') implementation project(':micro-common') } } } ","description":"","tags":["Gradle","Java"],"title":"使用 Gradle 构建 Java 项目","uri":"/posts/java/use-gradle-build-java-project/"},{"categories":null,"content":"Arch Linux 通过路由器无线连接 Canon PIXMA G3800 Arch Linux Version：03 Aug 2023\n连接打印机 安装 cups\n1 sudo pacman -S cups 设置 cups 服务开机自启并立即启动\n1 sudo systemctl enable --now cups 安装打印机驱动和字体相关软件\n1 sudo pacman -S gutenprint ghostscript gsfonts gutenprint：适用于 POSIX 系统的高质量打印机驱动程序，如果不安装这个后面选择打印机品牌和型号是会找不到 ghostscript（PostScript 语言和 PDF 文件的解释器）、gsfonts（GhostScript 标的准 Type1 字体）：PDF 和字体相关的包 安装打印机管理应用（Print Settings）\n1 sudo pacman -S system-config-printer 如果不安装该应用，也可以通过访问 cups 服务提供的管理页面：http://localhost:631 来添加打印机。点击上方的 Administration，输入用户名（root）和密码，点击 Add Printer。\n用该应用设置更简单，所以没有使用管理界面进行配置。\n打开 Print Settings，点击 Unlock，输入 root 用户密码解锁后，点击 Add\n点击 Network Printer，然后选择 Find Network Printer，在右侧输入打印机的 IP，然后点击 Find，在找到打印机后，点击 Forward\n选择打印机的品牌：Canon\n选择打印机的型号，这里选择 G3000 即可\n修改打印机名称和描述\n添加成功后，可以双击打印机图标对其属性进行配置\n如果需要在本地安装一个可以将文件打印成 PDF 文件的虚拟打印机，可以安装 cups-pdf，然后添加 Generic CUPS-PDF\n1 sudo pacman -S cups-pdf CUPS 管理页远程访问设置（不需要可略过） 修改配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 sudo vim /etc/cups/cupsd.conf ~~~ # 注释掉本地监听，设置监听 631 端口的所有请求 #Listen localhost:631 Port 631 # Restrict access to the server... \u003cLocation /\u003e Order allow,deny # 允许 192.168.1.1/24 网段的设备访问跟目录（/） Allow 192.168.1.* \u003c/Location\u003e # Restrict access to the admin pages... \u003cLocation /admin\u003e AuthType Default Require user @SYSTEM Order allow,deny # 允许 192.168.1.1/24 网段的设备访问管理页面（/admin） Allow 192.168.1.* \u003c/Location\u003e ~~~ 重启 cups 服务\n1 sudo systemctl restart cups 连接扫描仪 安装 sane\n1 sudo pacman -S sane 设置 sane 开机自启并立即启动\n1 sudo systemctl enable --now saned.socket 查看是否连接到扫描仪\n1 scanimage -L 这一步暂时是看不到目标扫描仪的\n修改配置文件\n1 2 3 4 sudo vim /etc/sane.d/pixma.conf # 将 IP 地址替换成扫描仪的 IP，在文件中添加 bjnp://192.168.1.20 查看是否连接到扫描仪\n1 2 3 scanimage -L # 此时应该会显示出目标扫描仪 device `pixma:G3000_192.168.1.20' is a CANON Canon PIXMA G3000 multi-function peripheral 测试扫描\n1 scanimage --device \"pixma:G3000_192.168.1.20\" --format=png --output-file test.png --progress 使用 GNOME 自带的 Document Scanner（simple-scan）也可使用该扫描仪\n参考文档：\nCUPS - ArchWiki SANE - ArchWiki SANE/Scanner-specific problems - ArchWiki ","description":"","tags":["Linux","Arch Linux"],"title":"Arch Linux 通过路由器无线连接 Canon PIXMA G3800","uri":"/posts/linux/arch-linux/archlinux-connect-canon-pixma-g3800-via-router/"},{"categories":null,"content":"OpenWrt 配置 DDNS 将 IPv6 解析到 CloudFlare 配置 CloudFlare 登录 CloudFlare，获取 Global API Key\n添加 DNS 记录\n配置 OpenWrt OpenWrt 版本：OpenWrt 21.02.3\n在 /root 目录创建 get-ipv6.sh 脚本\n1 2 3 4 5 6 7 # vim /root/get-ipv6.sh ~~~ #!/bin/sh ip -o addr show |/bin/grep -v deprecated|/bin/grep ' inet6 [^f:]'|/bin/sed -nr 's#^.+? +inet6 ([a-f0-9:]+)/.+? scope global .*? valid_lft ([0-9]+sec) .*#\\2 \\1#p'|/bin/grep 'ff:fe'|/usr/bin/sort -nr|/usr/bin/head -n1|/usr/bin/cut -d' ' -f2 ~~~ # chmod +x /root/get-ipv6.sh 安装 ddns-scripts 相关软件包\n1 2 # opkg update # opkg install ddns-scripts-cloudflare luci-app-ddns wget ca-certificates curl ca-bundle 打开管理页面，点击 Dynamic DNS\n点击下方的 Add new services...\nName：随便写，可以把域名中的点换成下划线，便于查看。例如：myhost_example_com IP address version：按需选择 IPv4-Address 或者 IPv6-Address DDNS Service Provider：选择 cloudflare.com-v4 设置完成后，点击 Create service，依次设置 Basic Settings、Advanced Settings、Timer Settings\nBasic Settings\nDomain 一栏要把三级域名和二级域名之间使用 @ 连接 Password：使用从 CloudFlare 获取的 Global API Key Advanced Settings：设置使用脚本方式获取本机的 IPv6 地址\nTimer Settings\n全部设置好后，点击 Save，并点击外面的 Save \u0026 Apply\n成功后，可以直接点击 Reload，然后查看 CloudFlare 上的 DNS 记录是否变化\n","description":"","tags":["OpenWrt"],"title":"OpenWrt 配置 DDNS 将 IPv6 解析到 CloudFlare","uri":"/posts/openwrt/openwrt-cloudflare-ddns/"},{"categories":null,"content":"Xray 结合 Cloudflare Warp 解锁 ChatGPT 下载安装 cloudflare-warp\n注册并连接 warp\n1 2 3 4 5 6 7 8 # 启动服务 sudo systemctl start warp-svc.service # 注册 warp-cli register # 连接，这里可能导致 ssh 断开连接 warp-cli connect # 验证，如果显示 warp=on，则表明设置成功 curl https://www.cloudflare.com/cdn-cgi/trace/ 修改 cloudflare-warp 使用 proxy 模式\n1 2 3 4 5 6 # 设置工作模式为 proxy warp-cli set-mode proxy # 设置 socks5 的监听端口，默认是 40000 warp-cli set-proxy-port 40000 # 验证，如果显示 warp=on，则表明设置成功 curl --socks5 127.0.0.1:40000 https://www.cloudflare.com/cdn-cgi/trace/ 修改 xray 配置文件，添加以下 routing.rule 和 outbound\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 { \"routing\":{ \"domainStrategy\":\"AsIs\", \"rules\":[ { \"type\":\"field\", \"domain\":[ \"domain:openai.com\" ], // 将域名以 openai.com 结尾请求路由到 tag 为 out-warp-proxy 的 outbound \"outboundTag\":\"out-warp-proxy\" } ] }, \"outbounds\":[ { \"protocol\":\"freedom\" }, { \"protocol\":\"socks\", \"settings\":{ \"servers\":[ { // cloudflare-warp 的 \"address\":\"127.0.0.1\", \"port\":40000, \"users\":[ // 如果设置了用户名和密码在这里添加 ] } ] }, // 该 outbound 的名称 \"tag\":\"out-warp-proxy\" } ] } ","description":"","tags":["VPN","AI","ChatGPT"],"title":"Xray 结合 Cloudflare Warp 解锁 ChatGPT","uri":"/posts/ai/xray-cloudflare-warp-unlock-chatgpt/"},{"categories":null,"content":"pacman 常用命令 更新系统（更新软件列表并升级所有软件包）\n1 pacman -Syu 安装软件包\n1 pacman -S \u003cpackage(s)\u003e 删除软件包\n1 pacman -R \u003cpackage(s)\u003e 删除软件包和只有它依赖的软件包\n1 pacman -Rs \u003cpackage(s)\u003e 删除软件包和所有不被任何软件依赖的软件包\n1 pacman -Ru \u003cpackage(s)\u003e 更新软件列表\n1 pacman -Sy 升级所有软件包\n1 pacman -Su 从远端仓库搜索软件包\n1 pacman -Ss [package] 显示软件仓库中的软件包\n1 pacman -Sl [repo] 查询已安装的软件包（不含软件包描述）\n1 pacman -Q [package] 查询已安装的软件包（包含软件包描述）\n1 pacman -Qs [package] 查询软件包的详细信息\n1 pacman -Qi [package(s)] 查询软件包的所有文件\n1 pacman -Ql [package(s)] 查询所有可以升级的软件包\n1 pacman -Qu 查询不被任何软件依赖的软件包\n1 pacman -Qt 查询所有不再作为依赖的软件包（名）\n1 2 3 pacman -Qdt # 只显示包名 pacman -Qdtq 删除不再作为依赖的软件包\n1 pacman -Rs $(pacman -Qdtq) 清理已删除的包文件（从缓存目录：/var/cache/pacman/pkg/）\n1 pacman -Sc 删除所有缓存文件\n1 pacman -Scc ","description":"","tags":["Linux","Arch Linux"],"title":"pacman 常用命令","uri":"/posts/linux/arch-linux/pacman-common-commands/"},{"categories":null,"content":"Xray 搭建 VPN Project X\n小小白白话文\n","description":"","tags":["VPN"],"title":"Xray 搭建 VPN","uri":"/posts/network/xray-vpn/"},{"categories":null,"content":"Log4j2 \u0026 SLF4J 引入依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u003cdependency\u003e \u003cgroupId\u003eorg.apache.logging.log4j\u003c/groupId\u003e \u003cartifactId\u003elog4j-api\u003c/artifactId\u003e \u003cversion\u003e2.19.0\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.logging.log4j\u003c/groupId\u003e \u003cartifactId\u003elog4j-core\u003c/artifactId\u003e \u003cversion\u003e2.19.0\u003c/version\u003e \u003c/dependency\u003e \u003c!-- The Apache Log4j SLF4J 2.0 API binding to Log4j 2 Core --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.logging.log4j\u003c/groupId\u003e \u003cartifactId\u003elog4j-slf4j2-impl\u003c/artifactId\u003e \u003cversion\u003e2.19.0\u003c/version\u003e \u003c/dependency\u003e 在 ClassPath 下添加配置文件 log4j2.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!-- status：设置Log4j2框架本身的日志级别，日志级别优先级：ALL \u003c TRACE \u003c DEBUG \u003c INFO \u003c WARN \u003c ERROR \u003c FATAL monitorInterval：每隔多少秒重新读取配置文件，可以在不重启应用的情况下修改配置--\u003e \u003cConfiguration status=\"ERROR\" monitorInterval=\"60\"\u003e \u003c!-- 定义常量，可在其它配置项中使用${变量名}进行引用。可选 --\u003e \u003cProperties\u003e \u003cProperty name=\"LOG_HOME\"\u003e/tmp\u003c/Property\u003e \u003cProperty name=\"PATTERN\"\u003e%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\u003c/Property\u003e \u003c/Properties\u003e \u003c!-- Appenders：日志输出位置，常用的有 Console、File、RollingFile 所有 Appender 见官方文档：https://logging.apache.org/log4j/2.x/manual/appenders.html --\u003e \u003cAppenders\u003e \u003c!-- 输出到控制台 name：输出器名 target：输出流。可选值：SYSTEM_OUT、SYSTEM_ERR。一般只设置 SYSTEM_OUT --\u003e \u003cConsole name=\"console\" target=\"SYSTEM_OUT\"\u003e \u003c!-- 输出格式，默认为\"%m%n\" --\u003e \u003cPatternLayout pattern=\"${PATTERN}\"/\u003e \u003c/Console\u003e \u003c!-- 输出到单个文件 name：输出器名 fileName：日志文件绝对路径 --\u003e \u003cFile name=\"file\" fileName=\"${LOG_HOME}/file/file.log\"\u003e \u003cPatternLayout pattern=\"${PATTERN}\"/\u003e \u003c/File\u003e \u003c!-- 输出到多个文件 name：输出器名 fileName：最新的日志会输出到该文件里，然后根据滚动策略（Policies） filePattern：归档文件输出格式 --\u003e \u003cRollingFile name=\"rollingFileInfo\" fileName=\"${LOG_HOME}/rollingFileInfo/rollingFile.log\" filePattern=\"${LOG_HOME}/rollingFileInfo/$${date:yyyy-MM}/rollingFileInfo-%d{yyyy-MM-dd}-%i.log\"\u003e \u003cPatternLayout pattern=\"${PATTERN}\"/\u003e \u003c!-- 日志滚动策略，常用的有 TimeBasedTriggeringPolicy 或 SizeBasedTriggeringPolicy --\u003e \u003cPolicies\u003e \u003c!-- 基于时间滚动 interval：间隔多少小时产生新文件 modulate：是否从 0 点开始计算时间间隔 --\u003e \u003cTimeBasedTriggeringPolicy interval=\"6\" modulate=\"true\"/\u003e \u003c/Policies\u003e \u003c!-- 日志过滤 level：日志级别 onMatch：接受/拒绝 level 及以上的日志，可选值：ACCEPT/DENY，通常使用 ACCEPT onMismatch：接受/拒绝 level 之下（不含）的日志，可选值：ACCEPT/DENY，通常使用 DENY--\u003e \u003cThresholdFilter level=\"INFO\" onMatch=\"ACCEPT\" onMismatch=\"DENY\"/\u003e \u003c!-- 同一文件夹下最多包含几个文件 max：7 --\u003e \u003cDefaultRolloverStrategy max=\"20\"/\u003e \u003c/RollingFile\u003e \u003cRollingFile name=\"rollingFileWarn\" fileName=\"${LOG_HOME}/rollingFileWarn/rollingFile.log\" filePattern=\"${LOG_HOME}/rollingFile/$${date:yyyy-MM}/rollingFileWarn-%d{yyyy-MM-dd}-%i.log\"\u003e \u003cPatternLayout pattern=\"${PATTERN}\"/\u003e \u003cPolicies\u003e \u003c!-- 基于文件大小滚动 size：每个日志文件最大大小 --\u003e \u003cSizeBasedTriggeringPolicy size=\"10MB\"/\u003e \u003c/Policies\u003e \u003c!-- 使用多个 Appender 和 ThresholdFilter 将不同级别的日志输出到不同的文件 --\u003e \u003cThresholdFilter level=\"WARN\" onMatch=\"ACCEPT\" onMismatch=\"DENY\"/\u003e \u003c/RollingFile\u003e \u003c/Appenders\u003e \u003c!-- 只有定义 Logger 并引入 Appender，Appender 才生效 --\u003e \u003cLoggers\u003e \u003c!-- 用来单独指定日志的形式 name：包路径 level：只输出 name 包下的 level 及以上级别的日志 additivity：设置该日志是否需要在 Root 中重复输出 --\u003e \u003cLogger name=\"oshi.util\" level=\"INFO\" additivity=\"false\"\u003e \u003c!-- 指定把这些日志输出到哪个 Appender ref：上方定义的 Appender 输出器名 --\u003e \u003cAppenderRef ref=\"console\"/\u003e \u003c/Logger\u003e \u003c!-- 指定项目默认的日志级别，默认只输出 level 及以上级别的日志 如果没有单独设置 Logger，默认就会使用 Root --\u003e \u003cRoot level=\"ALL\"\u003e \u003cAppenderRef ref=\"console\"/\u003e \u003cAppenderRef ref=\"file\"/\u003e \u003cAppenderRef ref=\"rollingFileInfo\"/\u003e \u003cAppenderRef ref=\"rollingFileWarn\"/\u003e \u003c/Root\u003e \u003c/Loggers\u003e \u003c/Configuration\u003e ","description":"","tags":["Java"],"title":"Log4j2 \u0026 SLF4J","uri":"/posts/java/log4j2-slf4j/"},{"categories":null,"content":"Arch Linux 2022.07.01 安装 电脑配置 启动 启动页面\n选择第一条：“Arch Linux install medium (x86_64, BIOS)”\n进入控制台页面\n安装 官方安装手册：https://wiki.archlinux.org/title/Installation_guide\n制作启动盘（略）\n连接无线网\n1 2 3 4 5 6 7 8 9 10 11 12 # 进入到 iwctl 的交互环境 $ iwctl # 列出所有无线网卡名称 [iwd]# device list # 使用指定的无线网卡扫描附近的 WIFI [iwd]# station \u003cdevice\u003e scan # 查看无线网卡扫描到的 WIFI 信息 [iwd]# station \u003cdevice\u003e get-networks # 使用指定无线网卡连接某个 WIFI，如果有密码会提示输入密码 [iwd]# station \u003cdevice\u003e connect SSID # Ctrl + d 退出 iwctl 交互环境，稍等一会测试是否联网成功 ping baidu.com 因为 Arch Linux 稍后需要从互联网下载必须的软件包，所以一定要联网\n更新系统时间\n1 2 3 4 # 自动同步互联网时间 timedatectl set-ntp true # 查看服务状态 timedatectl status 硬盘分区\n1 2 3 4 5 6 # 查看当前存在的磁盘信息 $ fdisk -l # 主要关注 Disk 后的 /dev/sda 和 /dev/nvme0n1。sdX 通常是机械硬盘，nvme0nX 通常是固态 Disk /dev/sda: 931.51 GiB, 1000204886016 bytes, 1953525168 sectors ... Disk /dev/nvme0n1: 238.47 GiB, 256060514304 bytes, 500118192 sectors 这里将 nvme0n1 分成如下两块：\n分区 分区类型 大小 挂载点 /dev/nvme0n1p1 EFI system partition 512M /mnt/boot /dev/nvme0n1p2 Linux filesystem 剩余所有 /mnt 没有分 swap 分区，是因为可以使用 swapfile 的方式设置交换空间，更灵活\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 $ fdisk /dev/nvme0n1 # 将磁盘格式化为 GPT 分区 Command (m for help): g # 新建第一个分区 Command (m for help): n Partition number (1-128, default 1): 1 First sector (2048-5001118158, default 2048): 2048 Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-500118158, default 500118158): +512M Do you want to remove the signature? [Y]es/[N]o: Y Command (m for help): t # 输入 L 查看分区类型的分区号 Partition type or alias (type L to list all): L 1 EFI System\tXXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXX 2 MBR partition scheme\tXXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXX ... # 使用 q 退出后，输入 EFI System 对应的编号 Partition type or alias (type L to list all): 1 # 新建第二个分区 Command (m for help): n Partition number (2-128, default 2): 2 First sector (1050624-5001118158, default 1050624): Last sector, +/-sectors or +/-size{K,M,G,T,P} (1050624-500118158, default 500117503): Do you want to remove the signature? [Y]es/[N]o: Y Command (m for help): t Partition number (1,2, default 2): 2 # 输入 L 查看分区类型的分区号 Partition type or alias (type L to list all): L 1 EFI System\tXXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXX ... 20 Linux filesystem\tXXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXX ... 23 Linux root (x86-64)\tXXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXX ... # 使用 q 退出后，输入 Linux filesystem 或 Linux root (x86-64) 对应的编号 Partition type or alias (type L to list all): 20 # 保存对分区的修改 Command (m for help): w 格式化分区\n1 2 $ mkfs.fat -F32 /dev/nvme0n1p1 $ mkfs.ext4 /dev/nvme0n1p2 挂载分区\n1 2 3 $ mount /dev/nvme0n1p2 /mnt # 以为 /mnt/boot 目录不存在，--mkdir 参数会自动创建该目录 $ mount --mkdir /dev/nvme0n1p1 /mnt/boot 安装基本软件包\n1 2 3 4 5 6 7 8 9 10 11 #修改 pacman 使用国内镜像站进行下载软件包 $ vim /etc/pacman.d/mirrorlist ~~~ # 在 Server 的最上方添加镜像站 Server = https://mirrors.tuna.tsinghua.edu.cn/archlinux/$repo/os/$arch ~~~ # 更新本地存储库 $ pacman -Syy # 安装基本软件包 $ pacstrap /mnt base linux linux-firmware 创建 fstab 文件，启动时自动挂载磁盘分区\n1 $ genfstab -U /mnt \u003e\u003e /mnt/etc/fstab chroot 到新的操作系统\n1 $ arch-chroot /mnt 设置新系统的时区\n1 $ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 将硬件时钟调整为和系统时钟一致，并生成 /etc/adjtime\n1 $ hwclock --systohc 本地化\n启用区域设置\n1 2 3 4 5 6 7 8 9 10 11 # 设置启用的区域 $ vim /etc/locale.gen ~~~ # 将以下两条记录前的 # 删除 en_US.UTF-8 UTF-8 ... zh_CN.UTF-8 UTF-8 ~~~ # 生成区域设置 $ locale-gen 设置系统的主语言环境\n1 2 3 $ echo LANG=en_US.UTF-8 \u003e /etc/locale.conf # 设置成功后可以查看当前系统的本地化信息 $ locale 设置主机名\n1 2 # 这里将主机名设置为 arch $ echo arch \u003e /etc/hostname 设置 hosts 文件\n1 2 3 4 5 6 7 $ vim /etc/hosts ~~~ 127.0.0.1\tlocalhost ::1\tlocalhost # arch 是主机名 127.0.0.2\tarch.localdomain\tarch ~~~ 设置 root 用户密码\n1 $ passwd 安装 GRUB 引导程序\n1 2 3 4 5 6 # 如果是 amd 的 CPU，需要将 intel-ucode 替换为 amd-ucode $ pacman -S grub efibootmgr intel-ucode # 将 GRUB 安装到 /boot 目录 $ grub-install --target=x86_64-efi --efi-directory=/boot --bootloader-id=GRUB # 创建 GRUB 的配置文件 $ grub-mkconfig -o /boot/grub/grub.cfg ThinkPad E480 安装完重启后不能引导 GRUB\n1 2 $ mkdir /boot/EFI/BOOT $ cp /boot/EFI/GRUB/grubx64.efi /boot/EFI/BOOT/BOOTx64.efi 如果没有复制 BOOTx64.efi 就关机了，可以使用安装盘启动，然后在安装盘的 GRUB 启动页面选择 UEFI Shell。\n1 2 3 4 5 6 7 8 Mapping table FS1: FS0: BLK2: # 通过 Mapping table 的结果，找到 EFI 分区 Shell\u003e FS1: FS1:\\\u003e mkdir EFI/BOOT FS1:\\\u003e cp EFI/GRUB/grubx64.efi EFI/BOOT/BOOTx64.efi 安装一些启动后的刚需应用\n1 2 # iwd 用于连接无线网 $ pacman -S vim iwd 退出 arch-chroot 并重启\n1 2 3 4 5 # 退出 arch-chroot $ exit # 取消安装盘对磁盘的挂载 $ umount -R /mnt $ reboot 常用设置 设置 vim 作为默认的编辑器\n1 echo EDITOR=/usr/bin/vim \u003e\u003e /etc/environment 调整 ~/.bashrc 和 ~/.bash_profile 文件\n这里从 Ubuntu 22.04 LTS 上复制过来一份，可以自行对配置进行修改\n~/.bashrc\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 # ~/.bashrc: executed by bash(1) for non-login shells. # If not running interactively, don't do anything case $- in *i*) ;; *) return;; esac # don't put duplicate lines or lines starting with space in the history. # See bash(1) for more options HISTCONTROL=ignoreboth # append to the history file, don't overwrite it shopt -s histappend # for setting history length see HISTSIZE and HISTFILESIZE in bash(1) HISTSIZE=1000 HISTFILESIZE=2000 # check the window size after each command and, if necessary, # update the values of LINES and COLUMNS. shopt -s checkwinsize # If set, the pattern \"**\" used in a pathname expansion context will # match all files and zero or more directories and subdirectories. #shopt -s globstar # make less more friendly for non-text input files, see lesspipe(1) [ -x /usr/bin/lesspipe ] \u0026\u0026 eval \"$(SHELL=/bin/sh lesspipe)\" # set variable identifying the chroot you work in (used in the prompt below) if [ -z \"${debian_chroot:-}\" ] \u0026\u0026 [ -r /etc/debian_chroot ]; then debian_chroot=$(cat /etc/debian_chroot) fi # set a fancy prompt (non-color, unless we know we \"want\" color) case \"$TERM\" in xterm-color|*-256color) color_prompt=yes;; esac # uncomment for a colored prompt, if the terminal has the capability; turned # off by default to not distract the user: the focus in a terminal window # should be on the output of commands, not on the prompt #force_color_prompt=yes if [ -n \"$force_color_prompt\" ]; then if [ -x /usr/bin/tput ] \u0026\u0026 tput setaf 1 \u003e\u0026/dev/null; then # We have color support; assume it's compliant with Ecma-48 # (ISO/IEC-6429). (Lack of such support is extremely rare, and such # a case would tend to support setf rather than setaf.) color_prompt=yes else color_prompt= fi fi if [ \"$color_prompt\" = yes ]; then PS1='${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ ' else PS1='${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$ ' fi unset color_prompt force_color_prompt # If this is an xterm set the title to user@host:dir case \"$TERM\" in xterm*|rxvt*) PS1=\"\\[\\e]0;${debian_chroot:+($debian_chroot)}\\u@\\h: \\w\\a\\]$PS1\" ;; *) ;; esac # enable color support of ls and also add handy aliases if [ -x /usr/bin/dircolors ]; then test -r ~/.dircolors \u0026\u0026 eval \"$(dircolors -b ~/.dircolors)\" || eval \"$(dircolors -b)\" alias ls='ls --color=auto' #alias dir='dir --color=auto' #alias vdir='vdir --color=auto' alias grep='grep --color=auto' alias fgrep='fgrep --color=auto' alias egrep='egrep --color=auto' fi # colored GCC warnings and errors #export GCC_COLORS='error=01;31:warning=01;35:note=01;36:caret=01;32:locus=01:quote=01' # some more ls aliases alias ll='ls -alF --time-style '\\''+%Y-%m-%d %H:%M:%S'\\''' alias la='ls -A' alias l='ls -CF' # Add an \"alert\" alias for long running commands. Use like so: # sleep 10; alert alias alert='notify-send --urgency=low -i \"$([ $? = 0 ] \u0026\u0026 echo terminal || echo error)\" \"$(history|tail -n1|sed -e '\\''s/^\\s*[0-9]\\+\\s*//;s/[;\u0026|]\\s*alert$//'\\'')\"' # Alias definitions. # You may want to put all your additions into a separate file like # ~/.bash_aliases, instead of adding them here directly. # See /usr/share/doc/bash-doc/examples in the bash-doc package. if [ -f ~/.bash_aliases ]; then . ~/.bash_aliases fi # enable programmable completion features (you don't need to enable # this, if it's already enabled in /etc/bash.bashrc and /etc/profile # sources /etc/bash.bashrc). if ! shopt -oq posix; then if [ -f /usr/share/bash-completion/bash_completion ]; then . /usr/share/bash-completion/bash_completion elif [ -f /etc/bash_completion ]; then . /etc/bash_completion fi fi ~/.bash_profile\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # if running bash if [ -n \"$BASH_VERSION\" ]; then # include .bashrc if it exists if [ -f \"$HOME/.bashrc\" ]; then . \"$HOME/.bashrc\" fi fi # set PATH so it includes user's private bin if it exists if [ -d \"$HOME/bin\" ] ; then PATH=\"$HOME/bin:$PATH\" fi # set PATH so it includes user's private bin if it exists if [ -d \"$HOME/.local/bin\" ] ; then PATH=\"$HOME/.local/bin:$PATH\" fi 启用网卡和网络服务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 查看网卡信息，如果网卡状态是 DOWN，需要启用网卡 $ ip link # 启用网卡 $ ip link set enp0s3 up # 启动无线网卡 ip link set wlan0 up # 网络服务 $ systemctl start systemd-networkd; # 域名解析服务 $ systemctl start systemd-resovled; # 无线网络服务（systemd-networkd 暂不支持无线，所以需要使用 iwd 服务连接无线） $ systemctl start iwd; # 开机自启 $ systemctl enable systemd-networkd; $ systemctl enable systemd-resovled; $ systemctl enable iwd; # systemd-resolved 会在 /run/systemd 目录下某个地方创建它自己的 resolv.conf。但是，把 DNS 解析信息存放在 /etc/resolv.conf 是更普遍的做法，很多应用程序也会依赖于 /etc/resolv.conf。因此为了兼容性，按照下面的方式创建一个到 /etc/resolv.conf 的符号链接。 $ rm /etc/resolv.conf $ ln -s /run/systemd/resolve/resolv.conf /etc/resolv.conf 设置 DHCP/静态IP\nDHCP\n1 2 3 4 5 6 7 8 $ vim /etc/systemd/network/20-enp3-dhcp.network ~~~ [Match] # 可以使用准确的网络设备名，也可以使用 enp3* 表示 enp3 开头的任意设备 Name=enp3* [Network] DHCP=yes ~~~ 1 2 3 4 5 6 7 $ vim /etc/systemd/network/20-wlan0-dhcp.network ~~~ [Match] Name=wlan0 [Network] DHCP=yes ~~~ 静态 IP\n1 2 3 4 5 6 7 8 9 $ vim /etc/systemd/network/10-enp3s0-static.network ~~~ [Match] Name=enp3s0 [Network] Address=192.168.1.2/24 Gateway=192.168.1.1 DNS=8.8.8.8 ~~~ 文件名可以任意设置，但是加载配置时会按照文件名的词汇顺序进行加载。通常文件名格式为 数字-名称.network。20-enp3-dhcp 和 10-enp3s0-static 均对 enp3s0 进行了设置，但是 10-enp3s0-static 在 20-enp3-dhcp 之前，所以对 enp3s0 的静态配置优先级高于 DHCP 配置。\n连接无线网\niwd 服务中包含 iwctl 命令。参考 安装下的 2. 连接无线网 。\n安装命令补全工具\nbash 默认只能对命令和路径进行自动补全，不支持对命令的选项等进行自动补全。所以可以通过安装 bash-completion 来增强 bash 的自动补全功能\n1 $ sudo pacman -S bash-completion 安装并开启 ssh 服务\n1 2 3 4 5 6 7 8 $ pacman -S open-ssh $ systemctl start sshd $ systemctl enable sshd # 设置允许 root 用户使用密码的方式进行 SSH 登录 $ vim /etc/ssh/sshd_config ~~~ PermitRootLogin yes ~~~ 创建新用户并授予 sudo 权限\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 查看新增用户时的默认设置 /etc/default/useradd $ useradd --default ~~~ GROUP=984 HOME=/home INACTIVE=-1 EXPIRE= SHELL=/bin/bash # .bash* 的默认配置文件 SKEL=/etc/skel CREATE_MAIL_SPOOL=no LOG_INIT=yes ~~~ # 新增用户 $ useradd newuser $ mkdir /home/newuser $ chown newuser: /home/newuser # 有新用户之后，就可以禁止 root 通过 ssh 进行登录了。 # 可以使用普通用户登录后，执行 su - root 切换到 root 用户 # 删除配置文件中的下面一行 $ vim /etc/ssh/sshd_config ~~~ PermitRootLogin yes ~~~ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 安装 sudo 工具 $ pacman -S sudo # 修改 /etc/sudoers 文件 $ visudo ~~~ ## User privilege specification ## root ALL=(ALL:ALL) ALL ## Read drop-in files from /etc/sudoers.d @includedir /etc/sudoers.d ~~~ # sudoers 文件下方包含 @includedir /etc/sudoers.d，所以可以把需要添加的配置写到该文件夹，这样可以不修改默认的配置文件。通常使用用户名作为配置文件名 # 设置 newuser 用户可以使用 sudo 执行所有命令 $ echo 'newuser ALL=(ALL) ALL' \u003e /etc/sudoers.d/newuser screen\n1 $ sudo pacman -S screen 图形化界面（GNOME，Wayland）\n安装 GNOME\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 $ sudo pacman -Syu \u0026\u0026 sudo pacman -S gnome ~~~ :: There are 59 members in group gnome: :: Repository extra 1) baobab 2) cheese 3) eog 4) epiphany 5) evince 6) file-roller 7) gdm 8) gedit 9) gnome-backgrounds 10) gnome-books 11) gnome-calculator 12) gnome-calendar 13) gnome-characters 14) gnome-clocks 15) gnome-color-manager 16) gnome-contacts 17) gnome-control-center 18) gnome-disk-utility 19) gnome-font-viewer 20) gnome-keyring 21) gnome-logs 22) gnome-maps 23) gnome-menus 24) gnome-music 25) gnome-photos 26) gnome-remote-desktop 27) gnome-session 28) gnome-settings-daemon 29) gnome-shell 30) gnome-shell-extensions 31) gnome-software 32) gnome-system-monitor 33) gnome-terminal 34) gnome-user-docs 35) gnome-user-share 36) gnome-video-effects 37) gnome-weather 38) grilo-plugins 39) gvfs 40) gvfs-afc 41) gvfs-goa 42) gvfs-google 43) gvfs-gphoto2 44) gvfs-mtp 45) gvfs-nfs 46) gvfs-smb 47) malcontent 48) mutter 49) nautilus 50) orca 51) rygel 52) sushi 53) totem 54) tracker3-miners 55) vino 56) xdg-user-dirs-gtk 57) yelp :: Repository community 58) gnome-boxes 59) simple-scan Enter a selection (default=all): resolving dependencies... :: There are 2 providers available for jack: :: Repository extra 1) jack2 2) pipewire-jack Enter a number (default=1): :: There are 2 providers available for emoji-font: :: Repository extra 1) noto-fonts-emoji :: Repository community 2) ttf-joypixels Enter a number (default=1): :: There are 5 providers available for xdg-desktop-portal-impl: :: Repository extra 1) xdg-desktop-portal-gnome 2) xdg-desktop-portal-gtk 3) xdg-desktop-portal-kde :: Repository community 4) xdg-desktop-portal-lxqt 5) xdg-desktop-portal-wlr Enter a number (default=1): ~~~ 设置在 tty1 进行登录时启动图形化界面\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 因为 /etc/profile 文件中包含下面的代码，所以可以在 /etc/profile.d 目录下创建以 .sh 结尾的脚本文件，在进行登录时，自动执行这些脚本 $ cat /etc/profile ~~~ # Load profiles from /etc/profile.d if test -d /etc/profile.d/; then for profile in /etc/profile.d/*.sh; do test -r \"$profile\" \u0026\u0026 . \"$profile\" done unset profile fi ~~~ # 创建在 tty1 登录时启动图形界面的脚本，文件名任意。如果只想在某个用户登录时才启动图形界面，则可以将下放的代码放到 ~/.bash_profile 文件中 $ sudo vim /etc/profile.d/gnome.sh ~~~ if [[ -z $DISPLAY \u0026\u0026 $(tty) == /dev/tty1 \u0026\u0026 $XDG_SESSION_TYPE == tty ]]; then MOZ_ENABLE_WAYLAND=1 QT_QPA_PLATFORM=wayland XDG_SESSION_TYPE=wayland exec dbus-run-session gnome-session fi ~~~ 设置启动时，显示图形化的登录页面\n1 2 3 4 5 # 使用 gnome 后，即使没有配置在 tty1 进行登录时启动图形化界面，开机后通过 gdm 登录也可以进入到图形化界面 $ sudo rm -rf /etc/profile.d/gnome.sh $ sudo pacman -S gdm $ sudo systemctl start gdm.service $ sudo systemctl enable gdm.service 安装 yay pacman 只能安装官方仓库提供好的软件包，用户上传到 AUR 中的包可以通过安装脚本或者 yay 等进行安装\n1 2 3 4 5 6 7 8 # 要安装 AUR 中的包必须安装 base-devel。在安装 AUR 中包的过程中需要使用 git $ sudo pacman -S --needed base-devel git # 从 AUR 中搜索 yay，复制 Git Clone URL 后的 URL，粘贴到 git clone 命令下 $ git clone https://aur.archlinux.org/yay.git # 在 yay 文件夹中会包含一个 PKGBUILD 脚本文件，AUR 中的每个包都是一个 PKGBUILD 脚本 $ cd yay # 构建并安装软件包。-s 表示自动执行 pacman 解决依赖关系；-i 表示构建软件包成功后立即安装。也可以在构建软件包结束后使用 pacman -U package.pkg.tar.xz 手动安装软件包 $ makepkg -si 在 yay 的 PKGBUILD 脚本中会去 go 的官网下载 go，而国内访问 go 的官网很慢，所以可能安装失败。可以使用下面的方式安装\n1 2 3 4 5 6 7 8 9 10 11 12 # 给 pacman 添加 archlinuxcn 仓库 $ sudo vim /etc/pacman.conf ~~~ # 添加到 /etc/pacman.conf 文件的末尾即可 [archlinuxcn] Server = https://mirrors.tuna.tsinghua.edu.cn/archlinuxcn/$arch ~~~ # 导入 archlinuxcn 的 GPG key $ sudo pacman -S archlinuxcn-keyring # 安装 yay $ sudo pacman -S yay archlinuxcn 仓库是由 Arch Linux 中文社区驱动的非官方仓库，包含中文用户常用的软件、工具、字体/美化包等\n从 AUR 安装 rtl8821ce 无线网卡驱动 rtl8821ce-dkms-git 1 2 3 4 # 查看网卡型号 $ lspci # 网卡驱动应该以 root 用户身份来安装 $ sudo yay -S rtl8821ce-dkms-git 切换网络管理服务\n因为 GNOME 默认使用 NetworkManager 服务管理网络，所以，安装并启用 NetworkManger，禁用 systemd-networkd 和 iwd 服务（NetworkManager 可以同时管理有线和无线网络，如果使用多个组件管理网络可能会有冲突）\n1 2 3 4 5 $ sudo pacman -S networkmanager $ sudo systemctl stop systemd-networkd iwd $ sudo systemctl disable systemd-networkd iwd $ sudo systemctl start NetworkManager $ sudo systemctl enable NetworkManager 启动蓝牙服务\n1 2 $ sudo systemctl start bluetooth $ sudo systemctl enable bluetooth 关闭自动休眠\n电脑休眠后会断开网络连接，如果需要进行远程操作，可以关闭自动休眠。在 GNOME 桌面下，进入 Settings -\u003e Power，关闭 Automatic Suspend，但是这种方式并没有生效，这有一种看不懂的 方式 说可以解决（没有测试）。还有下面这种方式，亲测可以解决：\n1 2 3 4 # 关闭 睡眠、挂起、休眠、混合睡眠 $ sudo systemctl mask sleep.target suspend.target hibernate.target hybrid-sleep.target # 恢复自动休眠 $ sudo systemctl umask sleep.target suspend.target hibernate.target hybrid-sleep.target sleep：通常表示关闭显示器，不同的系统可能会有不同的实现 suspend：suspend to RAM hibernate：suspend to disk hybrid-sleep：suspend to both，将电脑状态保存在二者中，电脑不掉电可以从 RAM 中恢复，否则可以从 disk 恢复 常用软件 浏览器\n1 2 3 4 # 微软的 Edge 在国内可以同步书签等 $ sudo yay -S microsoft-edge # 谷歌 Chrome 浏览器 $ sudo yay -S google-chrome 安装完后可能会因为缺少中文字体而出现乱码\n安装中文字体\n1 2 3 4 # 查看已安装的中文字体 $ fc-list :lang=zh # 安装开源的文泉驿微米黑中文字体 $ sudo pacman -S wqy-microhei 安装中文输入法\nGNOME 默认使用 ibus 输入法框架，所以这里安装 ibus-rime\n1 $ sudo pacman -S ibus-rime 然后在 Settings -\u003e Region\u0026Language -\u003e Input Sources 中添加 Chinese(Rime)，使用 Super+Space 切换输入法\n远程桌面\nGNOME 40 之后默认使用 freerdp 作为远程桌面服务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 安装所需的依赖包 $ sudo pacman -S gnome-remote-desktop pipewire pipewire-media-session # 将所需的服务设置为开机自启，并立即启动（--now）这些服务 $ systemctl --user enable --now gnome-remote-desktop pipewire pipewire-media-session gnome-remote-desktop # 启动并配置远程桌面 Settings -\u003e Sharing -\u003e Remote Desktop # 远程桌面在 GNOME 中被配置为了用户服务，所以必须登录后才能启动远程桌面服务。所以如果要在无人值守时远程访问，需要设置开机自动登录 $ sudo vim /etc/gdm/custom.conf ~~~ [daemon] AutomaticLoginEnable=True AutomaticLogin=username ~~~ # 如果电脑黑屏或者锁屏也会断开远程连接，所以禁止关闭屏幕 Settings -\u003e Power-\u003e Screen Blank 设置为 Never 其它可能用到的命令\n除了使用图形界面操作，还可以使用 grdctl 命令对远程桌面进行设置\n如果远程桌面连接失败，可以使用如下命令查看日志\n1 2 3 4 # 先关闭正在运行中的远程桌面服务 $ systemctl --user stop gnome-remote-desktop # 使用命令方式查看远程桌面服务的系统日志 $ env WLOG_LEVEL=DEBUG G_MESSAGES_DEBUG=all /usr/lib/gnome-remote-desktop-daemon 创建服务证书和私钥文件\n1 2 3 openssl genrsa -out rdp-tls.key 4096 openssl req -new -key rdp-tls.key -out rdp-tls.csr openssl x509 -req -days 730 -signkey rdp-tls.key -in rdp-tls.csr -out rdp-tls.crt bash-git-prompt\n该工具为 Git 用户提供信息丰富的 bash 提示\n1 2 3 4 5 6 7 8 9 10 11 # 将文件克隆到用户目录 $ git clone https://github.com/magicmonty/bash-git-prompt.git ~/.bash-git-prompt --depth=1 # 在 ~/.bashrc 中添加以下配置 ~~~ if [ -f \"$HOME/.bash-git-prompt/gitprompt.sh\" ]; then GIT_PROMPT_ONLY_IN_REPO=1 source $HOME/.bash-git-prompt/gitprompt.sh fi ~~~ # 重载 ~/.bashrc 配置 $ source ~/.bashrc 参考文档：\nInstallation guide 技术|如何在 Linux 上从 NetworkManager 切换为 systemd-network 清华大学开源软件镜像站 Localization (简体中文)/Simplified Chinese (简体中文) How to Disable Suspend and Hibernation Modes In Linux Error when connecting via RDP GNOME Remote Desktop - RDP setup guide How is the Gnome 42's new default RDP supposed to work? ","description":"","tags":["Linux","Arch Linux"],"title":"Arch Linux 2022.07.01 安装","uri":"/posts/linux/arch-linux/archlinux-20220701-install/"},{"categories":null,"content":"小米 R4A 千兆路由器刷 OpenWrt 一开始按照 B 站和恩山论坛上先刷 Breed 然后再刷 OpenWrt 的方式，但是刷完之后磁盘都是 tmpfs，路由器重启就会恢复出厂设置。所以下方是按照 OpenWrt 的 官方文档 提供的方式进行的。\n准备环境 下载官方 2.28.62 版本的 刷机包\n安装 Python 3\n下载 OpenWRTInvasion\n推荐使用 0.0.8 版本，0.0.8 版本不需要去 github 下载依赖包，并且可以自动获取 stok\n在 Firmware Selector 下载 squashfs-sysupgrade.bin（可以去官网下载最新的）\n使用网线将互联网和路由器，路由器和电脑进行连接，然后设置好路由器，使其能正常联网\n操作流程 修改路由器系统版本 最好将路由器的系统版本修改为 2.28.62，否则使用 OpenWRTInvasion 可能获取不到 telnet 权限。\n固件下载地址：miwifi_r4a_firmware_72d65_2.28.62.bin\n登录路由器控制台：192.168.31.1，点击右上角用户的下拉框，选择：系统升级。然后点击手动升级，选择下载好的固件即可 刷机过程中路由器会闪黄灯，成功之后会变蓝灯 破解获取路由器的 telnet 功能 解压并运行（OpenWRTInvasion）\n1 2 3 4 5 6 7 tar -zxvf OpenWRTInvasion-0.0.8.tar.gz cd OpenWRTInvasion-0.0.8 python -m pip install --upgrade pip pip install -r requirements.txt # 关闭防火墙，否则无法从本地服务获取到所需的依赖包（busybox 和 dropbear） sudo systemctl stop firewalld python remote_command_execution_vulnerability.py 这里安装必须包时，pycrypto 包可能报错。需要先在系统上安装 python-dev 包\n按提示输入信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 Router IP address [press enter for using the default 'miwifi.com']: Enter router admin password: ******** There two options to provide the files needed for invasion: 1. Use a local TCP file server runing on random port to provide files in local directory `script_tools`. 2. Download needed files from remote github repository. (choose this option only if github is accessable inside router device.) Which option do you prefer? (default: 1) **************** router_ip_address: miwifi.com stok: 8cf2b91b14feeb00d4cc7f965bd9ab0f file provider: local file server **************** start uploading config file... start exec command... local file server is runing on 0.0.0.0:41781. root='script_tools' # 注意，只有打印出这两条才说明从本地获取文件成功，否则就是失败的 local file server is getting 'busybox-mipsel' for 192.168.31.1. local file server is getting 'dropbearStaticMipsel.tar.bz2' for 192.168.31.1. # telnet 连接时，用户名和密码都是 root done! Now you can connect to the router using several options: (user: root, password: root) * telnet miwifi.com * ssh -oKexAlgorithms=+diffie-hellman-group1-sha1 -c 3des-cbc -o UserKnownHostsFile=/dev/null root@miwifi.com * ftp: using a program like cyberduck 连接路由器控制台，使用用户名和密码登录成功即破解成功\n1 telnet miwifi.com 如果成功会打印出如下信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 XiaoQiang login: root Password: BusyBox v1.19.4 (2019-06-28 10:13:42 UTC) built-in shell (ash) Enter 'help' for a list of built-in commands. ----------------------------------------------------- Welcome to XiaoQiang! ----------------------------------------------------- $$$$$$\\ $$$$$$$\\ $$$$$$$$\\ $$\\ $$\\ $$$$$$\\ $$\\ $$\\ $$ __$$\\ $$ __$$\\ $$ _____| $$ | $$ | $$ __$$\\ $$ | $$ | $$ / $$ |$$ | $$ |$$ | $$ | $$ | $$ / $$ |$$ |$$ / $$$$$$$$ |$$$$$$$ |$$$$$\\ $$ | $$ | $$ | $$ |$$$$$ / $$ __$$ |$$ __$$\u003c $$ __| $$ | $$ | $$ | $$ |$$ $$\u003c $$ | $$ |$$ | $$ |$$ | $$ | $$ | $$ | $$ |$$ |\\$$\\ $$ | $$ |$$ | $$ |$$$$$$$$\\ $$$$$$$$$ | $$$$$$ |$$ | \\$$\\ \\__| \\__|\\__| \\__|\\________| \\_________/ \\______/ \\__| \\__ root@XiaoQiang:~# 备份并刷入 OpenWrt 查看路由器分区信息\n1 2 3 4 5 6 7 cat /proc/mtd dev: size erasesize name mtd0: 01000000 00010000 \"ALL\" mtd1: 00030000 00010000 \"Bootloader\" mtd2: 00010000 00010000 \"Config\" ... 将 Bootloader 备份到路由器的 tmp 目录\n1 2 dd if=/dev/mtd0 of=/tmp/ALL.bin dd if=/dev/mtd1 of=/tmp/Bootloader.bin ALL 中包含下面的所有配置，如果路由器成砖，可以使用编程器进行恢复\nBootloader 是启动器文件，如果路由器成砖，可以结合使用 小米路由器修复工具 恢复\n新开一个终端，将路由器中的备份拷贝出来\n1 2 3 4 lftp root@miwifi.com # 会将该文件拷贝到当前目录 lftp root@miwifi.com:/\u003e get /tmp/ALL.bin lftp root@miwifi.com:/\u003e get /tmp/Bootloader.bin 将 openwrt 文件放到路由器中\n1 2 3 lftp root@miwifi.com:/\u003e cd /tmp # 把当前目录下的该文件拷贝到 /tmp 目录 lftp root@miwifi.com:/tmp\u003e put openwrt-21.02.3-ramips-mt7621-xiaomi_mi-router-4a-gigabit-squashfs-sysupgrade.bin 回到 telnet 的终端，刷入 breed\n1 2 cd /tmp mtd -e OS1 -r write openwrt-21.02.3-ramips-mt7621-xiaomi_mi-router-4a-gigabit-squashfs-sysupgrade.bin OS1 安装后的常用配置 使用 ssh 进行连接\n1 ssh root@192.168.1.1 修改 root 的密码\n命令行方式\n1 passwd root 图形页面方式\nSystem -\u003e Administration -\u003e Router Password\n修改 IP 和网段\n命令行方式\n1 vim /etc/config/network 1 2 3 4 5 6 7 config interface 'lan' option device 'br-lan' option proto 'static' option netmask '255.255.255.0' option ip6assign '60' # 修改这个 IP 地址即可 option ipaddr '192.168.8.1 1 reboot 图形页面方式\nNetwork -\u003e Interfaces，点击 LAN 后的 Edit，修改 IPv4 address，然后点击 Save。点击 LAN 中间出现的 Interface has 1 pending changes 提示，并点击 Save \u0026 Apply\n修改 SSH 端口等连接信息\n1 vim /etc/config/dropbear 设置 WI-FI\n网络 -\u003e 无线，修改下面两条记录的配置\n常规配置：\nESSID：无线名称 无线安全：\n加密：选择带密码的，这里选的是 WPA2-PSK/WPA3-SAE Mixed 秘钥：无线密码 802.11r 快速切换：两个记录的无线、加密方式、秘钥均相同时，勾选该选项，即可做到双频合一 修改之后，将这两个记录启用，并点击“保存并应用”\n设置静态 IP\n在“概览”页面下方“已分配的 DHCP 租约”处，点击“设为静态”，然后通过命令行修改 /etc/config/dhcp\n1 2 3 4 5 config host option name 'machine-name' # 在这里设置静态 IP option ip '192.168.1.2' option mac 'EA:6B:45:23:DE:5B' reboot 重启路由器\n修改 opkg 包管理器的镜像\n1 2 3 vim /etc/opkg/distfeeds.conf :%s@downloads.openwrt.org@mirrors.tuna.tsinghua.edu.cn/openwrt@% 1 2 3 4 5 6 7 # 将 downloads.openwrt.org 替换为 mirrors.tuna.tsinghua.edu.cn/openwrt src/gz openwrt_core https://mirrors.tuna.tsinghua.edu.cn/openwrt/releases/21.02.3/targets/ramips/mt7621/packages src/gz openwrt_base https://mirrors.tuna.tsinghua.edu.cn/openwrt/releases/21.02.3/packages/mipsel_24kc/base src/gz openwrt_luci https://mirrors.tuna.tsinghua.edu.cn/openwrt/releases/21.02.3/packages/mipsel_24kc/luci src/gz openwrt_packages https://mirrors.tuna.tsinghua.edu.cn/openwrt/releases/21.02.3/packages/mipsel_24kc/packages src/gz openwrt_routing https://mirrors.tuna.tsinghua.edu.cn/openwrt/releases/21.02.3/packages/mipsel_24kc/routing src/gz openwrt_telephony https://mirrors.tuna.tsinghua.edu.cn/openwrt/releases/21.02.3/packages/mipsel_24kc/telephony 1 2 # 更新软件包列表 opkg update 安装插件\n命令行方式\n1 2 3 4 5 6 7 8 9 10 # 查询所有已安装的软件 opkg list-installed # 查询所有可安装的软件 opkg list # 安装软件 opkg install \u003cpkgs\u003e # 卸载软件 opkg remove \u003cpkgs|regexp\u003e # 升级所有软件 opkg upgrade \u003cpkgs\u003e 图形化界面方式\nSystem -\u003e Software\n常用插件\n汉化包：luci-i18n-base-zh-cn ","description":"","tags":["OpenWrt"],"title":"小米 R4A 1200M 路由器刷 OpenWrt","uri":"/posts/openwrt/xiaomi-r4a-openwrt/"},{"categories":null,"content":"Docker 安装 Oracle 19c 安装 在宿主机上创建数据目录\n1 2 mkdir ~/Data/docker/oracle19c/oradata chown 54321.54321 ~/Data/docker/oracle19c/oradata 启动容器\ndocker 镜像地址：https://hub.docker.com/r/zhuyijun/oracle-12c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 docker run -d \\ --name orcl19c \\ --shm-size=2G \\ -p 1521:1521 -p 5500:5500 \\ -e ORACLE_SID=orcl \\ -e ORACLE_PDB=orclpdb1 \\ -e ORACLE_PWD=123456 \\ -e ORACLE_EDITION=standard \\ -e ORACLE_CHARACTERSET=al32utf8 \\ -e ORACLE_BASE=/opt/oracle \\ -e ORACLE_HOME=/opt/oracle/product/19c/dbhome_1 \\ -e PATH=/opt/oracle/product/19c/dbhome_1/bin:/opt/oracle/product/19c/dbhome_1/OPatch/:/usr/sbin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\ -v ~/Data/docker/oracle19c/oradata:/opt/oracle/oradata \\ registry.cn-hangzhou.aliyuncs.com/zhuyijun/oracle:19c 查看启动日志\n1 docker logs -ft orcl19c 常见错误 ORA-01078: failure in processing system parameters LRM-00109: could not open parameter file '/opt/oracle/product/19c/dbhome_1/dbs/initorcl.ora'\n1 2 # 缺少文件，从默认位置拷贝一份 cp /opt/oracle/admin/ORCL/pfile/init.ora.61202262246 /opt/oracle/product/19c/dbhome_1/dbs/initorcl.ora ORA-01261: Parameter db_recovery_file_dest destination string cannot be translated\n1 2 3 4 5 # 查看配置文件中 db_recovery_file_dest 的配置 cat /opt/oracle/product/19c/dbhome_1/dbs/initorcl.ora db_recovery_file_dest='\u003cORACLE_BASE\u003e/fast_recovery_area' # 创建这个文件夹 mkdir $ORACLE_BASE/fast_recovery_area ORA-01102: cannot mount database in EXCLUSIVE mode\n1 2 3 4 5 cd /opt/oracle/product/19c/dbhome_1/dbs # 杀死正在访问 lkORCL 的进程 fuser -k lkORCL # 确认已经杀死进程 fuser -u lkORCL kill 掉 lkORCL 进程后，需要重新启动数据库\n1 2 3 4 5 6 7 8 # 启动 oracle 例程。如果单独使用 startup 启动报错，可以尝试加上 pfile 参数 startup pfile='/opt/oracle/product/19c/dbhome_1/dbs/initorcl.ora' # 开启数据库 alter database open; # 如果提示缺少 spfile，则创建 create spfile from pfile='/opt/oracle/product/19c/dbhome_1/dbs/initorcl.ora'; # 关闭 oracle 例程和数据库 shutdown immediate ORA-00214: control file '/opt/oracle/oradata/ORCL/control01.ctl' version 1439 inconsistent with file '/opt/oracle/oradata/ORCL/control02.ctl' version 1386\n1 2 # 控制文件版本不一致，用 01 覆盖掉 02 cp /opt/oracle/oradata/ORCL/control01.ctl /opt/oracle/oradata/ORCL/control02.ctl 常用操作 连接数据库\n1 2 3 4 # 以管理员身份连接 sqlplus / as sysdba # 以指定用户连接到指定实例 sqlplus \u003cusername\u003e/\u003cpassword\u003e@\u003cinstance\u003e 创建/删除表空间\n1 2 3 create tablespace \u003ctablespace_name\u003e datafile '\u003cpath to datafile\u003e' size 500M autoextend on extent management local segment space management auto; drop tablespace \u003ctablespace_name\u003e including contents cascade constraints; 新建用户\nOracle 12c 之后添加了 CDB（Container Database），默认连接的都是 CDB。在 CDB 中创建用户，用户名必须以 C## 或 c## 开头\nInstance : CDB : PDB（Pluggable Databases） = 1 : N : N\n1 2 3 4 5 6 7 8 # 创建用户 create user \u003cusername\u003e identified by \u003cpassword\u003e [default tablespace \u003ctablespace_name\u003e]; # 用户授权。授予用户 connect,resource,dba 权限 grant connect,resource,dba to \u003cusername\u003e; # 修改用户密码 alter user \u003cusername\u003e identified by \u003cpassword\u003e; # 删除用户。cascade 是级联删除掉属于该用户的所有库表等 drop user \u003cusername\u003e [cascade]; CDB 和 PDB 操作\n1 2 3 4 5 6 7 8 9 10 # 查看当前容器 show con_name; # 查看 PDB 信息 show pdbs; # 切换 CDB 或者 PDB alter session set container=\u003cpdbname/cdbname\u003e # 开启 PDB alter pluggable database \u003cpdbname\u003e open; # 创建 PDB create pluggable database \u003cpdbname\u003e admin user \u003cusername\u003e identified by \u003cpassword\u003e default tablespace \u003ctablespace_name\u003e 查看数据库字符集\n1 2 3 select * from v$nls_parameters where parameter='NLS_CHARACTERSET'; # 通过设置环境变量的方式修改字符集 export NLS_LANG=\"SIMPLIFIED CHINESE_CHINA.AL32UTF8\" 执行 SQL 脚本\n1 2 3 4 5 6 7 8 # 设置一些参数，防止乱码 set define off; set echo off; set termout off; #执行脚本 start \u003cpath to sql script\u003e # 提交事务 commit; 导出导入\n1 2 3 4 # 如果指定了 tables 参数就只导出指定的表，否则导出实例下的所有表 exp \u003cusername\u003e/\u003cpassword\u003e@\u003cinstance\u003e [tables='\u003ctable1_name\u003e','\u003ctable2_name\u003e',...] file=\u003cpath to dump file\u003e compress=n # 导入文件 imp \u003cusername\u003e/\u003cpassword\u003e@\u003cinstance\u003e file=\u003cpath to dump file\u003e ignore=y full=y ","description":"","tags":["Oracle","Docker"],"title":"Docker 安装 Oracle 19c","uri":"/posts/database/oracle19c-install-by-docker/"},{"categories":null,"content":"Maven 同时使用私有仓库和公共仓库 让 Maven 先从私服查找依赖包，如果在私服找不到，则从公共仓库查找。\n在 settings.xml 中配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 \u003csettings\u003e ... \u003cprofiles\u003e \u003c!-- 企业内部私有仓库 --\u003e \u003cprofile\u003e \u003cid\u003einternal-public\u003c/id\u003e \u003crepositories\u003e \u003crepository\u003e \u003cid\u003einternal-public\u003c/id\u003e \u003curl\u003ehttp://nexus.internal.domain/repository/internal-public/\u003c/url\u003e \u003creleases\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003c/releases\u003e \u003csnapshots\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003ealways\u003c/updatePolicy\u003e \u003c/snapshots\u003e \u003c/repository\u003e \u003c/repositories\u003e \u003cpluginRepositories\u003e \u003cpluginRepository\u003e \u003cid\u003einternal-public\u003c/id\u003e \u003curl\u003ehttp://nexus.internal.domain/repository/internal-public/\u003c/url\u003e \u003creleases\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003c/releases\u003e \u003csnapshots\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003ealways\u003c/updatePolicy\u003e \u003c/snapshots\u003e \u003c/pluginRepository\u003e \u003c/pluginRepositories\u003e \u003c/profile\u003e \u003c!-- 阿里云公共仓库 --\u003e \u003cprofile\u003e \u003cid\u003ealiyun-public\u003c/id\u003e \u003crepositories\u003e \u003crepository\u003e \u003cid\u003ealiyun-public\u003c/id\u003e \u003curl\u003ehttps://maven.aliyun.com/repository/public/\u003c/url\u003e \u003creleases\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003c/releases\u003e \u003csnapshots\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003ealways\u003c/updatePolicy\u003e \u003c/snapshots\u003e \u003c/repository\u003e \u003c/repositories\u003e \u003cpluginRepositories\u003e \u003cpluginRepository\u003e \u003cid\u003ealiyun-public\u003c/id\u003e \u003curl\u003ehttps://maven.aliyun.com/repository/public/\u003c/url\u003e \u003creleases\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003c/releases\u003e \u003csnapshots\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003ealways\u003c/updatePolicy\u003e \u003c/snapshots\u003e \u003c/pluginRepository\u003e \u003c/pluginRepositories\u003e \u003c/profile\u003e \u003c/profiles\u003e \u003cactiveProfiles\u003e \u003c!-- 同时激活两个 profile --\u003e \u003cactiveProfile\u003einternal-public\u003c/activeProfile\u003e \u003cactiveProfile\u003ealiyun-public\u003c/activeProfile\u003e \u003c/activeProfiles\u003e ... \u003c/settings\u003e ","description":"","tags":["Java","Maven"],"title":"Maven 同时使用私有仓库和公共仓库","uri":"/posts/java/maven-uses-both-private-and-public-repositories/"},{"categories":null,"content":"Twitter 雪花算法（snowflake-2010）- Java 版 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * twitter \u003ca href=\"https://github.com/twitter-archive/snowflake/releases/tag/snowflake-2010\"\u003esnowflake-2010\u003c/a\u003e * \u003cp\u003e * \u003cpre\u003e * 41bit-时间戳 12bit-序列号 * ╭─────────────────────┴──────────────────────╮ ╭─────┴─────╮ * 0 - 00000000 00000000 00000000 00000000 00000000 0 - 00000 00000 - 00000000 0000 * │ ╰────┬────╯ * 1bit-符号位 10bit-工作机器ID * \u003c/pre\u003e * 41bit-时间戳：可以从基点开始，使用 2^41 / (2,199,023,255,552 / (1000 * 60 * 60 * 24 * 365)) ≈ 69.73 年 * 10bit-工作机器ID：可以支持 2^10 = 1024 台机器使用。细分为 5bit-数据中心ID（机房ID） 和 5bit-机器ID * 12bit-序列号：每毫秒、每台机器可以生成 2^12 = 4096 个不碰撞的序列号 * * @author wangshuo */ public class IdWorker { private static final Logger LOGGER = LoggerFactory.getLogger(IdWorker.class); /** 时间基点（UTC 2010-11-04 01:42:54.657） */ private final long twepoch = 1288834974657L; /** 机器ID 所占位数 */ private static final long WORKER_ID_BITS = 5L; /** 数据中心ID 所占位数 */ private static final long DATACENTER_ID_BITS = 5L; /** 单个数据中心机器ID 的最大值 */ private static final long MAX_WORKER_ID = -1L ^ (-1L \u003c\u003c WORKER_ID_BITS); /** 数据中ID 的最大值 */ private static final long MAX_DATACENTER_ID = -1L ^ (-1L \u003c\u003c DATACENTER_ID_BITS); /** 序列号所占位数 */ private static final long SEQUENCE_BITS = 12L; /** 机器ID 左移位数 */ private static final long WORKER_ID_SHIFT = SEQUENCE_BITS; /** 数据中心ID 左移位数 */ private static final long DATACENTER_ID_SHIFT = SEQUENCE_BITS + WORKER_ID_BITS; /** 时间截左移位数 */ private static final long TIMESTAMP_LEFT_SHIFT = SEQUENCE_BITS + WORKER_ID_BITS + DATACENTER_ID_BITS; /** 序列号的掩码（最大值） */ private static final long SEQUENCE_MASK = -1L ^ (-1L \u003c\u003c SEQUENCE_BITS); /** 机器ID */ private final long workerId; /** 数据中心ID */ private final long datacenterId; /** 序列号 */ private long sequence = 0L; /** 最后一次生成ID的时间截 */ private long lastTimestamp = -1L; public IdWorker(long workerId, long datacenterId) { if (workerId \u003e MAX_WORKER_ID || workerId \u003c 0) { throw new IllegalArgumentException(String.format(\"worker Id can't be greater than %d or less than 0\", MAX_WORKER_ID)); } if (datacenterId \u003e MAX_DATACENTER_ID || datacenterId \u003c 0) { throw new IllegalArgumentException(String.format(\"datacenter Id can't be greater than %d or less than 0\", MAX_DATACENTER_ID)); } this.workerId = workerId; this.datacenterId = datacenterId; LOGGER.info(\"worker starting. timestamp left shift {}, datacenter id bits {}, worker id bits {}, sequence bits {}, workerId {}\", TIMESTAMP_LEFT_SHIFT, DATACENTER_ID_BITS, WORKER_ID_BITS, SEQUENCE_BITS, workerId); } /** 获得下一个 ID */ public synchronized long nextId() { long timestamp = timeGen(); // 如果当前系统时间小于最后一次获取 ID 的时间，说明系统时间回退过，抛出异常 if (timestamp \u003c lastTimestamp) { LOGGER.error(\"Clock moved backwards. Refusing to generate id for {} milliseconds\", lastTimestamp - timestamp); throw new InvalidSystemClockException( String.format(\"Clock moved backwards. Refusing to generate id for %d milliseconds\", lastTimestamp - timestamp)); } // 同一毫秒内获取 ID，则进行序列号递增 if (lastTimestamp == timestamp) { // sequence + 1 \u003e 序列号最大值时，sequence 会变为 0 sequence = (sequence + 1) \u0026 SEQUENCE_MASK; // 毫秒内序列号溢出 if (sequence == 0) { // 阻塞到下一毫秒，再获取 ID timestamp = tilNextMillis(lastTimestamp); } } else { // 不同毫秒获取 ID，将序列号重置为 0 sequence = 0L; } // 记录最后一次获取 ID 的时间戳 lastTimestamp = timestamp; // 以二进制方式拼接时间戳、数据中心ID、机器ID、序列号 return ((timestamp - twepoch) \u003c\u003c TIMESTAMP_LEFT_SHIFT) | (datacenterId \u003c\u003c DATACENTER_ID_SHIFT) | (workerId \u003c\u003c WORKER_ID_SHIFT) | sequence; } /** * 阻塞到下一个毫秒 * * @param lastTimestamp 最后一次生成 ID 的时间戳 */ protected long tilNextMillis(long lastTimestamp) { long timestamp = timeGen(); while (timestamp \u003c= lastTimestamp) { timestamp = timeGen(); } return timestamp; } /** 获取以毫秒为单位的当前系统时间 */ protected long timeGen() { return System.currentTimeMillis(); } public static void main(String[] args) { IdWorker idWorker = new IdWorker(0, 0); long id = idWorker.nextId(); if (LOGGER.isInfoEnabled()) { LOGGER.info(String.valueOf(id)); } } } /** 系统时钟回流时，抛出该异常 */ class InvalidSystemClockException extends RuntimeException { public InvalidSystemClockException(String message) { super(message); } } 参考文档：\n源码：snowflake-2010 ","description":"","tags":["Java"],"title":"Twitter 雪花算法（snowflake-2010）- Java 版","uri":"/posts/java/twitter-snowflake-2010/"},{"categories":null,"content":"使用 guiscrcpy 在 Linux 上使用 Android 手机 环境说明 Fedora 35 小米 K30S Ultra（MIUI 12.5.1） 电脑安装 adb 和 guiscrcpy 安装 adb\n1 2 3 4 # 可以通过直接安装 android-tools 的方式进行安装 sudo dnf install android-tools # 也可以通过下载 platform tools 的方式进行安装 https://developer.android.com/studio/releases/platform-tools 安装 guiscrcpy\n手机设置 连续点击 MIUI version，开启开发者模式（Developer Mode）\n开启 USB 调试模式（USB debugging）\n注意：小米手机要同时开启 USB 调试模式（安全设置）（USB debugging（Security settings））选项，否则在电脑上只能预览，不能操作\n开始连接 启动 adb 服务\n1 2 3 4 # 启动 adb 服务 sudo adb start-server 或 sudo systemctl start adb # 设置开机自启动 sudo systemctl enable adb 一定要用 root 权限启动 adb 服务，否则连接 Android 后会出现 no premission 问题\n通过 USB 数据线将手机和电脑进行连接\n在手机允许 USB debugging\n打开 guiscrcpy，此时在页面上可以看到已连接的安卓手机\n可以进行一些调整\n取消 Bottonm Panel 的勾选\n取消 Swipe Panel 的勾选\n勾选 Keep display off，并取消手机的自动锁屏功能\n选择设备，开始连接\n","description":"","tags":["Android"],"title":"使用 guiscrcpy 在 Linux 上使用 Android 手机","uri":"/posts/android/guiscrcpy-for-linux/"},{"categories":null,"content":"Linux 新建/扩展 swap 交换空间 新建 swap 交换空间 目标：新建一个 2GB 的 swap 交换空间\n查看磁盘的块大小\n1 2 sudo stat / | grep \"IO Block\" Size: 4096 Blocks: 8 IO Block: 4096 directory 新建交换文件\n1 2 3 # bs：block size，推荐与上方查询出来的相同 # count：2(GB) * 1024(MB) * 1024(KB) * 1024(B) / 4096(B) = 524288(块) sudo dd if=/dev/zero of=/swap_file bs=4096 count=524288 修改交换文件的访问权限\n1 sudo chmod 600 /swap_file 设置交换文件\n1 sudo mkswap /swap_file 挂载交换文件\n1 2 3 sudo swapon /swap_file # 关闭交换分区命令 # sudo swapoff /swap_file 查看内存和交换空间信息\n1 2 3 4 free -h total used free shared buff/cache available Mem: 967Mi 234Mi 70Mi 1.0Mi 661Mi 573Mi Swap: 2.0Gi 0B 2.0Gi 在 /etc/fstab 中添加如下配置，开机自动挂载 swap 交换空间\n1 /swap_file swap swap defaults 1 1 扩展 swap 交换空间 目标：把 swap 交换空间从 2GB 扩展到 4GB\n查看已有的 swap 文件块大小\n1 2 sudo stat /swap_file | grep \"IO Block\" Size: 2147483648 Blocks: 4194312 IO Block: 4096 regular file 卸载已有的 swap 交换空间\n1 sudo swapoff /swap_file 扩展交换文件\n1 2 3 # bs：block size，推荐与上方查询出来的相同 # count：2(GB) * 1024(MB) * 1024(KB) * 1024(B) / 4096(B) = 524288(块) sudo dd if=/dev/zero of=/swap_file bs=4096 count=524288 oflag=append conv=notrunc 设置交换文件\n1 sudo mkswap /swap_file 挂载交换文件\n1 sudo swapon /swap_file 查看内存和交换分区信息\n1 2 3 4 free -h total used free shared buff/cache available Mem: 967Mi 237Mi 73Mi 1.0Mi 655Mi 567Mi Swap: 4.0Gi 0B 4.0Gi ","description":"","tags":["Linux"],"title":"Linux 新建/扩展 swap 交换空间","uri":"/posts/linux/linux-add-or-extend-swap/"},{"categories":null,"content":"Windows10 同时使用内网和外网 以管理员身份运行 cmd\n查看网络接口信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 C:\\Users\\system32\u003eipconfig /all Windows IP 配置 # 使用 USB 连接的手机热点（外网） 以太网适配器 以太网 2: 连接特定的 DNS 后缀 . . . . . . . : 描述. . . . . . . . . . . . . . . : Remote NDIS Compatible Device 物理地址. . . . . . . . . . . . . : 86-68-EA-31-96-3D IPv4 地址 . . . . . . . . . . . . : 192.168.52.192(首选) 子网掩码 . . . . . . . . . . . . : 255.255.255.0 默认网关. . . . . . . . . . . . . : fe80::b4f6:f8ff:fe53:740f%9 192.168.52.137 # 使用 WIFI 连接的公司内网 无线局域网适配器 WLAN: 连接特定的 DNS 后缀 . . . . . . . : 描述. . . . . . . . . . . . . . . : Intel(R) Wireless-AC 9560 160MHz 物理地址. . . . . . . . . . . . . : 40-EC-99-B3-90-A7 IPv4 地址 . . . . . . . . . . . . : 172.10.16.33(首选) 子网掩码 . . . . . . . . . . . . : 255.255.255.0 默认网关. . . . . . . . . . . . . : 172.10.16.254 主要需要记录的信息有：\n内外网的 IP、子网掩码、网关：用于添加路由规则 描述和物理地址：用于在下方查找网络接口编号 查看路由信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 C:\\WINDOWS\\system32\u003eroute print =========================================================================== 接口列表 # USB 连接的外网网络接口编号为：9 9...6e af e4 98 37 e1 ......Remote NDIS Compatible Device # WIFI 连接的内网网络接口编号为：2 2...40 ec 99 b3 90 a7 ......Intel(R) Wireless-AC 9560 160MHz =========================================================================== IPv4 路由表 =========================================================================== 活动路由: 网络目标 网络掩码 网关 接口 跃点数 # 包含两个网络目标为 0.0.0.0 的，所以会有冲突 0.0.0.0 0.0.0.0 172.10.16.254 172.10.16.33 35 0.0.0.0 0.0.0.0 192.168.52.137 192.168.52.192 25 # 内网网络接口已有的路由信息 172.10.16.0 255.255.255.0 在链路上 172.10.16.33 291 172.10.16.33 255.255.255.255 在链路上 172.10.16.33 291 172.10.16.255 255.255.255.255 在链路上 172.10.16.33 291 # 外网网络接口已有的路由信息 192.168.52.0 255.255.255.0 在链路上 192.168.52.192 281 192.168.52.192 255.255.255.255 在链路上 192.168.52.192 281 192.168.52.255 255.255.255.255 在链路上 192.168.52.192 281 =========================================================================== 永久路由: 无 调整路由规则\n1 2 3 4 5 6 # 删除所有目标为 0.0.0.0 的路由 route delete 0.0.0.0 # 所有向外发送的请求都使用外网网络接口 route add 0.0.0.0 mask 0.0.0.0 192.168.52.137 if 9 # 所有向 172.10.0.0/24 的请求都使用内网网络接口 route add 172.10.0.0 mask 255.255.0.0 172.10.16.254 if 2 操作路由表的命令说明：\n1 2 3 4 5 6 7 8 9 ## 删除路由 # route delete [-p] \u003c网络目标\u003e route delete [-p] \u003cdestination\u003e ## 添加路由 # route add [-p] \u003c网络目标\u003e mask \u003c网络掩码\u003e \u003c网关\u003e [metric \u003c跃点数\u003e] [if \u003c网络接口号\u003e] route add [-p] \u003cdestination\u003e mask \u003cmask\u003e \u003cgateway\u003e [metric \u003cmetric\u003e] [if \u003cinterface\u003e] ## 可以使用 -p 参数持久化保存路由（永久路由），否则重启后会消失 查看调整后的路由规则\n1 2 3 4 5 6 7 8 IPv4 路由表 =========================================================================== 活动路由: 网络目标 网络掩码 网关 接口 跃点数 # 只保留外网网络接口对 0.0.0.0 的路由 0.0.0.0 0.0.0.0 192.168.52.137 192.168.52.192 26 # 添加了内网网络接口对 172.10.0.0/24 的路由 172.10.0.0 255.255.0.0 172.10.16.254 172.10.16.33 36 ","description":"","tags":["Windows"],"title":"Windows10 同时使用内网和外网","uri":"/posts/windows/windows10-use-intranet-and-extranet-together/"},{"categories":null,"content":"MySQL 目录 事务 ","description":"","tags":["MSB","MySQL"],"title":"MySQL 目录","uri":"/posts/msb/mysql-%E8%B0%83%E4%BC%98/mysql-table-of-contents/"},{"categories":null,"content":"MySQL 读写分离 MySQL Proxy 和 MySQL Router 实现读写分离 MySQL Proxy 和 MySQL Router 是官方提供的两个玩具，不推荐使用。\nMySQL Proxy：应用程序连接 MySQL Proxy 后，MySQL Proxy 会自动将写请求和读请求分离，分别发送给 Master 和 Slave。但是官方不建议在生产环境使用 MySQL Proxy。\nMySQL Router：是 MySQL Proxy 的替代方案。但是 MySQL Router 启动后，包含读端口和写端口，因此就需要应用程序自己将读和写进行分离，分别发送到 MySQL Router 相应的端口上。应用程序需要额外将读写操作进行分流，麻烦。\n参考文档\nMySQL Router 8.0 Mycat 2 实现读写分离 首先需要准备 MySQL 主从复制/MySQL 组复制 环境\n节点类型 服务节点IP:端口 读写类型 主从同步的数据库名 Mycat 2 172.17.0.1:8066（宿主机） 主节点 172.17.0.2:3306（MySQL 5.7 in Docker） 可读可写 master_slave 从节点 172.17.0.3:3306（MySQL 5.7 in Docker） 只读 master_slave 安装 Java8+ 环境\n在主从节点均创建给 Mycat 程序使用的用户并授权\n1 2 3 4 5 6 CREATE USER 'mycat'@'172.17.0.1' IDENTIFIED BY 'password'; -- MySQL 8 必须赋予的权限 GRANT XA_RECOVER_ADMIN ON *.* to 'mycat'@'172.17.0.1'; -- 视情况赋予权限 GRANT ALL PRIVILEGES ON *.* to 'mycat'@'172.17.0.1'; FLUSH PRIVILEGES; 在主节点创建 Mycat 使用的数据库 mycat\n1 CREATE DATABASE IF NOT EXISTS `mycat`; 这个库称为 Mycat 的原型库（prototype），Mycat 在启动时，会自动在原型库下创建其运行时所需的数据表。\n这里为了省事，把 Mycat 服务用的 mycat 库和后面主从同步的 master_slave 库都放在了主节点上。\n下载 并安装 Mycat\n1 2 3 4 5 6 7 8 9 10 11 12 mkdir -p /path/to/mycat2 cd /path/to/mycat2 # 下载安装包 wget http://dl.mycat.org.cn/2.0/install-template/mycat2-install-template-1.21.zip # 下载 Mycat 2 所需依赖 jar wget http://dl.mycat.org.cn/2.0/1.21-release/mycat2-1.21-release-jar-with-dependencies.jar unzip mycat2-install-template-1.21.zip cd mycat # 复制 Mycat 2 所需依赖 jar 到 mycat 的 lib 文件夹 cp ../mycat2-1.21-release-jar-with-dependencies.jar lib/ # 授予 bin 目录下所有命令可执行权限 chmod +x bin/* 配置 Mycat 原型库的数据源（datasource）信息\n这个库必须配置，否则在启动 Mycat 时会报错\n1 2 cd /path/to/mycat2/mycat/conf/datasources vim prototypeDs.datasource.json 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 { // 数据库类型 \"dbType\":\"mysql\", \"idleTimeout\":60000, \"initSqls\":[], \"initSqlsGetConnection\":true, // 数据库读写类型：READ、WRITE、READ_WRITE。Mycat 对数据库需要是可读可写的 \"instanceType\":\"READ_WRITE\", \"maxCon\":1000, \"maxConnectTimeout\":3000, \"maxRetryCount\":5, \"minCon\":1, // 数据源名称，这里不要修改 \"name\":\"prototypeDs\", // 数据库密码 \"password\":\"password\", \"type\":\"JDBC\", // 数据库连接 \"url\":\"jdbc:mysql://172.17.0.2:3306/mycat?useUnicode=true\u0026serverTimezone=Asia/Shanghai\u0026characterEncoding=UTF-8\", // 数据库用户 \"user\":\"mycat\", \"weight\":0 } 添加 master_slave 数据库的数据源信息\n1 2 3 cp prototypeDs.datasource.json master.datasource.json cp prototypeDs.datasource.json slave-01.datasource.json vim master.datasource.json 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 { \"dbType\":\"mysql\", \"idleTimeout\":60000, \"initSqls\":[], \"initSqlsGetConnection\":true, // 数据库读写类型。在数据库集群时，Mycat 对主节点都是可读可写的 \"instanceType\":\"READ_WRITE\", \"maxCon\":1000, \"maxConnectTimeout\":3000, \"maxRetryCount\":5, \"minCon\":1, // 数据源名称。在后面配置数据库集群时会用到 \"name\":\"master\", // 数据库密码 \"password\":\"password\", \"type\":\"JDBC\", // 主节点数据库连接 \"url\":\"jdbc:mysql://172.17.0.2:3306/master_slave?useUnicode=true\u0026serverTimezone=Asia/Shanghai\u0026characterEncoding=UTF-8\", // 数据库用户 \"user\":\"mycat\", \"weight\":0 } 1 vim slave-01.datasource.json 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 { \"dbType\":\"mysql\", \"idleTimeout\":60000, \"initSqls\":[], \"initSqlsGetConnection\":true, // 数据库读写类型。在数据库集群时，Mycat 对从节点都是只读的 \"instanceType\":\"READ\", \"maxCon\":1000, \"maxConnectTimeout\":3000, \"maxRetryCount\":5, \"minCon\":1, // 数据源名称。在后面配置数据库集群时会用到 \"name\":\"slave-01\", // 数据库密码 \"password\":\"password\", \"type\":\"JDBC\", // 从节点数据库连接 \"url\":\"jdbc:mysql://172.17.0.3:3306/master_slave?useUnicode=true\u0026serverTimezone=Asia/Shanghai\u0026characterEncoding=UTF-8\", // 数据库用户 \"user\":\"mycat\", \"weight\":0 } 配置 master_slave 数据源的集群（cluster）信息\n1 2 3 4 cd /path/to/mycat2/mycat/conf/clusters # 注意：这里不要删除 prototype.cluster.json，否则启动 Mycat 时会报错 cp prototype.cluster.json master-slave.cluster.json vim master-slave.cluster.json 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 { // 集群类型：SINGLE_NODE（单节点）、MASTER_SLAVE（普通主从）、GARELA_CLUSTER（garela cluster/PXC集群）等 \"clusterType\":\"MASTER_SLAVE\", \"heartbeat\":{ \"heartbeatTimeout\":1000, \"maxRetry\":3, \"minSwitchTimeInterval\":300, \"slaveThreshold\":0 }, \"masters\":[ // 主节点数据源名称 \"master\" ], \"replicas\":[ // 从节点数据源名称 \"slave-01\" ], \"maxCon\":200, // 集群名称。在后面配置物理库（schema）时会用到 \"name\":\"master-slave\", \"readBalanceType\":\"BALANCE_ALL\", // NOT_SWITCH（不进行主从切换）、SWITCH（进行主从切换） \"switchType\":\"NOT_SWITCH\" } 配置物理库（schema）和 Mycat 中数据源/数据源集群的关系\n1 2 cd /path/to/mycat2/mycat/conf/schemas vim master_slave.schema.json 1 2 3 4 5 6 7 8 { // 物理库 \"schemaName\": \"master_slave\", // 指向集群，或者数据源 \"targetName\": \"master-slave\" // 这里可以配置数据表相关的信息，在物理表已存在或需要启动时自动创建物理表时配置此项 \"normalTables\": {} } 修改 Mycat 登录用户信息\n1 2 cd /path/to/mycat2/mycat/conf/users vim root.user.json 1 2 3 4 5 6 7 8 { \"dialect\":\"mysql\", // ip 为 null，允许任意 ip 登录 \"ip\":null, \"password\":\"123456\", \"transactionType\":\"xa\", \"username\":\"root\" } 修改 Mycat 服务端口等信息\n1 2 cd /path/to/mycat2/mycat/conf vim server.json 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 { \"loadBalance\":{ \"defaultLoadBalance\":\"BalanceRandom\", \"loadBalances\":[] }, \"mode\":\"local\", \"properties\":{}, \"server\":{ \"bufferPool\":{ }, \"idleTimer\":{ \"initialDelay\":3, \"period\":60000, \"timeUnit\":\"SECONDS\" }, \"ip\":\"0.0.0.0\", \"mycatId\":1, \"port\":8066, \"reactorNumber\":8, \"tempDirectory\":null, \"timeWorkerPool\":{ \"corePoolSize\":0, \"keepAliveTime\":1, \"maxPendingLimit\":65535, \"maxPoolSize\":2, \"taskTimeout\":5, \"timeUnit\":\"MINUTES\" }, \"workerPool\":{ \"corePoolSize\":1, \"keepAliveTime\":1, \"maxPendingLimit\":65535, \"maxPoolSize\":1024, \"taskTimeout\":5, \"timeUnit\":\"MINUTES\" } } } 启动 Mycat\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 ./bin/mycat start # 查看状态 ./bin/mycat status # 停止 ./bin/mycat stop # 暂停 ./bin/mycat pause # 重启 ./bin/mycat restart # 前台运行 ./bin/mycat console # 查看日志文件 tail -f /path/to/mycat2/mycat/logs/wrapper.log 使用 mysql 命令连接 Mycat\n1 mysql -uroot -p123456 -P8066 -h127.0.0.1 验证读写分离\n在主从节点均开启日志记录\n1 2 3 4 # 把日志输出到表；开启日志记录 SET GLOBAL log_output = 'TABLE'; SET GLOBAL general_log = 'ON'; # 清空 mysql.general_log 日志表中的记录 TRUNCATE TABLE mysql.general_log; 在 Mycat 中分别执行插入和查询语句\n1 2 3 INSERT INTO test VALUES(1, 'a'); SELECT * FROM test; SELECT * FROM test; 分别在主从节点执行如下语句，查询 SQL 执行历史\n1 2 3 4 5 6 7 8 9 -- 可以看到主节点上有一条 INSERT 和一条 SELECT；从节点上只有一条 SELECT SELECT event_time, user_host, thread_id, server_id, command_type, CAST(argument AS CHAR(500) CHARACTER SET utf8mb4) argument FROM mysql.general_log ORDER BY event_time DESC; 在主从节点关闭日志记录\n1 2 # 把日志输出到文件（默认设置）；关闭日志记录 SET GLOBAL log_output = 'FILE'; SET GLOBAL general_log = 'OFF'; 参考文档\nMycat 2 Mycat2 安装配置 [配置]数据源（datasource） [配置]集群（cluster） [配置]库（schema） [配置]用户（user） [配置]服务器（server） ","description":"","tags":["MSB","Database","MySQL"],"title":"MySQL 读写分离","uri":"/posts/msb/mysql/mysql-read-write-separation/"},{"categories":null,"content":"MySQL 主从复制 复制功能将来自 MySQL 数据库服务主节点的数据复制到一台或多台 MySQL 数据库服务从节点。复制默认是异步的，可以通过配置文件，调整复制所有数据库、选定的数据库、选定的表。\n主从复制应用场景 读写分离：在业务复杂的场景下，可能会出现写数据时锁表的情况，通过读写分离，主节点只处理写入操作，从节点只负责读取操作，可以减少锁的争用问题 数据热备：使用主从复制将数据复制到从节点，然后在从节点对数据进行备份。对从节点的暂停/关闭不影响主节点的运行。 横向扩展：可以根据业务量，动态增加或缩减从节点的数量 MySQL 主从复制流程 当主节点上的数据发生改变时，则将变化写入 binlog 中 从节点定期探测主节点的 binlog 是否改变，如果发生改变，则启动一个 I/O Thread 请求读取主节点 binlog 的变化 同时主节点为从节点的每个 I/O Thread 启动一个 dump Thread，用于向从节点发送 binlog 文件的变化 从节点接收到主节点的变化后，将其保存到 relay log（中继日志）中，并启动一个 SQL Thread 从 relay log 中读取改变，将其重放到数据库中，使其数据和主节点保持一致。最后 I/O Thread 和 SQL Thread 会进入睡眠状态，等待下次被唤醒。 具体流程\n从库通过手工执行 change master to ... 语句连接主库，使用 start slave； 启动复制 从库的 IO Thread 和主库的 dump Thread 建立连接。 从库根据 change master to... 语句中提供的 File 和 Position，IO Thread 向主库发起读取 binlog 的请求。 主库 dump Thread 根据从库的请求，将本地 binlog 以 events 的方式发给从库的 IO Thread。 从库 IO Thread 接收 binlog events，并存放到本地 relay log 中，传送过来的信息，会记录到 master.info 中 从库 SQL Thread 应用 relay-log，并且把应用过的记录到 relay-log.info 中，默认情况下，已经应用过的 relay 会自动被清理 注意\n主节点必须开启 binlog 功能。通常为了数据安全考虑，slave 也开启 binlog 功能 MySQL 主从复制至少需要两个 MySQL 服务 MySQL 复制最好确保主从节点的 MySQL 版本相同，否则，需要保证主节点的 MySQL 版本低于从节点 主从节点时间要同步 异步复制和半同步复制 MySQL 默认使用异步复制方式\n异步复制\n当主节点数据发生改变，写入 binlog 后，主节点直接进行事务提交。从节点监控到主节点的变化事件后，将变化重放到数据库中。此时主节点和从节点的事务提交是完全异步的，如果从节点执行失败，从节点就会丢失数据。\n半同步复制\n当主节点数据发生改变，写入 binlog 后，会等待从节点给返回 ACK（或超时），然后在进行事务提交。因此降低了从节点丢失数据的概率，同时会降低主节点的执行效率。\nMySQL 常用主从形式 一主一从\n主主复制\n一主多从：适合做读写分离\n多主一从：适合做数据汇总和热备\n一主一从搭建 安装 MySQL 数据库（略）\n为了方便，使用 docker 启动两个 MySQL 5.7\n节点类型 IP:port 主节点 172.17.0.2:3306 从节点 172.17.0.3:3306 在两个数据库中分别创建数据库\n1 2 # 主从复制不会自动创建数据库，所以需要手动创建 CREATE DATABASE master_slave; 修改主节点配置文件\n1 2 3 4 5 6 7 8 9 10 # 在 mysqld 模块中添加如下配置信息 [mysqld] # binlog 文件名称 log-bin=master-bin # binlog 日志格式，有 row、statement、mixed 三种格式。row 指的是把改变的内容复制过去，而不是把命令在从服务器上执行一遍；statement 指的是在主服务器上执行的 SQL 语句，在从服务器上执行同样的语句；mixed 指的是默认采用基于语句的复制，一旦发现基于语句的无法精确的复制时，就会采用基于行的复制。MySQL 默认采用基于语句的复制，效率比较高。 binlog-format=ROW # 当前服务的 id，要求各个服务的 id 必须不同 server-id=1 # 同步的数据库名称 binlog-do-db=master_slave 在主节点上创建用于同步的账号\n1 2 3 4 5 6 -- 创建用于同步的用户，可以修改用户名、允许的 IP、密码 CREATE USER 'repl'@'172.17.0.3' IDENTIFIED BY 'password'; -- 授权 'repl'@'localhost' 用户备份权限 GRANT REPLICATION SLAVE ON *.* TO 'repl'@'172.17.0.3'; -- 刷新权限 FLUSH PRIVILEGES; 重启主节点的 MySQL 服务\n修改从节点配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 # 在 mysqld 模块中添加如下配置信息 [mysqld] # 二进制文件的名称 log-bin=slave-bin # 二进制文件的格式 binlog-format=ROW # 当前服务的id server-id=2 # 同步的数据库 replicate_do_db=master_slave # 按表过滤，否则主库在执行其它库的操作时，从库会报错 replicate_wild_do_table=master_slave.% 重启从节点的 MySQL 服务\n在主节点上查看主节点的状态\n1 2 3 4 5 6 SHOW MASTER STATUS; +-------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +-------------------+----------+--------------+------------------+-------------------+ | master-bin.000001 | 154 | master_slave | | | +-------------------+----------+--------------+------------------+-------------------+ 在从节点上将其与主节点进行连接\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 -- master_log_file 值需要和上方输出的 File 保持一致，master_log_pos 表示从主节点 binlog 的那个位置开始复制，必须 \u003c=Position CHANGE MASTER TO master_host='172.17.0.2',master_port=3306,master_user='repl',master_password='password',master_log_file='master-bin.000001',master_log_pos=154; -- 启动 slave START SLAVE; -- 查看 slave 状态 SHOW SLAVE STATUS\\G Slave_IO_State: Waiting for master to send event Master_Host: 172.17.0.2 Master_User: repl Master_Port: 3306 Connect_Retry: 60 -- master 的 binlog 文件名 Master_Log_File: master-bin.000001 -- slave 将从该位置读取 master 的 binlog Read_Master_Log_Pos: 154 -- slave 的 relay log 文件名 Relay_Log_File: a050aab3b39b-relay-bin.000002 -- slave 从该位置向它的 relay log 文件写 Relay_Log_Pos: 321 Relay_Master_Log_File: master-bin.000001 -- 这两个值都是 Yes，主从复制才成功 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: master_slave Replicate_Ignore_DB 主从复制测试\n1 2 3 4 5 6 7 8 -- 在主节点上创建表，并添加数据 USE master_slave; CREATE TABLE test(id INT,name VARCHAR(10)); INSERT INTO test VALUES(1, 'a'); SELECT * FROM test; -- 在从节点上可以查询到该数据 USE master_slave; SELECT * FROM test; 此处只能主节点向从节点同步数据，在从节点上对数据的操作不会同步到主节点。\n参考文档\nMySQL 5.6 Replication MySQL 5.7 Primary-Secondary Replication ","description":"","tags":["MSB","Database","MySQL"],"title":"MySQL 主从复制","uri":"/posts/msb/mysql/mysql-primary-secondary-replication/"},{"categories":null,"content":"iptables iptables 中的基本概念 iptables 在 Linux 内核中，Netfilter 子系统负责对网络包进行处理和分发；iptabels 是在用户空间控制 Netfilter 子系统的命令行工具。\niptables 将网络包按照处理规则（Rule）分配给不同的表格（Tables），每个表格有对应的处理链（Chain）。处理规则由匹配规则（Match）和处理目标（Target）组成。\n挂载点（Hook Point） Netfilter 默认定义了 5 个挂载点\nFORWARD：仅作用于包通过网关计算机，从一个网络接口进入，从另一个网络接口离开\nINPUT：表示将会把包传递给本地进程\nOUTPUT：表示包由本地进程生成\nPREROUTING：表示包从网络接口进入，进入该挂载点的包已经进行了包的检查和验证\nPOSTROUTING：表示包离开网络接口\n表（Tables） iptables 内置了三种不同的 Tables 来完成工作，分别是 NAT、FILTER、MANGLE；每个表都配置了不同的处理规则，用于处理网络包的流动。默认会使用 FILTER 表的规则对网络包进行过滤\nNAT 用于重定向网络地址转换的链接，通常会基于源地址或目标地址 FILTER 用于设置允许进入计算机的包的规则 MANGLE 用于进行特殊的包处理。例如对包进行修改等 不同表下的数据包流向\nNAT\n网络接口 -\u003e PREROUTING -\u003e 本地进程 -\u003e OUTPUT -\u003e POSTROUTING -\u003e 网络接口\n网络接口 -\u003e PREROUTING -\u003e POSTROUTING -\u003e 网络接口\n网络接口 -\u003e PREROUTING -\u003e 本地进程 \u003c-\u003e OUTPUT -\u003e POSTROUTING -\u003e 网络接口\n这里注意：本地进程要有退出 本地进程 \u003c-\u003e OUTPUT 循环的机制，否则就会死循环\nFILTER\n网络接口 -\u003e INPUT -\u003e 本地进程 -\u003e OUTPUT -\u003e 下一个网络接口\n网络接口 -\u003e FORWARD -\u003e 下一个网络接口\n网络接口 -\u003e INPUT -\u003e 本地进程 -\u003e OUTPUT -\u003e INPUT -\u003e 本地进程 -\u003e OUTPUT -\u003e 网络接口\n这里注意：OUTPUT -\u003e INPUT -\u003e 本地进程 -\u003e OUTPUT 要有退出循环的机制，否则就会死循环\nMANGLE\n网络接口 -\u003e PREROUTING -\u003e FORWARD -\u003e POSTROUTING -\u003e 网络接口\n网络接口 -\u003e PREROUTING -\u003e INPUT -\u003e 本地进程 -\u003e OUTPUT -\u003e POSTROUTING -\u003e 网络接口\n网络接口 -\u003e PREROUTING -\u003e INPUT -\u003e 本地进程 -\u003e OUTPUT -\u003e INPUT -\u003e 本地进程 -\u003e OUTPUT -\u003e POSTROUTING -\u003e 网络接口\n这里注意：OUTPUT -\u003e INPUT -\u003e 本地进程 -\u003e OUTPUT 要有退出循环的机制，否则就会死循环\n链（Chain） iptables 的链（Chain）对应 Netfilter 的挂载点（Hook Point）；默认情况下每个链最初都是空的；可以在链中自定义规则（Rule）来决定数据包的最终去向；也可以根据自己需要，自定义链。\n规则（Rule） iptables 的规则（Rule）由一个或多个匹配（Match）以及一个目标（Target）组成，匹配决定了这个规则回应用在哪些包上，目标则决定包会被如何处理；\n规则的匹配部分和目标部分是可选的。如果没有匹配，则匹配所有包；如果没有目标，则不对包进行处理。\n匹配（Match） iptables 包含多种匹配，这些匹配分为通用匹配和特殊匹配。一些特殊匹配需要系统内核的支持，可以使用 iptables -m 来加载特殊匹配模块。\n目标（Target） 目标（Target）定义了符合匹配（Match）的情况下，对数据包进行什么操作。iptables 内置了 4 个目标：\nACCEPT：允许包通过本阶段，进入下一阶段；停止对本链进行遍历 DROP：完全停止包处理进行，不再对此包应用任何规则 QUEUE：将包发送至用户空间，由用户空间的程序进行处理 RETURN：停止调用当前链中的后续规则，继续使用调用链的下一个链处理 iptables 命令使用 iptables 参数 规则操作\n-A 新增规则 -D 删除规则 -R 修改规则 -I 插入规则 -L 列出规则 -F 清空规则链 通用参数\n-p 协议 -s 源地址 -d 目标地址 --sport 源端口 --dport 目标端口 -i 入口网卡 -o 出口网卡 -j 动作 动作（对应 Target）\nDROP 丢弃 ACCEPT 接受 REJECT 拒绝 iptables 常用命令 iptables -L：列出所有应用中的规则 iptables -t nat -L：查看 NAT 表（可以把 nat 替换为 filter/mangle 来查看这两个表）中的所有规则 iptables -F：清空所有规则 iptables -Z：清空所有计数器 iptables -A INPUT -i eth1 -p tcp -m tcp --dport 443 -j DROP：添加一条命令（丢掉从 eth1 网络端口进入的所有通过 443 端口的 tcp 请求） iptables -D INPUT -i eth1 -p tcp -m tcp --dport 443 -j DROP：删除一条命令（删除上方对 443 端口添加的规则） iptables -D INPUT 1：删除 INPUT 表中的第 1 条规则 iptables 修改默认规则 iptables 表的默认 policy 是 ACCEPT，所以在添加规则时，相当与是按黑名单的方式进行添加。如果不希望按黑名单的方式进行添加，可以来修改 policy\n例如，iptables -P FORWARD DROP，默认 DROP 掉经过 FORWARD 表的请求，相当于白名单模式。\n通常，对 INPUT、FORWARD、OUTPUT 的默认规则设置如下\niptables -P INPUT DROP：默认不让任何请求进入 iptables -P FORWARD DROP：默认不允许转发 iptables -P OUTPUT ACCEPT：默认所有请求都可以出去 备份和恢复 iptables-save 可以展示当前的所有表和规则，它的输出可以用于导出所有 iptables 规则，后续可以使用 iptables-restore 进行将这些规则添加到当前的 iptables 配置中\n1 2 iptables-save \u003e iptables.rules iptables-restore \u003c iptables.rules iptables 与系统安全 ICMP 防御 黑客可以通过僵尸网络，针对 ICMP 协议发动 DDoS 攻击，从而使你的业务无法正常服务；ICMP 的一些漏洞可能会导致你的系统出现安全管理风险；不是所有的 ICMP 协议的规则都需要阻断，否则会影响使用\n1 2 3 4 5 6 # 阻止所有未经允许的包进入系统 iptables -P INPUT DROP # 引入 conntrack 模块，允许 icmp 类型为 3，请求状态为新增/建立/关联的请求 iptables -A INPUT -m conntrack -p icmp --icmp-type 3 --ctstate NEW,ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -m conntrack -p icmp --icmp-type 11 --ctstate NEW,ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -m conntrack -p icmp --icmp-type 12 --ctstate NEW,ESTABLISHED,RELATED -j ACCEPT ICMP 类型\n3：用于获取目标不可达的原因 11：用于获取到达目标前，数据包是否已经超过 TTL 的生命周期 12：用于获取数据包是否有错误的 IP 头等信息 0 和 8：在 ping 一台主机时，首先向目标发送 8（echo-request），然后目标给返回 0（echo-reply）。所以 INPUT 允许 8 可以让服务器接收到其他主机的 ping 请求，OUTPUT 允许 0 服务器可以给其他主机返回相应。建议在解决网络问题时临时开放 5：重定向消息，可能被黑客利用 ","description":"","tags":["Linux"],"title":"iptables","uri":"/posts/linux/iptables/"},{"categories":null,"content":"Fedora35 无线网卡 rtl8821ce 驱动安装 Fedora35，kernel 版本是 5.15.18-200，开机之后只要打开 wifi 过一会就会死机。使用 journalctl -f 查看系统日志发现网络相关的日志报红。\nLinux Kernel 5.9 版本后带有由 Realtek 开发的损坏的 rtw88 模块，该模块与大多数 8821ce 版本的芯片兼容性很差。\n禁用自带的 rtw88 模块，使用 https://github.com/tomaspinho/rtl8821ce 提供的开源驱动。\n禁用自带的 rtw88 模块\n1 2 # 在 /etc/modprobe.d 目录下创建一个以 .conf 结尾的文件，并写入 blacklist rtw88_8821ce echo 'blacklist rtw88_8821ce' | sudo tee /etc/modprobe.d/rtw88-blacklist.conf 重启电脑后，会发现 wifi 按钮消失了，同时系统日志不再提示网络错误\n克隆并安装驱动\n1 2 3 git clone https://github.com/tomaspinho/rtl8821ce.git cd rtl8821ce sudo ./dkms-install.sh 安装成功后，重启电脑即可\n其他问题\nkernel-core 和 kernel-headers 版本不一致，在安装驱动时提示缺少对应版本的 kernel-headers\n$ sudo ./dkms-install.sh About to run dkms install steps... Creating symlink /var/lib/dkms/rtl8821ce/v5.5.2_34066.20200325/source -\u003e /usr/src/rtl8821ce-v5.5.2_34066.20200325 Error! Your kernel headers for kernel 5.15.18-200.fc35.x86_64 cannot be found at /lib/modules/5.15.18-200.fc35.x86_64/build or /lib/modules/5.15.18-200.fc35.x86_64/source. Please install the linux-headers-5.15.18-200.fc35.x86_64 package or use the --kernelsourcedir option to tell DKMS where it's located. Error! Your kernel headers for kernel 5.15.18-200.fc35.x86_64 cannot be found at /lib/modules/5.15.18-200.fc35.x86_64/build or /lib/modules/5.15.18-200.fc35.x86_64/source. Please install the linux-headers-5.15.18-200.fc35.x86_64 package or use the --kernelsourcedir option to tell DKMS where it's located. Finished running dkms install steps.\n安装 kernel-devel 即可解决该问题\n1 sudo dnf install kernel-devel ","description":"","tags":["Linux","Fedora"],"title":"Fedora35 无线网卡 rtl8821ce 驱动安装","uri":"/posts/linux/fedora/fedora-rtl8821ce-drivers/"},{"categories":null,"content":"Typora + PicGo-Core + gitee 图床 配置 Typora Typora 依次打开：File -\u003e Preferences -\u003e Image\nWhen Insert... 选择：Upload image（上传图片）\n下方勾选：Apply above rules to local images（对本地位置的图片应用上述规则）\nImage Upload Setting -\u003e Image Uploader 选择：PicGo-Core（command line）\n点击 Download or Upgrade 下载 PicGo-Core\npicgo 命令默认位置在 ~/.config/Typora/picgo/linux/picgo PicGo-Core 配置文件默认位置：~/.picgo/config.json 新建 gitee 仓库 新建一个开源仓库（略）\n创建令牌\n设置 -\u003e 安全设置 -\u003e 私人令牌 -\u003e 生成新令牌\n只勾选 user_info 和 projects 即可，提交获得令牌\n配置 PicGo-Core 可以将 picgo 命令链接到当前用户的 .local/bin 目录下，就可以在任意目录使用该命令了\n1 2 $ cd ~/.local/bin $ ln -s ~/.config/Typora/picgo/linux/picgo picgo 安装 gitee-smart 插件\n1 2 3 # 旧版本叫 gitee-uploader，新版本叫 gitee-smart #$ picgo install gitee-uploader $ picgo install gitee-smart 选择使用 gitee 作为图床\n1 2 3 4 5 6 7 8 9 10 11 # 使用箭头移动，回车确认 $ picgo use ? Use an uploader imgur aliyun upyun ❯ gitee smms tcyun github (Move up and down to reveal more choices) 配置 gitee 图床的信息\n1 2 3 4 5 6 7 8 9 10 11 12 $ picgo set uploader gitee # 仓库位置 ? repo: swang-harbin/pic-bed # 分支 ? branch: master # 令牌 ? token: abcdefghijklmnopqrstuvwxyz123456 # 路径，这里把图片放在了仓库下的 images 目录，并按照上传年份进行分组 ? path: images/$customPath # 配合 path 使用，可以将图片按上传年份进行分组 ? customPath: 年 ? customUrl: 配置好后，图片保存路径类似于：pic-bed/images/2021/xxx.png\n可以安装 super-prefix 插件，把上传时间作为图片名\n1 $ picgo install super-prefix 配置 super-prefix 插件\n1 2 3 4 5 $ picgo set plugin super-prefix # 置空即可，在 gitee-smart 插件中已经按照年进行分组了，这里可以不设置 ? 例如 YYYY/MM/DD/ # 自动生成 YYYYMMDDHHmmss 格式的文件名 ? 例如 YYYYMMDDHHmmss YYYYMMDDHHmmss 配置好后，图片保存路径类似于：pic-bed/images/2021/20210105172014.png\n","description":"","tags":["Typora"],"title":"Typora + PicGo-Core + gitee 图床","uri":"/posts/typora/typora-picgo-core-gitee/"},{"categories":null,"content":"MySQL 官方提供的 Employees 案例库 Employees Sample Database\n安装案例库 从 Employees DB on GitHub 下载压缩文件\n解压缩，移动到解压后的目录，执行如下命令\n1 mysql -uuser_name -ppassword \u003c employees.sql 关系图 ","description":"","tags":["MySQL"],"title":"MySQL 官方提供的 Employees 案例库","uri":"/posts/mysql/mysql-employees-sample-database/"},{"categories":null,"content":"MySQL 学生表练习题 表结构 1 2 3 4 5 6 7 8 -- 1.学生表（学生编号，学生姓名，出生年月，学生性别） student(s_id, s_name, s_birth, s_sex) -- 2.课程表（课程编号，课程名称，教师编号） course(c_id, c_name, t_id) -- 3.教师表（教师编号，教师姓名） teacher(t_id, t_name) -- 4.成绩表（学生编号，课程编号，分数） score(s_id, c_id, s_score) 测试数据 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 -- 建表 -- 学生表 CREATE TABLE `student` ( `s_id` VARCHAR(20), `s_name` VARCHAR(20) NOT NULL DEFAULT '', `s_birth` VARCHAR(20) NOT NULL DEFAULT '', `s_sex` VARCHAR(10) NOT NULL DEFAULT '', PRIMARY KEY (`s_id`) ); -- 课程表 CREATE TABLE `course` ( `c_id` VARCHAR(20), `c_name` VARCHAR(20) NOT NULL DEFAULT '', `t_id` VARCHAR(20) NOT NULL, PRIMARY KEY (`c_id`) ); -- 教师表 CREATE TABLE `teacher` ( `t_id` VARCHAR(20), `t_name` VARCHAR(20) NOT NULL DEFAULT '', PRIMARY KEY (`t_id`) ); -- 成绩表 CREATE TABLE `score` ( `s_id` VARCHAR(20), `c_id` VARCHAR(20), `s_score` INT(3), PRIMARY KEY (`s_id`, `c_id`) ); -- 插入学生表测试数据 INSERT INTO student VALUES ('01', '赵雷', '1990-01-01', '男'); INSERT INTO student VALUES ('02', '钱电', '1990-12-21', '男'); INSERT INTO student VALUES ('03', '孙风', '1990-05-20', '男'); INSERT INTO student VALUES ('04', '李云', '1990-08-06', '男'); INSERT INTO student VALUES ('05', '周梅', '1991-12-01', '女'); INSERT INTO student VALUES ('06', '吴兰', '1992-03-01', '女'); INSERT INTO student VALUES ('07', '郑竹', '1989-07-01', '女'); INSERT INTO student VALUES ('08', '王菊', '1990-01-20', '女'); -- 课程表测试数据 INSERT INTO course VALUES ('01', '语文', '02'); INSERT INTO course VALUES ('02', '数学', '01'); INSERT INTO course VALUES ('03', '英语', '03'); -- 教师表测试数据 INSERT INTO teacher VALUES ('01', '张三'); INSERT INTO teacher VALUES ('02', '李四'); INSERT INTO teacher VALUES ('03', '王五'); -- 成绩表测试数据 INSERT INTO score VALUES ('01', '01', 80); INSERT INTO score VALUES ('01', '02', 90); INSERT INTO score VALUES ('01', '03', 99); INSERT INTO score VALUES ('02', '01', 70); INSERT INTO score VALUES ('02', '02', 60); INSERT INTO score VALUES ('02', '03', 80); INSERT INTO score VALUES ('03', '01', 80); INSERT INTO score VALUES ('03', '02', 80); INSERT INTO score VALUES ('03', '03', 80); INSERT INTO score VALUES ('04', '01', 50); INSERT INTO score VALUES ('04', '02', 30); INSERT INTO score VALUES ('04', '03', 20); INSERT INTO score VALUES ('05', '01', 76); INSERT INTO score VALUES ('05', '02', 87); INSERT INTO score VALUES ('06', '01', 31); INSERT INTO score VALUES ('06', '03', 34); INSERT INTO score VALUES ('07', '02', 89); INSERT INTO score VALUES ('07', '03', 98); 测试题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 -- 1、查询\"01\"课程比\"02\"课程成绩高的学生的信息及课程分数 select a.*, b.s_score as 01_score, c.s_score as 02_score from student a join score b on a.s_id = b.s_id and b.c_id = '01' left join score c on a.s_id = c.s_id and c.c_id = '02' or c.c_id = NULL where b.s_score \u003e c.s_score; -- 2、查询\"01\"课程比\"02\"课程成绩低的学生的信息及课程分数 select a.*, b.s_score as 01_score, c.s_score as 02_score from student a left join score b on a.s_id = b.s_id and b.c_id = '01' or b.c_id = NULL join score c on a.s_id = c.s_id and c.c_id = '02' where b.s_score \u003c c.s_score; -- 3、查询平均成绩大于等于60分的同学的学生编号和学生姓名和平均成绩 select b.s_id, b.s_name, ROUND(AVG(a.s_score), 2) as avg_score from student b join score a on b.s_id = a.s_id GROUP BY b.s_id, b.s_name HAVING ROUND(AVG(a.s_score), 2) \u003e= 60; -- 4、查询平均成绩小于60分的同学的学生编号和学生姓名和平均成绩 -- (包括有成绩的和无成绩的) select b.s_id, b.s_name, ROUND(AVG(a.s_score), 2) as avg_score from student b left join score a on b.s_id = a.s_id GROUP BY b.s_id, b.s_name HAVING ROUND(AVG(a.s_score), 2) \u003c 60 union select a.s_id, a.s_name, 0 as avg_score from student a where a.s_id not in ( select distinct s_id from score); -- 5、查询所有同学的学生编号、学生姓名、选课总数、所有课程的总成绩 select a.s_id, a.s_name, count(b.c_id) as sum_course, sum(b.s_score) as sum_score from student a left join score b on a.s_id = b.s_id GROUP BY a.s_id, a.s_name; -- 6、查询\"李\"姓老师的数量 select count(t_id) from teacher where t_name like '李%'; -- 7、查询学过\"张三\"老师授课的同学的信息 select a.* from student a join score b on a.s_id = b.s_id where b.c_id in ( select c_id from course where t_id = ( select t_id from teacher where t_name = '张三')); -- 8、查询没学过\"张三\"老师授课的同学的信息 select * from student c where c.s_id not in ( select a.s_id from student a join score b on a.s_id = b.s_id where b.c_id in ( select c_id from course where t_id = ( select t_id from teacher where t_name = '张三'))); -- 9、查询学过编号为\"01\"并且也学过编号为\"02\"的课程的同学的信息 select a.* from student a, score b, score c where a.s_id = b.s_id and a.s_id = c.s_id and b.c_id = '01' and c.c_id = '02'; -- 10、查询学过编号为\"01\"但是没有学过编号为\"02\"的课程的同学的信息 select a.* from student a where a.s_id in (select s_id from score where c_id = '01') and a.s_id not in (select s_id from score where c_id = '02'); -- 11、查询没有学全所有课程的同学的信息 select s.* from student s where s.s_id in ( select s_id from score where s_id not in ( select a.s_id from score a join score b on a.s_id = b.s_id and b.c_id = '02' join score c on a.s_id = c.s_id and c.c_id = '03' where a.c_id = '01')); -- 12、查询至少有一门课与学号为\"01\"的同学所学相同的同学的信息 select * from student where s_id in ( select distinct a.s_id from score a where a.c_id in (select a.c_id from score a where a.s_id = '01') ); -- 13、查询和\"01\"号的同学学习的课程完全相同的其他同学的信息 select a.* from student a where a.s_id in ( select distinct s_id from score where s_id != '01' and c_id in (select c_id from score where s_id = '01') group by s_id having count(1) = (select count(1) from score where s_id = '01')); -- 14、查询没学过\"张三\"老师讲授的任一门课程的学生姓名 select a.s_name from student a where a.s_id not in ( select s_id from score where c_id = (select c_id from course where t_id = ( select t_id from teacher where t_name = '张三')) group by s_id); -- 15、查询两门及其以上不及格课程的同学的学号，姓名及其平均成绩 select a.s_id, a.s_name, ROUND(AVG(b.s_score)) from student a left join score b on a.s_id = b.s_id where a.s_id in ( select s_id from score where s_score \u003c 60 GROUP BY s_id having count(1) \u003e= 2) GROUP BY a.s_id, a.s_name; -- 16、检索\"01\"课程分数小于60，按分数降序排列的学生信息 select a.*, b.c_id, b.s_score from student a, score b where a.s_id = b.s_id and b.c_id = '01' and b.s_score \u003c 60 ORDER BY b.s_score DESC; -- 17、按平均成绩从高到低显示所有学生的所有课程的成绩以及平均成绩 select a.s_id, (select s_score from score where s_id = a.s_id and c_id = '01') as 语文, (select s_score from score where s_id = a.s_id and c_id = '02') as 数学, (select s_score from score where s_id = a.s_id and c_id = '03') as 英语, round(avg(s_score), 2) as 平均分 from score a GROUP BY a.s_id ORDER BY 平均分 DESC; -- 18.查询各科成绩最高分、最低分和平均分：以如下形式显示：课程ID，课程name，最高分，最低分，平均分，及格率，中等率，优良率，优秀率 --及格为\u003e=60，中等为：70-80，优良为：80-90，优秀为：\u003e=90 select a.c_id, b.c_name, MAX(s_score), MIN(s_score), ROUND(AVG(s_score), 2), ROUND(100 * (SUM(case when a.s_score \u003e= 60 then 1 else 0 end) / SUM(case when a.s_score then 1 else 0 end)), 2) as 及格率, ROUND(100 * (SUM(case when a.s_score \u003e= 70 and a.s_score \u003c= 80 then 1 else 0 end) / SUM(case when a.s_score then 1 else 0 end)), 2) as 中等率, ROUND(100 * (SUM(case when a.s_score \u003e= 80 and a.s_score \u003c= 90 then 1 else 0 end) / SUM(case when a.s_score then 1 else 0 end)), 2) as 优良率, ROUND(100 * (SUM(case when a.s_score \u003e= 90 then 1 else 0 end) / SUM(case when a.s_score then 1 else 0 end)), 2) as 优秀率 from score a left join course b on a.c_id = b.c_id GROUP BY a.c_id, b.c_name; -- 19、按各科成绩进行排序，并显示排名(实现不完全) -- mysql没有rank函数 select a.s_id, a.c_id, @i := @i + 1 as i保留排名, @k := (case when @score = a.s_score then @k else @i end) as rank不保留排名, @score := a.s_score as score from ( select s_id, c_id, s_score from score WHERE c_id = '01' GROUP BY s_id, c_id, s_score ORDER BY s_score DESC ) a, (select @k := 0, @i := 0, @score := 0) s union select a.s_id, a.c_id, @i := @i + 1 as i, @k := (case when @score = a.s_score then @k else @i end) as rank, @score:=a.s_score as score from ( select s_id, c_id, s_score from score WHERE c_id='02' GROUP BY s_id, c_id, s_score ORDER BY s_score DESC ) a, (select @k := 0, @i := 0, @score := 0) s union select a.s_id, a.c_id, @i := @i + 1 as i, @k := (case when @score = a.s_score then @k else @i end) as rank, @score:=a.s_score as score from ( select s_id, c_id, s_score from score WHERE c_id='03' GROUP BY s_id, c_id, s_score ORDER BY s_score DESC ) a, (select @k := 0, @i := 0, @score := 0) s; -- 20、查询学生的总成绩并进行排名 select a.s_id, @i := @i + 1 as i, @k := (case when @score = a.sum_score then @k else @i end) as rank, @score:=a.sum_score as score from (select s_id, SUM(s_score) as sum_score from score GROUP BY s_id ORDER BY sum_score DESC) a, (select @k := 0, @i := 0, @score := 0) s; -- 21、查询不同老师所教不同课程平均分从高到低显示 select a.t_id, c.t_name, a.c_id, ROUND(avg(s_score), 2) as avg_score from course a left join score b on a.c_id = b.c_id left join teacher c on a.t_id = c.t_id GROUP BY a.c_id, a.t_id, c.t_name ORDER BY avg_score DESC; -- 22、查询所有课程的成绩第2名到第3名的学生信息及该课程成绩 select d.*, c.排名, c.s_score, c.c_id from ( select a.s_id, a.s_score, a.c_id, @i := @i + 1 as 排名 from score a, (select @i := 0) s where a.c_id = '01' ) c left join student d on c.s_id = d.s_id where 排名 BETWEEN 2 AND 3 UNION select d.*, c.排名, c.s_score, c.c_id from ( select a.s_id, a.s_score, a.c_id, @j := @j + 1 as 排名 from score a, (select @j := 0) s where a.c_id = '02' ) c left join student d on c.s_id = d.s_id where 排名 BETWEEN 2 AND 3 UNION select d.*, c.排名, c.s_score, c.c_id from ( select a.s_id, a.s_score, a.c_id, @k := @k + 1 as 排名 from score a, (select @k := 0) s where a.c_id = '03' ) c left join student d on c.s_id = d.s_id where 排名 BETWEEN 2 AND 3; -- 23、统计各科成绩各分数段人数：课程编号,课程名称,[100-85],[85-70],[70-60],[0-60]及所占百分比 select distinct f.c_name, a.c_id, b.`85-100`, b.百分比, c.`70-85`, c.百分比, d.`60-70`, d.百分比, e.`0-60`, e.百分比 from score a left join (select c_id, SUM(case when s_score \u003e 85 and s_score \u003c= 100 then 1 else 0 end) as `85-100`, ROUND(100 * (SUM(case when s_score \u003e 85 and s_score \u003c= 100 then 1 else 0 end) / count(*)), 2) as 百分比 from score GROUP BY c_id) b on a.c_id = b.c_id left join (select c_id, SUM(case when s_score \u003e 70 and s_score \u003c= 85 then 1 else 0 end) as `70-85`, ROUND(100 * (SUM(case when s_score \u003e 70 and s_score \u003c= 85 then 1 else 0 end) / count(*)), 2) as 百分比 from score GROUP BY c_id) c on a.c_id = c.c_id left join (select c_id, SUM(case when s_score \u003e 60 and s_score \u003c= 70 then 1 else 0 end) as `60-70`, ROUND(100 * (SUM(case when s_score \u003e 60 and s_score \u003c= 70 then 1 else 0 end) / count(*)), 2) as 百分比 from score GROUP BY c_id) d on a.c_id = d.c_id left join (select c_id, SUM(case when s_score \u003e= 0 and s_score \u003c= 60 then 1 else 0 end) as `0-60`, ROUND(100 * (SUM(case when s_score \u003e= 0 and s_score \u003c= 60 then 1 else 0 end) / count(*)), 2) as 百分比 from score GROUP BY c_id) e on a.c_id = e.c_id left join course f on a.c_id = f.c_id; -- 24、查询学生平均成绩及其名次 select a.s_id, @i := @i + 1 as '不保留空缺排名', @k := (case when @avg_score = a.avg_s then @k else @i end) as '保留空缺排名', @avg_score := avg_s as '平均分' from (select s_id, ROUND(AVG(s_score), 2) as avg_s from score GROUP BY s_id) a, (select @avg_score := 0, @i := 0, @k := 0) b; -- 25、查询各科成绩前三名的记录 -- 1.选出b表比a表成绩大的所有组 -- 2.选出比当前id成绩大的 小于三个的 select a.s_id, a.c_id, a.s_score from score a left join score b on a.c_id = b.c_id and a.s_score \u003c b.s_score group by a.s_id, a.c_id, a.s_score HAVING COUNT(b.s_id) \u003c 3 ORDER BY a.c_id, a.s_score DESC; -- 26、查询每门课程被选修的学生数 select c_id, count(s_id) from score a GROUP BY c_id; -- 27、查询出只有两门课程的全部学生的学号和姓名 select s_id, s_name from student where s_id in ( select s_id from score GROUP BY s_id HAVING COUNT(c_id) = 2); -- 28、查询男生、女生人数 select s_sex, COUNT(s_sex) as 人数 from student GROUP BY s_sex; -- 29、查询名字中含有\"风\"字的学生信息 select * from student where s_name like '%风%'; -- 30、查询同名同性学生名单，并统计同名人数 select a.s_name, a.s_sex, count(*) from student a JOIN student b on a.s_id != b.s_id and a.s_name = b.s_name and a.s_sex = b.s_sex GROUP BY a.s_name, a.s_sex; -- 31、查询1990年出生的学生名单 select s_name from student where s_birth like '1990%'; -- 32、查询每门课程的平均成绩，结果按平均成绩降序排列，平均成绩相同时，按课程编号升序排列 select c_id, ROUND(AVG(s_score), 2) as avg_score from score GROUP BY c_id ORDER BY avg_score DESC, c_id ASC; -- 33、查询平均成绩大于等于85的所有学生的学号、姓名和平均成绩 select a.s_id, b.s_name, ROUND(avg(a.s_score), 2) as avg_score from score a left join student b on a.s_id = b.s_id GROUP BY s_id HAVING avg_score \u003e= 85; -- 34、查询课程名称为\"数学\"，且分数低于60的学生姓名和分数 select a.s_name, b.s_score from score b LEFT JOIN student a on a.s_id = b.s_id where b.c_id = ( select c_id from course where c_name = '数学') and b.s_score \u003c 60; -- 35、查询所有学生的课程及分数情况； select a.s_id, a.s_name, SUM(case c.c_name when '语文' then b.s_score else 0 end) as '语文', SUM(case c.c_name when '数学' then b.s_score else 0 end) as '数学', SUM(case c.c_name when '英语' then b.s_score else 0 end) as '英语', SUM(b.s_score) as '总分' from student a left join score b on a.s_id = b.s_id left join course c on b.c_id = c.c_id GROUP BY a.s_id, a.s_name; -- 36、查询任何一门课程成绩在70分以上的姓名、课程名称和分数； select a.s_name, b.c_name, c.s_score from course b left join score c on b.c_id = c.c_id left join student a on a.s_id = c.s_id where c.s_score \u003e= 70; -- 37、查询不及格的课程 select a.s_id, a.c_id, b.c_name, a.s_score from score a left join course b on a.c_id = b.c_id where a.s_score \u003c 60; --38、查询课程编号为01且课程成绩在80分以上的学生的学号和姓名； select a.s_id, b.s_name from score a LEFT JOIN student b on a.s_id = b.s_id where a.c_id = '01' and a.s_score \u003e 80; -- 39、求每门课程的学生人数 select count(*) from score GROUP BY c_id; -- 40、查询选修\"张三\"老师所授课程的学生中，成绩最高的学生信息及其成绩 -- 查询老师id select c_id from course c, teacher d where c.t_id = d.t_id and d.t_name = '张三'; -- 查询最高分（可能有相同分数） select MAX(s_score) from score where c_id = '02'; -- 查询信息 select a.*, b.s_score, b.c_id, c.c_name from student a LEFT JOIN score b on a.s_id = b.s_id LEFT JOIN course c on b.c_id = c.c_id where b.c_id = (select c_id from course c, teacher d where c.t_id = d.t_id and d.t_name = '张三') and b.s_score in (select MAX(s_score) from score where c_id = '02'); -- 41、查询不同课程成绩相同的学生的学生编号、课程编号、学生成绩 select DISTINCT b.s_id, b.c_id, b.s_score from score a, score b where a.c_id != b.c_id and a.s_score = b.s_score; -- 42、查询每门功成绩最好的前两名 -- 牛逼的写法 select a.s_id, a.c_id, a.s_score from score a where (select COUNT(1) from score b where b.c_id = a.c_id and b.s_score \u003e= a.s_score) \u003c= 2 ORDER BY a.c_id; -- 43、统计每门课程的学生选修人数（超过5人的课程才统计）。要求输出课程号和选修人数，查询结果按人数降序排列，若人数相同，按课程号升序排列 select c_id, count(*) as total from score GROUP BY c_id HAVING total \u003e 5 ORDER BY total, c_id ASC; -- 44、检索至少选修两门课程的学生学号 select s_id, count(*) as sel from score GROUP BY s_id HAVING sel \u003e= 2; -- 45、查询选修了全部课程的学生信息 select * from student where s_id in ( select s_id from score GROUP BY s_id HAVING count(*) = (select count(*) from course)); --46、查询各学生的年龄 -- 按照出生日期来算，当前月日 \u003c 出生年月的月日则，年龄减一 select s_birth, (DATE_FORMAT(NOW(), '%Y') - DATE_FORMAT(s_birth, '%Y') - (case when DATE_FORMAT(NOW(), '%m%d') \u003e DATE_FORMAT(s_birth, '%m%d') then 0 else 1 end)) as age from student; -- 47、查询本周过生日的学生 select * from student where WEEK(DATE_FORMAT(NOW(), '%Y%m%d')) = WEEK(s_birth) select * from student where YEARWEEK(s_birth) = YEARWEEK(DATE_FORMAT(NOW(), '%Y%m%d')) select WEEK(DATE_FORMAT(NOW(), '%Y%m%d')); -- 48、查询下周过生日的学生 select * from student where WEEK(DATE_FORMAT(NOW(), '%Y%m%d')) + 1 = WEEK(s_birth); -- 49、查询本月过生日的学生 select * from student where MONTH(DATE_FORMAT(NOW(), '%Y%m%d')) = MONTH(s_birth); -- 50、查询下月过生日的学生 select * from student where MONTH(DATE_FORMAT(NOW(), '%Y%m%d')) + 1 = MONTH(s_birth); ","description":"","tags":["MSB","MySQL"],"title":"MySQL 学生表练习题","uri":"/posts/mysql/mysql-student-practice/"},{"categories":null,"content":"Spark 的 cache、persist、checkpoint 为什么要使用 重复使用某个转换过程很耗时的转换算子会严重影响性能。因此将这种转换算子的结果 RDD 进行缓存，再次使用时从缓存中直接获取结果 RDD，而不从头进行转换计算，可以提高效率。\npersist 和 cache persist 可以指定多个存储级别，指定将该 RDD 存储到什么位置。见 org.apache.spark.storage.StorageLevel。 cache 就是存储级别为 MEMORY_ONLY 的 persist 存储级别 说明 NONE 不缓存 DISK_ONLY 使用未序列化的方式，将数据保存到磁盘 MEMORY_ONLY 使用未序列化的方式，将数据保存到内存 MEMORY_ONLY_SER 使用序列化的方式，将数据保存到内存 MEMORY_AND_DISK 使用未序列化的方式，优先将数据保存到内存，如果内存不足则保存到磁盘 MEMORY_AND_DISK_SER 使用序列化的方式，优先将数据保存到内存，如果内存不足则保存到磁盘 DISK_ONLY_2、MEMORY_ONLY_2、MEMORY_ONLY_SER_2、MEMORY_AND_DISK_2、MEMORY_AND_DISK_SER_2 在原来的基础上，将持久化后的数据在其他节点生成一份副本 OFF_HEAP 使用序列化的方式，把数据保存到堆外内存 序列化方式会将 RDD 的每个 partition 序列化成一个字节数组，可以节省内存。\n如果因为内存不足等原因缓存失败，此时如果再次使用该 RDD，依旧会从头执行它的转换过程。\n示例 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 public static void main(String[] args) { SparkConf conf = new SparkConf() .setAppName(\"spark-rdd-cache-persist\") .setMaster(\"local\"); JavaSparkContext sc = new JavaSparkContext(conf); sc.setLogLevel(\"ERROR\"); JavaRDD\u003cInteger\u003e dataRdd = sc.parallelize(Arrays.asList(1, 2, 3)); // 模拟一个耗时，并且会被重复使用的 Transform 算子 JavaRDD\u003cInteger\u003e slowRdd = dataRdd.map(d -\u003e { TimeUnit.SECONDS.sleep(1); return d; }); // 💡对执行慢并且会被重复使用的 Transform 算子进行缓存 slowRdd.cache(); //slowRdd.persist(StorageLevel.MEMORY_ONLY()); // 第一个 Action 算子 long s = System.currentTimeMillis(); slowRdd.foreach(d -\u003e {}); long e = System.currentTimeMillis(); System.out.println(\"first：\" + (e - s)); // 第二个 Action 算子 s = System.currentTimeMillis(); slowRdd.foreach(d -\u003e {}); e = System.currentTimeMillis(); System.out.println(\"second：\" + (e - s)); } 结果\n1 2 3 4 5 6 7 # 不对 slowRdd 进行缓存，两次执行时间均在 3 秒以上 first：4202 second：3057 # 对 slowRdd 进行缓存，再次使用 slowRdd 时，直接从缓存中获取，时间显著减少 first：4139 second：49 注意事项 如果 RDD 结果过大，需要保证内存/磁盘足够大，否则会缓存失败。缓存失败后，再次使用该 RDD 时会重新执行 Transform 的过程，即不会带来性能的提升。\n如果 RDD 结果过大，可能直接读取结果的耗时大于重新计算的耗时，此时进行缓存还可能降低效率。\npersist 持久化的数据由 blockManager 管理，所以当 executor 所在进程 stop 后，持久化的数据也会被清除。\ncheckpoint persist 保存的数据在进程结束后会被清除。\ncheckpoint 可以手动指定保存位置，可以是磁盘，也可以是 HDFS 等，从而提高数据的容错性。进程结束后数据不会被清除，再次启动时，可以从指定位置直接读取数据。\n示例 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 public static void main(String[] args) throws IOException { SparkConf conf = new SparkConf() .setAppName(\"spark-rdd-checkpoint\") .setMaster(\"local\"); JavaSparkContext sc = new JavaSparkContext(conf); sc.setLogLevel(\"ERROR\"); // 💡设置 checkpoint 的保存位置，可以使用 hdfs sc.setCheckpointDir(\"/path/to/checkpoint\"); JavaRDD\u003cInteger\u003e dataRdd = sc.parallelize(Arrays.asList(1, 2, 3)); // 模拟一个耗时，并且会被重复使用的 Transform 算子 JavaRDD\u003cInteger\u003e slowRdd = dataRdd.map(d -\u003e { TimeUnit.SECONDS.sleep(1); return d; }); // 模拟从数据库获取这个 RDD 的 checkpoint 文件路径 String checkpointFile = readCheckpointFile(); if (Objects.isNull(checkpointFile) || checkpointFile.length() == 0) { // 💡数据库中不存在 checkpoint 文件路径，则对 RDD 进行 checkpoint slowRdd.checkpoint(); } else { // 数据库中存在 checkpoint 文件，则从该文件还原 slowRdd = sc.checkpointFile(checkpointFile); } // 💡对 RDD 的 checkpoint 实际发生在第一次执行的 Action 算子中 long s = System.currentTimeMillis(); slowRdd.foreach(d -\u003e {}); long e = System.currentTimeMillis(); System.out.println(\"耗时：\" + (e - s)); // 首次进行 checkpoint 时，把 checkpoint 文件的路径保存到数据库。在程序重新启动时，可以直接从该文件恢复 RDD if (Objects.isNull(checkpointFile) || checkpointFile.length() == 0) { /* 💡sc.setCheckpointDir() 只是指定了 checkpoint 的输出文件夹， 💡每个 RDD 的实际数据是保存在该文件夹下的 /uuid/rdd-nn 目录下，在恢复的时候需要指定到 rdd-nn 文件夹才行 */ checkpointFile = slowRdd.getCheckpointFile().get(); saveCheckpointFile(checkpointFile); } } private static String readCheckpointFile() throws IOException { BufferedReader br = new BufferedReader(new FileReader(\"/path/to/db.txt\")); String checkpointFile = br.readLine(); br.close(); return checkpointFile; } private static void saveCheckpointFile(String checkpointFile) throws IOException { BufferedWriter bw = new BufferedWriter(new FileWriter(\"/path/to/db.txt\")); bw.write(checkpointFile); bw.flush(); bw.close(); } 执行结果对比\n1 2 3 4 # 第一次启动，对 slowRdd 进行了计算和 checkpoint，所以耗时较长 耗时：9490 # 再次启动，直接从 checkpoint 文件恢复了 slowRdd，明显提高了性能 耗时：577 注意事项 进行 checkpoint 的 RDD 会被计算两次，所以在执行 checkpoint 前最好先执行一次 persist，可以提高效率。\n","description":"","tags":["Spark","JAVA"],"title":"Spark 的 cache、persist、checkpoint","uri":"/posts/spark/spark-cache-persist-checkpoint/"},{"categories":null,"content":"Spark SQL 恢复 checkpoint 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 public static void main(String[] args) { SparkConf conf = new SparkConf() .setAppName(\"spark-sql-recovery-checkpoint\") .setMaster(\"local[*]\"); SparkSession ss = SparkSession.builder().config(conf).getOrCreate(); SparkContext sc = ss.sparkContext(); sc.setLogLevel(\"ERROR\"); // 设置 checkpoint 文件输出文件夹 sc.setCheckpointDir(\"file:/path/to/checkpoint\"); ss.read().option(\"header\", true).csv(\"/path/to/user.csv\").createOrReplaceTempView(\"user\"); ss.read().option(\"header\", true).csv(\"/path/to/balance.csv\").createOrReplaceTempView(\"balance\"); Dataset\u003cRow\u003e ds = ss.sql(\"select * from user u left join balance b on u.id = b.id\"); // 在 checkpoint 前进行 cache，可以提高效率 ds.cache(); // 执行此处后会在 checkpoint 文件夹下生成 rdd-nn 文件夹 Dataset\u003cRow\u003e checkpoint = ds.checkpoint(); // 获取 rdd-nn 文件夹的路径，恢复 checkpoint 时，需要使用该路径 String checkpointFile = ((LogicalRDD) checkpoint.queryExecution().optimizedPlan()).rdd().getCheckpointFile().get(); // 获取恢复后的 RDD RDD\u003cInternalRow\u003e recoveryRdd = sc.checkpointFile(checkpointFile, ClassManifestFactory.classType(UnsafeRow.class)); StructType schema = ds.schema(); // 生成恢复后的 Dataset Dataset\u003cRow\u003e recoveryDs = ss.internalCreateDataFrame(recoveryRdd, schema, false); ds.show(); recoveryDs.show(); } 参考文档 Checkpointing\n","description":"","tags":["Spark","JAVA"],"title":"Spark SQL 恢复 checkpoint","uri":"/posts/spark/sparksql/spark-sql-recovery-checkpoint/"},{"categories":null,"content":"RESTful REST 和 RESTful REST 全称为 REpresentational State Transfer（表述性状态转移），最初由 Roy Fielding 在 论文 中提出。RESTful 是一种架构风格，表示有 REST 风格的。\n资源的表述性状态转移 表述性状态转移，实际上是“资源的表述性状态转移”，可以将其拆分为 3 部分进行说明。\n资源\nREST 将网络上的所有实体（例如文本、图片、服务等）都称为“资源”，每个资源都有特定的 URI，可以通过这个 URI 来获取或修改它。\n表述性\n表述性即“资源”具体呈现出来的形式，例如 txt、HTML、XML、JSON、二进制、JPG、PNG 格式等。\n状态转移\n通过 HTTP 协议的四种请求方式，来对资源进行获取或修改。其中 GET 用来获取资源、POST 用来新建资源、PUT 用来更新资源、DELETE 用来删除资源\nRST 的约束 REST 有 6 个指导约束，如果接口满足这些约束，就可以说该接口是符合 REST 风格的。\n客户端-服务器：就是前后端分离，服务端和客户端可以独立发展 无状态：服务端不保存客户端的状态信息（不使用 session，通常使用 token） 可缓存：GET 请求应该是可缓存的。即获取资源的请求是可以缓存的 统一接口：服务端提供接口，可以给不同的客户端使用。缺点是会降低效率，因为为了能给不同的客户端使用，服务端接口返回的信息包含了对象的全部属性，不能做定制化返回 分层系统：对服务进行分层，在真实服务前可添加网关或代理组件，或将不同服务部署在不同的服务器。服务与服务、客户端与服务间可能包含多个中介。不同层间可以按层来设置安全策略。因为引入了中介层，所以会增加开销和延迟，可以通过设置缓存进行抵消。 按需代码（可选）：服务端可以通过返回脚本等形式来扩展客户端功能。 REST API 设计指南 可以参考 GitHub API\nAPI 与用户的通信协议，总是使用 HTTPs 协议\n尽量将 API 部署在专用域名下\n1 2 3 4 # 专用域名 https://api.github.com # 如果确定 API 很简单不会有进一步扩展，可以考虑放在主域名下 https://github.com/api API 中应该带版本号\n1 2 3 4 5 6 # 可以在 URL 中包含版本号，简介明了（同时与资源应该有永不改变的 URI 思想冲突） /api/v3/rate-limit # 可以在请求头的 Accept 中添加版本号（要求客户端必须能向请求头中设置信息） Accept: application/vnd.domain.v3+json # 可以自定义请求头来设置版本号（要求客户端必须能向请求头中设置信息） x-github-media-type: github.v3 API 版本号应该只包含主版本号\n1 2 3 4 5 6 # 主版本号.次版本号.修订号 # 只包含主版本号 /api/v1 # 不应该包含次版本号和修订号 /api/v1.1 /api/v1.1.1 不要使用文件扩展名\n1 2 # 不要在请求后添加文件扩展名，应该使用 `Content-Type` 在请求头中达 /users.xml 使用名词来表示资源，并使用小写字母\n1 2 3 4 5 6 7 8 9 # 获取所有用户 /users # 获取 ID=1 的用户 /user/1 # 获取 ID=1 的用户的所有仓库 /user/1/repos # 这是不符合标准的，因为包含动词 get /getAllUsers 使用 HTTP 协议的请求方式来表明意图\n请求方式 说明 GET 获取资源 POST 创建资源 PUT 更新资源 PATCH 部分更新资源 DELETE 删除资源 合理使用 Query Parameter，禁止多层 URL\n1 2 3 4 5 6 7 8 9 10 11 # 获取 ID=1 的用户的所有仓库 /user/1/repos # 获取 ID=1 的用户的所有私有仓库 /user/1/repos?type=private # 分页获取 ID=1 的用户的私有仓库 /user/1/repos?type=private\u0026page=1\u0026per-page=5 # 获取 ID=1 用户的前 10 个仓库 /user/1/repos?limit=10 # 这样的 URL 语义不明确，并且难以扩展 /user/1/repos/private URL 中多个单词使用 - 进行分隔而不是 _，因为 _ 在某些客户端会被隐藏\n1 /rate-limit 不要在 URL 结尾添加 /\n1 2 3 /users # 不要再结尾添加 / /users/ 响应结果中包含准确的状态码。可以使用 HTTP 状态码，也可以自定义状态码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 HTTP/1.1 401 Bad Request Content-Type: application/json { \"error\": \"Invalid API key.\" } # 发生错误不要返回 200，否则客户端需要解析后才能获取错误信息 HTTP/1.1 200 OK Content-Type: application/json { \"status\": \"failure\", \"data\": { \"error\": \"Invalid API key.\" } } RESTful API 最好做到 Hypermedia（HATEOAS），即返回结果中提供相关链接\n1 2 3 4 5 6 7 8 9 10 11 12 # 请求成功后，可以把相关的链接放到返回参数中，这样客户端根据返回结果就知道下一步可以做什么 HTTP/1.1 200 OK Content-Type: application/json { \"status\": \"In progress\", \"links\": {[ { \"rel\":\"cancel\", \"method\": \"delete\", \"href\":\"/api/status/12345\" } , { \"rel\":\"edit\", \"method\": \"put\", \"href\":\"/api/status/12345\" } ]} } API 的身份认证应该使用 OAuth 2.0 框架\n统一返回格式\n返回结果应该尽量使用 JSON，并保持格式一致，便于客户端统一解析\n参考文档 http://www.ruanyifeng.com/blog/2018/10/restful-api-best-practices.html http://www.ruanyifeng.com/blog/2014/05/restful_api.html http://restful.p2hp.com ","description":"","tags":["RESTful"],"title":"RESTful","uri":"/posts/restful/restful/"},{"categories":null,"content":"docker 启动 nginx 将静态文件、配置、日志和宿主机进行映射的启动 配置文件，可放在宿主机的 $HOME/.local/share/docker/nginx/conf/nginx.conf 中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; #include /etc/nginx/conf.d/*.conf; # 可以在 conf.d 目录下使用 .conf 结尾的配置文件进行配置 include conf.d/*.conf; charset utf-8; } 启动新容器\n1 2 3 4 5 6 7 8 9 10 11 docker run -d \\ --restart=always \\ --name nginx \\ -p 80:80 \\ -v $HOME/.local/share/docker/nginx/html:/usr/share/nginx/html:ro \\ -v $HOME/.local/share/docker/nginx/conf/nginx.conf:/etc/nginx/nginx.conf:ro \\ -v $HOME/.local/share/docker/nginx/conf.d:/etc/nginx/conf.d:ro \\ -v $HOME/.local/share/docker/nginx/log:/var/log/nginx \\ -e UID=`id -u` \\ -e GID=`id -g` \\ nginx:1.23.1 如果有 SSL 证书 可以将证书放在宿主机的 $HOME/.local/share/docker/nginx/cert 目录下\n1 2 $ ls $HOME/.local/share/docker/nginx/cert com.domain.key com.domain.pem 在宿主机的 $HOME/.local/share/docker/nginx/conf.d 下添加配置文件\n80.conf\n1 2 3 4 5 6 server { listen 80; # 按照域名证书进行调整 server_name *.domain.com domain.com; return 301 https://$server_name$request_uri; } 把发送到 80 的请求都重定向到 443\n443.conf\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 server { listen 443 ssl; # 按照域名证书进行调整 server_name *.domain.com domain.com; # 开启ssl # 配置ssl证书 ssl_certificate /usr/share/nginx/cert/com.domain.pem; # 配置证书秘钥 ssl_certificate_key /usr/share/nginx/cert/com.domain.key; # ssl会话cache ssl_session_cache shared:SSL:1m; # ssl会话超时时间 ssl_session_timeout 5m; # 配置加密套件，写法遵循 openssl 标准 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE; ssl_prefer_server_ciphers on; location / { root /usr/share/nginx/html; index index.html index.htm; } } 在启动命令中添加下面两个参数\n1 2 -p 443:443 \\ -v $HOME/.local/share/docker/nginx/cert:/usr/share/nginx/cert \\ ","description":"","tags":["Nginx"],"title":"docker 启动 nginx","uri":"/posts/nginx/nginx-docker/"},{"categories":null,"content":"使用 netboot.xyz 给 Oracle Cloud Infrastructure 实例重装系统 通过 Oracle Cloud Shell 连接并登录实例\n计算 -\u003e 实例 -\u003e 实例详细信息\n从 netboot.xyz 下载合适的文件，将其添加到系统启动菜单后，重启系统\n1 2 3 4 5 6 7 8 # 创建目录 mkdir -p /boot/efi/EFI/netboot # 因为使用的是 OCI ARM 架构的服务器，所以下载了 `netboot.xyz-arm64.efi` wget https://boot.netboot.xyz/ipxe/netboot.xyz-arm64.efi /boot/efi/EFI/netboot # 将该文件添加到启动项，名称为 netboot.xyz efibootmgr -c -L netboot.xyz -l /EFI/netbootnetboot.xyz-arm64.efi # 重启服务器 reboot 服务器重启后会进入如下界面\n选择 Linux Network Installs，按回车键，然后选好需要安装的系统，等待下载完成\n1 2 http://mirrors.kernel.org/fedora/releases/35/Server/aarch64/os/images/pxeboot/vmlinuz... ok http://mirrors.kernel.org/fedora/releases/35/Server/aarch64/os/images/pxeboot/initrd.img... 52% 输入 1 选择使用 VNC 模式。使用 VNC 前请确定为该服务器分配了外网IP，否则只能在 Cloud Shell 页面使用终端进行安装\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 Starting installer, one moment... anaconda 35.22.2-3.fc35 for Fedora 35 started. * installation log files are stored in /tmp during the installation * shell is available on TTY2 * if the graphical installation interface fails to start, try again with the inst.text bootoption to start text installation * when reporting a bug add logs from /tmp as separate text/plain attachments ================================================================================ ================================================================================ Text mode provides a limited set of installation options. It does not offer custom partitioning for full control over the disk layout. Would you like to use VNC mode instead? 1) Start VNC 2) Use text mode # 输入 1 启动 VNC 模式 Please make a selection from the above ['c' to continue, 'q' to quit, 'r' to refresh]: 1 ================================================================================ ================================================================================ VNC Password Please provide VNC password (must be six to eight characters long). You will have to type it twice. Leave blank for no password # 设置 VNC 密码 Password: Password (confirm): 12:30:35 Starting VNC... 12:30:37 The VNC server is now running. 12:30:37 You chose to execute vnc with a password. # 参考这里 10.0.0.49:1，所以使用 VNC Viewer 连接时输入 外网IP:1 进行连接 12:30:37 Please manually connect your vnc client to orcl-0.sub10230137080.vnc1000016.oraclevcn.com:1 (10.0.0.49:1) to begin the install. 12:30:37 Attempting to start vncconfig 安全组设置开放所有端口\n使用 VNC Viewer 进行远程连接，然后通过图形界面进行安装即可\n1 外网IP:1 ","description":"","tags":["Linux","netboot.xyz"],"title":"使用 netboot.xyz 给 Oracle Cloud Infrastructure 实例重装系统","uri":"/posts/linux/oracle-cloud-reinstall-os-by-netboot-xyz/"},{"categories":null,"content":"Java17 新特性 https://docs.oracle.com/en/java/javase/17/language/java-language-changes.html\n封闭类 封闭类（sealed classes）在 Java15 中以预览版发布，在 Java16 中改进后的封闭类再次以预览版发布，在 Java17 中正式发布。\n类的扩展性\n在有封闭类之前，Java 中类的扩展性只有两种极端情况：要么可以任意扩展子类（默认情况），要么不允许扩展子类（final 或 私有内部类） 而封闭类则处于两者之间，仅允许有限的扩展 扩展性使用顺序\n在日常的接口涉及和编码实践中，应该按由高到低的顺序使用下方的四个限定方法\n使用私有类 使用 final 修饰符 使用 sealed 修饰符 不受限制的扩展性 新的关键字\nJava 引入了 3 个封闭类相关的关键字\nsealed：被 sealed 修饰的类是封闭类，被 sealed 修饰的接口是封闭接口 permits：用于标识哪些类可以继承该类/接口 non-sealed：封闭类的子类必须使用 final/sealed/non-sealed 修饰，分别表示该子类“不允许有子类”、“允许有限个子类”、“允许有任意个子类”。 封闭类和许可类\n使用 sealed 修饰的父类称为“封闭类”，封闭类的子类称为“许可类”\n封闭类必须有许可类 封闭类和许可类必须在同一模块或者同一包空间 许可类必须是封闭类的直接扩展类 许可类必须声明是否保持封闭 许可类可以声明为终极类（final），从而关闭扩展性 许可类可以声明为封闭类（sealed），从而延续受限制的扩展性 许可类可以声明为解封类（non-sealed），从而支持不受限制的扩展性 代码示例\n以四大人种（Race）为例：黄种人（Mongoloid）、白种人（Caucasoid）、黑种人（Negroid）、棕种人（Australoid）\n父类（封闭类）使用 sealed 关键字进行修饰，并使用 permits 关键字指定它的所有子类（许可类）\n1 2 3 4 5 6 7 8 9 /** * 人种，Race 类只允许有下面 4 种子类实现 * \u003cp\u003e四大人种 * \u003cli\u003e黑种人（Negroid） * \u003cli\u003e黄种人（Mongoloid） * \u003cli\u003e白种人（Caucasoid） * \u003cli\u003e棕种人（Australoid） */ public sealed interface Race permits Mongoloid, Caucasoid, Negroid, Australoid {} 子类（许可类）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * 黑种人 * \u003cp\u003e可以使用 final 修饰，不允许该许可类再派生子类 */ public final class Negroid implements Race {} /** * 黄种人 * \u003cp\u003e可以使用 sealed 修饰，允许该许可类可以派生有限个子类，需要使用 permits 指定哪些类可以继承该类 */ public sealed class Mongoloid implements Race permits Chinese {} /** * 白种人 * \u003cp\u003e可以使用 non-sealed 修饰，允许该许可类派生任意个子类 */ public non-sealed class Caucasoid implements Race {} /** * 棕种人 */ public final class Australoid implements Race {} 可以省略 permits 的情况\n许可类和封闭类必须处于同一个模块（module）或者包空间（package）里。如果两者处在同一个模块里，那么他们可以处在不同的包空间里。\n1 2 3 # module-info.java module icu.intelli { } 1 2 3 4 5 6 7 8 9 package icu.intelli.sealed.modern; public sealed interface Race permits // 封闭类和许可类在同一个模块，不在同一个包，可以使用全类名的方式声明许可类 icu.intelli.sealed.modern.impl.Mongoloid, icu.intelli.sealed.modern.impl.Caucasoid, icu.intelli.sealed.modern.impl.Negroid, icu.intelli.sealed.modern.impl.Australoid { } 封闭类和许可类再同一个源码文件里，封闭类可以不使用 permits 指定许可类列表\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /** * 封闭类和许可类在同一个源码文件里，封闭类可以不使用 `permits` 指定许可类列表 */ public sealed interface Race { /** * 内部类 */ final class Negroid implements Race { } sealed class Mongoloid implements Race { } non-sealed class Caucasoid implements Race { } final class Chinese extends Mongoloid { } } /** * 非内部类 */ final class Australoid implements Race { } 虽然可以省略 permits，但是推荐明确写明 permits，便于阅读代码。\n","description":"","tags":["Java"],"title":"Java17 新特性","uri":"/posts/java/java%E6%96%B0%E7%89%B9%E6%80%A7/java17-new-future/"},{"categories":null,"content":"Java10 新特性 ","description":"","tags":["Java"],"title":"Java10 新特性","uri":"/posts/java/java%E6%96%B0%E7%89%B9%E6%80%A7/java10-new-future/"},{"categories":null,"content":"Java12 新特性 ","description":"","tags":["Java"],"title":"Java12 新特性","uri":"/posts/java/java%E6%96%B0%E7%89%B9%E6%80%A7/java12-new-future/"},{"categories":null,"content":"Java13 新特性 ","description":"","tags":["Java"],"title":"Java13 新特性","uri":"/posts/java/java%E6%96%B0%E7%89%B9%E6%80%A7/java13-new-future/"},{"categories":null,"content":"Java14 新特性 switch 表达式 switch 表达式在 Java12 中以预览版发布，在 Java13 中改进后的 switch 表达式再次以预览版发布，在 Java14 中正式发布。\n对比 switch 语句和 switch 表达式\n以获取当前月份的天数为例，对 switch 语句和 switch 表达式进行对比\nswitch 语句\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 LocalDate today = LocalDate.now(); Month month = today.getMonth(); // 需要声明一个变量用于存储结果值（对变量的声明和赋值是分离的） int daysInMonth; switch (month) { // 利用 case 的穿透特性，需要在每钟情况前都添加 case 关键字 case JANUARY: case MARCH: case MAY: case JULY: case AUGUST: case OCTOBER: case DECEMBER: // 需要在每种情况中都写赋值语句。（如果忘记赋值，编译器也不会报错，会使用默认值进行返回） daysInMonth = 31; // 每种情况都要写 break 语句。（如果忘记写，就会穿透，从而出现 bug） break; case FEBRUARY: if (today.isLeapYear()) { daysInMonth = 29; } else { daysInMonth = 28; } break; default: daysInMonth = 30; break; } System.out.println( \"There are \" + daysInMonth + \" days in this month.\"); switch 表达式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 LocalDate today = LocalDate.now(); Month month = today.getMonth(); // 不需要单独声明结果变量，直接使用 = 连接 switch 表达式即可，变量的声明和赋值是在一起的 int daysInMonth = switch (month) { // 需要使用 case 的穿透时，不需要在每钟情况前都写 case 关键字 case JANUARY, MARCH, MAY, JULY, AUGUST, OCTOBER, // 不需要重复写赋值语句和 break DECEMBER -\u003e 31; case FEBRUARY -\u003e { if (today.isLeapYear()) { // 引入了新的关键字 yield，用来在 case 块中根据条件来返回不同的值 yield 29; } else { yield 28; } } default -\u003e 30; }; System.out.println( \"There are \" + daysInMonth + \" days in this month.\"); switch 表达式的变化\nswitch 表达式对变量的声明和赋值是在一起的\n1 2 3 int daysInMonth = switch (month) { // ... } switch 表达式使用 case 穿透时，不需要重复写 case 关键字，并且使用 , 进行分割\n1 2 3 case JANUARY, MARCH, // ... switch 表达式中使用 -\u003e 而不是 :。-\u003e 右侧可以是表达式、代码块或者异常抛出语句。使用 -\u003e 后就不需要添加 break 了\n1 2 3 case JANUARY, // 不需要重复写赋值语句和 break DECEMBER -\u003e 31; switch 表达式中可以使用 yield 关键字返回结果值\n1 2 3 4 5 6 7 case FEBRUARY -\u003e { if (today.isLeapYear()) { yield 29; } else { yield 28; } } 怪味的 switch 表达式\n以下的写法都是可以编译通过的，但是强烈不推荐这样使用！！！\n使用了 -\u003e，但是依旧使用变量赋值的方式，并使用 break\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 int daysInMonth; switch (month) { case JANUARY, // ... DECEMBER -\u003e // 使用 -\u003e 后依旧使用赋值语句，不简洁 daysInMonth = 31; case APRIL, // ... JUNE -\u003e { daysInMonth = 30; // 使用了 -\u003e 的同时使用 break 是多余的 break; } // ... } 同时使用 : 和 yield\n1 2 3 4 5 6 7 8 9 10 11 12 int daysInMonth = switch (month) { // 使用 switch 表达式后，依旧使用 : 和 case 的方式并不简洁 case JANUARY: // ... case DECEMBER: yield 31; case APRIL: // ... case NOVEMBER: yield 30; // ... }; ","description":"","tags":["Java"],"title":"Java14 新特性","uri":"/posts/java/java%E6%96%B0%E7%89%B9%E6%80%A7/java14-new-future/"},{"categories":null,"content":"Java15 新特性 文字块 文字块（text blocks）在 Java13 中以预览版发布，在 Java14 中进行了改进，在 Java15 中正式发布。\n语法\n文字块的开始分隔符由三个双引号（\"\"\"）、任意个空格以及换行结束符共同构成，开始分隔符必须单独成行。文字块的结束分隔符由三个双引号（\"\"\"）构成。\n1 2 3 4 5 // 开始分隔符必须单独成行 String textBlock = \"\"\" \"\"\"; // 这种写法编译不通过 textBlock = \"\"\"\"\"\"; 对比普通字符串\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 不使用文字块 String nonTextBlock = \"{\\n\" + \" \\\"name\\\":\\\"张三\\\",\\n\" + \" \\\"gender\\\":\\\"男\\\",\\n\" + \"}\"; // 使用文字块 String textBlock = \"\"\" { \"name\":\"张三\", \"gender\":\"男\" } \"\"\"; // 输出结果的格式是相同的 System.out.println(nonTextBlock); System.out.println(textBlock); 使用文字块后，不需要再使用如下字符进行格式化，从而达到“所见即所得”的效果：\n换行字符（\\n） 连接字符（+） 双引号没有使用转义字符（\\） 文字块的编译\n文字块在编译期间会通过如下三个步骤将其编译为字符串，文字块的本质就是字符串\n将文字内容里的所有换行符统一换成 LF（\\u000A） 为了能够处理 Java 源代码里的缩进空格，要删除所有文字内容行和结束分隔符两者共享的前导空格，以及所有文字内容行的尾部空格 最后处理转义字符，这样开发人员编写的转义序列就不会在前两步被修改或删除 下方以 · 表示前导空格，以 ! 表示尾部空格，在编译时，这些空格都会被去掉。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 String textBlock = \"\"\" ····{ ···· \"name\":\"张三\",!!!! ···· \"gender\":\"男\" ····} ····!!!!\"\"\"; // 可以利用结束符，调整前导空格的个数，进而调整文本的位置 String textBlock = \"\"\" ···· { ···· \"name\":\"张三\",!!!! ···· \"gender\":\"男\" ···· } ····\"\"\"; // length 是 3（1、换行符、2） String textBlock = \"\"\" ····1!!! ····2!!!\"\"\"; // length 是 4（1、换行符、2、换行符） String textBlock = \"\"\" ····1!!! ····2!!! ····!!!\"\"\"; // 可以使用 \\s 代表空格转移符，length 是 6（1、空格、换行符、2、换行符、空格） String textBlock = \"\"\" ····1\\s ····2!!! ····\\s\"\"\"; // 如果一行中的字符太多，可以使用 \\（行终止符）对其进行换行书写。实际等价于 “Hello World”。 // 在 Hello 和 \\ 之间包含一个空格，根据上方的编译规则，该空格是会被保留的 String textBlock = \"\"\" ····Hello \\ ····World\"\"\"; ","description":"","tags":["Java"],"title":"Java15 新特性","uri":"/posts/java/java%E6%96%B0%E7%89%B9%E6%80%A7/java15-new-future/"},{"categories":null,"content":"Java16 新特性 类型匹配 类型匹配在 Java14 中以预览版发布，在 Java15 中改进后的类型匹配再次以预览版发布，在 Java16 中正式发布。\n类型匹配主要是对 instanceof 关键字的语法进行了升级\n对比 instanceof 语法\n在 Java16 之前，使用 instanceof 的代码\n1 2 3 4 5 6 7 8 9 public static boolean oldInstanceof(Shape shape) { // 1. 类型判断 if (shape instanceof Rectangle) { // 2. 强制类型转换 // 3. 声明新的本地变量 Rectangle rect = (Rectangle) shape; return rect.length() == rect.width(); } } 在 Java16 之后，使用 instanceof\n1 2 3 4 5 6 public static boolean newInstanceof(Shape shape) { // 类型判断 + 声明变量 if (shape instanceof Rectangle rect) { return rect.length() == rect.width(); } } 可以发现，新的 instanceof 语法，不需要每次都进行强制类型转换和声明新变量\n匹配变量的作用域\ninstanceof 语句的各个部分可以使用上方名词进行描述。匹配变量作为我们最终需要使用的变量，我们需要知道它在不同场景下的作用域\n正常情况\n1 2 3 4 5 6 7 public static boolean isSquare(Shape shape) { if (shape instanceof Rectangle rect) { // 这里可以使用 rect return rect.length() == rect.width(); } // 这里不能使用 rect } 取反\n1 2 3 4 5 6 7 8 9 public static boolean isSquare(Shape shape) { // 如果目标变量（shape）不是 Rectangle 类型，我们就不能使用匹配变量（rect）；否则，我们可以使用匹配变量（rect） if (!(shape instanceof Rectangle rect)) { // 这里不能使用 rect return shape instanceof Square; } // 这里可以使用 rect return rect.length() == rect.width(); } 逻辑与和逻辑或\n1 2 3 4 5 6 7 8 9 10 11 public static boolean isSquare(Shape shape) { return shape instanceof Square || // 逻辑与，当前面条件为 true 时才会判断后面的条件。所以 rect 会被赋值，因此可以在逻辑与后面直接使用 rect (shape instanceof Rectangle rect \u0026\u0026 rect.length() == rect.width()); } public static boolean isSquare(Shape shape) { return shape instanceof Square || // 逻辑或，当前面条件为 false 时，才会判断后面的条件。因为前面为 false，所以 shape 不是 Rectangle 类型，所以 rect 不会被赋值，因此在逻辑或后面也就不能使用 rect。该语句编译器会报错。 (shape instanceof Rectangle rect || rect.length() == rect.width()); } 按位与和按位或\n1 2 3 4 5 6 7 8 9 10 11 12 // 因为按位与和按位或无论前面条件是否成立都会执行后方的判断条件 public static boolean isSquare(Shape shape) { return shape instanceof Square | // 所以，编译器无法确定前方的条件是否成立，也就不知道 rect 是否被赋值，因此不能在按位与后使用 rect (shape instanceof Rectangle rect \u0026 rect.length() == rect.width()); } public static boolean isSquare(Shape shape) { return shape instanceof Square | // 所以，编译器无法确定前方的条件是否成立，也就不知道 rect 是否被赋值，因此不能在按位或后使用 rect (shape instanceof Rectangle rect | rect.length() == rect.width()); } 影子变量\n1 2 3 4 5 6 7 8 9 10 // 全局变量 public static Rectangle rect = null; public static boolean isSquare(Shape shape) { if (shape instanceof Rectangle rect) { // 这里使用的是局部变量 rect return rect.length() == rect.width(); } // 这里不能使用局部变量 rect，可以使用全局变量 rect } 影子变量：即局部变量会遮盖住全局变量。\n在上方所有例子中，如果存在全局变量 rect，那么，在不能使用匹配变量 rect 的地方使用的 rect，实际使用的是全局变量 rect。\n档案类 档案类在 Java14 中以预览版发布，在 Java15 中改进的档案类再次以预览版发布，在 Java16 中正式发布。\n档案类是用来表示“不可变数据”的“透明载体”。Java 为档案类引入了新的关键字：record\n1 2 3 4 5 6 7 8 9 10 /** * 档案类 * \u003cp\u003e * 使用 record 进行声明，并在类名后使用 () 来添加不可变的成员变量 * * @param id ID * @param name 姓名 */ public record UserRecord(Long id, String name) { } 不可变数据\n档案类不允许被继承，并且默认继承自 java.lang.Record 类。因此不能通过父/子类改变档案类的行为； 档案类的属性都是私有的，并只为其提供了 get 方法。因此档案类的变量是不可变的变量； 档案类中不允许声明成员变量。因此只能通过全参的构造方法来创建档案类对象； 档案类中不允许声明本地（native）方法。 透明载体\n档案类默认生成全参的构造方法 档案类默认生成 equals、hashCode、toString 方法 可通过档案类提供的默认 get 方法读取属性值 1 2 3 4 5 6 7 8 // 只能通过全参的构造方法创建档案类的实例 UserRecord u1 = new UserRecord(1L, \"张三\"); UserRecord u2 = new UserRecord(1L, \"张三\"); // 这两个档案类对象是相同的 boolean b = Objects.equals(u1, u2); // 档案类仅提供了与属性同名的 get 方法 Long id = u1.id(); String name = u1.name(); 上方的档案类等价于\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 import java.util.Objects; import java.util.StringJoiner; // 类上使用 final 关键字进行修饰，不允许该类被继承 // 默认继承自 Record public final class User /*extends Record*/ { /** * ID，私有化成员变量，仅可在构造方法中进行一次初始化 */ private final Long id; /** * 姓名，私有化成员变量，仅可在构造方法中进行一次初始化 */ private final String name; public User(Long id, String name) { this.id = id; this.name = name; } /** * 仅对外提供同名 get 方法 */ public Long id() { return id; } /** * 仅对外提供同名 get 方法 */ public String name() { return name; } /** * 重写了 equals 方法，如果所有属性通过 equals 比较均相同，则两个对象相同 */ @Override public boolean equals(Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } User user = (User) o; return Objects.equals(id, user.id) \u0026\u0026 Objects.equals(name, user.name); } /** * 重写了 hashCode 方法 */ @Override public int hashCode() { return Objects.hash(id, name); } /** * 重写了 toString 方法，格式：类名[propName=propVal, propName=propVal] */ @Override public String toString() { return new StringJoiner(\", \", User.class.getSimpleName() + \"[\", \"]\") .add(\"id=\" + id) .add(\"name=\" + name) .toString(); } } 重写档案类的默认方法\n可以重写档案类默认提供的构造器、getter、equals、hashCode、toString 方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 public record UserRecord(Long id, String name) { /** * 可以重写构造方法，与普通类不同的是 * \u003col\u003e\u003cli\u003e构造方法名后不需要有参数 * \u003cli\u003e不需要在构造方法中给实例变量赋值\u003c/ol\u003e */ public UserRecord { // 添加自定义逻辑 if (Objects.isNull(id) || Objects.isNull(name)) { throw new IllegalArgumentException(\"id 和 name 均不能为 null\"); } } /** * 可以重写 id 属性的 get 方法 */ @Override public Long id() { // 添加自定义逻辑 return this.id; } /** * 可以重写 name 属性的 get 方法 */ @Override public String name() { // 添加自定义逻辑 return this.name; } /** * 可以重写 equals 方法 */ @Override public boolean equals(Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } UserRecord that = (UserRecord) o; // 默认是所有属性都 equals 才相等 return Objects.equals(id, that.id); } /** * 可以重写 hashCode 方法 */ @Override public int hashCode() { return Objects.hash(id, name); } /** * 可以重写 toString 方法 */ @Override public String toString() { return new StringJoiner(\", \", UserRecord.class.getSimpleName() + \"[\", \"]\") .add(\"id=\" + id) .add(\"name='\" + name + \"'\") .toString(); } } 只读实例\n因为档案类的实例和数据都是不可变的，所以档案类的实例是只读实例，所以天生线程安全。\n","description":"","tags":["Java"],"title":"Java16 新特性","uri":"/posts/java/java%E6%96%B0%E7%89%B9%E6%80%A7/java16-new-future/"},{"categories":null,"content":"Java11 新特性 ","description":"","tags":["Java"],"title":"Java11 新特性","uri":"/posts/java/java%E6%96%B0%E7%89%B9%E6%80%A7/java11-new-future/"},{"categories":null,"content":"Java9 新特性 JShell JShell 是 Java9 以后提供的交互式编程环境（REPL，Read Eval Print Loop）。类似于 Bash Shell、Python Shell。一旦输入完成即可获得返回结果，不需要编辑器、编译器、解释器。\n启动 JShell\n1 2 3 4 5 $ jshell | Welcome to JShell -- Version 17.0.1 | For an introduction type: /help intro jshell\u003e 可以添加 -v 选项启动详细模式，在执行命令时，获得更多的信息。\n获取帮助\n1 jshell\u003e /help 打印 Hello World\n1 jshell\u003e System.out.println(\"Hello World\") 退出 JShell\n1 jshell\u003e /exit JShell 重复声明变量\nJShell 支持重复声明变量，重复声明的变量可以是不同类型，后声明的变量会覆盖掉之前的。\n1 2 3 4 5 6 7 8 jshell\u003e String gender = \"男\" gender ==\u003e \"男\" jshell\u003e gender = \"女\" gender ==\u003e \"女\" jshell\u003e Integer gender = 0 gender ==\u003e 0 JShell 表达式\n1 2 3 4 5 6 7 8 jshell\u003e 1 + 1 $1 ==\u003e 2 jshell\u003e \"Hello\" == \"Hello\" $2 ==\u003e true jshell\u003e \"Hello\" == new String(\"Hello\") $3 ==\u003e false JShell 创建和使用方法\n1 2 3 4 5 6 7 8 9 10 11 jshell\u003e String greeting(String language) { ...\u003e return switch(language) { ...\u003e case \"Chinese\" -\u003e \"你好\"; ...\u003e case \"English\" -\u003e \"Hello\"; ...\u003e default -\u003e throw new RuntimeException(\"Unsupported language\"); ...\u003e }; ...\u003e } | created method greeting(String) jshell\u003e greeting(\"Chinese\") $4 ==\u003e \"你好\" JShell 在处理简单的小逻辑，验证简单的小问题时，比 IDE 更有效率。\n","description":"","tags":["Java"],"title":"Java9 新特性","uri":"/posts/java/java%E6%96%B0%E7%89%B9%E6%80%A7/java9-new-future/"},{"categories":null,"content":"Java8 新特性 https://www.oracle.com/java/technologies/javase/8-whats-new.html\n","description":"","tags":["Java"],"title":"Java8 新特性","uri":"/posts/java/java%E6%96%B0%E7%89%B9%E6%80%A7/java8-new-future/"},{"categories":null,"content":"Java 新特性目录\nJava8 新特性 Java9 新特性 Java10 新特性 Java11 新特性 Java12 新特性 Java13 新特性 Java14 新特性 Java15 新特性 Java16 新特性 Java17 新特性 ","description":"","tags":["Java"],"title":"Java 新特性目录","uri":"/posts/java/java%E6%96%B0%E7%89%B9%E6%80%A7/java-new-future-table/"},{"categories":null,"content":"Shell 的小技巧 kill 结合 ps 结束进程\n1 kill `ps -ef | grep regex | grep -v \"grep\" | awk '{print $2}'` 替换 regex 为实际表达式即可\nif 判断上次执行结果是否成功\n1 2 3 4 if [ $(echo $?) -eq 0 ] then echo \"success\" fi 获取指定范围的随机数\n1 awk -v min=1 -v max=6 'BEGIN{srand(); print int(min+rand()*(max-min+1))}' ","description":"","tags":["Linux"],"title":"Shell 的小技巧","uri":"/posts/linux/shell-tips/"},{"categories":null,"content":"Ubuntu20.4 服务端不响应 syn/ack Ubuntu 20.4 作为服务端，在 8080 端口启动了 tomcat 服务，并且使用 ufw allow 8080/tcp 开启了防火墙端口。在服务器上使用 curl localhost:8080 可以获取到 tomcat 服务的返回结果，但是在其他机器上访问服务失败。\n使用 tcpdump -nn -i ens3 port 8080 抓包，显示客户端向服务端发送 syn 后，服务端没有回应 syn/ack\n1 2 3 4 5 root@localhost:~$ sudo tcpdump -nn -i ens3 port 8080 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on ens3, link-type EN10MB (Ethernet), capture size 262144 bytes 02:17:33.433600 IP 118.26.138.146.2107 \u003e 10.0.0.92.8080: Flags [S], seq 868991592, win 64240, options [mss 1380,nop,wscale 8,nop,nop,sackOK], length 0 02:17:34.434020 IP 118.26.138.146.2107 \u003e 10.0.0.92.8080: Flags [S], seq 868991592, win 64240, options [mss 1380,nop,wscale 8,nop,nop,sackOK], length 0 执行下方命令后，并重新开启 ufw 防火墙后，就可以通过其他机器进行访问了\n1 sudo iptables -P INPUT ACCEPT \u0026\u0026 sudo iptables -F 对 iptables 的这两个参数不了解，如果是生产环境，请自行理解清楚后再执行\n","description":"","tags":["Linux","Ubuntu"],"title":"Ubuntu20.4 服务端不响应 syn/ack","uri":"/posts/linux/ubuntu/ubuntu20.4-do-not-send-syn-and-ack/"},{"categories":null,"content":"maven 项目打 jar 包 对于普通的 maven 项目，如果使用 java -jar 执行打包后的 jar 文件，通常会报如下错误：\n1 no main manifest attribute, in output.jar 这是因为 jar 包的 META-INF/MANIFEST.MF 文件中缺少相关信息，参考：JAR File Specification\n对于 Maven 项目，可以使用 maven-jar-plugin 插件来生成完整的 META-INF/MANIFEST.MF\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u003cproject\u003e ... \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e \u003cartifactId\u003emaven-jar-plugin\u003c/artifactId\u003e \u003cversion\u003e3.2.0\u003c/version\u003e \u003cconfiguration\u003e \u003carchive\u003e \u003cmanifest\u003e \u003c!-- 是否把项目的依赖包的信息添加到 META-INF 文件的 Class-Path 中 --\u003e \u003caddClasspath\u003etrue\u003c/addClasspath\u003e \u003c!-- 如果需要一个可执行的 jar，需要指定主类 --\u003e \u003cmainClass\u003eicu.intelli.TestMain\u003c/mainClass\u003e \u003c!-- 该 jar 包所需依赖包的路径名前缀 --\u003e \u003cclasspathPrefix\u003elib\u003c/classpathPrefix\u003e \u003c/manifest\u003e \u003c/archive\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e ... \u003c/project\u003e 该插件只会将相关信息写入 jar 包中的 META-INF/MANIFEST.MF 文件。如果项目中通过 GAV 的方式引入了依赖，在执行 jar 的时候，可能会报出 ClassNotFound 异常。\n因此，我们需要将项目所需的依赖包都复制到 maven-jar-plugin 的 classpathPrefix 指定的路径下。此时就需要添加 maven-dependency-plugin 插件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 \u003cproject\u003e ... \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e \u003cartifactId\u003emaven-dependency-plugin\u003c/artifactId\u003e \u003cversion\u003e3.2.0\u003c/version\u003e \u003cexecutions\u003e \u003cexecution\u003e \u003cid\u003ecopy-dependencies\u003c/id\u003e \u003c!-- 在 package 阶段执行该插件 --\u003e \u003cphase\u003epackage\u003c/phase\u003e \u003cgoals\u003e \u003c!-- 执行复制依赖包的操作 --\u003e \u003cgoal\u003ecopy-dependencies\u003c/goal\u003e \u003c/goals\u003e \u003cconfiguration\u003e \u003c!-- 把项目所需的依赖复制到 lib 路径下，与 maven-jar-plugin 中的 classpathPrefix 相对应--\u003e \u003coutputDirectory\u003e${project.build.directory}/lib\u003c/outputDirectory\u003e \u003coverWriteReleases\u003efalse\u003c/overWriteReleases\u003e \u003coverWriteSnapshots\u003efalse\u003c/overWriteSnapshots\u003e \u003coverWriteIfNewer\u003etrue\u003c/overWriteIfNewer\u003e \u003c/configuration\u003e \u003c/execution\u003e \u003c/executions\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e ... \u003c/project\u003e 在执行 mvn package 命令后，该插件会把项目的所有依赖包复制到 target/lib 目录中。同时，输出的 output.jar 也会生成在 target 目录，这时在 target 目录执行 java -jar output.jar 就可以执行该 jar 包了。\n但是此时还有一个问题：必须将 output.jar 和 lib 放到同一个目录，才能执行成功。我们希望把依赖包和项目代码打包到一个 jar 中。此时可以使用 maven-assembly-plugin 插件（使用该插件后，如无需要，就可以不使用 maven-jar-plugin 和 maven-dependency-plugin 插件了）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 \u003cproject\u003e ... \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e \u003cartifactId\u003emaven-assembly-plugin\u003c/artifactId\u003e \u003cversion\u003e3.3.0\u003c/version\u003e \u003cconfiguration\u003e \u003cdescriptorRefs\u003e \u003c!-- 将依赖包也打包到 jar 中 --\u003e \u003cdescriptorRef\u003ejar-with-dependencies\u003c/descriptorRef\u003e \u003c/descriptorRefs\u003e \u003carchive\u003e \u003cmanifest\u003e \u003c!-- 如果需要一个可执行的 jar，指定主类 --\u003e \u003cmainClass\u003eicu.intelli.TestMain\u003c/mainClass\u003e \u003c/manifest\u003e \u003c/archive\u003e \u003c/configuration\u003e \u003cexecutions\u003e \u003cexecution\u003e \u003c!-- this is used for inheritance merges --\u003e \u003cid\u003emake-assembly\u003c/id\u003e \u003c!-- bind to the packaging phase --\u003e \u003cphase\u003epackage\u003c/phase\u003e \u003cgoals\u003e \u003cgoal\u003esingle\u003c/goal\u003e \u003c/goals\u003e \u003c/execution\u003e \u003c/executions\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e ... \u003c/project\u003e 执行 mvn package 后，会在 target 目录下生成 output--jar-with-dependencies.jar 包\n","description":"","tags":["Maven","Java"],"title":"maven 项目打 jar 包","uri":"/posts/java/maven-package-jar/"},{"categories":null,"content":"Ubuntu20.4 使用 x11vnc x11vnc 是一个不依赖任何图形界面的 VNC 服务。在电脑重启后没有进行图形界面登录时，也可以使用。但是由于 GNOME 的管理机制，连接成功登录后，会黑屏（有不完美的解决方案）。\nGITHUB Ubuntu VNC 基本使用 安装 x11vnc\n1 sudo apt install x11vnc net-tools -y 启动 x11vnc 服务，默认的启动端口是 5900\n1 x11vnc -display :0 设置远程连接密码\n1 x11vnc -storepasswd 会返回如下信息\n1 2 3 4 Enter VNC password: Verify password: Write password to /home/USERNAME/.vnc/passwd? [y]/n y Password written to: /home/USERNAME/.vnc/passwd 设置完密码后，可以使用如下命令启动服务\n1 x11vnc -rfbauth /home/USERNAME/.vnc/passwd 启动时的常用配置说明\n使用 -nopw -accept popup:0 设置可以不使用 VNC 密码进行连接 使用 -once 设置同时只允许存在一个最新的连接 使用 -forever 设置允许任意个连接同时存在 使用 -viewonly 设置只允许查看，不允许操作 常用的启动命令如下\n1 x11vnc -auth guess -forever -loop -noxdamage -repeat -rfbauth /home/USERNAME/.vnc/passwd -rfbport 5900 -shared 设置服务开机启动 需要 x11vnc 服务在不登录的时候也能成功启动\n修改 /etc/gdm3/custom.conf 文件，取消 WaylandEnable=false 前的 #，重启电脑\n使用 sudo loginctl 查看登录用户\n1 2 SESSION UID USER SEAT TTY c1 125 gdm seat0 tty1 记住 gdm 用户的 UID\n编写服务自启动文件，添加 /etc/systemd/system/x11vnc.service\n在 -auth 选项中使用 gdm 用户的 UID，可以将密码文件存储在 /etc/vnc/x11vnc.passwd 中\n1 2 3 4 5 6 7 8 9 10 11 12 [Unit] Description=x11vnc Server. Documentation=man：x11vnc(1) After=display-manager.service network.target syslog.target [Service] Type=simple ExecStart=x11vnc -auth /run/user/125/gdm/Xauthority -forever -loop -noxdamage -repeat -rfbauth /etc/vnc/x11vnc.passwd -rfbport 5900 -shared [Install] WantedBy=multi-user.target Alias=x11vnc.service 启动服务并设置为开机自启\n1 2 3 sudo systemctl daemon-reload sudo systemctl start x11vnc.service sudo systemctl enable x11vnc.service 重启电脑后，进行连接，会进入登录界面。但是输入密码登录后会黑屏。\n黑屏解决方案 参考 Configure x11vnc to boot at startup，两种解决方案的原理都是相同的，都是对一个用户启动两个 vnc 服务。在电脑重启后通过第一个 vnc 服务进行登录（登录后会黑屏），然后通过登录后自启的另一个 vnc 服务进行连接。注意：此处不同的 vnc 服务均需要使用不同的端口号。\n按照上方的方式，已经创建了所需的第一个 vnc 服务，下方开始配置另一个 vnc 服务。\n解决方案1：自启另一个 x11vnc 服务 点击 Activities 搜索 Startup Applications，添加一个自启脚本\nName：Remote VNC Connect Command：x11vnc -auth guess -rfbport 5901 -rfbauth /home/USERNAME/.vnc/passwd 解决方案2：使用 vino 作为另一个 vnc 服务 vino 的安装使用参考 Ubuntu20.4 使用 vino VNC。\n为不同用户修改 vino server 的监听端口\n1 2 $ gsettings set org.gnome.Vino alternative-port 5901 $ gsettings set org.gnome.Vino use-alternative-port true ","description":"","tags":["Linux","Ubuntu","VNC"],"title":"Ubuntu20.4 使用 x11vnc","uri":"/posts/linux/ubuntu/ubuntu20.4-x11vnc/"},{"categories":null,"content":"Ubuntu20.4 使用 vino VNC 几种 VNC 的使用可参考\nUbuntu 社区\nVino is the default VNC server in Ubuntu to share your existing desktop with other users\nvino wiki\narchlinux Vino\n注意：vino 必须在用户登录图形界面后才能进行远程连接，所以如果电脑重启后没有通过图形界面登录时连接不了的。如果需要不登录也能访问，推荐使用其他方案，例如使用 x11vnc，参考 Ubuntu20.4 使用 x11vnc。\n安装\n如果在 Settings \u003e Sharing 里没有 Screen Sharing，才需要安装\n1 sudo apt install vino 点击 Settings \u003e Sharing \u003e Screen Sharing，设置密码等信息\n使用 VNC 连接工具进行连接：domain.com:5900，默认端口是 5900\n常用 VNC 工具\nVNC Viewer Tight VNC Remmina 如果连接时出现安全认证相关问题，在 Ubuntu 上执行\n1 gsettings set org.gnome.Vino require-encryption false 设置用户自动登录\nSettings \u003e Users，打开 Automatic Login\n","description":"","tags":["Linux","Ubuntu","VNC"],"title":"Ubuntu20.4 使用 vino VNC","uri":"/posts/linux/ubuntu/ubuntu20.4-vino-vnc/"},{"categories":null,"content":"Nginx 实现同一主机不同域名访问不同服务 有 2 个域名和 1 台服务器，需要根据访问时使用的不同域名，将请求转发到不同的服务上（Nginx 配置多个 server）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 user root; worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; # 设置编码集 charset utf-8; server { listen 80; # 将通过 domain-1 访问的请求，转发到 domain-1 文件夹 server_name domain-1.com; location / { # 可根据需要使用 root、alias 或 proxy_pass root html/domain-1; } } server { listen 80; # 将通过 domain-2 访问的请求，转发到 domain-2 文件夹 server_name domain-2.com; location / { # 可根据需要使用 root、alias 或 proxy_pass root html/domain-2; } } } ","description":"","tags":["Nginx"],"title":"Nginx 实现同一主机不同域名访问不同服务","uri":"/posts/nginx/nginx-multi-server/"},{"categories":null,"content":"使用 ittun-ngrok 进行内网穿透 ittun 官网\nNGrok 服务器搭建 参考：NGrok 服务器搭建\n准备工作\n一个域名 有公网 IP 的 Linux64 服务器 注意：未备案的域名只能用国外服务器\n域名解析配置\n例如：使用 ngrok.domain.com 作为 ngrok 服务的地址，则可以配置 ngrok 及其子域名的解析地址\n下载 服务端文件\n启动命令参考：\n1 2 3 $ ./ngrokd -domain=\"ngrok.domain.com\" -httpAddr=\":80\" -httpsAddr=\":443\" -tunnelAddr=\":44433\" # 后台启动并将日志文件输出到 ngrok.log 文件 $ nohup /opt/ittun-server/ngrokd -domain=\"ngrok.domain.com\" -httpAddr=\":80\" -httpsAddr=\":443\" -tunnelAddr=\":44433\" 1\u003e\u003engrok.log 2\u003e\u00261 \u0026 有以下提示即启动成功\n1 2 3 4 5 [10/07/21 02:59:42] [INFO] [registry] [tun] No affinity cache specified [10/07/21 02:59:42] [INFO] Listening for public http connections on [::]:80 [10/07/21 02:59:42] [INFO] Listening for public https connections on [::]:443 [10/07/21 02:59:42] [INFO] Listening for control and proxy connections on [::]:44433 [10/07/21 02:59:42] [INFO] [metrics] Reporting every 30 seconds 安装客户端 从 ittun 下载对应版本的客户端\n解压，并修改配置文件\n1 2 3 $ unzip ittun_[name].zip $ cp config.yml config.yml.bak $ vim config.yml config.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 服务端的域名和 tunnelAddr 指定的端口 server_addr: \"ngrok.domain.com:44433\" tunnels: # 隧道名，可以自定义，此处表示内网机上的 ssh 服务 ssh: # 可通过 ssh username@ngrok.domain.com -p 51001 远程连接内网机 remote_port: 51001 # 内网机上 ssh 服务的协议和端口号 proto: tcp: \":22\" # 内网机上启动的 web 服务 web: # 可通过二级域名 web.ngrok.domain.com 从外网访问内网机上的 web 服务 subdomain: web # 静态文件路径（相对/绝对路径皆可） root: \"html/\" # 内网机 web 服务的协议和端口号 # 如果内网机在该端口上没有运行的 web 服务，则 ngrok 会使用该端口自动启动一个 web 服务，并将 root 中的静态文件作为展示的资源 # 否则，由内网机该端口的 web 服务提供服务（root 的配置失效） proto: http: \":8080\" # 将访问一级域名的请求转发到内网机的某个服务 main: # 访问 domain.com，会返回内网机 9090 端口上的服务 hostname: domain.com # root 和 proto 的配置规则与上方 web 中的一致 root: \"html/\" proto: http: \":9090\" 启动服务\n1 2 3 ./ngrok -config config.yml start [隧道名...] # 启动所有配置中的 tunnels ./ngrok -config config.yml start ssh web main 成功效果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ITTUN (Ctrl+C to quit) # online 表示与服务端连接成功，如果是其它则说明与服务端连接失败 Tunnel Status online Version 1.7/1.7 # 使用 ssh username@ngrok.domain.com -p 51001 命令，即可远程连接内网机 Forwarding tcp://ngrok.domain.com:51001 -\u003e 127.0.0.1:22 # 访问 http://web.ngrok.domain.com，实际访问的是内网机 8080 端口上的服务 Forwarding http://web.ngrok.domain.com -\u003e 127.0.0.1:8080 # 内网机 8080 端口上的服务，返回的是 html/ 目录下的资源 Http Server 127.0.0.1:8080 -\u003e html/ # 访问 http://domain.com，实际访问的是内网机 9090 端口上的服务 Forwarding http://domain.com -\u003e 127.0.0.1:9090 Web Interface disabled # Conn 0 Avg Conn Time 0.00ms ","description":"","tags":["Linux"],"title":"使用 ittun-ngrok 进行内网穿透","uri":"/posts/linux/ittun-ngrok/"},{"categories":null,"content":"@SuppressWarnings 从 JDK 1.5 开始，可以使用 @SuppressWarnings 来抑制编译器报出的一些不合适的警告信息。\n官方文档 @SuppressWarnings 类的定义信息如下，基础说明可参考 JavaSE 11 API\n1 2 3 4 5 @Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE}) @Retention(RetentionPolicy.SOURCE) public @interface SuppressWarnings { String[] value(); } 在 JLS 中，有提到\nJava 编程语言定义了如下 3 种警告\n未经检查的警告，使用 unchecked 指定 弃用警告，使用 deprecation 指定 删除警告，使用 removal 指定 对于其他类型的警告，编译器供应商应记录他们支持的 @SuppressWarnings 的字符串。鼓励供应商合作以确保相同的名称在多个编译器中工作。\n由上可知，Java 官方只定义了 3 种编译警告类型，其它的编译警告都是由第三方编译器提供的。\n查看编译器支持的警告 可以使用如下命令查看 JDK 支持哪些编译器警告\n1 javac -X JDK 11 支持的编译器警告如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 $ java -version java version \"11.0.12\" 2021-07-20 LTS Java(TM) SE Runtime Environment 18.9 (build 11.0.12+8-LTS-237) Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.12+8-LTS-237, mixed mode) $ javac -X -Xlint:\u003c密钥\u003e(,\u003c密钥\u003e)* 要启用或禁用的警告, 使用逗号分隔。 在关键字前面加上 - 可禁用指定的警告。 支持的关键字包括: all 启用所有警告 auxiliaryclass 有关辅助类在源文件中隐藏, 但在其他文件中使用的警告。 cast 有关使用了不必要转换的警告。 classfile 有关与类文件内容相关的问题的警告。 deprecation 有关使用了已过时项的警告。 dep-ann 有关项在 JavaDoc 中标记为已过时但未使用 @Deprecated 注释的警告。 divzero 有关除以常量整数 0 的警告。 empty 有关 if 之后没有语句的警告。 exports 有关与模块导出相关的问题的警告。 fallthrough 有关从 switch 语句的一个 case 向下顺序执行到下一个 case 的警告。 finally 有关 finally 子句未正常终止的警告。 module 有关模块系统相关问题的警告。 opens 有关与模块打开相关的问题的警告。 options 有关与使用命令行选项相关的问题的警告。 overloads 有关与方法重载相关的问题的警告。 overrides 有关与方法覆盖相关的问题的警告。 path 有关命令行上的路径元素无效的警告。 processing 有关与注释处理相关的问题的警告。 rawtypes 有关使用了原始类型的警告。 removal 有关使用了标记为待删除的 API 的警告。 requires-automatic 有关在 requires 子句中使用自动模块的警告。 requires-transitive-automatic 有关 requires 过渡中的自动模块的警告。 serial 有关未提供序列版本 ID 的可序列化类的警告。 此外还警告有关可串行化元素对非公共成员的访问。 static 有关使用实例来访问静态成员的警告。 try 有关与使用 try 块 (例如 try-with-resources) 相关的问题的警告。 unchecked 有关未检查操作的警告。 varargs 有关潜在不安全的 vararg 方法的警告 preview 有关使用预览语言功能的警告 none 禁用所有警告 这些额外选项如有更改, 恕不另行通知。 注意：-X 代表了“额外选项”，并不是 JAVA 官方的标准选项。\n第三方编译器警告 常用的第三方编译器警告说明参考：\nIDEA Code Inspection Eclipse Suppress Warnings IBM editor-suppress-warnings 常用警告 关键字 说明 unchecked（官方提供） 抑制未经检查操作的警告 deprecation （官方提供） 抑制调用过期元素（使用 @Deprecated 标注的）的警告。 removal（官方提供） 抑制调用在未来会被删除的元素（使用 @Deprecated(since=\"9\", forRemoval=true) 标注的）的警告 all 抑制所有警告。推荐明确指定警告类型，不推荐使用该类型 rawtypes 抑制使用原始类型的警告 fallthrough 抑制 switch 语句中缺少 break 的警告 serial 抑制可序列化类没有 serialVersionUID 的警告 try 抑制 try-cache-finally 相关的警告 日常开发中，最常用到的只有 rawtypes 和 unchecked，通常在使用了泛型的时候，会需要使用到这两个警告类型。\n使用格式 @SuppressWarnings 可以标注在类、字段、方法、形参、构造器、局部变量身上\n1 2 3 @SuppressWarnings(\"\") @SuppressWarnings({}) @SuppressWarnings(value = {}) 对于普通语句出现的警告，并不能使用 @SuppressWarnings 进行抑制。IDEA 提供了使用 //noinspection 对这种警告进行抑制\n1 2 //noinspection unchecked executor.execute(pram1, parm2) 对于 SonarLint 提示的警告，可以使用 @SuppressWarnings(\"squid:S3776\") 方式进行一直，S3776 是 squid 的值\n","description":"","tags":["Java"],"title":"@SuppressWarnings","uri":"/posts/java/suppress-warnings/"},{"categories":null,"content":"SQL INNER/LEFT/RIGHT/FULL JOIN 表准备 首先，创建 4 张表，每个表都包含三个字段：ID，NAME\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 CREATE TABLE T1 ( ID INT, NAME VARCHAR ); CREATE TABLE T2 ( ID INT, NAME VARCHAR ); CREATE TABLE T3 ( ID INT, NAME VARCHAR ); CREATE TABLE T4 ( ID INT, NAME VARCHAR ); 向四张表中插入数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 -- T1 INSERT INTO T1 (ID, NAME) VALUES (1, 'name11'); -- T2 INSERT INTO T2 (ID, NAME) VALUES (1, 'name21'); INSERT INTO T2 (ID, NAME) VALUES (2, 'name22'); -- T3 INSERT INTO T3 (ID, NAME) VALUES (1, 'name31'); INSERT INTO T3 (ID, NAME) VALUES (2, 'name32'); INSERT INTO T3 (ID, NAME) VALUES (3, 'name33'); -- T4 INSERT INTO T4 (ID, NAME) VALUES (1, 'name41'); INSERT INTO T4 (ID, NAME) VALUES (2, 'name42'); INSERT INTO T4 (ID, NAME) VALUES (3, 'name43'); INSERT INTO T4 (ID, NAME) VALUES (4, 'name44'); 按顺序，T1 表中只有一条数据，T2 表中有两条数据，每个表中 ID 的值是按照顺序排列的，NAME 的值后方添加 表编号 和 记录ID\n表预览\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 -- T1 | ID | NAME | | ---- | ------ | | 1 | name11 | -- T2 | ID | NAME | | ---- | ------ | | 1 | name21 | | 2 | name22 | -- T3 | ID | NAME | | ---- | ------ | | 1 | name31 | | 2 | name32 | | 3 | name33 | -- T4 | ID | NAME | | ---- | ------ | | 1 | name41 | | 2 | name42 | | 3 | name43 | | 4 | name44 | INNER JOIN 语法格式：\nLeftTable INNER JOIN RightTable ON JoinCriteria WHERE FilterCriteria INNER JOIN 是将左右两张表做笛卡尔积，然后根据 ON 后的“连接条件”对笛卡尔积后的结果进行筛选。INNER JOIN 的执行结果与左右表的顺序无关。\nINNER JOIN 中 ON 后的“连接条件”和 WHERE 后的“过滤条件”是没有区别的\n“连接条件”中如果需要包含多个条件，可以使用 AND/OR 以及 () 进行连接。可以使用 WHERE 对连接后的结果进行条件过滤。\n示例 1 SELECT * FROM T3 INNER JOIN T4 ON T3.ID = T4.ID 先对 T3 和 T4 进行笛卡尔积\n1 2 3 4 5 6 7 8 9 10 11 12 13 |T3.ID\t|T3.NAME\t|T4.ID\t|T4.NAME |1\t|name31\t|1\t|name41 |1\t|name31\t|2\t|name42 |1\t|name31\t|3\t|name43 |1\t|name31\t|4\t|name44 |2\t|name32\t|1\t|name41 |2\t|name32\t|2\t|name42 |2\t|name32\t|3\t|name43 |2\t|name32\t|4\t|name44 |3\t|name33\t|1\t|name41 |3\t|name33\t|2\t|name42 |3\t|name33\t|3\t|name43 |3\t|name33\t|4\t|name44 然后根据 ON 后的连接条件对笛卡尔积的结果进行筛选\n1 2 3 4 |T3.ID\t|T3.NAME\t|T4.ID\t|T4.NAME |1\t|name31\t|1\t|name41 |2\t|name32\t|2\t|name42 |3\t|name33\t|3\t|name43 LEFT/RIGHT JOIN 语法格式：\nBaseTable LEFT JOIN SecondaryTable ON JoinCriteria WHERE FilterCriteria SecondaryTable RIGHT JOIN BaseTable ON JoinCriteria WHERE FilterCriteria LEFT JOIN 左侧的表为“基表”，右侧的表为“辅表”；RIGHT JOIN 右侧的表为“基表”，左侧的表为“辅表”。\nLEFT/RIGHT JOIN 的执行结果与“基表”是强相关的。\n执行过程分为 2 个步骤：\n将基表和辅表做笛卡尔积，然后根据 ON 后的“连接条件”对笛卡尔积后的结果进行筛选； 如果经过第一步后，基表中的某条记录没有任何符合“连接条件”的连接记录，则将基表中的该记录保留，使用 NULL 值对辅表的列值进行填充，然后将二者连接生成一条连接记录。 在实际情况下，第一步不会直接进行笛卡尔积，数据库会对 SQL 进行优化，但是最终获得的结果是相同的。\n“连接条件”中如果需要包含多个条件，可以使用 AND/OR 以及 () 进行连接。可以使用 WHERE 对连接后的结果进行条件过滤。\n例 1：ON TRUE 1 SELECT * FROM T1 LEFT JOIN T2 ON TRUE 将 T1 与 T2 进行笛卡尔积\n1 2 3 |T1.ID\t|T1.NAME\t|T2.ID\t|T2.NAME |1\t|name11\t|1\t|name21\t|1\t|name11\t|2\t|name22\tON 后的条件为 TRUE，所有结果均符合条件，所以全部保留\n1 2 3 |T1.ID\t|T1.NAME\t|T2.ID\t|T2.NAME |1\t|name11\t|1\t|name21\t|1\t|name11\t|2\t|name22\t例 2：ON FALSE 1 SELECT * FROM T1 LEFT JOIN T2 ON FALSE 将 T1 与 T2 进行笛卡尔积\n1 2 3 |T1.ID\t|T1.NAME\t|T2.ID\t|T2.NAME |1\t|name11\t|1\t|name21 |1\t|name11\t|2\t|name22 ON 后的条件为 FALSE，所以丢弃所有结果，进而出现基表中的某条记录没有任何符合“连接条件”的连接记录的情况，所以将基表中的该记录保留，使用 NULL 值对辅表的列值进行填充，然后将二者连接生成一条连接记录。因此最终结果为：\n1 2 |T1.ID\t|T1.NAME\t|T2.ID\t|T2.NAME |1\t|name11\t|NULL\t|NULL 例 3：“子表” JOIN “父表” 这里“子表”和“父表”表示：父表 ID 是子表 ID 的超集\n1 SELECT * FROM T1 LEFT JOIN T2 ON T1.ID = T2.ID 将 T1 与 T2 进行笛卡尔积\n1 2 3 |T1.ID\t|T1.NAME\t|T2.ID\t|T2.NAME |1\t|name11\t|1\t|name21 |1\t|name11\t|2\t|name22 ON 后的条件为 T1.ID = T2.ID，只有第一条符合条件，所以只保留第一条\n1 2 |T1.ID\t|T1.NAME\t|T2.ID\t|T2.NAME |1\t|name11\t|1\t|name21 例 4：“父表” JOIN “子表” 这里“子表”和“父表”表示：父表 ID 是子表 ID 的超集\n1 SELECT * FROM T2 LEFT JOIN T1 ON T1.ID = T2.ID 将 T2 与 T1 进行笛卡尔积，得到如下结果\n1 2 3 |T2.ID\t|T2.NAME\t|T1.ID\t|T1.NAME |1\t|name21\t|1\t|name11 |2\t|name22\t|1\t|name11 ON 后的条件为 T1.ID = T2.ID，第一条符合条件，所以保留；第二条不符合条件，进而出现基表中的某条记录没有任何符合“连接条件”的连接记录的情况，所以将基表中的该记录保留，使用 NULL 值对辅表的列值进行填充，然后将二者连接生成一条连接记录。因此最终结果为：\n1 2 3 |T2.ID\t|T2.NAME\t|T1.ID\t|T1.NAME |1\t|name21\t|1\t|name11 |2\t|name22\t|NULL\t|NULL 例 5：ON 后多条件 1 SELECT * FROM T3 LEFT JOIN T2 ON T2.ID = T3.ID AND T2.NAME = 'name21' 将 T3 与 T2 进行笛卡尔积\n1 2 3 4 5 6 7 |T3.ID\t|T3.NAME\t|T2.ID\t|T2.NAME |1\t|name31\t|1\t|name21 |1\t|name31\t|2\t|name22 |2\t|name32\t|1\t|name21 |2\t|name32\t|2\t|name22 |3\t|name33\t|1\t|name21 |3\t|name33\t|2\t|name22 ON 后的条件要求 T2.ID = T3.ID AND T2.NAME = 'name21'，符合条件的只有第一条，同时对于基表 T3 中 ID 为 2 和 3 的两条记录均出现基表中的某条记录没有任何符合“连接条件”的连接记录的情况，所以将基表中的该记录保留，使用 NULL 值对辅表的列值进行填充，然后将二者连接生成一条连接记录。因此最终结果为：\n1 2 3 4 |T3.ID\t|T3.NAME\t|T2.ID\t|T2.NAME |1\t|name31\t|1\t|name21 |2\t|name32\t|NULL\t|NULL |3\t|name33\t|NULL\t|NULL 例 6：1-n/n-n 1 select * from T3 LEFT JOIN T2 ON T3.ID \u003e 1 T3 和 T2 做笛卡尔积\n1 2 3 4 5 6 7 |T3.ID\t|T3.NAME\t|T2.ID\t|T2.NAME |1\t|name31\t|1\t|name21 |1\t|name31\t|2\t|name22 |2\t|name32\t|1\t|name21 |2\t|name32\t|2\t|name22 |3\t|name33\t|1\t|name21 |3\t|name33\t|2\t|name22 ON 后的条件为 T3.ID \u003e 1，T3.ID 为 2 和 3 的 4 条记录符合条件，而 T3.ID 为 1 的 2 条记录均不满足该条件，进而出现基表中的某条记录没有任何符合“连接条件”的连接记录的情况，所以将基表中的该记录保留，使用 NULL 值对辅表的列值进行填充，然后将二者连接生成一条连接记录。因此最终结果为：\n1 2 3 4 5 6 |T3.ID\t|T3.NAME\t|T2.ID\t|T2.NAME |1\t|name31\t|NULL\t|NULL |2\t|name32\t|1\t|name21 |2\t|name32\t|2\t|name22 |3\t|name33\t|1\t|name21 |3\t|name33\t|2\t|name22 例 7：多表 JOIN 多表 JOIN 会按由左至右的顺序先将前两个表进行 JOIN，生成一个临时表，然后使用这个临时表再与第三张表进行 JOIN\n1 SELECT * FROM T2 LEFT JOIN T1 ON T2.ID = T1.ID LEFT JOIN T3 ON T2.ID = T3.ID 首先将 T2 和 T1 进行连接，生成如下结果\n1 2 3 |T2.ID\t|T2.NAME\t|T1.ID\t|T1.NAME |1\t|name21\t|1\t|name11 |2\t|name22\t|NULL\t|NULL 将上方的结果作为临时表，再与 T3 做笛卡尔积\n1 2 3 4 5 6 7 |T2.ID\t|T2.NAME\t|T1.ID\t|T1.NAME\t|T3.ID\t|T3.NAME |1\t|name21\t|1\t|name11\t|1\t|name31 |1\t|name21\t|1\t|name11\t|2\t|name32 |1\t|name21\t|1\t|name11\t|3\t|name33 |2\t|name22\t|NULL\t|NULL\t|1\t|name31 |2\t|name22\t|NULL\t|NULL\t|2\t|name32 |2\t|name22\t|NULL\t|NULL\t|3\t|name33 第 2 个 ON 后的条件为 T2.ID = T3.ID，符合条件的只有如下两条\n1 2 3 |T2.ID\t|T2.NAME\t|T1.ID\t|T1.NAME\t|T3.ID\t|T3.NAME |1\t|name21\t|1\t|name11\t|1\t|name31 |2\t|name22\t|NULL\t|NULL\t|2\t|name32 如果将第 2 个 ON 后的条件修改为 T1.ID = T3.ID，则只有第一条符合条件，进而出现基表中的某条记录没有任何符合“连接条件”的连接记录的情况，所以将基表中的该记录保留，使用 NULL 值对辅表的列值进行填充，然后将二者连接生成一条连接记录。因此最终结果为：\n1 2 3 |T2.ID\t|T2.NAME\t|T1.ID\t|T1.NAME\t|T3.ID\t|T3.NAME |1\t|name21\t|1\t|name11\t|1\t|name31 |2\t|name22\t|NULL\t|NULL\t|NULL\t|NULL 例8：使用括号 括号中的 JOIN 会优先被执行，然后生成的中间表再与其他表进行 JOIN\n1 SELECT * FROM T4 LEFT JOIN (T3 LEFT JOIN T2 ON T3.ID = T2.ID) ON T4.ID = T2.ID 优先执行 (T3 LEFT JOIN T2 ON T3.ID = T2.ID)，得到结果\n1 2 3 4 |T3.ID\t|T3.NAME\t|T2.ID\t|T2.NAME |1\t|name31\t|1\t|name21 |2\t|name32\t|2\t|name22 |3\t|name33\t|NULL\t|NULL 然后将 T4 与上方的结果做笛卡尔积\n1 2 3 4 5 6 7 8 9 10 11 12 13 |T4.ID\t|T4.NAME\t|T3.ID\t|T3.NAME\t|T2.ID\t|T2.NAME |1\t|name41\t|1\t|name31\t|1\t|name21 |1\t|name41\t|2\t|name32\t|2\t|name22 |1\t|name41\t|3\t|name33\t|NULL\t|NULL |2\t|name42\t|1\t|name31\t|1\t|name21 |2\t|name42\t|2\t|name32\t|2\t|name22 |2\t|name42\t|3\t|name33\t|NULL\t|NULL |3\t|name43\t|1\t|name31\t|1\t|name21 |3\t|name43\t|2\t|name32\t|2\t|name22 |3\t|name43\t|3\t|name33\t|NULL\t|NULL |4\t|name44\t|1\t|name31\t|1\t|name21 |4\t|name44\t|2\t|name32\t|2\t|name22 |4\t|name44\t|3\t|name33\t|NULL\t|NULL 根据第 2 个 ON 后的条件对上方的结果进行过滤。只有 2 条符合条件，基表 T4 中 ID 为 3 和 4 的记录出现了基表中的某条记录没有任何符合“连接条件”的连接记录的情况，所以将基表中的该记录保留，使用 NULL 值对辅表的列值进行填充，然后将二者连接生成一条连接记录。因此最终结果为：\n1 2 3 4 5 |T4.ID\t|T4.NAME\t|T3.ID\t|T3.NAME\t|T2.ID\t|T2.NAME |1\t|name41\t|1\t|name31\t|1\t|name21 |2\t|name42\t|2\t|name32\t|2\t|name22 |3\t|name43\t|1\t|NULL\t|NULL\t|NULL |4\t|name44\t|1\t|NULL\t|NULL\t|NULL 例 9：混合使用 1 SELECT * FROM (T2 LEFT JOIN T3 ON T2.ID = T3.ID) RIGHT JOIN (T4 RIGHT JOIN T5 ON T4.ID = T5.ID) ON T3.ID = T5.ID OR T4.ID = 4 WHERE T2.ID IS NOT NULL 先执行 (T2 LEFT JOIN T3 ON T2.ID = T3.ID)，生成临时表 TMP_1\n1 2 3 |T2.ID\t|T2.NAME\t|T3.ID\t|T3.NAME |1\t|name21\t|1\t|name31 |2\t|name22\t|2\t|name32 再执行 (T4 RIGHT JOIN T5 ON T4.ID = T5.ID)，生成临时表 TMP_2\n1 2 3 4 5 6 |T4.ID\t|T4.NAME\t|T5.ID\t|T5.NAME |1\t|name41\t|1\t|name51 |2\t|name42\t|2\t|name52 |3\t|name43\t|3\t|name53 |4\t|name44\t|4\t|name54 |NULL\t|NULL\t|5\t|name55 将 TMP_1 和 TMP_2 进行笛卡尔积\n1 2 3 4 5 6 7 8 9 10 11 |T2.ID\t|T2.NAME\t|T3.ID\t|T3.NAME\t|T4.ID\t|T4.NAME\t|T5.ID\t|T5.NAME |1\t|name21\t|1\t|name31\t|1\t|name41\t|1\t|name51 |2\t|name22\t|2\t|name32\t|1\t|name41\t|1\t|name51 |1\t|name21\t|1\t|name31\t|2\t|name42\t|2\t|name52 |2\t|name22\t|2\t|name32\t|2\t|name42\t|2\t|name52 |1\t|name21\t|1\t|name31\t|3\t|name43\t|3\t|name53 |2\t|name22\t|2\t|name32\t|3\t|name43\t|3\t|name53 |1\t|name21\t|1\t|name31\t|4\t|name44\t|4\t|name54 |2\t|name22\t|2\t|name32\t|4\t|name44\t|4\t|name54 |1\t|name21\t|1\t|name31\t|NULL\t|NULL\t|5\t|name55 |2\t|name22\t|2\t|name32\t|NULL\t|NULL\t|5\t|name55 根据最后一个 ON 条件 T3.ID = T5.ID OR T4.ID = 4 进行筛选。符合条件的有基表 TMP_2（其实最终的基表是 T5） 中 T5.ID 为 1，2，4 的 4 条记录，然后 T5.ID 为 3，5 的 2 条记录出现了基表中的某条记录没有任何符合“连接条件”的连接记录的情况，所以将基表中的该记录保留，使用 NULL 值对辅表的列值进行填充，然后将二者连接生成一条连接记录。因此最终结果为：\n1 2 3 4 5 6 7 |T2.ID\t|T2.NAME\t|T3.ID\t|T3.NAME\t|T4.ID\t|T4.NAME\t|T5.ID\t|T5.NAME |1\t|name21\t|1\t|name31\t|1\t|name41\t|1\t|name51 |2\t|name22\t|2\t|name32\t|2\t|name42\t|2\t|name52 |NULL\t|NULL\t|NULL\t|NULL\t|3\t|name43\t|3\t|name53 |1\t|name21\t|1\t|name31\t|4\t|name44\t|4\t|name54 |2\t|name22\t|2\t|name32\t|4\t|name44\t|4\t|name54 |NULL\t|NULL\t|NULL\t|NULL\t|NULL\t|NULL\t|5\t|name55 最后执行 WHERE 条件 T2.ID IS NOT NULL\n1 2 3 4 5 |T2.ID\t|T2.NAME\t|T3.ID\t|T3.NAME\t|T4.ID\t|T4.NAME\t|T5.ID\t|T5.NAME |1\t|name21\t|1\t|name31\t|1\t|name41\t|1\t|name51 |2\t|name22\t|2\t|name32\t|2\t|name42\t|2\t|name52 |1\t|name21\t|1\t|name31\t|4\t|name44\t|4\t|name54 |2\t|name22\t|2\t|name32\t|4\t|name44\t|4\t|name54 FULL JOIN 语法格式：LeftTable FULL JOIN RightTable ON JoinCriteria WHERE FilterCriteria\nFULL JOIN 的执行结果与左右表的顺序无关。\n执行过程分为 2 个步骤：\n将左表和右表做笛卡尔积，然后根据 ON 后的“连接条件”对笛卡尔积后的结果进行筛选； 如果经过第一步后，左表（右表）中的某条记录没有任何符合“连接条件”的连接记录，则将左表（右表）中的该记录保留，使用 NULL 值对右表（左表）的列值进行填充，然后将二者连接生成一条连接记录。 示例 创建两张新表并插入数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 -- 建表 CREATE TABLE FT1 ( ID INT, NAME VARCHAR ); CREATE TABLE FT2 ( ID INT, NAME VARCHAR ); -- 添加数据 INSERT INTO FT1 (ID, NAME) VALUES (1, 'name11'); INSERT INTO FT1 (ID, NAME) VALUES (2, 'name12'); INSERT INTO FT2 (ID, NAME) VALUES (2, 'name22'); INSERT INTO FT2 (ID, NAME) VALUES (3, 'name23'); 查询语句\n1 2 3 SELECT * FROM FT1 FULL JOIN FT2 ON FT1.ID = FT2.ID -- 因为 FULL JOIN 的执行结果与左右表顺序无关，所以上下两条语句是等价的 SELECT * FROM FT2 FULL JOIN FT1 ON FT2.ID = FT1.ID 先将 FT1 和 FT2 进行笛卡尔积\n1 2 3 4 5 |FT1.ID\t|FT1.NAME |FT2.ID |FT2.NAME |1\t|name11\t|2\t|name22 |1\t|name11\t|3\t|name23 |2\t|name12\t|2\t|name22 |2\t|name12\t|3\t|name23 然后通过 ON 条件 FT1.ID = FT2.ID 对上方数据进行筛选\n1 2 |FT1.ID\t|FT1.NAME |FT2.ID |FT2.NAME |2\t|name12\t|2\t|name22 此时，会发现左表中 FT1.ID 为 1 的记录以及右表中 FT2.ID 为 3 的记录均没有任何符合“连接条件”的连接记录，所以将 FT1.ID 为 1 的记录保留，然后使用 NULL 填充右表中的列值；将 FT2.ID 为 3 的记录保留，然后使用 NULL 值填充左表中的列值\n1 2 3 |FT1.ID\t|FT1.NAME |FT2.ID |FT2.NAME |1\t|name11\t|NULL\t|NULL |NULL |NULL\t|3\t|name23 将第 4 步和第 5 步的结果合并到一起，得到最终结果\n1 2 3 4 |FT1.ID\t|FT1.NAME |FT2.ID |FT2.NAME |2\t|name12\t|2\t|name22 |1\t|name11\t|NULL\t|NULL |NULL |NULL\t|3\t|name23 ","description":"","tags":["SQL"],"title":"SQL INNER/LEFT/RIGHT/FULL JOIN","uri":"/posts/database/sql-join/"},{"categories":null,"content":"自动推送 Maven 项目到 Docker/Docker 仓库 开启 Docker 的远程连接端口 参考：configure-where-the-docker-daemon-listens-for-connections\n有两种方式进行配置，一种是修改 systemd 的配置文件，另一种是修改 daemon.json，两种方式任选其一即可，否则会出现冲突。\nsystemd 方式\n使用 vim /usr/lib/systemd/system/docker.service 编辑 docker.service 文件\n在 ExecStart 后面添加 -H tcp://0.0.0.0:2375\n1 2 [Service] ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock -H tcp://0.0.0.0:2375 重新加载 systemctl 的配置并重启 docker\n1 systemctl daemon-reload \u0026\u0026 systemctl restart docker daemon.json 方式\n在 /etc/docker/daemon.json 的 hosts 数组里添加 UNIX socket 和可以远程访问 Docker 的 IP 地址\n1 2 3 { \"hosts\": [\"unix:///var/run/docker.sock\", \"tcp://127.0.0.1:2375\"] } 重启 Docker\n如果在基于 systemd 的系统上使用该方式，需要将 /usr/lib/systemd/system/docker.service 里的 -H fd:// 删除掉\n下载 Docker CLI Jib 需要使用 Docker CLI 才能将镜像 push 到远程 Docker daemon。可以从 https://download.docker.com/ 上下载，或者使用命令行安装 Docker CLI。\nJib GoogleContainerTools/jib 可以在本地不安装 Docker daemon，并且不使用 Dockerfile 的情况下，将 Java 应用程序构建成 Docker 镜像，并 push 到远程仓库/Docker daemon。\npom.xml 文件配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 \u003cproject\u003e ... \u003cproperties\u003e \u003c!--指定 jib-maven-plugin 插件的版本 --\u003e \u003cjib-maven-plugin.version\u003e3.1.4\u003c/jib-maven-plugin.version\u003e \u003c/properties\u003e \u003cplugin\u003e \u003cgroupId\u003ecom.google.cloud.tools\u003c/groupId\u003e \u003cartifactId\u003ejib-maven-plugin\u003c/artifactId\u003e \u003cversion\u003e${jib-maven-plugin.version}\u003c/version\u003e \u003cconfiguration\u003e \u003c!-- 以哪个镜像作为基本镜像 --\u003e \u003cfrom\u003e \u003cimage\u003eopenjdk:8\u003c/image\u003e \u003c/from\u003e \u003c!-- 将该模块部署到哪个仓库 --\u003e \u003cto\u003e \u003cimage\u003edocker.io/swanghub/flowable-test\u003c/image\u003e \u003c!-- 推荐使用 credHelper 或者将用户名和密码配置在 maven 的 settings.xml 中 --\u003e \u003c!--auth\u003e \u003cusername\u003eusername\u003c/username\u003e \u003cpassword\u003epassword\u003c/password\u003e \u003c/auth--\u003e \u003ccredHelper\u003ewincred\u003c/credHelper\u003e \u003ctags\u003e \u003ctag\u003e${project.version}\u003c/tag\u003e \u003ctag\u003elatest\u003c/tag\u003e \u003c/tags\u003e \u003c/to\u003e \u003c!-- 配置 Docker daemon --\u003e \u003cdockerClient\u003e \u003c!-- docker 命令的路径 --\u003e \u003cexecutable\u003e/path/to/docker.exe\u003c/executable\u003e \u003cenvironment\u003e \u003c!-- Docker daemon 的 IP 和监听的端口 --\u003e \u003cDOCKER_HOST\u003eintelli.icu:2375\u003c/DOCKER_HOST\u003e \u003c/environment\u003e \u003c/dockerClient\u003e \u003c!-- 容器相关属性设置 --\u003e \u003ccontainer\u003e \u003c!-- 要暴露的端口 --\u003e \u003cports\u003e \u003cport\u003e8080\u003c/port\u003e \u003c/ports\u003e \u003c!-- 修改镜像默认时间，否则会出现镜像内时区不正确 --\u003e \u003ccreationTime\u003eUSE_CURRENT_TIMESTAMP\u003c/creationTime\u003e \u003c/container\u003e \u003c!-- 允许使用 http 连接 --\u003e \u003callowInsecureRegistries\u003etrue\u003c/allowInsecureRegistries\u003e \u003c/configuration\u003e \u003cexecutions\u003e \u003c!-- 在执行 mvn package 的同时，将项目打包成 docker 镜像并推动到 Docker daemon --\u003e \u003cexecution\u003e \u003cid\u003epush-docker-image-when-maven-package\u003c/id\u003e \u003cphase\u003epackage\u003c/phase\u003e \u003cgoals\u003e \u003cgoal\u003edockerBuild\u003c/goal\u003e \u003c/goals\u003e \u003c/execution\u003e \u003c!-- 在执行 mvn deploy 的同时，将项目打包成 docker 镜像并推送到 docker 远程仓库 --\u003e \u003cexecution\u003e \u003cid\u003epush-docker-image-when-maven-deploy\u003c/id\u003e \u003cphase\u003edeploy\u003c/phase\u003e \u003cgoals\u003e \u003cgoal\u003ebuild\u003c/goal\u003e \u003c/goals\u003e \u003c/execution\u003e \u003c/executions\u003e \u003c/plugin\u003e ... \u003c/project\u003e 关于账号认证相关的信息可参考：jib-maven-plugin#authentication-methods，上方使用了 docker-credential-helpers 作为认证方式\n使用过程遇到的问题可从 faq 和 issues 中查找解决方案\nIDEA 连接 Docker 参考：IDEA Docker 插件文档\n在 IDEA 中添加 Docker 连接\nFile -\u003e Settings -\u003e Build, Execution, Deployment -\u003e Docker\n使用 Alt + 8 在 Service 窗口中即可看到已连接的 Docker 信息\n执行 mvn package 后即可在 Services -\u003e Docker -\u003e Images 中查看到新的镜像，执行 mvn deploy，即可将镜像推送到远程 Docker 仓库。\n右键点击指定镜像，点击 Create Container，即可创建容器。\n","description":"","tags":["Java","IDEA","Docker","Maven","Jib"],"title":"自动推送 Maven 项目到 Docker/Docker 仓库","uri":"/posts/java/maven-docker/"},{"categories":null,"content":"Android 安装 Linux 环境介绍 在以下两款手机上进行了操作，整体流程都是相同的\n荣耀 7C LND-AL30 红米 Note5A MDE6S 刷机过程中需要用到 adb 和 fastboot 命令，可从 Android 官方提供的 platform-tools 进行下载。\n整体流程介绍 获取 ROOT 权限\n获取 ROOT 权限需要以下 3 步\n解锁 BootLoader 刷入第三方 Recovery 刷入 root 权限管理工具 安装 BusyBox\n安装 LinuxDeploy\n详细操作 获取 ROOT 权限 解锁 BootLoader\n华为 2018 年关闭了官方的 BootLoader 解锁通道，所以直接从淘宝上花了 20 块钱，远程帮忙解锁的，一定要找商家要 16 位的解锁码，防止以后操作失误把手机 BL 给上锁了。\n小米手机可以参考官方提供的 解锁小米手机\n下载第三方 Recovery\n从 TWRP 上根据机型下载 twrp.img 文件\n手机开机，使用 USB 将手机和电脑进行连接，开启开发者模式，并信任此电脑。\n刷入第三方 Recovery\n1 2 3 4 5 6 7 8 9 10 # 显示出电脑已连接的设备，如果成功连接，是可以看到有设备信息输出的 adb devices # 重启手机到 bootloader 模式 adb reboot bootloader # 刷入第三方 recovery fastboot flash recovery /path/to/twrp.img # 华为手机需要使用如下命令输入第三方 recovery fastboot flash revocery_ramdisk /path/to/twrp.img # 重启手机 fastboot reboot 刷入 root 权限管理工具\n下载最新的 Magisk，复制一份将文件扩展名修改为 .zip，然后将两个文件都存储到手机里。\n手机关机后，按住 音量+ + 开机键，当手机显示出 logo 后，立刻松开所有按键，稍后会自动进入到 Team Win Recovery 界面（不同型号手机进入 Recovery 模式的快捷键可能不同）。\n点击 Install，找到 Magisk-vX.X.zip 文件并点击，然后滑动 Swipe to confirm Flash，刷入 root 权限管理工具。\n成功后，按照提示，重启手机即可。\n安装 BusyBox 下载最新的 BusyBox 并安装。\n启动 BusyBox，点击左上角三个横杠 -\u003e Settings -\u003e 勾选 Debug mode，便于查看执行日志信息。\n返回，点击 INSTALL 进行安装。\n系统只读问题\n点击 INSTALL 后，日志出现：'/system/*': Read-only file system。\n1 2 3 4 5 6 7 8 9 10 11 # 手机开机，使用 USB 将手机和电脑进行连接，开启开发者模式，并信任此电脑。 # 使用 shell 方式连接手机 adb shell # 切换到 root 用户 su # 查看 /system 的挂载信息，此处要记住它的设备路径，类似于 /dev/block/mmxxx mount | grep /system # 取消 /system 的挂载 umount /system # 重新将其挂载为读写模式 mount -o rw -t ext4 /dev/block/mmxxx /system 安装 LinuxDeploy 下载最新的 Linux Deploy 并安装。\n使用 Magisk 授予 LinuxDeploy root 权限\n启动 Linux Deploy，点击左上角三个横杠 -\u003e Settings：\n勾选 Lock screen：当程序运行时，保持屏幕常量 勾选 Lock Wi-Fi：当程序运行时，保持 Wi-Fi 一直开启 勾选 Wake lock：当屏幕灭了后，保持 CPU 一直运行 设置 PATH variable 为 /system/xbin，并点击 Update ENV：设置 BusyBox 的路径 勾选 Debug mode：可以查看详细日志 点击右下角的 Properties 图标，可以用来配置要安装的 Linux 的属性信息：\nDistribution：可以选择要安装的发行版\nArchitecture：选择系统架构，安卓手机通常都是 arm64\nDistribution suite：Linux 发行版的版本\nSource path：Linux 发行版的资源路径，会从这个地址下载所需的 Linux 文件。\n推荐使用国内镜像，否则下载速度会慢，安装时容易出现错误\nUbuntu 的清华大学镜像：http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ CentOS 的阿里云镜像：https://mirrors.aliyun.com/centos-altarch/ Installation type：默认 File 即可\nInstallation path：安装的镜像路径。${EXTERNAL_STORAGE} 表示内部存储位置。该配置可以手动修改。\nImage size(MB)：镜像的大小。就是安装的 Linux 可以使用多大的存储空间。按需配置。\nFile system：文件系统格式，默认 ext4 即可\nUser name：管理员的用户名（非 root 用户）\nUser password：管理员的密码\nPrivileged users：授予用户哪些角色权限\n1 2 3 username:aid_inet username:aid_sdcard_rw username:aid_graphics INIT 勾选 Enable，Init system 选择 sysv：chroot 不支持 systemd，所以使用 sysV 作为软件自启动的方式\nMOUNTS 可以自己制定挂载设备\nSSH 勾选 Enable：允许使用 SSH 进行连接\nPulseAudio 勾选 Enable：允许播放声音\nGUI：图形化页面，根据需求选择是否开启\n点击右上角三个点，选择 Install，开始安装\n1 2 3 4 5 # 开始安装部署 \u003e\u003e\u003e deploy ... # 安装部署成功 \u003c\u003c\u003c deploy 点击 START 启动 Linux 系统\n1 2 3 4 5 # 开始启动 \u003e\u003e\u003e start ... # 启动成功 \u003c\u003c\u003c start 通过标题栏上的 IP，可以使用 shell 工具进行连接\n点击 STOP 关闭 Linux 系统\n1 2 3 4 5 # 开始关闭 \u003e\u003e\u003e stop ... # 关闭成功 \u003c\u003c\u003c stop 镜像扩容\n参考：linuxdeploy issues 395\n首先点击 STOP 停止镜像，使用 USB 将手机和电脑进行连接，开启开发者模式，并信任此电脑\n为安全起见，可以将镜像文件先复制到电脑进行备份\n1 2 # 从手机中将镜像拉取到电脑上 adb pull /mnt/sdcard/linux.img linux.img.bak 执行命令进行扩容\n1 2 3 4 5 6 7 8 9 # 连接 adb shell adb shell # 切换到 root 用户 su # 在镜像后面追加空白的空间（bs 块大小，count 要追加的块数量），以下是追加了 1GB，可通过修改 count 值调整扩容大小。 dd if=/dev/zero bs=4096 count=262144 \u003e\u003e /mnt/sdcard/linux.img # 重新分配空间 e2fsck -f /mnt/sdcard/linux.img resize2fs /mnt/sdcard/linux.img 如果执行失败，可以将镜像拉取到 Linux 电脑上，进行扩容后，再使用 adb push /path/to/newLinux.img /mnt/sdcard/linux.img\n额外操作 访问不到互联网\n网络相关权限问题，安卓将硬件相关权限归到了不同的用户组，需要把用户添加到相关组，才能有相关设备的使用权限。\n1 2 cat /etc/passwd | grep inet usermod -G aid_inet root 开源软件仓库：F-DROID\n可以使用清华镜像源：https://mirrors.tuna.tsinghua.edu.cn/help/fdroid/，加速下载\n安卓手机 shell 工具：Termux，使用 F-DROID 即可安装\n","description":"","tags":["Android"],"title":"Android 安装 Linux","uri":"/posts/android/android-install-linux/"},{"categories":null,"content":"Linux ulimit 命令介绍 ulimit 用来限制当前 shell 可占用的系统资源数量，如内存大小，文件描述符数量等。\n命令格式和参数说明 命令格式\n1 ulimit [-HSabcdefiklmnpqrstuvxPT] [limit] root 用户不受 ulimit 的限制。-H 和 -S 选项为给定资源设置硬限制或软限制。如果 -H 和 -S 均未指定，则软限制和硬限制均被设置。limit 的值可以是数字，也可以是hard，soft，unlimited 之一。如果省略 limit，则默认打印资源软限制的当前值，可使用 -H 选项打印硬限制的值。\n选项说明\n-S：软限制，当超过限制值时会报警 -H：硬限制，不允许超过限制值 -a：列出当前用户的资源限制情况 -b：socket 缓冲区的大小 -c：单个核心文件的最大尺寸 -d：单个进程数据段的最大尺寸 -e：进程的最大调度优先级（nice 值） -f：当前 shell 及其子进程写入文件的最大大小 -i：挂起信号的最大数量 -k：当前进程可分配的最大 kqueue 数 -l：单个进程可锁定的内存最大值 -m：可使用的最大物理内存大小（许多系统不遵守此限制） -n：可以打开文件描述符的最大数量（大多数系统不允许设置此值） -p：管道缓冲区大小（可能未设置） -q：POSIX 消息队列中的最大字节数 -r：最大实时调度优先级 -s：可以使用的堆大小 -t：最多可以使用多少秒的 CPU -u：单个用户可用的最大进程数 -v：可使用的虚拟内存大小 -x：可锁定的最大文件数 -P：伪终端的最大数量 -T：最大线程数 示例\n查看当前 shell 可用的资源硬限制情况\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 wangshuo@ubuntu:~$ ulimit -Ha core file size (blocks, -c) unlimited data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 63412 max locked memory (kbytes, -l) 65536 max memory size (kbytes, -m) unlimited open files (-n) 1048576 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) unlimited cpu time (seconds, -t) unlimited max user processes (-u) 63412 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited 修改当前 shell 可以打开文件描述符的最大数量（硬限制）\n1 ulimit -Hn 1048576 持久化修改 设置到用户的个人配置文件 如果仅需要对当前用户生效，可以修改 ~/.bashrc（不需要使用密码登录就生效） 或 ~/.profile（必须使用密码登录才生效），加入如下命令即可\n1 2 ulimit -Hn 65535 ulimit -Hu 1024 应用程序的启动脚本 可以将 ulimit 命令添加到应用程序的启动脚本中，当使用脚本启动应用程序时，只对当前脚本生效。\n1 2 3 4 #/bin/bash ulimit -Hn 65535 ulimit -Hu 1024 ./sbin/nginx 全局配置文件 在 ulimit 的全局配置文件 /etc/security/limits.conf 中可以进行更高级的配置\n1 2 3 4 5 # /etc/security/limits.conf # #Each line describes a limit for a user in the form: # #\u003cdomain\u003e \u003ctype\u003e \u003citem\u003e \u003cvalue\u003e 参数说明\n\u003cdomain\u003e 可以是\n用户名 组名，使用 @group 格式 通配符 *，用于记录 通配符 %，也可以与 %group 语法一起使用，用于最大登录限制 注意：组和通配符限制不适用与 root 用户。要对 root 用户进行限制，必须使用用户名 root。\n\u003ctype\u003e 有两个可选值\nsoft：软限制 hard：硬限制 \u003citem\u003e 可以是\ncore：限制核心文件大小（KB） data：最大数据大小（KB） fsize：最大文件大小（KB） memlock：最大锁定内存地址空间（KB） nofile：打开文件描述符的最大数量 rss：最大物理内存大小（KB） stack：最大堆大小（KB） cpu：最大 CPU 时间（MIN） nproc：最大进程数 as：限制地址空间（KB） maxlogins：此用户的最大登录次数 maxsyslogins：系统上的最大登录次数 priority：运行用户进程的优先级 locks：用户可以持有的最大文件锁数 sigpending：最大挂起信号数 msgqueue：POSIX 消息队列使用的最大内存（bytes） nice：允许的最大优先级，范围 [-20, 19] rtprio：最大实时优先级 chroot：改变用户根目录（Debian 特有的） \u003cvalue\u003e：具体的值\n示例\n1 2 3 4 5 6 7 8 9 * soft core 0 root hard core 100000 * hard rss 10000 @student hard nproc 20 @faculty soft nproc 20 @faculty hard nproc 50 ftp hard nproc 0 ftp - chroot /ftp @student - maxlogins 4 ","description":"","tags":["Linux"],"title":"Linux ulimit 命令介绍","uri":"/posts/linux/linux-ulimit/"},{"categories":null,"content":"访问者模式（Visitor） 在结构不变的情况下动态改变对于内部元素的动作\n","description":"","tags":["MSB","Design Pattern","Java"],"title":"访问者模式（Visitor）","uri":"/posts/msb/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/visitor/"},{"categories":null,"content":"Docker 数据持久化 参考：Manage data in Docker\nDocker 默认情况下将创建的所有文件都保存在一个可写的容器层（writable container layer）。这意味着\n当容器消失后数据也不存在了，并且其他进程很难访问到容器内的数据。 容器的可写层与容器运行所在的宿主机是强耦合的，所以不能很容易迁移数据。 向容器的可写层写数据必须有存储驱动（storage driver）来管理文件系统。存储驱动使用 Linux 内核提供的联合文件系统，有直接写入主机文件系统的数据卷相比，这种额外的抽象层会降低性能。 Docker 有两种方式将容器的文件持久化保存到宿主机上：volumes 和 bind mounts。如果在 Linux 上使用，还可以用 tmpfs mount，如果在 Windows 上使用，还可以用 named pipe。\n简单对比 不管使用哪种类型，在容器内看着都是相同的，在容器的文件系统中它可能是一个目录或者一个文件。\n三者最简单的区分方式是将数据存储到了宿主机的什么地方\nVolumes 将数据保存在由 Docker 管理（/var/lib/docker/volumes/）的宿主机文件系统的一部分。非 Docker 进程不应该修改这部分文件系统。Volumes 是 Docker 持久化数据最好的方式。 Bind mounts 可能将数据保存在宿主机的任意位置。甚至可能将数据保存在系统系统文件或目录中。宿主机上的非 Docker 进程或者 Docker 容器都可以随意修改它们。 tmpfs mounts 只能将数据保存在宿主机的内存中，并且不能写入到宿主机的文件系统中。 详细对比 Volumes 由 Docker 创建和管理。默认会在容器或服务创建时由 Docker 自动创建，也可以使用 docker volume create 命令手动创建。\n一个 volume 可以同时挂载在多个容器上。当没有运行中的容器使用某个 volume，它不会被自动删除。可以使用 docker volume prune 手动删除无用的 volumes。\n当挂载 volume 时，它可能是被命名的或者匿名的。第一次挂载的时候 Docker 会分配给 volume 一个随机的名字，以保证该 volume 在当前宿主机上唯一。除了名称，二者没有区别。\nVolumes 支持使用 volume drivers 将数据保存在远程主机或者云提供商，以及其他的可能性。\nBind mounts：Docker 从早期就可用的方式。Bind mounts 功能有限。这种方式会将宿主机的文件/目录挂载到容器内。如果宿主机上不存在这个文件/目录，Docker daemon 会自动创建它。如果你正在开发新的 Docker 应用程序，推荐使用 Volumes 替代。不能使用 Docker CLI 命令直接管理 Bind mounts。\ntmpfs mounts：这种方式不会将数据持久化到宿主机或者容器的磁盘。它可以在容器的生命周期内被容器使用，用于存储非持久状态或敏感信息\nnamed pipes：npipe 挂载可用于 Docker 主机和容器之间的通信。常见用例是在容器内运行第三方工具并使用 named pipes 连接到 Docker 引擎 API。\nBind mounts 和 volumes 都可以使用 -v 标签，但是语法上有轻微不同。tmpfs mounts 可以使用 --tmpfs 标签。建议对容器和服务使用 --mount 标签，因为语法更清晰。\nVolumes 的良好用例 Volumes 是 Docker 容器或服务优先选择的持久化数据方式。\n在多个运行中的容器间共享数据。多个容器可以同时挂载相同的 volume，可以是 read-write 或 read-only 的。 当宿主机不能保证具有给定的目录或文件结构时。Volumes 可以将宿主机的配置与容器运行时分离。 当想将数据保存在远程服务器或者云供应商上时 当想对数据进行备份，恢复，或者将它从一个 Docker 主机迁移到另一个时。可以停止容器，然后备份 volumes 的目录（例如：/var/lib/docker/volumes/\u003cvolume-name\u003e） 在 Docker Desktop 上有高性能 I/O 的需求。Volumes 将数据存储在 Linux VM 而不是宿主机，这意味着它可以有更低的延迟和更高的吞吐量。 当应用程序需要 Docker Desktop 上完全的文件系统行为时。例如数据库引擎需要精确控制磁盘刷新以保证事务的持久性。Volumes 将数据存储在 Linux VM 中可以做出这种保证，但是 Bind mounts 不行。 Bind mounts 的良好用例 在一般情况下，应该使用 Volumes。Bind mounts 可应用于一下场景：\n在宿主机中共享配置文件给容器。Docker 默认为容器提供 DNS 解析就是使用这种方式，将 /etc/resolv.conf 从宿主机挂载到了每个容器中。 在宿主机和容器的开发环境之间共享源代码或者工件。例如可以将 maven 的 /target 目录挂载到容器中中，这样每次在宿主机上构建 maven 项目，容器都可以访问重新构建的工件。 当宿主机的文件/目录结构与容器所需的一致时。 tmpfs mounts 的良好用例 tmpfs 挂载最适用于您不希望数据在主机上或容器内持久化的情况。这可能是出于安全原因或在您的应用程序需要写入大量非持久状态数据时保护容器的性能。\nBind mounts 或 Volumes 的使用建议 如果将空 Volumes 挂载到容器中已存在的文件/目录中时，这些文件/目录会复制到该 Volumes 中。同样的，如果在启动容器的时候指定了一个尚不存在的 Volumes，Docker 则会创建一个空 Volumes。这时预先填充另一个容器所需数据的最好的方法。 如果将 bind mount 或非空的 Volumes 挂载到容器中已存在的文件/目录中时，这些文件/目录会被 mount 掩盖。被掩盖的文件不会被删除或修改，但在 bind mount 和 volumes 时无法访问。 ","description":"","tags":["Docker"],"title":"Docker 数据持久化","uri":"/posts/docker/docker-storage/"},{"categories":null,"content":"基于 Nexus 的 Maven 私服 环境介绍 Ubuntu Server 20.4 LTS Sonatype Nexus：Nexus Repository OSS 3 JDK 8：JDK 8u_202 Nexus Repository OSS 3 最新版下载地址：\nMac：https://download.sonatype.com/nexus/3/latest-mac.tgz Windows：https://download.sonatype.com/nexus/3/latest-win64.zip Linux：https://download.sonatype.com/nexus/3/latest-unix.tar.gz 配置 Java 环境 参考 Ubuntu 配置 Java 环境\n安装 Nexus 解压压缩包\n1 $ tar -zxvf nexus-3.33.0-01-unix.tar.gz 可以得到两个文件夹\nnexus-3.33.0-01：nexus 的安装目录。包含 nexus 运行所需的依赖和启动脚本等 sonatype-work：nexus 的工作目录。包含 nexus 的数据、日志、配置文件等 启动 nexus（nexus 不推荐使用 root 用户进行启动）\n1 2 3 4 5 6 # 添加一个系统用户 nexus $ useradd -r -s /bin/bash nexus # 将 nexus 文件夹内的所有文件的所属用户和所属组修改为 nexus $ chown -R nexus. /path/to/nexus # 使用 nexus 用户启动 nexus $ su nexus /path/to/nexus/nexus-3.33.0-01/bin/nexus start 稍等一会后，通过 8081 端口，即可访问 nexus\n初始设置 点击右上角 Sign in 后，根据提示进行登录\n修改密码\n配置匿名访问\nEnable anonymous access：允许匿名访问。默认情况下，任何人都可以从仓库搜索，浏览和下载组件。 Disable anonymous access：不允许匿名访问。任何人或构建工具，都必须有用户凭证才能进行访问。 出于安全考虑，这里选择 Disable anonymous access。\n是否分享匿名信息给 Sonatype\n选择 否\n基本配置修改 修改启动用户\n在 /path/to/nexus/nexus-3.33.0-01/bin/nexus.rc 修改 nexus 默认的启动用户\n1 run_as_user=\"nexus\" 修改后，直接使用 /path/to/nexus/nexus-3.33.0-01/bin/nexus start 即可使用 nexus 用户启动 nexus\n修改数据文件夹（data_dir）\n在 /path/to/nexus/nexus-3.33.0-01/bin/nexus.vmoptions 里修改 nexus 的数据文件夹\n1 2 3 4 -XX:LogFile=/path/to/nexus/data/log/jvm.log -Dkaraf.data=/path/to/nexus/data -Dkaraf.log=/path/to/nexus/datalog -Djava.io.tmpdir=/path/to/nexus/data/tmp 修改启动端口\nnexus 的配置文件在 $data_dir/etc/nexus.properties，如果上方修改了数据文件夹，可以将 /path/to/nexus/nexus-3.33.0-01/etc/nexus-default.properties 复制到 /path/to/nexus/data/etc/nexus.properties 下，然后进行修改\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## DO NOT EDIT - CUSTOMIZATIONS BELONG IN $data-dir/etc/nexus.properties ## # Jetty section application-port=8090 application-host=0.0.0.0 nexus-args=${jetty.etc}/jetty.xml,${jetty.etc}/jetty-http.xml,${jetty.etc}/jetty-requestlog.xml nexus-context-path=/ # Nexus section nexus-edition=nexus-pro-edition nexus-features=\\ nexus-pro-feature nexus.hazelcast.discovery.isEnabled=true 指定 JAVA_HOME 和虚拟机参数\n修改 /path/to/nexus/nexus-3.33.0-01/bin/nexus\n1 2 3 4 # Uncomment the following line to override the JVM search sequence INSTALL4J_JAVA_HOME_OVERRIDE=/path/to/jdk/jdk1.8.0_202 # Uncomment the following line to add additional VM parameters # INSTALL4J_ADD_VM_PARAMS= 可以将 nexus 用户的家目录修改为 nexus 的数据文件夹（data_dir)\n1 usermod -d /path/to/nexus/data nexus 配置环境变量\n1 2 3 4 # nexus environment NEXUS_HOME=/path/to/nexus/nexus-3.33.0-01 PATH=NEXUS_HOME/bin:$PATH export NEXUS_HOME PATH systemd 服务设置 在 /usr/lib/systemd/system 目录下创建 nexus.service\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [Unit] Description=nexus Server After=network.target [Service] Type=forking LimitNOFILE=65535 ExecStart=/path/to/nexus/nexus-3.33.0-01/bin/nexus start ExecReload=/path/to/nexus/nexus-3.33.0-01/bin/nexus restart ExecStop=/path/to/nexus/nexus-3.33.0-01/bin/nexus stop User=nexus Restart=on-abort TimeoutSec=600 [Install] WantedBy=multi-user.target 通过 systemd 操作 nexus.service 即可\n1 2 3 4 5 6 7 8 9 10 # 启动服务 systemctl start nexus.service # 停止服务 systemctl stop nexus.service # 重启服务 systemctl restart nexus.service # 设置开机自启 systemctl enable nexus.service # 取消开机自启 systemctl disable nexus.service 控制台页面 仓库介绍 Blob Stores：文件存储位置，对应服务器上的一个目录\nRepositories：仓库。可以是 maven、docker、apt、conda 等格式\n仓库的类型有 3 种\nproxy：代理仓库，通常被代理的是 Maven 的中央仓库。当用户通过 Nexus 获取依赖包时，Nexus 先从被代理的仓库把依赖包下载到 Nexus 仓库，然后在发送给用户。\nhosted：Nexus 的宿主机仓库。用于存放第三方的依赖包（例如个人或者公司内部的）。\nVersion policy：该仓库存储什么版本的依赖包。区别可参考 Maven 的 SNAPSHOT 和 RELEASE 的区别\nRelease：正式版本的依赖包 Snapshot：快照版本的依赖包 Mixed：混合存储 Deployment policy：发布策略。\nAllow redeploy：允许用户重新发布（快照版库通常使用） Disable redeploy：不允许用户重新发布（正式版库通常使用） Read-only：只读（只允许用户使用，不允许用户上传） group：将两个仓库合到一起使用。可以将 maven-central（proxy），maven-release（hosted），maven-snapshot（hosted） 三个仓库添加到同一个组里使用\nNexus 默认给创建的 Maven 仓库\nmaven-central（proxy）：对 maven 中央仓库的代理，俗称“镜像仓库”\nmaven-release（hosted）：私服的发布版本库\nmaven-snapshot（hosted）：私服的快照版本库\nmaven-public（group)：将上方三个仓库组合在一起提供服务\n可以使用默认给创建的，也可以自己创建新的 Repository\n清理策略 定期清理仓库中的依赖包，减少对服务器资源的占用。\n角色用户权限 可以针对不同角色对不同的仓库设置不同的使用策略。\n使用 参考 Maven 仓库\n","description":"","tags":["Nexus","Maven","Java"],"title":"基于 Nexus 的 Maven 私服","uri":"/posts/java/maven-private-server-base-on-nexus/"},{"categories":null,"content":"迭代器模式（Iterator） 迭代器模式最主要的用途就是对容器进行遍历。\n在 Java 中已经使用 java.util.Iterator 接口对 java.util.Collection 的所有子类提供了迭代器的支持。\n迭代器将对集合进行遍历的行为与集合进行了分离，对外提供了统一的遍历方式，隐藏了集合的内部实现细节。可以在不改变调用方代码的情况下，改变集合的代码（例如修改集合内部的数据结构）。\n自定义集合和迭代器 代码 定义迭代器接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * 自定义的迭代器接口 */ public interface Iterator\u003cE\u003e { /** * 判断是否有下一个元素 * * @return 有就返回 true，否则返回 false */ boolean hasNext(); /** * 返回下一个元素 * * @return 下一个元素。如果不存在下一个元素，应该抛出异常。 */ E next(); } 集合类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 /** * 自定义的集合类（模拟 ArrayList） */ public class Array\u003cE\u003e { /** * 用于存储元素 */ private Object[] elements; /** * 当前对象中包含的元素个数 */ private int size; public Array() { // 创建对象时，默认初始化一个长度为 8 的数组 elements = new Object[8]; } /** * 向数组中添加元素 * * @param e 被添加的元素 */ public void add(E e) { // 动态扩容 if (elements.length == size) { elements = Arrays.copyOf(elements, size * 2); } // 添加元素后，size 自增 1 elements[size++] = e; } /** * 获取迭代器的方法 * * @return 迭代器 */ public Iterator\u003cE\u003e iterator() { return new Iter(); } /** * 通过内部类的方式实现 Iterator 接口 * 对于不同的集合，其遍历方式也不同，所以将具体的迭代器在其内部进行实现，达到高内聚的目的 */ private class Iter implements Iterator\u003cE\u003e { /** * 记录当前元素的角标 */ private int cursor; @Override public boolean hasNext() { return cursor != size; } @Override @SuppressWarnings(\"unchecked\") public E next() { // 返回当前元素后，cursor 自增 1 return (E) elements[cursor++]; } } } 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class TestMain { public static void main(String[] args) { // 创建 Array 对象 Array\u003cInteger\u003e array = new Array\u003c\u003e(); // 向 Array 中添加测试数据 for (int i = 0; i \u003c 10; i++) { array.add(i); } // 使用自定义的迭代器进行迭代 Iterator\u003cInteger\u003e itr = array.iterator(); while (itr.hasNext()) { System.out.println(itr.next()); } } } 类图和说明 创建迭代器接口，一般包含 hasNext 和 next 两个方法 创建集合类，需要有一个 iterator 方法用来返回迭代器 在结合类中通过内部类的方式，创建 Iterator 接口的实现 JDK 中的迭代器 迭代器接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package java.util; import java.util.function.Consumer; /** * 集合上的迭代器 * * @param \u003cE\u003e 该迭代器返回的元素类型 */ public interface Iterator\u003cE\u003e { /** * 如果迭代器有更多的元素 * （换句话说，如果 next 方法返回一个元素，而不是抛出异常，则返回 true） * * @return 如果迭代有更多的元素返回 true */ boolean hasNext(); /** * 返回迭代中的下一个元素 * * @return 迭代中的下一个元素 * @throws NoSuchElementException 如果迭代中没有更多元素 */ E next(); /** * 从底层集合中移除迭代器返回的最后一个元素（可选）。每调用一次 next 方法，只能调用该方法一次。 * * @throws UnsupportedOperationException 如果此迭代器不支持该操作 * * @throws IllegalStateException 如果在调用该方法前没有调用 next 方法，或者调用 next 方法后，多次调用该方法。 */ default void remove() { throw new UnsupportedOperationException(\"remove\"); } } Iterable 接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package java.lang; import java.util.Iterator; import java.util.Objects; import java.util.Spliterator; import java.util.Spliterators; import java.util.function.Consumer; /** * 实现此接口允许对象成为“for-each loop”的目标 * * @param \u003cT\u003e 迭代器返回的元素类型 */ public interface Iterable\u003cT\u003e { /** * 返回 T 类型元素的迭代器 * * @return 一个迭代器 */ Iterator\u003cT\u003e iterator(); } Collection 继承了 Iterable 接口，并且其实现类中，使用内部类的方式实现了 Iterator 接口\n","description":"","tags":["MSB","Design Pattern","Java"],"title":"迭代器模式（Iterator）","uri":"/posts/msb/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/iterator/"},{"categories":null,"content":"代理模式（Proxy） 静态代理 静态代理的代理类是运行前就由开发人员写好的，并且在类中明确指明了被代理对象。\n代码 被代理类和代理类的公共接口\n1 2 3 4 5 6 7 8 9 /** * 可销售的 */ public interface Salable { /** * 销售商品 */ void sale(); } 被代理类\n1 2 3 4 5 6 7 8 9 /** * 金士顿：可以销售内存条 */ public class Kingston implements Salable { @Override public void sale() { System.out.println(\"销售 Kingston 内存条\"); } } 代理类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /** * 金士顿的代理 * \u003cp\u003e * 和被代理对象实现相同的接口 */ public class KingstonProxy implements Salable { /** * 被代理的对象，在编译期间就确定了 */ private Salable salable = new Kingston(); @Override public void sale() { // 在实际执行代理对象的方法前后，可以添加自己的处理 System.out.println(\"记录买家信息\"); salable.sale(); System.out.println(\"给买家发货\"); } } 测试类\n1 2 3 4 5 6 7 8 public class TestMain { public static void main(String[] args) { // 创建代理对象 Salable proxy = new KingstonProxy(); // 通过代理的方法进行调用 proxy.sale(); } } 类图和说明 创建代理类和被代理类的公共接口 创建被代理类，实现公共接口 创建代理类，实现公共接口。其包含被代理对象的引用，并在创建代理对象时，对被代理对象进行初始化。实现接口方法，并添加额外的处理 通过代理对象调用接口方法 扩展方式可有两种 模仿代理类（KingstonProxy），给原被代理类（Kingston）创建新的代理类 将现有代理类（KingstonProxy）作为被代理类，给其创建新的代理类 静态代理和 装饰者模式 很相似，区别在于装饰者模式中被装饰对象是通过构造方法传入的，然后被装饰对象可以进行嵌套；而静态代理模式中，被代理对象是直接在代理类中写死的。\nJDK 动态代理 静态代理的代理类是运行前由开发人员写好的，并且在类中明确指明了被代理对象。而动态代理是将对被代理对象进行的增强进行了抽取，然后可以在程序运行时，由 JVM 动态的给不同的被代理类生成代理类。\n例：要分别统计 Salable 的 sale 方法和 Showable 的 show 方法的执行耗时。\n​\t如果使用静态代理，就需要创建两个代理类：SaleConsumeTimeProxy 和 ShowConsumeTimeProxy。\n​\t而使用动态代理，我们只需要将统计时间的代码抽象为一个 ConsumeTimeInvocationHandler，然后在调用 sale 或 show 方法时，通过 JVM 动态生成的代理对象进行调用即可。\n代码 被代理类和代理类的公共接口\n1 2 3 4 5 6 7 8 9 /** * 可销售的 */ public interface Salable { /** * 销售商品 */ void sale(); } 具体的被代理类\n1 2 3 4 5 6 7 8 9 /** * 金士顿：可以销售内存条 */ public class Kingston implements Salable { @Override public void sale() { System.out.println(\"销售 Kingston 内存条\"); } } 因为要记录方法的执行时间，所以将记录执行时间的功能抽取成一个 InvocationHandler\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; /** * 统计运行时间的 InvocationHandler */ public class ConsumeTimeInvocationHandler implements InvocationHandler { /** * 被代理对象，可以是任意类型 */ private Object obj; /** * 通过构造方法传入被代理对象 * * @param obj 被代理对象 */ public ConsumeTimeInvocationHandler(Object obj) { this.obj = obj; } /** * 使用 JVM 生成的代理对象进行方法调用时，会执行该方法 * * @param proxy JVM 动态生成的代理对象 * @param method 被代理的方法 * @param args 被代理方法的参数 * @return 方法返回值 * @throws Throwable 反射调用方法过程发生的异常 */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // 在被代理对象的方法执行前记录开始时间 long start = System.currentTimeMillis(); // 通过反射调用被代理对象的方法 Object result = method.invoke(obj, args); // 在被代理对象的方法执行后记录结束时间，并打印耗时 long end = System.currentTimeMillis(); System.out.println(method.getName() + \" 执行花费 \" + (end - start) / 1000.0 + \" 秒\"); // 被调用方法的返回值，如果方法返回值为 void，则返回 null return result; } } 在需要使用代理对象时，通过 Proxy 的 newProxyInstance 方法来动态生成代理对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import javax.print.PrintException; import java.lang.reflect.Proxy; public class TestMain { public static void main(String[] args) throws PrintException { // 被代理对象 Salable salable = new Kingston(); // 由 JVM 动态生成 Salable 的代理对象 Salable salableProxy = (Salable) Proxy.newProxyInstance( // 使用哪个类加载器将生成的代理对象加载到内存（指定与被代理类相同的类加载器即可） Salable.class.getClassLoader(), // 该代理对象应该实现哪些接口 new Class[]{Salable.class}, // 被代理对象的方法被调用时，要通过代理做什么 new ConsumeTimeInvocationHandler(salable)); // 通过代理对象调用 sale 方法 salableProxy.sale(); } } 扩展实现\n假如 Showable 接口的 show 方法也需要记录执行时间\nShowable 接口\n1 2 3 4 5 6 7 8 9 /** * 可显示的 */ public interface Showable { /** * 显示画面 */ void show(); } Showable 的具体实现\n1 2 3 4 5 6 7 8 9 /** * 电视 */ public class Television implements Showable { @Override public void show() { System.out.println(\"电视显示画面\"); } } 在需要代理对象时，依旧可以使用上方定义的 ConsumeTimeInvocationHandler 类来进行执行时间的记录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package com.example.proxy.dynamic; import javax.print.PrintException; import java.lang.reflect.Proxy; public class TestMain { public static void main(String[] args) throws PrintException { // 被代理对象 Showable showable = new Television(); // 由 JVM 动态生成 Showable 的代理对象 Showable showableProxy = (Showable) Proxy.newProxyInstance( Showable.class.getClassLoader(), // 可以通过这种方式获取被代理类实现的所有接口 Television.class.getInterfaces(), // 💡 使用一个 ConsumeTimeInvocationHandler 类即可统计任意对象的任意方法的耗时 new ConsumeTimeInvocationHandler(showable)); // 通过代理对象调用 show 方法 showableProxy.show(); } } 原理解析 在生成代理对象前，加入如下代码，让 JVM 将其动态生成的代理类保存到磁盘\n1 2 3 // 保存 JVM 生成的代理类，JDK8 使用上面的，JDK11 使用下面的 System.getProperties().setProperty(\"sun.misc.ProxyGenerator.saveGeneratedFiles\", \"true\"); //System.getProperties().setProperty(\"jdk.proxy.ProxyGenerator.saveGeneratedFiles\", \"true\"); 可以在 com.sun.proxy 包下找到 JVM 动态生成的代理类 $Proxy0，通过 IDEA 反编译后的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 // Source code recreated from a .class file by IntelliJ IDEA // (powered by FernFlower decompiler) package com.sun.proxy; import com.example.proxy.dynamic.Salable; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.lang.reflect.UndeclaredThrowableException; /** * 由 JVM 在运行时动态生成的代理类，该类实现了 Salable 接口 *（其会实现我们调用 Proxy.newProxyInstance 方法时，传入的所有接口） */ public final class $Proxy0 extends Proxy implements Salable { private static Method m0; private static Method m1; private static Method m2; // JVM 会根据传入的接口，在该代理类中给所有接口的方法都创建一个 Method 属性 private static Method m3; static { try { m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\"); m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\"); // 这里通过反射给 Method 属性进行赋值 m3 = Class.forName(\"com.example.proxy.dynamic.Salable\").getMethod(\"sale\"); } catch (NoSuchMethodException var2) { throw new NoSuchMethodError(var2.getMessage()); } catch (ClassNotFoundException var3) { throw new NoClassDefFoundError(var3.getMessage()); } } public $Proxy0(InvocationHandler var1) throws { super(var1); } public final void sale() throws { try { // 此处的 h 就是我们调用 Proxy.newProxyInstance 方法传入的那个 InvocationHandler // 在这里就会执行我们自己写的 ConsumeTimeInvocationHandler 的 invoke 方法 super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } public final boolean equals(Object var1) throws { // 跟 sale 方法类似} public final String toString() throws { // 跟 sale 方法类似} public final int hashCode() throws { // 跟 sale 方法类似} } java.lang.reflect.Proxy 类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package java.lang.reflect; public class Proxy implements java.io.Serializable { private static final Class\u003c?\u003e[] constructorParams = { InvocationHandler.class }; /** 代理实例的 InvocationHandler */ protected InvocationHandler h; protected Proxy(InvocationHandler h) { Objects.requireNonNull(h); this.h = h; } @CallerSensitive public static Object newProxyInstance(ClassLoader loader, Class\u003c?\u003e[] interfaces, InvocationHandler h)throws IllegalArgumentException { final Class\u003c?\u003e[] intfs = interfaces.clone(); // 1.从类加载器中查找或者生成代理类的 Class 对象，此处就生成了 $Proxy0 这个代理类 Class\u003c?\u003e cl = getProxyClass0(loader, intfs); // 2.获取代理类 $Proxy0 入参为 InvocationHandler 数组的构造器 final Constructor\u003c?\u003e cons = cl.getConstructor(constructorParams); // 3.使用代理类 $Proxy0 的构造器和自定义的 ConsumeTimeInvocationHandler 创建一个代理对象 return cons.newInstance(new Object[]{h}); } } JDK 动态代理是通过 ASM（可以直接操作二进制）修改的字节码文件。反射只能读取到类文件中的属性和方法，但是不能对其进行修改。\n类图和说明 创建被代理接口（JDK 动态代理需要根据传入的接口给代理类生成代理方法，所以只能对被代理对象实现的接口中的方法进行代理） 创建具体的被代理类实现被代理接口 创建增强类，实现 InvocationHandler 接口，并重写 invoke 方法，在该方法中添加对被代理对象的增强 在需要用到代理对象的地方，使用 Java 提供的 Proxy.newProxyInstance 方法动态创建代理对象 自定义的 InvocationHandler 接口的实现，可以对任意类型的对象进行增强 CGLib 动态代理 CGLib（Code Generation Library）是一个代码生成类库，可以在运行期间生成已有类的扩展类或已有接口的具体实现类。\nCGLib 代理是通过动态生成已有类（或接口）的子类，来进行对原有类（或接口）的增强。\nJDK 动态代理要求被代理的类必须实现一个或多个接口，而 CGLib 对此没有要求。\nJDK 动态代理和 CGLib 动态代理底层使用的都是 ASM。\n代码 引入 cglib 依赖\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003ecglib\u003c/groupId\u003e \u003cartifactId\u003ecglib\u003c/artifactId\u003e \u003cversion\u003e3.3.0\u003c/version\u003e \u003c/dependency\u003e 创建被代理类\n使用 CGLib 代理，被代理的类可以不实现任何接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * 金士顿，被代理类 * 注意：此处对比 JDK 的动态代理，Kingston 可以不实现任何接口 */ public class Kingston { /** * 销售内存条 */ public void sale() { System.out.println(\"销售 Kingston 内存条\"); } /** * 其他方法 */ public void other() { System.out.println(\"Kingston 执行 other 方法\"); } } 创建一个自定义的 MethodInterceptor，来添加对代理对象的方法进行增强，这里依旧记录方法的执行时间\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import net.sf.cglib.proxy.MethodInterceptor; import net.sf.cglib.proxy.MethodProxy; import java.lang.reflect.Method; /** * 统计运行时间的 MethodInterceptor */ public class ConsumeTimeMethodInterceptor implements MethodInterceptor { /** * 使用代理对象进行方法调用时，都会执行该方法 * * @param o CGLib 动态生成的代理对象 * @param method 当前代理对象调用的方法 * @param objects 方法的参数数组 * @param methodProxy 用于调用被代理对象的方法 * @return * @throws Throwable */ @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { // 在被代理对象的方法执行前记录开始时间 long start = System.currentTimeMillis(); /* 通过反射调用被代理对象的方法 CGLib 生成的代理对象是继承自被代理对象的，所以调用被代理对象的方法，需要使用 invokeSuper */ Object result = methodProxy.invokeSuper(o, objects); // 在被代理对象的方法执行后记录结束时间，并打印耗时 long end = System.currentTimeMillis(); System.out.println(method.getName() + \" 执行花费 \" + (end - start) / 1000.0 + \" 秒\"); // 被调用方法的返回值，如果方法返回值为 void，则返回 null return result; } } 测试主类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import net.sf.cglib.proxy.Enhancer; public class TestMain { public static void main(String[] args) { // 创建一个增强器 Enhancer enhancer = new Enhancer(); // 指定要生成代理类的父类 enhancer.setSuperclass(Kingston.class); // 设置代理类需要做的增强 enhancer.setCallback(new ConsumeTimeMethodInterceptor()); // 创建代理对象 Kingston kingston = (Kingston) enhancer.create(); // 通过代理对象调用被代理类的方法 kingston.sale(); kingston.other(); } } 类图和说明 创建任意需要被代理的类 创建 MethodInterceptor 接口的实现类，在其提供的 intercept 方法中，对被代理类的方法进行增强 使用 cglib 提供的 Enhancer 设置被代理类和对其进行的增强，通过 create 方法动态生成代理对象 通过生成的代理对象，调用被代理对象的方法 其他说明\n对代理类创建的增强类，只能实现 cglib 提供的 net.sf.cglib.proxy.Callback 接口的子接口 Enhancer 的 setCallback 方法支持传入 Callback 对象数组或者 CallbackFilter，所以可以对被代理对象进行链式增强 Spring AOP Spring AOP 是基于 AspectJ 来实现织入增强的，而 AspectJ 会动态选择使用 JDK 动态代理还是 CGLib 动态代理。\nSpring AOP 的使用参考：Spring 注解：AOP 功能测试\n","description":"","tags":["MSB","Design Pattern","Java"],"title":"代理模式（Proxy）","uri":"/posts/msb/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/proxy/"},{"categories":null,"content":"享元模式（Flyweight） 享元全称“共享元数据”，通过重复利用元数据对象，减少创建对象的数量，从而减少内存占用并提高系统性能。\n常见的使用场景：数据库连接池，字符串常量池，线程池等池化场景。\n代码 享元实体类（被共享的对象类）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 /** * 享元实体，需要被池化的对象 */ public class FlyweightEntity { /** * 享元实体自己的属性 */ private String name; /** * 用于标识当前对象是否正在使用 */ private boolean using = true; public String getName() { return name; } public void setName(String name) { this.name = name; } /** * 判断当前对象是否空闲 * * @return 如果没有被使用，返回 true，否则，返回 false */ public boolean isFree() { return !using; } /** * 设置当前对象为空闲状态 */ public void free() { using = false; } } 享元对象池，用于获取享元对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import java.util.ArrayList; import java.util.List; /** * 享元对象池 */ public class FlyweightPool { /** * 享元实体对象池 */ private List\u003cFlyweightEntity\u003e entities = new ArrayList\u003c\u003e(); /** * 返回没有被使用的享元实体 * * @return 没有被使用的享元实体 */ public FlyweightEntity getFlyweightEntity() { // 先尝试从缓存列表中返回一个空闲的对象 for (FlyweightEntity entity : entities) { if (entity.isFree()) { return entity; } } // 如果缓存中没有空闲的，则创建新对象返回，并添加到缓存中 FlyweightEntity entity = new FlyweightEntity(); entities.add(entity); return entity; } } 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class TestMain { public static void main(String[] args) { // 创建享元对象池 FlyweightPool flyweightPool = new FlyweightPool(); // 从池中获取享元对象 FlyweightEntity fE1 = flyweightPool.getFlyweightEntity(); fE1.setName(\"张三\"); // 释放该享元对象 fE1.free(); // 从池中获取享元对象 FlyweightEntity fE2 = flyweightPool.getFlyweightEntity(); fE2.setName(\"李四\"); // 两次获取的享元对象地址相同，说明享元对象被复用了 System.out.println(fE1 == fE2); } } 类图及说明 创建享元实体类，其中包含一个属性用来标识当前对象的状态，防止通过池子获取对象时，获取到其他地方正在使用的对象 创建享元池化类，包含一个集合（可以是列表/ Map 等）缓存享元实体对象；还有一个方法用来返回复用的享元对象 ","description":"","tags":["MSB","Design Pattern","Java"],"title":"享元模式（Flyweight）","uri":"/posts/msb/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/flyweight/"},{"categories":null,"content":"财务自由股票投资方法系列课程 股票是实现财务自由的三大核心工具之一\n“学习投资首先应该学会，除非有必要采取行动，否则什么都不要做，彻底不作为”\n“价值投资”\n财务自由股票投资方法并不是最赚钱的股票投资方法，也不是能让你快速在股市赚钱的投资方法，更不是让你成为股神的投资方法。它只是最容易实现财务自由的投资方法\n股票有国产的，合资的和外国的：A 股，港股，美股\n掌握投资方面的知识和技能就可以了\n股票是什么 股票是股份制公司为了筹集资金而发行的一种所有权凭证\n买股票就是买公司\n看起来好的公司不一定真好\n股东 持有股票的人就是股东。股东可以转让股票，但是不能退股\n股东的权利\n获得股息和红利的权利 -- 通过股票实现财务自由的基础 参加股东大会的权利 -- 小股东用不到 行使表决权 -- 小股东用不到 知情权 -- 上市公司需定期公布财务报表和重大事项 转让权 -- 获得价差收益（股民投资股票的核心原因，如果要实现财务自由，不能把该点作为核心原因） 股票市场 股票市场就是股票公开流通买卖的市场，也叫股市\n主要了解 A 股，港股，美股即可 三个股市市场的周期波动和结算货币不同，为我们进行资产配置提供了方便 A 股票 都是中国国内的公司，暂时不接受外国公司来中国上市\n港股\u0026美股 世界各地的上市公司，中国大陆的公司也可以\nA 股投资方法 A 股市场的主要风险 市场风险 -- 价格大幅下跌导致亏损的风险\n对于掌握了财务自由股票投资技能的人来说是机会\n风险化解方法：等待好价格\n财务造假风险 -- 上市公司财务造假导致亏损的风险\n风险化解方法：选出好公司\n退市风险 -- 上市公司连续亏损或财务造假被终止上市的风险\n风险化解方法：选出好公司\n投资 A 股的注意事项 不融资买股票，也不融券做空 远离烂公司和有造假嫌疑的公司 不进行短期炒作，只进行长期投资 远离大股东多次减持的公司 远离不派息或派息很少的公司 实现财务自由的股票投资方法 选出好公司 等待好价格 买进 长期持有 卖出 选出好公司 海选公司 盈利能力强\n选择好公司的第一个条件：连续 5 年 ROE 大于 15%~20%\n现金含量高\n选择好公司的第二条件：连续 5 年净现金含量大于 80%~100%\n安全性高\n选择好公司的第三个条件：连续 5 年毛利率大于 30%~40%\nROE = 销售净利率 x 总资产周转率 x 权益乘数\n销售净利率：主要和毛利率和费用率有关。\n在费用率一定的情况下，公司的销售净利率越高，公司毛利率越高。\n毛利率越高，公司产品的盈利能力越强\n总资产周转率：直接反映公司管理层的运营能力\n权益乘数：反映公司动用的债务杠杆的倍数\nROE 一定时，毛利率越高，公司越安全。\n总结：连续 5 年 ROE 大于 15%~20%，连续 5 年净现金含量大于 80%~100%，连续 5 年毛利率大于 30%~40%，上市大于 3 年\n精挑细选 连续 5 年的 ROE 中，平均值或最近 1 年的数值低于 20%的，淘汰掉\n连续 5 年的平均净利润现金含量低于 100%的，淘汰掉\n连续 5 年的毛利率中，平均值或最近 1 年的数值低于 40%的，淘汰掉\n连续 5 年的资产负债率中，平均值或最近 1 年的数值大于 60%的，淘汰掉\n连续 5 年的派息比率中，有 1 年或 1 年以上小于 25%的，淘汰掉\n派息比率：就是分红比率，也叫股息支付率\n派息比率=每股股息/每股收益 x100%=公司股息支付总额/公司净利润 x100%\n派息比率多年维持在 40%~70%的公司，是较好的公司 派息比率低于 25%的公司要么是能力不行要么就是不够厚道 派息比率高于 70%的公司一般不能持续，毕竟公司发展也需要钱 通过该方式选出好公司的前提是：公司的财务报表没有造假\n实践 i 问财搜索：A 股，连续 5 年 ROE 大于 15%，连续 5 年净现金含量大于 80%，连续 5 年毛利率大于 30%，上市大于 3 年\n可以的到 21 家公司\n把数据导入到 Excel\n用 ROE（净资产收益率），毛利率和净利润现金含量筛选公司，见精挑细选\nROE，毛利率，净利润现金含量通过 Excel 表格即可得到\n选出的公司：三七互娱，金达威，浙江美大，爱尔眼科，重庆啤酒，吉比特\n资产负债率\n访问：http://stockpage.10jqka.com.cn/股票代码/\n派息比率\n如果感觉数据有异常，可以通过其他途径（例如年报）了解 \u003e 选出的公司：金达威，浙江美大，爱尔眼科，吉比特 假设公司财务造假 之前做过一个假设：假设所有公司的财务数据都是真实的\n所以，现在需要假设公司财务造假\n仔细研究这 4 家公司多期的财报 只要有造假嫌疑（不用确定）的公司我们淘汰掉 等待好价格期间变坏的公司，依然要淘汰 2. 等待好价格 第一种方法：绝对估值法 一只股票内在价值 10 元 -\u003e 现价 5 元，那现在就是好价格。\n该方法想要取得好效果，关键是要能计算出股票的内在价值\n目前常用“自由现金流贴现模型”计算股票的内在价值\n自由现金流贴现模型原理：假设公司永久的经营下去，然后把未来产生的自由现金流贴现到今天，就得出了今天公司的价值\n原理简单，但是计算过程困难。因为再用这个模型计算一家公司的内在价值之前，我们需要先假设 3 个数据：未来自由现金流量的预测，折现率，未来自由现金流量的增长率。这 3 数据出现很小的变动，计算出来的内在价值就会差距很大\n实际上我们直接预测股价反而比预测这 3 个数据来的容易，所以不推荐用。巴菲特在用，所以提一下。\n第二种方法：市盈率和股息率法 市盈率 简称 PE，是用来评估股票水平是否合理的指标之一。我们主要看 TTM 市盈率\n计算公式\n静态市盈率=股票现价/上年度每股收益 TTM 市盈率（动态市盈率）=股票现价/过去四个季度的每股收益 市盈率还表示，如果公司目前的盈利能力保持不变，并且每年把净利润全部分红，我们通过分红收回本金的年限.\n投资 100 万，市盈率为 10 --\u003e 假设年净利润 100%分配，通过分红收回 100 万就需要 10 年的时间 投资 100 万，市盈率为 50 --\u003e 假设年净利润 100%分配，通过分红收回 100 万就需要 50 年的时间 查看沪深 A 股的市盈率：http://value500.com/PE.asp 或 https://www.legulegu.com/stockdata/market_pe\n通过深证 A 股市盈率走势图和深证成指的历史走势图，我们可以看到\n深证 A 股市盈率主要在 20~60 之间波动，40 是中间值\n当市盈率小于 20 的时候，股市就会见底然后开始上涨\n当市盈率大于 60 的时候，股市就会见顶然后开始下跌\n当市盈率在 40 左右的时候，股市后期涨跌都有可能\n当深证 A 股的市盈率在 40 左右时，代表 A 股的价格和价值整体相符，这时候投资价值不大；当深证 A 股的市盈率在 20 左右或小于 20 的时候，代表 A 股的价格大幅低于价值，此时投资价值很大，这是的价格就是好价格，可以大胆买进；当深证 A 股的市盈率在 60 左右或大于 60 的时候，代表 A 股的价格已经高于价值，这是投资风险很大，不能买进，只能卖出。\n以上数据反映的是整个股市的情况。具体到某只股票还需要结合其自身情况来看。\n对于好公司来讲，其价格一般情况下是不便宜的，只有在股市整体大跌的时候，好公司才有可能出现好价格，这是由于市场上的投资者恐慌性卖出导致的，这恰恰是高明投资者的机会\n当深证 A 股的市盈率小于 20 且目标公司股票的 TTM 市盈率小于 15 的时候，就是好价格 出现好价格的时机：深证 A 股的市盈率\u003c20 的时候 出不出现好价格是由市场决定的，能不能选出好公司是由我们自己的能力决定的\n一定要有足够的耐心 条件不符合标准时 -\u003e 等待 条件符合标准时 -\u003e 勇敢的买进 股票知识我们实现财务自由的一个工具而已\n股息率 股息率是股息与股票价格之间的比率\n计算公式\n实际股息率=每年股息的税后净额/股票买入价 x100% 动态股息率=上年度股息税后净额/股票市价 x100% 实际股息率与动态股息率的作用\n实际股息率主要在我们持有股票的时候用 动态股息率主要在我们买卖股票的时候用 示例\n某公司每年每股的现金分红是 1 元\n小白：以 20 元/股的价格购买 --\u003e 股息率为：1/20x100%=5%\n投资 100 万，每年有 5 万元的分红收入\n小黑：以 10 元/股的价格购买 --\u003e 股息率为：1/10x100%=10%\n投资 100 万，每年有 10 万元的分红收入\n在投资实践中，股息率是衡量公司是否具有投资价值的重要标尺之一\n从实现财务自由的角度来看，股息率才是最重要的\n我们选择好公司最主要的原因就是为了能持续的获得比较稳定的现金分红，其次才是获得价格增值\n我们以低市盈率买进，是为了能获得比较高的股息率\n动态股息率大于多少的股票才能买进呢?\n一家好公司的动态股息率\u003e10 年期国债收益率，即可买进。如果不是好公司，即使动态股息率符合标准，也不能买。\n总结 深证 A 股额市盈率小于 20 且目标公司股票的 TTM 市盈率小于 15 动态股息率大于 10 年期国债收益率 该投资目标是从财务自由的角度出发制定的，所以也可能错过一些比较牛逼的公司\n实践 计算动态股息率 计算动态股息率\n假设好价格是 M，公司每股分红 0.4 元，每股股息税 10%（2015 年后持有 1 年以上没有股息税）\n所以每股股息税后净额是：0.4x(1-10%)=0.36 元\n假如未来股息保持不变，以 X 元的价格买进，未来的股息率=0.36/Mx100%\u003e10 年期国债收益率\n可以算出好价格 M\u003c每股股息税后净额/十年期国债收益率\n事实上，好公司的股息未来很可能是增加的，未来实际的股息率很可能大于 5.1%\n查看 10 年期国债收益率\n如果动态股息率\u003e10 年期国债收益率，即可购买\n计算市盈率 查看深证/沪证 A 股的市盈率\n如果深证市盈率小于 20%，即可能出现好价格\n查看某个股票的 TTM 动态市盈率，如果小于 15%，假设好价格是 X\n好价格计算：\nTTM 市盈率 = X/每股收益，所以好价格 X=15x 每股收益\n我们知道 TTM 市盈率=股价/每股收益，所以每股收益=目前股价/目前 TTM 市盈率\n所以好价格 X=15x 目前股价/目前 TTM 市盈率\n注意事项\n我们判断一只股票能不能买进的时候，没有关于这只股票或者股市未来是涨还是跌的任何猜测。只有计算和对比。实现财务自由的股票投资方法全是计算和对比。\n无论何时我们是否要买进一只股票的依据取决于计算结果\n不预测，只计算\n3. 买进 我们最终的投资收益不但取决于我们能不能选出好公司，分辨出好价格。更重要的是我们在好价格，买进了多少好公司的股票。\n买进技巧 一般把投资股票的资金平分成三份，买进 3-5 只目标股\n投资资金 \u003c 1 亿元 --\u003e 选择\u003c=5 只股票 投资资金 \u003e 1 亿元 --\u003e 选择\u003c10 只股票 当市盈率和股息率符合条件时 --\u003e 买进三分之一\n目标股下跌 5%-10%时 --\u003e 再买进三分之一\n目标股再下跌 5%-10%时 --\u003e 再买进三分之一\n4. 长期持有 当我们把资金都买成目标股以后，我们要做的就是长期持有，可能是 3 年，5 年，10 年，也可能更久\n持有期间进本不需要看行情走势 只要每年读一下目标公司的财务报表 查收一下每年的现金股息分红 如果实在忍不住看股票的走势，那就每年看一两次 5. 卖出 第一种情况：市盈率过高的时候 所持有股票市盈率\u003e50 倍，卖出\n此时深证 A 股的市盈率也在 60 左右或已大于 60，更要卖出\n第二种情况：动态股息率过低的时候 比如说小白 2012 年以 7 元每股买进了服药玻璃\n一直持有到 2017 年还没有卖出\n在 2017/5/15 号获得 2016 年度的现金分红，每股股息：0.75 元\n2017 年获得的 2016 年的实际股息率为：0.75/7x100%=11%\n动态股息率=0.75/26.16x100%=2.9%\u003c3.6%，动态股息率小于 10 年期国债收益率，说明服药玻璃的持有价值在减小\n在实践中，当动态股息率小于 10 年期国债收益率的三分之一时候，封老师会卖掉\n这个时候卖掉，后期有机会在股价更低的时候买回来\n第三种情况：好公司有变坏迹象的时候 每年读持股公司的财报，发现有变坏迹象的时候卖出。\n不能等公司明显变坏时才卖出，因为股价早已下跌很多\n好公司变坏的迹象：是指公司本身素质发生变化。比如：公司核心竞争力在变弱等。\n而不是因行业突发性利空时间导致的短期或中期负面影响。例如：乳品行业，白酒行业都层因外部突发事件经历过较大调整，但是行业不会消失，行业中的好公司的核心竞争力没有变弱，这种情况反倒是给了高明的投资者一个好的买入机会\n美股投资方法 美股投资的主要风险 市场风险：价格大幅下跌导致亏损的风险\n对于掌握了财务自由股票投资技能的人来说是机会\n风险化解方法：在好价格买进\n财务造假的风险：上市公司财务造假导致亏损的风险\n风险化解方法：选择好公司\n退市的风险：上市公司不再符合上市条件而被终止上市的风险\n风险化解方法：选择好公司\n1995 年至 2005 年十年间，美国三大股市共有 9273 家公司退市。\n十年间，纽约证交所（NYSE）退市 1906 家；NASDAQ 退市 6257 家；美国交易所（AMEX）退市 1010 家。\n其中，一半自愿退市（主要是私有化）；另一半是被迫退市\n私有化带来的风险：私有化成功，公司退市，高位买入被套就没有回本的机会\n风险化解方法：在好价格买进\n券商破产的风险：因券商破产导致股票或资金损失的可能\n风险化解方法：至选择由 SIPC（美国证券投资者保护公司）承保的美股券商\n投资美股的注意事项 不融资买股票，也不融券做空 不进行短期炒作，只进行长期投资 远离烂公司和有造假嫌疑的公司 远离大股东多次减持的公司 远离不派息或派息很少的公司 远离被做空机构质疑的公司 不申购新股 实现财务自由的美股投资方法 选出好公司 等待好价格 买进 长期持有 卖出 选出好公司 海选公司\n打开 同花顺问财，搜索：美股，连续5年ROE大于15%，连续5年毛利率大于40%，连续5年经营活动净现金流量除以净利润大于80%，资产负债率小于60%，市值大于50亿\n精挑细选\n连续 5 年的 ROE 中，平均值或最近 1 年的数值低于 20% 的，淘汰掉 连续 5 年的平均净利润现金含量低于 100% 的，淘汰掉 连续 5 年的派息比率中，互联网高科技类公司有 1 年或 1 年以上小于 20% 的（该类公司不喜欢分红，分 20% 已经很厚道），淘汰掉 连续 5 年的派息比率中，非互联网高科技类公司有 1 年或 1 年以上小于 30% 的（该类公司有分红传统，派息比率自然要高一些，可以选 40%-70% 之间的公司），淘汰掉 中国和美国以外的公司，淘汰掉 实践\n使用 雪球，以 NVDA 为例，\n股息(TTM)：表示英伟达最近 4 个季度的股息发放为 0.16 美元\n股息率(TTM)：股息(TTM) / 当前股价 x 100%。0.16/437.53x100%=0.04%\n派息比率（股息支付率）：动态关键指标 -\u003e 股息支付率（入口没了，TODO）\n假设公司财务造假\n之前做过一个假设：假设所有公司的财务数据都是真实的\n所以，现在需要假设公司财务造假\n仔细研究这些公司多期的财报 只要有造假嫌疑（不用确定）的公司我们淘汰掉 等待好价格期间变坏的公司，依然要淘汰 等待好价格 好价格确定方法：根据市盈率和股息率\n查看标普500指数市盈率：www.multpl.com\n标普 500 指数的市盈率主要波动区间为 10-20，当市盈率小于 10 时，美股低估，投资价值大，后期会上涨；当市盈率大于 20 时，美股高估，后期会下跌\n在 2000 年后，标普 500 市盈率波动区间上移，最低为 15 左右，与 2000 年后美联储的超低利率导致的。\n2000 年后美联储利率没超过过 6%，6% 才应该是正常水平。\n若利率长期维持在在 0 附近，则美股合理估值区间难回 10-20 倍市盈率之间；若利率难以长期维持在 0 附近，重回 6% 正常水平，则美股合理估值区间必回 10-20 倍市盈率之间\n好价格的市盈率标准：\n标普 500 指数的市盈率小于 10 且目标公司股票的动态市盈率（ttm）小于 15 或者 标普 500 指数跌幅大于 50%（最高点到最低点）且目标公司股票的动态市盈率（ttm）小于 15（在标普 500 没有回归到 10-20 正常区间时可以用该标准） 好价格股息率的标准：\n动态股息率大于 美国 10 年国债收益率\n动态股息率计算：$每股股息0.9/每股股价100%$\n0.9 是因为中国投资者会被扣 10% 的股息红利税\n买进 同时满足市盈率和股息率标准\n长期持有 卖出 符合任意一种卖出：\n动态市盈率大于 40，如果此时标普 500 指数的市盈率也已经大于 20，更要卖出 动态股息率过低的时候（当动态股息率小于美国 10 年期国债收益率的 1/3 时，卖掉） 好公司有变坏迹象（详细查看财务报表） ","description":"","tags":["Financial","WeiMiao"],"title":"财务自由股票投资方法系列课程","uri":"/posts/financial/%E5%BE%AE%E6%B7%BC/%E8%B4%A2%E5%8A%A1%E8%87%AA%E7%94%B1%E8%82%A1%E7%A5%A8%E6%8A%95%E8%B5%84%E6%96%B9%E6%B3%95%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B/"},{"categories":null,"content":"财务自由系统操作课 - 哲学课和基础课 实现财务自由的十大步骤 为什么要实现财务自由 我自己的财务自由目标 我选择的实现财务自由的路径是 我需要掌握的核心技能 我打算怎么学习实现财务自由的技能 财务自由词汇 财务自由\n标准：家庭非工资收入\u003e正常的生活总支出\n家庭非工资收入：股息收入，房租收入，REITs 分红收入，股权分红\n通常投资收入要占家庭总收入的 80%以上\n生钱资产\n能够持续给你带来净现金流入的东西\n耗钱资产\n能够持续给你带来净现金流出的东西\n其他资产\n即不能带来持续的净现金流入，也不能带来持续的净现金流出的东西\n资产\n你拥有或能控制的能够以货币计价的东西\n财商\n识别生钱资产，耗钱资产，其他资产并能获取生钱资产的能力\n净现金流\n某一个东西在一段时间内（通常是每月或每年）发生的现金流入和流出的差额.\n现金流入 - 现金流出 \u003e 0；净现金流为正\n现金流入 - 现金流出 \u003c 0；净现金流为负\n净现金流的方向就是一切。净现金流的方向决定一个东西是“生钱资产”还是“耗钱资产”\n负债\n借来的未来需要偿还的东西\n负债购买生钱资产，能够带来持续的正现金流入，就是好负债\n负债购买耗钱资产，带来了持续的现金流出，就是坏负债\n财务报表\n公司，家庭，个人财务方面的 B 超图，能够反映相关主体的财务健康状况\n收入\n个人收入包括现金收入和账面收入。\n现金收入：工资，股息，房租，公司股权分红等，有较强的确定性，是实现财务自由的重点\n账面收入：股票，房子上涨带来的账面收入，有较强的不确定性，不是重点\n支出\n你的支出会减少你的钱而增加别人的钱\n购买“生钱资产”的支出是好支出\n购买“耗钱资产”的支出是坏支出\n利率\n资金使用的成本\n利息\n资金的使用成本。利息收入是投资收入的一种，收益率一般比较低\n利息 = 本金 * 利率\n股息\n上市公司给股票投资者的现金分红。股息收入是实现财务自由的主要收入之一\n一般公司利润好就分的多，公司亏损就不分。\nREITs 分红收入\n持有 REITs 定期获得的分红收入。投资 REITs 就是间接投资房地产。REITs 分红收入是实现财务自由的主要收入之一\n美国 REITs 每季度或每月分红一次\n香港 REITs 没半年分红一次\n和股息不同，法律强制 REITs 每年必须把不低于 90%的应税收入分配给投资者\n房租收入\n把房子租给别人获得的收入。净租金收入是实现财务自由的主要收入之一\n净租金收入 = 房租收入 - 房子发生的总支出\n账面收益\n资产市场价大于买入成本价，只有卖掉以后账面收益才能转化成真实收益\n投资\n根据投资计划投入资金买卖“生钱资产”的行为\n投资计划\n包括投资目标，投资期限，投资金额，投资工具，买入标准，卖出标准等，有没有投资计划是投资和投机的关键区别之一\n投资者\n根据投资计划买卖“生钱资产”的人\n投机\n投入资金赚差价的行为。投机 = 赌博\n投机者\n投入资金赚差价的人。投机者是赌徒在投资领域的专用称呼\n炒股\n炒=火+少，炒的意思是在火上烤并且越来越少。炒股就是通过买股票让自己是在火上烤并且钱越来越少的行为\n炒房\n炒房就是通过买房让自己是在火上烤并且钱越来越少的行为\n企业家\n成功的创造了一家具有强大系统公司的人\n有钱人\n资产规模大的人\n富人\n持有“生钱资产”的规模大于总资产 80%的人\n穷人\n资产规模很小或没有资产的人\n有钱的穷人\n资产规模大但生钱资产占比小于 30%的人\n没钱的富人\n掌握了获取生钱资产的技能，但是还没有钱的人\n风险\n收益的不确定性和本金损失的可能性\n投资有风险：投机有风险，投资无风险\n货币\n通常被叫做“钱”，是交易的媒介。现代货币基本都是信用货币，也叫法币。\n现代货币的本质是央行发行的债券，他是央行的负债\n货币就是政府的负债，政府有信用货币就有价值，政府没信用货币就没有价值\n政府的信用靠财政（税收）来保障，一旦税收没有保障，或者税收增长的速度远低于货币增长的速度，政府就可能失去信用\n没有价值的货币称为劣币，“生钱资产”是良币，要把劣比换成良币。\n良币驱逐劣币：当市场上同时存在劣币和良币的时候，一段时间后良币将被聪明人给保存起来，从而退出市场，市场上留下来的都是劣币。\n我们在现实生活中发现，“生钱资产”基本都在富人手里，穷人手中主要是存款，也就是劣币。所以富人越来越富，穷人越来越穷\n外币\n指本国货币以外的其他国家或地区的货币\n目前国际储备货币有：美元，欧元，日元，英镑，瑞士法郎，澳元，加元，人民币。这些外币有较强的安全性和稳定性，世界范围内认可度比较高\n汇率\n一种货币换另一种货币的比率\n时间\n每个人最重要的资源，也是最公平的资源\n财务自由的目的就是为了获得更多的可自由支配的时间\n财务自由的重点不是财务而是时间\n复利\n在拿到利息后继续把利息投资，就是俗称的利滚利\n$S = p(1+i)^n$\n有价证券\n证明持有人拥有某种收益权利的凭证\n有价证券可以带来股息或利息\n股票是有价证券的一种\n债券也是有价证券的一种\n股票\n股份公司发行的所有权凭证\n股票持有人是股份公司的所有者，拥有相应的权利，比如参加股东大会，股票表决，收取分红等。通常持有股票数低于总股数 5%的所有者只有分红的权利\nREITs\n房地产投资信托资金\n是一种房地产资产证券化的工具\n为了降低房地产的投资成本\nREITs 90%左右的收入来自房地产，持有 REITs 相当于间接持有房地产\n债券\n标准化的借条。借款人主要是政府，银行，大公司，风险和收益都很小\n抵押贷款\n把财产抵押给别人向别人借钱。如果到期不能偿还本息，别人就可以处置财产\n还钱不容易，借钱须谨慎\n企业\n以盈利为目的的法人或非法人组织。\n法人\n就相当于你在法律层面上复制了一个虚构的你，但是在法律层面上这个虚构的你可以帮你行使权利和承担责任。只可以承担民事责任，不能承担刑事责任\n法人主要包括：有限责任公司和股份有限公司\n非法人\n非法人不能独立承担民事责任，也就是不能隔离你的风险，但是一般有税收上的优惠\n非法人主要包括：个人独资企业，合伙企业，企业的分支机构（分公司，办事处，代表处）等等\n公司\n以盈利为目的的法人企业\n公司股权的分红收入也是实现财务自由的主要收入之一\n股市\n股票集中交易的市场。本质就是合法的把投机者的钱变成投资者，上市公司和政府的钱的地方\n投资者赚取股利和价差\n上市公司可以增发获利\n政府获得税收\n楼市\n房地产交易的市场。本质就是合法的把投机者的钱变成投资者，房产中介和政府的钱的地方\n投资者获得房租和差价\n房产中介获得佣金\n银行获得利息\n政府获得税收\n税收\n政府凭借权利强行征收的钱。可以简单理解成政府收的保护费。\n当然，政府会把部分收入取之于民而用之于民\n政府通常还会用税收的手段来鼓励或者抑制某种投资行为\n聪明的投资者哦都会利用政府的税收优惠政策为自己合法的增加收入\n通过财务报表读懂家庭 家庭的财务状态分为：财务危机，财务安全，财务自由，每个家庭必然属于其中的一种。\n下方三种情况是比较安全的，否则家庭的财务状况就是不安全的\n生钱资产形成的负债/总负债 \u003e80% 且家庭资产负债率 \u003c70% 生钱资产形成的负债/总负债 \u003c80% 且家庭资产负债率 \u003c50% 生钱资产形成的负债/总负债 \u003c20% 且家庭资产负债率 \u003c30% 总资产 - 总负债 = 净资产\n通过财务报表读懂人生 ","description":"","tags":["Financial","WeiMiao"],"title":"财务自由系统操作课 - 哲学课和基础课","uri":"/posts/financial/%E5%BE%AE%E6%B7%BC/%E8%B4%A2%E5%8A%A1%E8%87%AA%E7%94%B1%E7%B3%BB%E7%BB%9F%E6%93%8D%E4%BD%9C%E8%AF%BE-%E5%93%B2%E5%AD%A6%E8%AF%BE%E5%92%8C%E5%9F%BA%E7%A1%80%E8%AF%BE/"},{"categories":null,"content":"微淼目录 财务自由系统操作课 - 哲学课和基础课 财务自由股票投资方法系列课程 ","description":"","tags":["Financial","WeiMiao"],"title":"微淼目录","uri":"/posts/financial/%E5%BE%AE%E6%B7%BC/weimiao-table/"},{"categories":null,"content":"组合模式（Composite） 组合模式也叫部分-整体模式。用于处理树状结构（例如：目录树，菜单树，组织架构树）。\n树状结构包含树枝和树叶，树枝下可以包含树枝和树叶。\n以组织架构树为例，部门就是树枝，人员就是树叶，部门中可以包含子部门和人员\n透明模式 通常，对于树枝节点，都包含 add，remove，getChild 等方法来对其子节点进行操作；而叶子节点是没有这些操作的。透明模式就是将这些方法都放在它们共同的接口中，此时直接通过接口即可调用这些方法。\n代码 组织（公共接口）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import java.util.List; /** * 组织接口，是部门和员工的父接口。 * 透明模式：将 add，remove，getChild 方法放在了父接口中 */ public interface Organization { /** * 添加子组织 * * @param organization 组织（部门/员工） */ void add(Organization organization); /** * 移除子组织 * * @param organization 组织（部门/员工） */ void remove(Organization organization); /** * 获取所有子节点 * * @return 子节点集合 */ List\u003cOrganization\u003e getChild(); /** * 打印 */ void print(); } 部门（树枝）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 import java.util.ArrayList; import java.util.List; import java.util.Objects; import static java.lang.System.out; /** * 部门（树枝） */ public class Department implements Organization { /** * 部门名称 */ private String name; /** * 层级 */ private Integer level; /** * 部门下的组织（包含子部门和员工） */ private List\u003cOrganization\u003e organizations; public Department(String name) { this.name = name; this.organizations = new ArrayList\u003c\u003e(); } @Override public void add(Organization organization) { organizations.add(organization); } @Override public void remove(Organization organization) { organizations.remove(organization); } @Override public List\u003cOrganization\u003e getChild() { return this.organizations; } @Override public void print() { if (Objects.isNull(this.level)) { this.level = 0; out.println(this.name + \"【\" + this.level + \"】\"); } for (Organization organization : this.organizations) { if (organization instanceof Department) { Department department = (Department) organization; department.level = this.level + 1; for (int i = 0; i \u003c department.level; i++) { out.print(\" \"); } out.println(department.name + \"【\" + department.level + \"】\"); } else { for (int i = 0; i \u003c this.level + 1; i++) { out.print(\" \"); } } organization.print(); } } } 员工（树叶）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 import java.util.List; import static java.lang.System.out; /** * 员工（树叶） * 因为此时使用的是透明模式，所以树叶中的 add，remove，getChild 方法可以抛出异常或者作为空方法 */ public class Employee implements Organization { /** * 员工姓名 */ private String name; /** * 员工年龄 */ private Integer age; public Employee(String name, Integer age) { this.name = name; this.age = age; } @Override public void add(Organization organization) { throw new UnsupportedOperationException(\"不支持添加子节点\"); } @Override public void remove(Organization organization) { throw new UnsupportedOperationException(\"不支持移除子节点\"); } @Override public List\u003cOrganization\u003e getChild() { throw new UnsupportedOperationException(\"不支持获取子节点\"); } @Override public void print() { out.println(this.name + \"（\" + this.age + \"）\"); } } 类图和说明 创建树枝和树叶的公共接口，通常包含 add，remove，getChild 方法 创建树枝类，包含存储其子节点的列表 创建树叶类，它里面的 add，remove，geteChild 方法可以抛出异常或做空实现 应用程序在调用的时候，可以完全使用公共接口进行调用 如需扩展，只需要实现公共接口，然后维护好各个对象间部分-整体的关系即可 安全模式 因为 add，remove，getChild 方法只有树枝才有，所以在安全模式中，将这些方法放在了具体的树枝类中。这样当应用程序调用时，就需要手动判断当前对象的类型（是树枝还是树叶），然后调用各自的方法。\n代码 组织（公共接口）\n1 2 3 4 5 6 7 8 9 10 11 /** * 组织接口，是部门和员工的父接口。 * 安全模式：将 add，remove，getChild 方法放在了具体的树枝中 */ public interface Organization { /** * 打印 */ void print(); } 部门（树枝）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 import java.util.ArrayList; import java.util.List; import java.util.Objects; import static java.lang.System.out; /** * 部门（树枝） */ public class Department implements Organization { /** * 部门名称 */ private String name; /** * 层级 */ private Integer level; /** * 部门下的组织（包含子部门和员工） */ private List\u003cOrganization\u003e organizations; public Department(String name) { this.name = name; this.organizations = new ArrayList\u003c\u003e(); } public void add(Organization organization) { organizations.add(organization); } public void remove(Organization organization) { organizations.remove(organization); } public List\u003cOrganization\u003e getChild() { return this.organizations; } @Override public void print() { if (Objects.isNull(this.level)) { this.level = 0; out.println(this.name + \"【\" + this.level + \"】\"); } for (Organization organization : this.organizations) { if (organization instanceof Department) { Department department = (Department) organization; department.level = this.level + 1; for (int i = 0; i \u003c department.level; i++) { out.print(\" \"); } out.println(department.name + \"【\" + department.level + \"】\"); } else { for (int i = 0; i \u003c this.level + 1; i++) { out.print(\" \"); } } organization.print(); } } } 员工（树叶）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import static java.lang.System.out; /** * 员工（树叶） * 安全模式中，对子节点的操作在具体的树枝中，所以树叶中不用再重写那些方法 */ public class Employee implements Organization { /** * 员工姓名 */ private String name; /** * 员工年龄 */ private Integer age; public Employee(String name, Integer age) { this.name = name; this.age = age; } @Override public void print() { out.println(this.name + \"（\" + this.age + \"）\"); } } 类图和说明 创建公共接口，因为使用安全模式，所以公共接口中不再包含 add，remove，getChild 方法 创建树枝，包含存储其子节点的列表，以及对该列表进行操作的方法 创建树叶，不再需要包含多余的方法 应用程序在调用时，需要区分对象是树枝还是树叶，从而调用不同的方法 如需扩展，只需要实现公共接口，然后维护好各个对象间部分-整体的关系即可 ","description":"","tags":["MSB","Design Pattern","Java"],"title":"组合模式（Composite）","uri":"/posts/msb/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/composite/"},{"categories":null,"content":"Jmeter 简单压测 HTTP 接口 右键点击 Test Plan，新建一个 Thread Group\n设置请求数和时间区间\n右键点击 Thread Group，新建一个 HTTP Request\n设置接口信息，请求参数等信息，然后点击 Start 启动测试即可\n其他 请求参数中使用随机数：使用${__Random(1,100,)}，即可生成 [1,100] 范围内的随机数\n","description":"","tags":["Java","JMeter"],"title":"Jmeter 简单压测 HTTP 接口","uri":"/posts/java/jmeter-test-http-interface/"},{"categories":null,"content":"SpringBoot 自定义注解在 Service 层对入参进行验证 自定义注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package icu.intelli.annotation; import java.lang.annotation.*; /** * 自定义对 Service 层的入参进行验证的注解 * * @author wangshuo */ @Target({ElementType.TYPE, ElementType.METHOD, ElementType.PARAMETER}) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface ServiceParamValidate { } 校验注解的切面类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 package icu.intelli.aspect; import icu.intelli.annotation.ServiceParamValidate; import org.apache.commons.lang3.StringUtils; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.annotation.Pointcut; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import javax.validation.ConstraintViolation; import javax.validation.Validator; import java.lang.annotation.Annotation; import java.lang.reflect.Method; import java.util.Iterator; import java.util.Objects; import java.util.Set; /** * 使用切面，在 Service 层对参数进行校验 * * @author wangshuo */ @Component @Aspect public class ServiceParamValidateAspect { @Autowired private Validator validator; /** * 对 service 包下以 Service 结尾的类的所有方法进行拦截 */ @Pointcut(\"execution(* icu.intelli.service.*Service.*(..))\") public void pointCut() { } /** * 在执行方法前对方法参数进行校验 * * @param joinPoint 切点 */ @Before(\"pointCut()\") public void doBefore(JoinPoint joinPoint) { // 获取方法参数 Object[] args = joinPoint.getArgs(); // 如果没有参数，不需要验证 if (args.length == 0) { return; } // 获取类信息 Class\u003c?\u003e clazz = joinPoint.getTarget().getClass(); ServiceParamValidate classAnnotation = clazz.getAnnotation(ServiceParamValidate.class); // 获取方法签名信息 MethodSignature signature = (MethodSignature) joinPoint.getSignature(); Method method = signature.getMethod(); ServiceParamValidate methodAnnotation = method.getAnnotation(ServiceParamValidate.class); // 类上或者方法上只要有一个包含 @ServiceValidated，就对方法的所有参数都进行验证 boolean hasGlobalAnnotation = Objects.nonNull(classAnnotation) || Objects.nonNull(methodAnnotation); // 如果包含全局范围的注解，就对方法的所有参数进行校验；否则只对标有注解的参数进行校验 if (hasGlobalAnnotation) { for (Object arg : args) { validate(arg); } } else { // 一维是参数，二维是注解 Annotation[][] annotations = method.getParameterAnnotations(); for (int i = 0; i \u003c annotations.length; i++) { Object arg = args[i]; Annotation[] annotation = annotations[i]; for (Annotation anno : annotation) { if (ServiceParamValidate.class.isAssignableFrom(anno.annotationType())) { validate(arg); } } } } } /** * Java Bean 数据校验 * 如果参数不符合要求，可通过抛出自定义异常，然后在全局异常处理中进行拦截进行处理 * * @param target 需要被校验的 Bean * @author wangshuo */ private \u003cT\u003e void validate(T target) { // 不能对 null 对象进行验证 if (Objects.isNull(target)) { return; } Set\u003cConstraintViolation\u003cT\u003e\u003e constraintViolations = validator.validate(target); Iterator\u003cConstraintViolation\u003cT\u003e\u003e iterator = constraintViolations.iterator(); StringBuilder message = new StringBuilder(); while (iterator.hasNext()) { ConstraintViolation\u003cT\u003e error = iterator.next(); message.append(\"[\") .append(error.getPropertyPath().toString()) .append(\"]\") .append(error.getMessage()); } if (StringUtils.isNotBlank((message))) { throw new RuntimeException(message.toString()); } } } ","description":"","tags":["JAVA","Spring Boot"],"title":"SpringBoot 自定义注解在 Service 层对入参进行验证","uri":"/posts/spring-boot/springboot-service-validation/"},{"categories":null,"content":"使用 InheritableThreadLocal 在父子线程间共享数据 使用示例 InheritableThreadLocalUtil 工具类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class InheritableThreadLocalUtil { private InheritableThreadLocalUtil() { } private static final ThreadLocal\u003cObject\u003e THREAD_LOCAL = new InheritableThreadLocal\u003c\u003e(); public static Object get() { return THREAD_LOCAL.get(); } public static void set(Object obj) { THREAD_LOCAL.set(obj); } public static void remove() { THREAD_LOCAL.remove(); } } 测试主类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class ThreadMain { public static void main(String[] args) { // 主线程中使用 InheritableThreadLocal 设置了变量 \"666\"，希望传递给子线程使用 InheritableThreadLocalUtil.set(\"666\"); // 创建并启动子线程 new Thread(() -\u003e { // 子线程可以通过 get() 方法获取父线程中设置的变量 Object val = InheritableThreadLocalUtil.get(); System.out.println(val); // 移除子类中的共享变量，让垃圾回收器可以进行回收 InheritableThreadLocalUtil.remove(); }).start(); // 移除父类中的共享变量，让垃圾回收器可以进行回收 InheritableThreadLocalUtil.remove(); } } InheritableThreadLocal 源码分析 InheritableThreadLocal 继承自 ThreadLocal，并重写了三个方法\n1 2 3 4 5 6 7 8 9 10 11 public class InheritableThreadLocal\u003cT\u003e extends ThreadLocal\u003cT\u003e { protected T childValue(T parentValue) { return parentValue; } ThreadLocalMap getMap(Thread t) { return t.inheritableThreadLocals; } void createMap(Thread t, T firstValue) { t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue); } } 在 Thread 类中包含了两个 ThreadLocalMap 类型的变量：threadLocals 和 inheritableThreadLocals。可以将 ThreadLocalMap 看作 Map。\n1 2 3 4 public class Thread implements Runnable { ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; } 在调用 InheritableThreadLocal 的 set() 方法时，会调用其父类 ThreadLocal 的 set() 方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class ThreadLocal\u003cT\u003e { public void set(T value) { // 获取当前线程，即父线程 Thread t = Thread.currentThread(); // InheritableThreadLocal 重写了 getMap 方法，返回的是 Thread 类中的 inheritableThreadLocals 属性 ThreadLocalMap map = getMap(t); if (map != null) // 这里将当前 InheritableThreadLocal 对象作为 key，需要共享给子线程的变量作为 value 设置到父线程的 inheritableThreadLocals 属性中 map.set(this, value); else // InheritableThreadLocal 重写了 createMap 方法，就是给当前线程的 inheritableThreadLocals 属性赋值，并设置共享变量 createMap(t, value); } } 在调用 Thread 的构造方法时，都会调用他的 init() 方法\n1 2 3 4 5 6 7 8 9 10 11 private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) { // 获取当前线程，即父线程 Thread parent = currentThread(); // 入参 inheritThreadLocals 默认是 true。父线程的 inheritableThreadLocals 不是空说明要共享变量给子线程 if (inheritThreadLocals \u0026\u0026 parent.inheritableThreadLocals != null) // 创建一个新的 ThreadLocalMap，将父线程 inheritableThreadLocals 属性中的值都添加到这个新的 ThreadLocalMap 中，并将这个 ThreadLocalMap 赋值给子线程的 inheritableThreadLocals 属性 this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); } 当在子线程中调用 InheritableThreadLocal 的 get() 方法时候，即可从自己的 inheritableThreadLocals 属性中，获取父线程共享的变量\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class ThreadLocal\u003cT\u003e { public T get() { // 当前线程，即子线程 Thread t = Thread.currentThread(); // InheritableThreadLocal 重写了 getMap 方法，返回的是 Thread 类中的 inheritableThreadLocals 属性 ThreadLocalMap map = getMap(t); if (map != null) { // 从 inheritableThreadLocals 中根据 key 来获取值 ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; } } // 初始值就是 null return setInitialValue(); } } InheritableThreadLocal 不使用于线程池场景 InheritableThreadLocal 在新建线程时，将父线程的数据共享给子线程。而在使用线程池后，由于线程池是提前创建了一些线程，所以不能通过 InheritableThreadLocal 来共享数据。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 private static void testInheritableThreadLocal() { // 创建线程池 ExecutorService threadPool = Executors.newCachedThreadPool(); // 父线程要将变量共享给线程池创建的线程 InheritableThreadLocalUtil.set(\"666\"); // 调大 i 的边界，可以更容易看到 null 值 for (int i = 0; i \u003c 10; i++) { threadPool.execute(() -\u003e { // 在子线程中获取父线程的共享变量 Object val = InheritableThreadLocalUtil.get(); if (Objects.isNull(val)) { // 由于 InheritableThreadLocal 不能达到该需求，所以会出现获取到的变量为 null System.out.println(val); } // 移除新线程中的共享变量，让垃圾回收器可以进行回收 InheritableThreadLocalUtil.remove(); }); } // 任务都执行结束后，关闭线程池 threadPool.shutdown(); // 移除父线程中的共享变量，让垃圾回收器可以进行回收 InheritableThreadLocalUtil.remove(); } 由于 InheritableThreadLocal 不能完成将父线程中的变量共享给线程池创建的线程的需求，所以会出现子线程获取到的变量为 null。可参考 线程池使用 TransmittableThreadLocal 在父子线程间共享数据。\n","description":"","tags":["Java"],"title":"使用 InheritableThreadLocal 在父子线程间共享数据","uri":"/posts/java/inheritable-thread-local/"},{"categories":null,"content":"线程池使用 TransmittableThreadLocal 在父子线程间共享数据 TransmittableThreadLocal 是 alibaba 提供的，用于在使用线程池等会复用线程的组件时，在父子线程间共享数据。\n详情见 GitHub：https://github.com/alibaba/transmittable-thread-local\n使用方式 引入 Maven 依赖\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e \u003cartifactId\u003etransmittable-thread-local\u003c/artifactId\u003e \u003cversion\u003e2.12.1\u003c/version\u003e \u003c/dependency\u003e TransmittableThreadLocalUtil 工具类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class TransmittableThreadLocalUtil { private TransmittableThreadLocalUtil() { } private static final ThreadLocal\u003cObject\u003e THREAD_LOCAL = new TransmittableThreadLocal\u003c\u003e(); public static Object get() { return THREAD_LOCAL.get(); } public static void set(Object obj) { THREAD_LOCAL.set(obj); } public static void remove() { THREAD_LOCAL.remove(); } } 测试主类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public class ThreadMain { public static void main(String[] args) { testTransmittableThreadLocal(); } private static void testTransmittableThreadLocal() { // 通过 alibaba 提供的 TtlExecutors 对线程池进行包装 ExecutorService threadPool = TtlExecutors.getTtlExecutorService(Executors.newCachedThreadPool()); // 父线程要将变量共享给线程池创建的线程 TransmittableThreadLocalUtil.set(\"666\"); for (int i = 0; i \u003c 1000; i++) { threadPool.execute(() -\u003e { // 在子线程中获取父线程的共享变量 Object val = TransmittableThreadLocalUtil.get(); if (Objects.isNull(val)) { // 此时可以获取到共享变量，所以不会出现 null System.out.println(val); } // 移除新线程中的共享变量，让垃圾回收器可以进行回收 TransmittableThreadLocalUtil.remove(); }); } // 任务都执行结束后，关闭线程池 threadPool.shutdown(); // 移除父线程中的共享变量，让垃圾回收器可以进行回收 TransmittableThreadLocalUtil.remove(); } } ","description":"","tags":["Java"],"title":"线程池使用 TransmittableThreadLocal 在父子线程间共享数据","uri":"/posts/java/transmittable-thread-local/"},{"categories":null,"content":"观察者模式（Observer） 观察者模式也叫发布-订阅模式。主要包含两类对象：观察者和被观察者（也叫主题）。当主题的状态发生改变后，要通知观察者。\n个人认为按照订阅-通知更好理解流程。例如商品到货提醒的流程：首先通过商品1提供的订阅按钮2将我们3添加到该商品的待通知列表里，然后，当商品到货后，它会通过我们的手机4来给待通知列表里的所有人发送到货通知。\n简单模式 最简单的方式，用于理解观察者模式的代码。\n该方式观察者在主题状态发生改变的时候可以执行自己的逻辑，但是它不能知道主题具体发生了什么变化。\n代码 主题（被观察者）：提供了一个列表用于存储观察者集合\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 import java.util.ArrayList; import java.util.List; /** * 主题（被观察者） */ public class Subject { /** * 记录被观察者的状态 */ private int state; /** * 保存观察者的集合，当状态发生改变的时候，回调观察者提供的接口 */ private List\u003cObserver\u003e obs = new ArrayList\u003c\u003e(); /** * 改变被观察者的状态 * * @param state 变更后的状态 */ public void changeState(int state) { this.state = state; // 只要状态发生改变，就通知所有观察者 notifyObservers(); } /** * 添加一个观察者 * * @param observer 观察者 */ public void addObserver(Observer observer) { obs.add(observer); } /** * 删除一个观察者 * * @param observer 观察者 */ public void deleteObserver(Observer observer) { obs.remove(observer); } /** * 通知所有观察者, 回调其提供的方法 */ private void notifyObservers() { for (Observer o : obs) { o.update(); } } } 观察者接口\n1 2 3 4 5 6 7 8 9 10 11 /** * 观察者接口 */ public interface Observer { /** * 当被观察者状态发生改变后, 会回调该接口 * 观察者可以在该方法中进行相应的业务处理 */ void update(); } 具体的观察者\n观察者 1\n1 2 3 4 5 6 7 8 9 10 11 /** * 观察者的具体实现 */ public class ObsOne implements Observer { @Override public void update() { System.out.println(\"ObsOne 观察到了 Subject 的状态改变……\"); } } 观察者 2\n1 2 3 4 5 6 7 8 9 10 11 /** * 观察者的具体实现 */ public class ObsTwo implements Observer { @Override public void update() { System.out.println(\"ObsTwo 观察到了 Subject 的状态发生改变……\"); } } 测试主类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /** * 测试类 */ public class Main { public static void main(String[] args) { // 新建一个主题（被观察者） Subject subject = new Subject(); // 为其添加两个观察者 subject.addObserver(new ObsOne()); subject.addObserver(new ObsTwo()); // 当主题的状态发生改变的时候，就会回调观察者提供的方法 subject.changeState(1); subject.changeState(2); } } 类图和说明 首先创建主题（被观察者）类，其包含状态，观察者列表，以及改变状态，对观察者列表进行操作的方法 创建观察者接口，其包含一个抽象方法，当主题状态改变时，会回调该方法 创建具体的观察者，实现观察者接口，重写 update 方法，编写自己的业务逻辑 将观察者添加到主题的观察者列表中，当主题状态改变时，会回调列表中观察者提供的方法 当需要扩展的时候，只需要实现观察者接口，并将具体的观察者添加到主题的观察者列表中即可 带参数的 该方式当主题状态发生改变后，可以给观察者返回相应参数（推）；也可以将自己当成参数传给观察者，从而让观察者可以自己获取主题的状态（拉）。\n以交通灯（被观察者）和步行者/骑自行车的人（观察者）为例\n代码 主题（被观察者）接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 /** * 被观察者接口 */ public interface Subject { /** * 添加观察者 * * @param observer 观察者对象 */ void addObserver(Observer observer); /** * 删除观察者 * * @param observer 观察者对象 */ void deleteObserver(Observer observer); /** * 通知所有观察者, 同时可以将被观察者和某些参数传给观察者, 以使观察者可以获取到被观察者的相关属性信息等 * * @param subject 被观察者 * @param arg 额外参数, 根据需要, 可以扩展多个 */ void notifyObservers(Subject subject, Object arg); } 具体的主题（被观察者）：交通灯\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 /** * 交通灯, 被观察者 */ public class TrafficLights implements Subject { /** 交通灯颜色（观察者观察的属性）变化后，要通知观察者。 */ private Color color; /** 观察者列表 */ private List\u003cObserver\u003e obs = new ArrayList\u003c\u003e(); public void changeColor(Color color, Object arg) { this.color = color; notifyObservers(this, arg); } @Override public void addObserver(Observer observer) { obs.add(observer); } @Override public void deleteObserver(Observer observer) { obs.remove(observer); } @Override public void notifyObservers(Subject subject, Object arg) { for (Observer ob : obs) { ob.update(subject, arg); } } public Color getColor() { return color; } } 观察者\n步行者\n1 2 3 4 5 6 7 8 9 10 11 /** * 步行者，观察者 */ public class Walker implements Observer { @Override public void update(Subject subject, Object arg) { System.out.println(\"Walker 观察到了 TrafficLights 变成了：\" + ((TrafficLights) subject).getColor() + \"，附加参数是：\" + arg); } } 骑自行车的人\n1 2 3 4 5 6 7 8 9 10 11 /** * 骑自行车的人，观察者 */ public class Cyclists implements Observer { @Override public void update(Subject subject, Object arg) { System.out.println(\"Cyclists 观察到了 TrafficLights 变成了：\" + ((TrafficLights) subject).getColor() + \"，附加参数是：\" + arg); } } 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Main { public static void main(String[] args) { // 创建一个主题（交通灯） TrafficLights s = new TrafficLights(); // 步行者和骑自行车的人都是观察者 s.addObserver(new Walker()); s.addObserver(new Cyclists()); // 改变交通灯的颜色 s.changeColor(Color.RED, \"红灯停\"); s.changeColor(Color.GREEN, \"绿灯行\"); } } 类图和说明 首先创建主题（被观察者）接口，其包含对观察者列表进行操作的方法 创建具体的主题，实现主题接口，重写方法。其包含状态属性，观察者列表，以及改变状态的方法 创建观察者接口，其包含一个抽象方法，当主题状态改变时，会回调该方法 创建具体的观察者，实现观察者接口，重写 update 方法，编写自己的业务逻辑 将观察者添加到主题的观察者列表中，当主题状态改变时，会回调列表中观察者提供的方法 当需要扩展的时候，只需要实现观察者接口，并将具体的观察者添加到主题的观察者列表中即可 JDK 提供的 JDK 原生提供了 Observer 和 Observable 类来实现观察者模式。\n代码 Observer 接口（观察者）\n1 2 3 4 5 6 7 8 9 10 11 12 13 package java.util; /** * 当一个类想要在被观察对象发生改变时收到通知，可以实现该接口 */ public interface Observer { /** * 每当被观察对象发生改变时，都会调用此方法。应用程序调用被观察对象的 notifyObservers 方法来通知对象的所有观察者。 * * @param o 被观察对象 * @param arg 应用程序传给 notifyObservers 方法的参数 */ void update(Observable o, Object arg); } Observable 类（主题，被观察者）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 package java.util; /** * 此类标识被观察对象。它可以被子类继承来表示应用程序想要观察的对象。 * 一个被观察对象可以有一个或多个观察者。观察者可以是任何实现 Observer 接口的对象。在 observable 实例更改后，应用程序会通过 Observable 的 notifyObservers 方法，进而调用观察者的 update 方法将更改通知给所有观察者。 * 发送通知的顺序未指定。Observable 类中默认的顺序是根据注册的顺序来通知观察者，但是子类可能会更改此顺序，例如使用不保证顺序，在单独的线程上传递通知。 * 注意，这种通知机制与线程无关，完全独立于 Object 类的 wait 和 notify 机制。 * 当一个被观察对象被创建时，它的观察者集合是空的。当且仅当 equals 方法返回 true 时，两个观察者才被认为是相同的。 */ public class Observable { /** 当被观察者状态发生改变时，将其设置为 true；当通知完所有观察者后，将其设置为 false */ private boolean changed = false; private Vector\u003cObserver\u003e obs; /** 构造一个被观察者，包含一个空的观察者集合 */ public Observable() { obs = new Vector\u003c\u003e(); } /** * 向该对象的观察者集合中添加一个观察者，前提是它与集合中已有的观察者不同。没有指定将通知传递给多个观察者的顺序。 * * @param o 被添加的观察者对象 * @throws NullPointerException 如果参数 o 是 null */ public synchronized void addObserver(Observer o) { if (o == null) throw new NullPointerException(); if (!obs.contains(o)) { obs.addElement(o); } } /** * 从此对象的观察者列表中删除一个观察者。给该方法传递 null 将不起作用 * * @param o 被删除的观察者对象 */ public synchronized void deleteObserver(Observer o) { obs.removeElement(o); } public void notifyObservers() { notifyObservers(null); } /** * 如 hasChanged 方法已提示此对象已更改，则通知它的所有观察者，然后调用 clearChanged 方法来指示此对象已不再更改。 * 每个观察者都有它自己的 update 方法，它使用两个参数调用：此观察者对象和 arg 参数 * * @param arg 任意对象 */ public void notifyObservers(Object arg) { /* * 一个临时的缓存数组, 用作当前观察者状态的快照 */ Object[] arrLocal; synchronized (this) { /* 我们不希望观察者在持有自己的监视器的同时对任意代码进行回调。 * 从 Vector 中提取每个 Observable 并存储观察者状态的代码需要同步，但通知观察者不需要（不应该）同步。 * 这里存在的任何潜在竞争条件的最差结果是： * 1. 新添加的观察者会错过正在进行的通知 * 2. 最近未注册的 Observer 在它不关心时会被错误地通知 */ if (!changed) return; arrLocal = obs.toArray(); clearChanged(); } for (int i = arrLocal.length-1; i\u003e=0; i--) ((Observer)arrLocal[i]).update(this, arg); } /** * 清空观察者列表，使该对象不再有任何观察者 */ public synchronized void deleteObservers() { obs.removeAllElements(); } /** * 将此被观察者对象标记为已更改。此时 hasChanged 方法将返回 true */ protected synchronized void setChanged() { changed = true; } /** * 表示此对象不再更改，或者它已经将最近的更改通知了所有观察者，因此 hasChanged 方法现在将返回 false。该方法由 notifyObservers 方法自动调用 */ protected synchronized void clearChanged() { changed = false; } /** * 测试此对象是否已更改 * * @return 当且仅当 setChanged 方法在 clearChanged 方法之后调用时才返回 true */ public synchronized boolean hasChanged() { return changed; } /** * 返回此被观察者对象的观察者数量 * * @return 此对象的观察者数量 */ public synchronized int countObservers() { return obs.size(); } } 具体的主题（被观察者）：交通灯\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /** * 交通灯, 被观察者 */ public class TrafficLights extends Observable { /** 交通灯颜色（观察者观察的属性）变化后，要通知观察者。 */ private Color color; public void changeColor(Color color, Object arg) { this.color = color; this.setChanged(); this.notifyObservers(arg); } public Color getColor() { return this.color; } } 观察者\n步行者\n1 2 3 4 5 6 7 8 9 10 11 /** * 步行者，观察者 */ public class Walker implements Observer { @Override public void update(Observable o, Object arg) { System.out.println(\"Walker 观察到了 TrafficLights 变成了：\" + ((TrafficLights) o).getColor() + \"，附加参数是：\" + arg); } } 骑自行车的人\n1 2 3 4 5 6 7 8 9 10 11 /** * 骑自行车的人，观察者 */ public class Cyclists implements Observer { @Override public void update(Observable o, Object arg) { System.out.println(\"Cyclists 观察到了 TrafficLights 变成了：\" + ((TrafficLights) o).getColor() + \"，附加参数是：\" + arg); } } 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Main { public static void main(String[] args) { // 创建一个主题（交通灯） TrafficLights s = new TrafficLights(); // 步行者和骑自行车的人都是观察者 s.addObserver(new Walker()); s.addObserver(new Cyclists()); // 改变交通灯的颜色 s.changeColor(Color.RED, \"红灯停\"); s.changeColor(Color.GREEN, \"绿灯行\"); } } 类图和说明 创建具体的主题，继承 JDK 的 Observable 类，它可以包含自己的状态属性，并提供方法对其进行改变。在该方法中依次调用父类的 setChanged 和 notifyObservers 方法 创建具体的观察者，实现 JDK 的 Observer 接口，重写 update 方法，编写自己的业务逻辑 将观察者添加到主题的观察者列表中，当主题状态改变时，会回调列表中观察者提供的方法 当需要扩展的时候，只需要实现 Observer 接口，并将具体的观察者添加到主题的观察者列表中即可 事件监听 事件监听机制，将主题中观察者观察的属性移动到“事件（Event）”对象中，将主题独立为“事件源（Event Source）”，将观察者称为“监听器（Listener）”。\n因为对观察者模式中的主题进行了拆分，提高了事件的复用性（可以应用在其他事件监听机制中）和扩展性（可以有自己的继承机制，可参考 java.awt.event.KeyEvent）。\n当事件源发生改变时，会创建事件，并调用监听器的回调方法，将事件通知给监听器。\n代码 事件源\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 import java.awt.*; import java.util.ArrayList; import java.util.List; /** * 交通信号灯, 是一个事件源（主题/被观察者） */ public class TrafficLights { /** * 用于存放 ColorChange 监听器（观察者） */ private List\u003cColorChangeListener\u003e listeners = new ArrayList\u003c\u003e(); /** * 事件源提供的改变颜色的方法 * * @param color 目标颜色 */ public void changeColor(Color color) { // 当事件源颜色改变后，通知所有监听器 for (ColorChangeListener listener : listeners) { // 创建颜色改变事件对象，通过事件的方式进行通知 listener.colorChanged(new ColorChangeEvent(this, color)); } } /** * 添加 ColorChange 监听器 * * @param listener 被添加的 ColorChange 监听器 */ public void addColorListener(ColorChangeListener listener) { listeners.add(listener); } /** * 移除 ColorChange 监听器 * * @param listener 被移除的 ColorChange 监听器 */ public void removeColorListener(ColorChangeListener listener) { listeners.remove(listener); } } 颜色改变事件。通常事件对象都继承自 java.util.EventObject 类，通过它提供的 getSource 方法可以在监听器中获取事件源对象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import java.awt.*; import java.util.EventObject; /** * 颜色改变事件 * * @author wangshuo * @date 2021/07/27 */ public class ColorChangeEvent extends EventObject { /** * 监听器监听（观察者观察）的属性 */ private Color color; /** * 事件源发生变化时，调用事件的构造方法创建事件对象，通过事件的方式通知监听器 * * @param source 事件源对象 * @param color 事件源传入的变量 * @throws IllegalArgumentException 如果 source 是 null. */ public ColorChangeEvent(Object source, Color color) { super(source); this.color = color; } /** * 监听器可通过该方法获取事件源的变化情况 * * @return 变化后的颜色 */ public Color getColor() { return color; } } 事件监听器接口。通常继承 java.util.EventListener，用于标记当前接口是一个事件监听器接口\n1 2 3 4 5 6 7 8 9 10 import java.util.EventListener; /** * 颜色改变监听器 */ public interface ColorChangeListener extends EventListener { void colorChanged(ColorChangeEvent evt); } 具体的时间监听器。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import java.awt.*; /** * 自定义的颜色改变监听器 */ public class CustomColorChangeListener implements ColorChangeListener { /** * 重写 ColorChangeListener 的 colorChanged 方法 * * @param evt 事件对象，可通过该对象获取事件源和变化的属性信息 */ @Override public void colorChanged(ColorChangeEvent evt) { // 获取事件源对象 TrafficLights source = (TrafficLights) evt.getSource(); // 获取事件源改变时，传过来的变化信息 Color color = evt.getColor(); System.out.println(\"监听器观察到了\" + source + \" 的颜色变成了：\" + color); } } 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 import java.awt.*; public class Main { public static void main(String[] args) { // 创建事件源对象 TrafficLights trafficLights = new TrafficLights(); // 向事件源中添加事件监听器 trafficLights.addColorListener(new CustomColorChangeListener()); // 当事件源被监听的属性发生改变时，相应的监听器可以得到通知 trafficLights.changeColor(Color.RED); } } 类图和说明 主题中包含监听器的列表，对监听器列表进行操作、以及改变状态的方法。在改变状态的时候，通过 new 事件对象的方式通知监听器 事件对象继承自 EventObject 类，包含从主题中分离的变化属性，和获取该属性的方法，并可通过父类提供的 getSource 方法获取事件源对象 事件监听接口继承自 EventListener，用于标记当前类是事件监听器。具体的事件监听器可通过事件对象获取事件源和相关参数，进行业务处理 当需要扩展时，可根据需要创建自己的事件监听器，并将其注册到事件源中即可 商品：就是被观察者（即主题），它包含一个待通知列表 ↩︎\n订阅按钮：商品提供了订阅按钮，可以将我们添加到它的待通知列表中；相应的，主题应该提供将观察者添加到观察者列表中的方法 ↩︎\n我们：我们就是观察者 ↩︎\n我们的手机：商品通过手机给我们发送通知；相应的观察者要给主题提供一个方法，当主题状态发生改变的时候，通过回调该方法给观察者列表中的观察者发送通知 ↩︎\n","description":"","tags":["MSB","Design Pattern","Java"],"title":"观察者模式（Observer）","uri":"/posts/msb/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/observer/"},{"categories":null,"content":"使用 guiscrcpy 在 Windows 10 上使用 Android 手机 环境说明 Windows 10\n小米 K30S Ultra（MIUI 12.5.1）\nscrcpy v1.18\nguiscrcpy v4.10.0\n电脑安装 scrcpy 和 guiscrcpy 下载 scrcpy 和 guiscrcpy\nscrcpy 下载地址\nguiscrcpy 下载地址\n解压 scrcpy 到某个位置\n将 guiscrcpy.exe 也移动到某个位置\n双击 guiscrcpy.exe，根据提示的不同，从 scrcpy-win64-v1.18 中选择对应的文件\n设置 scrcpy-server 位置\n设置 adb 位置\n设置 scrcpy 位置\n手机设置 连续点击 MIUI version，开启开发者模式（Developer Mode）\n开启 USB 调试模式（USB debugging）\n注意：小米手机要同时开启 USB 调试模式（安全设置）（USB debugging（Security settings））选项，否则在电脑上只能预览，不能操作\n开始连接 通过 USB 数据线将手机和电脑进行连接\n在手机允许 USB debugging\n打开 guiscrcpy，此时在页面上可以看到已连接的安卓手机\n可以进行一些调整\n取消 Bottonm Panel 的勾选\n取消 Swipe Panel 的勾选\n勾选 Keep display off，并取消手机的自动锁屏功能\n选择设备，开始连接\n","description":"","tags":["Android"],"title":"使用 guiscrcpy 在 Windows 10 上使用 Android 手机","uri":"/posts/android/guiscrcpy-for-windows/"},{"categories":null,"content":"CentOS7 显示中文 查看当前系统语言\n1 $ echo $LANG 默认应该是：en_US.UTF-8\n查看系统已经安装的语言包\n1 $ locale 如果没有 zh_CN.UTF-8，安装中文语言包\n1 $ sudo yum groupinstall chinese-support 设置系统语言为 zh_CN.UTF-8\n临时设置\n1 $ LANG=zh_CN.UTF-8 永久设置\n1 echo LANG=zh_CN.UTF-8 \u003e /etc/locale.conf 重启服务器\n","description":"","tags":["Linux","CentOS"],"title":"CentOS7 显示中文","uri":"/posts/linux/linux-chinese/"},{"categories":null,"content":"Linux 打 RPM 包 环境准备 使用的操作系统是华为的 openEuler 21.03，打包过程需要使用 root 用户或者具备 sudo 权限\n启动 openEuler 的网络链接\n查看所有设备\n1 2 3 4 $ sudo nmcli device status DEVICE TYPE STATE CONNECTION enp0s3 ethernet disconnected -- lo loopback unmanaged -- 链接设备\n1 2 $ sudo nmcli device connect enp0s3 Device 'enp0s3' successfully activated with ... 包管理器解决了一个什么问题？ 告诉你软件源码在哪 告诉你如何安装和构建这个软件的源码 告诉你如何删除这个软件 打 RPM 包需要什么？ rpm-build：打包用的软件 spec：spec 文件，描述了软件打包的各项基本信息 RPM 打包使用的目录和文件介绍 rpm-build 使用到的目录介绍 BUILD：源码包解压至此并完成编译 RPMS：生成的 RPM 包会输出在这里【*】 SOURCES：放源码包（如 .tar 包）和所有 patch 补丁【*】 SPECS：放 rpm 包的配置文件（.spec），需要自己编写的【*】 SRPMS：生成/保存源码 RPM 包（SRPM） BUILDROOT：保存 %install 阶段安装的文件 spec 文件格式 spec 文件中定义了大量的宏，记录了包管理器应该如何处理软件。\nName：软件包的名字，必须和 spec 文件名一致 Version：软件包的版本号 Release：软件包 Release 编号 Summary：简短的单行描述（dnf info 命令可以查看到该描述） License：软件所使用的授权协议 Group：软件包的分组，在可视化环境下，可以根据分组找到该软件包 URL：软件网站地址（dnf info 命令可以查看到该 URL） Source0：软件源码地址 Patch0：Patch ID（补丁） BuildArch：软件架构（x86，arm 等），有些包不依赖架构则使用 noarch BuildRequires：构建依赖（例如 GoLang，Java 等），在构建的时候需要使用到的依赖。多个依赖使用多行。可加版本号（如 BuildRequires: perl(URI) \u003e= 1.58） Requires：安装依赖，在安装该软件包的时候需要的依赖。多个依赖使用多行。可加版本号（如 BuildRequires: perl(JSON) \u003e= 2.5） %global：用于定义全局变量 %description：软件的长描述 %package：可以使用多个该标签，让 spec 文件可以打出多个包 %prep：预处理，一般是用来执行解压缩命令的 %patch： %autosetup： %build：编译软件时执行 %install：安装软件时执行 %clean：卸载软件时执行 %files：定义软件包的内容文件格式等信息 %changelog：变更日志 最简单的 spec 配置文件\nName:\thowdy Version: 1 Release: 1%\\{?dist} Summary: Say hello, Texas style License: Public Domain Source0: howdy %description A simple program to greet the user, Texas style. %install %files %changelog 打包实战 安装 rpm-build 和 rpmdevtools\n1 2 3 $ sudo dnf install rpm-build rpmdevtools # 或者 $ sudo yum install rpm-build rpmdevtools 生成 rpm-build 所需的目录\n1 $ sudo rpmdev-setuptree 默认在用户家目录下创建 rpmbuild 文件夹，可以通过修改 ~/.rpmmacros 中的 _topdir 进行自定\n以 python-journal-brief 为例，去 pipy 下载源码包，当前最新的是：journal-brief-1.1.7.tar.gz。将该源代码的压缩包移动到 rpmbuild/SOURCES 目录\n1 $ sudo mv journal-brief-1.1.7.tar.gz ~/rpmbuild/SOURCES 编写 spec 文件（可以去 Fedora Package Sources/openSuse Build Service/openEuler Build Service 找人家写好的 spec 文件作为参考），或查看软件提供方提供的安装说明。\n$ sudo vim ~/rpmbuild/SPECS/python-journal-brief.spec %global srcname journal-brief %global sum Find new systemd journal entries since last run Name:\tpython-%{srcname} Version:\t1.1.7 Release:\t5%{?dist} Summary:\t%{sum} License:\tGPLv2+ URL:\thttps://pypi.python.org/pypi/%{srcname} Source0:\thttps://pypi.python.org/packages/source/j/%{srcname}/%{srcname}-%{version}.tar.gz BuildArch:\tnoarch # en_US.UTF-8 locale required for tests BuildRequires:\tglibc-langpack-en BuildRequires:\tpython3-devel BuildRequires:\tpython3-PyYAML BuildRequires:\tpython3-setuptools %if 0%{?with_check} BuildRequires:\tpython3-pytest python3-flexmock %endif # with_check %description Python module for examining, bookmarking, and filtering systemd journal entries. %package -n %{srcname} Summary:\tShow interesting new systemd journal entries since last run Requires:\tpython3-%{srcname} = %{version}-%{release} Requires:\tpython3-setuptools %description -n %{srcname} Run this from cron to get a daily or hourly briefing of interesting new systemd journal entries. %package -n python3-%{srcname} Summary:\t%{sum} Requires:\tsystemd-python3 Requires:\tpython3-PyYAML Recommends:\t%{srcname} = %{version}-%{release} %{?python_provide:%python_provide python3-%{srcname}} %description -n python3-%{srcname} Python module for examining, bookmarking, and filtering systemd journal entries. %prep %autosetup -n %{srcname}-%{version} %build %py3_build %install %py3_install %if 0%{?with_check} %check %{__python3} %{py_setup} test %endif # with_check %files -n %{srcname} %{_bindir}/%{srcname} %files -n python3-%{srcname} %license LICENSE %doc README.md %{python3_sitelib}/* %changelog * Fri Jun 04 2021 Python Maint \u003cpython-maint@redhat.com\u003e - 1.1.7-5 - Rebuilt for Python 3.10 * Wed Jan 27 2021 Fedora Release Engineering \u003creleng@fedoraproject.org\u003e - 1.1.7-4 - Rebuilt for https://fedoraproject.org/wiki/Fedora_34_Mass_Rebuild * Mon Oct 5 2020 Tim Waugh \u003ctwaugh@redhat.com\u003e - 1.1.7-3 - Build requires python3-setuptools. * Wed Jul 29 2020 Fedora Release Engineering \u003creleng@fedoraproject.org\u003e - 1.1.7-2 - Rebuilt for https://fedoraproject.org/wiki/Fedora_33_Mass_Rebuild * Mon Jul 13 2020 Tim Waugh \u003ctwaugh@redhat.com\u003e - 1.1.7-1 - 1.1.7. * Tue Jul 7 2020 Tim Waugh \u003ctwaugh@redhat.com\u003e - 1.1.6-1 - 1.1.6. * Fri Jun 19 2020 Tim Waugh \u003ctwaugh@redhat.com\u003e - 1.1.5-16 - Add conditional markers for checks. * Tue May 26 2020 Miro Hrončok \u003cmhroncok@redhat.com\u003e - 1.1.5-15 - Rebuilt for Python 3.9 * Thu Jan 30 2020 Fedora Release Engineering \u003creleng@fedoraproject.org\u003e - 1.1.5-14 - Rebuilt for https://fedoraproject.org/wiki/Fedora_32_Mass_Rebuild * Thu Oct 03 2019 Miro Hrončok \u003cmhroncok@redhat.com\u003e - 1.1.5-13 - Rebuilt for Python 3.8.0rc1 (#1748018) * Thu Aug 15 2019 Tim Waugh \u003ctwaugh@redhat.com\u003e - 1.1.5-12 - Rebuild against Python 3.8. * Thu Aug 15 2019 Tim Waugh \u003ctwaugh@redhat.com\u003e - 1.1.5-11 - Fix running of tests. * Fri Jul 26 2019 Fedora Release Engineering \u003creleng@fedoraproject.org\u003e - 1.1.5-10 - Rebuilt for https://fedoraproject.org/wiki/Fedora_31_Mass_Rebuild * Thu Feb 14 2019 Tim Waugh \u003ctwaugh@redhat.com\u003e - 1.1.5-9 - Build requires en_US.UTF-8 for test suite (bug #1675746). * Sat Feb 02 2019 Fedora Release Engineering \u003creleng@fedoraproject.org\u003e - 1.1.5-8 - Rebuilt for https://fedoraproject.org/wiki/Fedora_30_Mass_Rebuild * Sat Jul 14 2018 Fedora Release Engineering \u003creleng@fedoraproject.org\u003e - 1.1.5-7 - Rebuilt for https://fedoraproject.org/wiki/Fedora_29_Mass_Rebuild * Tue Jun 19 2018 Miro Hrončok \u003cmhroncok@redhat.com\u003e - 1.1.5-6 - Rebuilt for Python 3.7 * Fri Feb 09 2018 Fedora Release Engineering \u003creleng@fedoraproject.org\u003e - 1.1.5-5 - Rebuilt for https://fedoraproject.org/wiki/Fedora_28_Mass_Rebuild * Thu Jul 27 2017 Fedora Release Engineering \u003creleng@fedoraproject.org\u003e - 1.1.5-4 - Rebuilt for https://fedoraproject.org/wiki/Fedora_27_Mass_Rebuild * Sat Feb 11 2017 Fedora Release Engineering \u003creleng@fedoraproject.org\u003e - 1.1.5-3 - Rebuilt for https://fedoraproject.org/wiki/Fedora_26_Mass_Rebuild * Mon Dec 19 2016 Miro Hrončok \u003cmhroncok@redhat.com\u003e - 1.1.5-2 - Rebuild for Python 3.6 * Tue Nov 1 2016 Tim Waugh \u003ctwaugh@redhat.com\u003e - 1.1.5-1 - 1.1.5: - setup: don't install tests.format (RH bug #1390250) * Sun Jul 24 2016 Tim Waugh \u003ctwaugh@redhat.com\u003e - 1.1.4-1 - 1.1.4. * Tue Jul 19 2016 Fedora Release Engineering \u003crel-eng@lists.fedoraproject.org\u003e - 1.1.3-4 - https://fedoraproject.org/wiki/Changes/Automatic_Provides_for_Python_RPM_Packages * Thu Feb 04 2016 Fedora Release Engineering \u003creleng@fedoraproject.org\u003e - 1.1.3-3 - Rebuilt for https://fedoraproject.org/wiki/Fedora_24_Mass_Rebuild * Tue Nov 10 2015 Fedora Release Engineering \u003crel-eng@lists.fedoraproject.org\u003e - Rebuilt for https://fedoraproject.org/wiki/Changes/python3.5 * Mon Nov 9 2015 Tim Waugh \u003ctwaugh@redhat.com\u003e - 1.1.3-1 - 1.1.3 (bug #1279097). * Wed Nov 4 2015 Tim Waugh \u003ctwaugh@redhat.com\u003e - 1.1.2-2 - Add python3-PyYAML runtime dependency (bug #1277715). * Fri Oct 30 2015 Tim Waugh \u003ctwaugh@redhat.com\u003e - 1.1.2-1 - 1.1.2. - Run doctests in %%check. * Fri Oct 23 2015 Tim Waugh \u003ctwaugh@redhat.com\u003e - 1.1.1-2 - journal-brief sub-package requires python3-setuptools due to entrypoint usage. - python3-journal-brief sub-package requires systemd-python3, not (absent) main package. * Fri Oct 16 2015 Tim Waugh \u003ctwaugh@redhat.com\u003e - 1.1.1-1 - Initial spec file. 此时的目录结构\n1 2 3 4 5 6 7 8 rpmbuild/ ├── BUILD ├── RPMS ├── SOURCES │ └── journal-brief-1.1.7.tar.gz ├── SPECS │ └── python-journal-brief.spec └── SRPMS 安装构建过程所需的依赖\n1 $ sudo dnf builddep ~/rpmbuild/SPECS/python-journal-brief.spec 打包\n1 $ sudo rpmbuild -ba ~/rpmbuild/SPECS/python-journal-brief.spec 执行结束后，会在 rpmbuild/RPMS 目录下生成 RPM 包\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 rpmbuild/ ├── BUILD │ └── journal-brief-1.1.7 │ └── ... ├── BUILDROOT ├── RPMS │ └── noarch │ ├── journal-brief-1.1.7-5.noarch.rpm │ └── python3-journal-brief-1.1.7-5.noarch.rpm ├── SOURCES │ └── journal-brief-1.1.7.tar.gz ├── SPECS │ └── python-journal-brief.spec └── SRPMS └── python-journal-brief-1.1.7-5.src.rpm 安装测试\n1 2 3 $ sudo rpm -ivh ~/rpmbuild/RPMS/noarch/python3-journal-brief-1.1.7-5.noarch.rpm # 或者 $ sudo dnf localinstall ~/rpmbuild/RPMS/noarch/python3-journal-brief-1.1.7-5.noarch.rpm 创建本地 repo 安装 createrepo\n1 $ sudo dnf install createrepo -y 将所有 rpm 移动到一个目录，例如 ~/repo\n1 2 $ mkdir -p ~/repo $ cp ~/rpmbuild/RPMS/**/*.rpm ~/repo 创建一个新的 repo\n1 $ sudo createrepo --database ~/repo 在 /etc/yum.repos.d 目录下新建 myTestRepo.repo\n1 2 3 4 5 6 [local] name=My Test Repo baseurl=file:///root/repo enabled=1 gpgcheck=0 protect=1 更新 dnf\n1 $ sudo dnf update 此时使用 dnf search 命令即可查询我们自己仓库中的软件包\n1 2 3 4 $ sudo dnf search python3-journal-brief Last metadata expiration check: 0:00:06 ago on Sun 11 Jul 2021 11:53:43 PM CST. ========================== Name Exactly Matched: python3-journal-brief =========================== python3-journal-brief.noarch : Find new systemd journal entries since last run 并且使用 dnf install 命令即可安装\n1 $ sudo dnf install python3-journal-brief 延伸学习资料 Maximum RPM【RedHat 编写的】 RPM 包简介 软件包引入的验证 openEuler社区软件包引入提交流程 参考 Linux 中国：《Linux 应用生态训练营》\n","description":"","tags":["Linux"],"title":"Linux 打 RPM 包","uri":"/posts/linux/linux-packaging-rpm/"},{"categories":null,"content":"Linux 使用 Docker 安装 TIM 和微信 使用的操作系统是 Ubuntu 20.4 / Fedora 35\n安装 TIM TIM 的 Docker 镜像提供者 GitHub 主页：https://github.com/top-bettercode/docker-qq\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 docker run -d --name tim \\ --device /dev/snd \\ --ipc=\"host\" \\ -v $HOME/Data/docker/TIMFiles:/TencentFiles \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e XMODIFIERS=@im=fcitx \\ -e QT_IM_MODULE=fcitx \\ -e GTK_IM_MODULE=fcitx \\ -e DISPLAY=unix$DISPLAY \\ -e AUDIO_GID=`getent group audio | cut -d: -f3` \\ -e VIDEO_GID=`getent group video | cut -d: -f3` \\ -e GID=`id -g` \\ -e UID=`id -u` \\ bestwu/qq:office 需要修改的地方：\n-v $HOME/Data/docker/TIMFiles:/TencentFiles：宿主机和 Docker 内的 TIM 文件路径的映射 fcitx：根据自己的输入法设置，修改为 ibus 或者 fcitx 安装微信 微信的 Docker 镜像提供者 GitHub 主页：https://github.com/top-bettercode/docker-wechat\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 docker run -d --name wechat \\ --device /dev/snd \\ --ipc=\"host\"\\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -v $HOME/Data/docker/WeChatFiles:/WeChatFiles \\ -e DISPLAY=unix$DISPLAY \\ -e XMODIFIERS=@im=fcitx \\ -e QT_IM_MODULE=fcitx \\ -e GTK_IM_MODULE=fcitx \\ -e AUDIO_GID=`getent group audio | cut -d: -f3` \\ -e VIDEO_GID=`getent group video | cut -d: -f3` \\ -e GID=`id -g` \\ -e UID=`id -u` \\ bestwu/wechat 需要修改的地方：\n-v $HOME/Data/docker/WeChatFiles:/WeChatFiles：宿主机和 Docker 内的微信文件路径的映射 fcitx：根据自己的输入法设置，修改为 ibus 或者 fcitx 去除 Wine System Tray 安装结束启动后，会出现一个 Wine System Tray 的窗口，很不好看\n可通过下列方式将图标移动到通知栏中间\n安装 Tweaks、Extendsion、TopIcons\n1 2 3 4 # Ubuntu 20.4 安装 sudo apt install gnome-tweak-tool gnome-shell-extension-top-icons-plus # Fedora35 使用的是 Gnome41，在 Gnome41 中 Tweaks 和 Extensions 分离开了，同时 TopIcons 的原作者不再更新该插件，可以安装 https://extensions.gnome.org/extension/2890/tray-icons-reloaded/ 插件获得同样的效果 sudo dnf install gnome-tweaks gnome-extensions-app 重启 gnome-shell（最好先将当前正在进行的工作保存，重启后，可能会丢失未保存的数据！）\n1 gnome-shell -r 打开 Tweaks，选择 Extensions（Fedora 35 直接打开 Extensions），按下图打开 Topicons plus（或 Tray Icons: Reloaded） 插件\n遇到的问题 安装的 TIM 和 微信都可以进行语音通话，但是不能进行视频通话（可以看对方，但是检测不到自己这边的摄像头）。尝试过在 Docker 运行时添加如下参数，仍不好使，据说是因为 Wine 的原因，不支持视频。\n1 2 3 4 --privileged --device /dev/media0 --device /dev/video0 --device /dev/video1 ","description":"","tags":["Linux"],"title":"Linux 使用 Docker 安装 TIM 和微信","uri":"/posts/linux/linux-docker-install-tim-and-wechat/"},{"categories":null,"content":"Linux 安装 JetBrains Mono 字体 下载字体\nhttps://www.jetbrains.com/lp/mono/\n将字体解压到 /usr/share/fonts（对所有用户生效）或 ~/.local/share/fonts（对指定用户生效）\n1 2 3 4 5 6 # 解压字体包 $ sudo unzip JetBrainsMono-2.225.zip # 创建放置 JetBrains 字体的单独文件夹 $ sudo mkdir /usr/share/fonts/JetBrains # 将解压出的字体移动到 JetBrains 字体文件夹 $ sudo mv fonts/* /usr/share/fonts/JetBrains 安装字体\n1 fc-cache -f -v 可以使用 fc-list 查看已安装的字体\n","description":"","tags":["Linux"],"title":"Linux 安装 JetBrains Mono 字体","uri":"/posts/linux/linux-install-jetbrains-mono/"},{"categories":null,"content":"Qv2ray For Linux 教程 下载安装 Qv2ray 方式一：命令行安装 Debian，Ubuntu 及其衍生发行版：\n1 2 3 4 # 安装相关的工具 sudo apt install gnupg ca-certificates curl # 安装 Qv2ray sudo apt update; sudo apt install qv2ray 或者\n1 snap install qv2ray 方式二：二进制安装 打开 https://github.com/Qv2ray/Qv2ray/releases\n选择下载 Qv2ray.v2.7.0-pre2.linux-x64.AppImage\n打开软件\n如果出现以下报错：\n​\t请您右键安装包，然后点击属性 -\u003e 权限 -\u003e 允许作为软件运行即可\n​\t​\t不出意外您会看到以下界面\n​\t下载 V2Ray 核心文件 Qv2ray 本身并 不包含 名为 v2ray-core 的 V2Ray 可执行文件，多数时候您需要自己下载\n官方下载链接： https://github.com/v2fly/v2ray-core/releases\n将 v2ray 核心文件提取到一个固定路径。 建议将文件提取到 QV2RAY_CONFIG_PATH/vcore\n如果您不会这样操作，也可以随便提取到一个您找的到的文件夹里\n提取好后在 Qv2ray 中配置一下 V2Ray Core\n打开 Qv2ray 并转到首选项窗口。 在内核设置中，配置以下选项：\n核心可执行文件路径: 将此设置为您的 V2Ray 可执行文件存在的地方\n导入节点到 Qv2ray 点击分组 点击加号 分组名称填您喜欢的即可\n点击订阅设置\n打勾此分组是一个订阅\n然后填入您的订阅地址\n更新间隔填一天\n点击更新订阅 最后点击ok即可\n参考文档 Qv2ray For Linux 教程\n","description":"","tags":["Linux","Qv2ray"],"title":"Qv2ray For Linux 教程","uri":"/posts/linux/qv2ray-for-linux/"},{"categories":null,"content":"Linux 开机自动挂载磁盘及 /etc/fstab 文件说明 查看磁盘的 UUID 和 TYPE\n1 2 $ blkid /dev/sda1 /dev/sda1: UUID=\"67840e8d-8d2b-4fac-b17b-aa70e1329bda\" TYPE=\"ext4\" PARTUUID=\"cd83ae7d-1933-490c-8f39-9d403865ad01\" 修改 /etc/fstab 文件，添加如下内容\n1 UUID=67840e8d-8d2b-4fac-b17b-aa70e1329bda /home/wangshuo/Data ext4 defaults 0 2 /etc/fstab 文件参数说明 /etc/fstab 文件包含以下列\n1 # \u003cfile system\u003e \u003cmount point\u003e \u003ctype\u003e \u003coptions\u003e \u003cdump\u003e \u003cpass\u003e file system：被挂载的文件系统的路径或者 UUID，推荐使用 UUID，因为在新增磁盘后，原有的磁盘路径可能发生改变，而磁盘的 UUID 是不会受该影响的。\nmount point：挂载点\ntype：被挂载磁盘的文件系统类型\noptions：可选参数，默认使用 defaults 即可，多个参数可以使用 , 分隔\n属性值 说明 defaults 默认选项包含：rw，suid，dev，exec，auto，nouser，async auto/noauto 在执行 mount -a 的时候（例如开机的时候）是否自动挂载。 user/owner 允许所有用户/设备所有者挂载 comment 给 fstab-maintaining programs 使用的（不知道干什么的） nofail 该设备不存在的时候，不报错 详细参数可通过 man 8 mount 查看。\ndump：能否被 dump 备份命令作用，通常设置为 0 即可\n属性值 说明 0 不备份 1 每天备份 2 不定期备份 pass：开机时，fsck 通过该值确定文件系统的检查顺序，通常设置为 2 即可\n属性值 说明 0 不进行检查（默认值） 1 最先检查（根目录） 2 1 级别完成后，进行检查（其他目录） ","description":"","tags":["Linux"],"title":"Linux 开机自动挂载磁盘及 /etc/fstab 文件说明","uri":"/posts/linux/linux-auto-mount-and-fstab/"},{"categories":null,"content":"马士兵网约车三期目录 项目介绍 项目设计 Eureka Eureka Client internal-common 分布式事务 分布式锁 ","description":"","tags":["MSB","Project","网约车三期","Java"],"title":"马士兵网约车三期目录","uri":"/posts/msb/%E7%BD%91%E7%BA%A6%E8%BD%A6%E4%B8%89%E6%9C%9F/msb-online-text-three-table/"},{"categories":null,"content":"马士兵会话管理目录 会话管理入门 Spring Security Spring Security 集群 - - https ","description":"","tags":["MSB","Session Manage","Java"],"title":"马士兵-会话管理目录","uri":"/posts/msb/%E4%BC%9A%E8%AF%9D%E7%AE%A1%E7%90%86/msb-session-management-table/"},{"categories":null,"content":"马士兵咚宝商城目录 咚宝商城第一节课 ","description":"","tags":["MSB","Project","咚宝商城","Java"],"title":"马士兵咚宝商城目录","uri":"/posts/msb/%E5%92%9A%E5%AE%9D%E5%95%86%E5%9F%8E/dongbao-mall-table/"},{"categories":null,"content":"马士兵-设计模式目录 源码地址\n单例模式（Singleton） 策略模式（Strategy） 工厂模式（Factory） 外观/门面模式（Facade） 中介/调停者模式（Mediator） 装饰者模式（Decorator） 观察者模式（Observer） 组合模式（Composite） 享元模式（Flyweight） 代理模式（Proxy） 迭代器模式（Iterator） 访问者模式（Visitor） ","description":"","tags":["MSB","Design Pattern","Java"],"title":"马士兵设计模式目录","uri":"/posts/msb/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/msb-design-pattern-table/"},{"categories":null,"content":"Typora 设置自动显示标题序号 File → Preferences... Appearance → Open Theme Folder 新建一个 base.user.css 在 base.user.css 中添加\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 /** initialize css counter */ #write, .sidebar-content,.md-toc-content { counter-reset: h1 } #write h1, .outline-h1, .md-toc-item.md-toc-h1 { counter-reset: h2 } #write h2, .outline-h2, .md-toc-item.md-toc-h2 { counter-reset: h3 } #write h3, .outline-h3, .md-toc-item.md-toc-h3 { counter-reset: h4 } #write h4, .outline-h4, .md-toc-item.md-toc-h4 { counter-reset: h5 } #write h5, .outline-h5, .md-toc-item.md-toc-h5 { counter-reset: h6 } /** put counter result into headings */ #write h1:before, h1.md-focus.md-heading:before, .outline-h1\u003e.outline-item\u003e.outline-label:before, .md-toc-item.md-toc-h1\u003e.md-toc-inner:before{ counter-increment: h1; content: counter(h1) \" \" } #write h2:before, h2.md-focus.md-heading:before, .outline-h2\u003e.outline-item\u003e.outline-label:before, .md-toc-item.md-toc-h2\u003e.md-toc-inner:before{ counter-increment: h2; content: counter(h1) \".\" counter(h2) \" \" } #write h3:before, h3.md-focus.md-heading:before, .outline-h3\u003e.outline-item\u003e.outline-label:before, .md-toc-item.md-toc-h3\u003e.md-toc-inner:before { counter-increment: h3; content: counter(h1) \".\" counter(h2) \".\" counter(h3) \" \" } #write h4:before, h4.md-focus.md-heading:before, .outline-h4\u003e.outline-item\u003e.outline-label:before, .md-toc-item.md-toc-h4\u003e.md-toc-inner:before { counter-increment: h4; content: counter(h1) \".\" counter(h2) \".\" counter(h3) \".\" counter(h4) \" \" } #write h5:before, h5.md-focus.md-heading:before, .outline-h5\u003e.outline-item\u003e.outline-label:before, .md-toc-item.md-toc-h5\u003e.md-toc-inner:before { counter-increment: h5; content: counter(h1) \".\" counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5) \" \" } #write h6:before, h6.md-focus.md-heading:before, .outline-h6\u003e.outline-item\u003e.outline-label:before, .md-toc-item.md-toc-h6\u003e.md-toc-inner:before { counter-increment: h6; content: counter(h1) \".\" counter(h2) \".\" counter(h3) \".\" counter(h4) \".\" counter(h5) \".\" counter(h6) \" \" } /** override the default style for focused headings */ #write\u003eh3.md-focus:before, #write\u003eh4.md-focus:before, #write\u003eh5.md-focus:before, #write\u003eh6.md-focus:before, h3.md-focus:before, h4.md-focus:before, h5.md-focus:before, h6.md-focus:before { color: inherit; border: inherit; border-radius: inherit; position: inherit; left:initial; float: none; top:initial; font-size: inherit; padding-left: inherit; padding-right: inherit; vertical-align: inherit; font-weight: inherit; line-height: inherit; } 重启 Typora\n","description":"","tags":["Typora"],"title":"Typora 设置自动显示标题序号","uri":"/posts/typora/typora-set-auto-head/"},{"categories":null,"content":"Typora 修改字体 File → Preferences... Appearance → Open Theme Folder 新建一个 base.user.css 在 base.user.css 中添加\n1 2 3 4 5 6 7 8 9 html, body { /*custom font*/ font-family: \"JetBrains Mono\",\"思源黑体\"; } :root { /*monospace font for codes, fences*/ --monospace: \"JetBrains Mono\",\"思源等宽\"; } 设置目标字体\n重启 Typora\n这种修改字体的方式对于默认的 Github 主题是生效的，其它的主题可能没有遵守相关的规范，或者有自己的设计，就需要使用调试模式来测试了\n参考文档：\nWrite Custom Theme for Typora ","description":"","tags":["Typora"],"title":"Typora 修改字体","uri":"/posts/typora/typora-change-font/"},{"categories":null,"content":"IDEA/DataGrip 添加自定义数据源 添加自定义的数据库驱动 人大金仓（kingbase8）的 URL templates\n1 2 default jdbc:kingbase8://{host::localhost}?[:{port::54321}][/{database}?] default jdbc:kingbase8://{host::localhost}?[:{port::54321}][/DMSERVER?schema={database}] 达梦（DM）的 URL templates\n1 2 default jdbc:dm://{host::localhost}?[:{port::5236}][/{database}?] default jdbc:dm://{host::localhost}?[:{port::5236}][/DMSERVER?schema={database}] 添加数据源 ","description":"","tags":["Java","IDEA","DataGrip"],"title":"IDEA/DataGrip 添加自定义数据源","uri":"/posts/java/idea-datagrip-custom-datasource/"},{"categories":null,"content":"Maven 的 dependencies 和 dependencyManagement 区别 \u003cdependencyManagement\u003e 仅是声明依赖，通常在顶级父模块中做版本管理。在父模块中使用 \u003cdependencyManagement\u003e 标签声明依赖，其子模块不会自动引入 \u003cdependencyManagement\u003e 中的依赖，需要在子模块中手动引入才可以\n\u003cdependencies\u003e 是真实的引入了依赖，子模块会继承父模块 \u003cdependencies\u003e 中的依赖\n常用方式 在顶级父模块的 pom 中使用 \u003cdependencyManagement\u003e 和 \u003cproperties\u003e 声明依赖和版本号，进行依赖的版本控制\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 \u003c!-- 在 properties 中设置版本号，进行统一的版本管理 --\u003e \u003cproperties\u003e \u003ccommons-lang3.version\u003e3.11\u003c/commons-lang3.version\u003e \u003cselenium.version\u003e3.141.59\u003c/selenium.version\u003e \u003clombok.version\u003e1.18.20\u003c/lombok.version\u003e \u003c/properties\u003e \u003c!-- 引入需要给所有模块使用的依赖，不需要指定 version 了，因为在 dependencyManagement 中已经指定了 --\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c!-- 在 dependencyManagement 中声明依赖和版本，并不会引入到当前模块和其子模块中 --\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003c!-- commons-lang3 工具包 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.commons\u003c/groupId\u003e \u003cartifactId\u003ecommons-lang3\u003c/artifactId\u003e \u003cversion\u003e${commons-lang3.version}\u003c/version\u003e \u003c/dependency\u003e \u003c!-- selenium 模拟浏览器进行自动化--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.seleniumhq.selenium\u003c/groupId\u003e \u003cartifactId\u003eselenium-java\u003c/artifactId\u003e \u003cversion\u003e${selenium.version}\u003c/version\u003e \u003c/dependency\u003e \u003c!-- selenium chrome 驱动--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.seleniumhq.selenium\u003c/groupId\u003e \u003cartifactId\u003eselenium-chrome-driver\u003c/artifactId\u003e \u003cversion\u003e${selenium.version}\u003c/version\u003e \u003c/dependency\u003e \u003c!-- lombok --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003cversion\u003e${lombok.version}\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e 在子模块的 pom 中只需要使用 \u003cdependencies\u003e 引入需要的依赖即可，并且不需要指定版本号\n1 2 3 4 5 6 7 \u003c!-- 子模块只需要引入自己需要的依赖即可，并且不需要指定版本号，会自动使用父模块中指定的版本，通过父模块进行统一的版本管理 --\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.commons\u003c/groupId\u003e \u003cartifactId\u003ecommons-lang3\u003c/artifactId\u003e \u003c/dependency\u003e \u003c/dependencies\u003e ","description":"","tags":["Java","Maven"],"title":"Maven 的 dependencies 和 dependencyManagement 区别","uri":"/posts/java/maven-dependencies-dependencymanagement/"},{"categories":null,"content":"Maven 的 SNAPSHOT 和 RELEASE 的区别 SNAPSHOT 是快照的意思，代表开发分支上的最新代码，并不能保证代码的稳定性和不可变性。相反的, RELEASE 代表正式版本，保证了代码的稳定性和不可变性，项目每到一个阶段后，就需要发布一个正式版本。\n对于版本以 -SNAPSHOT 结尾的 jar 包，Maven 每次构建时都会从远程仓库拉取，即使本地仓库已经包含了该 jar 包。而对于非 -SNAPSHOT 结尾的 jar，Maven 每次构建时都会从本地仓库进行获取，只有当本地仓库不存在该 jar 的时候，才会从远程仓库拉取。\n通过 Maven 提供的 release 程序，可以将 x.y-SNAPSHOT 修改为 x.y。同时该程序也提供了对开发版本的增量更新。例如将 1.0-SNAPSHOT 发布为 1.0 版本后，将开发分支的版本更新为 1.1-SNAPSHOT\n官方文档：What_is_a_SNAPSHOT_version\n什么时候用 SNAPSHOT 假如两个小组 A，B 分别负责开发两个模块 service 和 common，版本都是 1.0，其中 service 模块依赖于 common 模块。此时如果对 common 模块进行了修改并发布到了 Nexus 上，则必须通知 A 组的同事，删除本地的 jar，然后重新进行构建。\n如果使用了 SNAPSHOT，即可解决沟通的问题。只需将 common 的版本设置为 1.0-SNAPSHOT，service 模块依赖于该版本的 common，则每次对 common 进行修改发布到 Nexus 后，service 在进行构建时，都会自动去 Nexus 拉取最新的 jar 包，并进行构建。\n所以，开发的时候使用 SNAPSHOT 版本的 jar，可以减少因为版本更新造成的大量沟通问题。发布正式版本的时候使用 RELEASE 版本的 jar，可以防止对未上线的代码进行发布后，对正式版本造成影响。\n调整 SNAPSHOT 的更新频率 如果使用了 SNAPSHOT，每次构建都从远程仓库拉取新的 jar 包，那么 maven 的本地缓存机制就没有用了，所以我们可以调整对 SNAPSHOT 版本的包的拉取频率，可以修改为 always（每次构建都拉取），daily（每天拉取），interval（每分钟拉取），never（从不拉取）\n在 IDEA 中配置 IDEA 默认是不会更新 SNAPSHOT 的，需要在设置中勾选 Always update snapshots，然后点击 Maven 的刷新按钮\n在 settings.xml 中配置 参考官方配置文件示例：settings，添加如下配置\n1 2 3 4 \u003csnapshots\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003ealways\u003c/updatePolicy\u003e \u003c/snapshots\u003e 在 pom.xml 中配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u003crepositories\u003e \u003crepository\u003e \u003cid\u003enexus-public\u003c/id\u003e \u003cname\u003enexus-release\u003c/name\u003e \u003curl\u003ehttp://XXXXXXX/repository/maven-public/\u003c/url\u003e \u003creleases\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003c/releases\u003e \u003csnapshots\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003ealways\u003c/updatePolicy\u003e \u003c/snapshots\u003e \u003c/repository\u003e \u003c/repositories\u003e 使用 -U 参数强制使用最新快照构建 可以在任何 Maven 命令中添加 -U 参数强制 Maven 下载最新的快照进行构建\n1 mvn clean package -U ","description":"","tags":["Java","Maven"],"title":"Maven 的 SNAPSHOT 和 RELEASE 的区别","uri":"/posts/java/maven-snapshot-release/"},{"categories":null,"content":"Maven 多模块版本升级 项目结构 最上层 mall 模块是下面所有子模块的顶级父类，现在要实现更改 mall 的版本，所有子模块的版本也要同步更改\nMaven 的版本管理机制 子模块中可以不指定 \u003cversion\u003e 标签，则子模块使用其父模块的版本。但是必须在子模块中指定 parent.version\n顶级父模块 mall 的 pom\n1 2 3 4 5 6 7 8 \u003cgroupId\u003eicu.intelli\u003c/groupId\u003e \u003cartifactId\u003emall\u003c/artifactId\u003e \u003c!-- 顶级父模块中指定版本号 --\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003cpackaging\u003epom\u003c/packaging\u003e \u003cmodules\u003e \u003cmodule\u003eapi\u003c/module\u003e \u003c/modules\u003e 父模块 api 的 pom\n1 2 3 4 5 6 7 8 9 10 11 12 \u003cparent\u003e \u003cartifactId\u003emall\u003c/artifactId\u003e \u003cgroupId\u003eicu.intelli\u003c/groupId\u003e \u003c!-- 但是必须指定 parent.version --\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/parent\u003e \u003c!-- 作为 mall 的子模块，其不需要指定 groupId 和 version，会自动使用 mall 的 --\u003e \u003cartifactId\u003eapi\u003c/artifactId\u003e \u003cpackaging\u003epom\u003c/packaging\u003e \u003cmodules\u003e \u003cmodule\u003ecart-api\u003c/module\u003e \u003c/modules\u003e 子模块 cart-api 的 pom\n1 2 3 4 5 6 7 8 9 \u003cparent\u003e \u003cartifactId\u003eapi\u003c/artifactId\u003e \u003cgroupId\u003eicu.intelli\u003c/groupId\u003e \u003c!-- 但是必须指定 parent.version --\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/parent\u003e \u003c!-- 作为 api 的子模块，其不需要指定 groupId 和 version，会自动使用 api 的 --\u003e \u003cartifactId\u003ecart-api\u003c/artifactId\u003e \u003cpackaging\u003ejar\u003c/packaging\u003e 出现的问题 虽然在子模块中不用指定自己的 \u003cversion\u003e 了，但是当版本升级的时候，还是需要修改所有子模块中的 parent.verison\n批量更新 POM 中的版本 方式一 在顶级父模块的 pom 中添加 version 插件\n1 2 3 4 5 6 7 8 9 10 11 12 \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.codehaus.mojo\u003c/groupId\u003e \u003cartifactId\u003eversions-maven-plugin\u003c/artifactId\u003e \u003cversion\u003e2.8.1\u003c/version\u003e \u003cconfiguration\u003e \u003cgenerateBackupPoms\u003efalse\u003c/generateBackupPoms\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e 在顶级父模块根目录执行如下命令修改版本号\n1 2 # 将所有模块的版本都修改为 1.0.RELEASE mvn versions:set -DnewVersion=1.0-RELEASE 以上命令会将 mall/pom.xml 以及其所有子模块的 parent.verison 都修改为 1.0-RELEASE\n结论 顶级父模块的 pom 中维护 \u003cversion\u003e 标签，子模块的 pom 中不用指定自己的 \u003cversion\u003e 和 \u003cgroupId\u003e。子模块的 pom 中包含父模块的 \u003cgroupId\u003e，\u003cartifactId\u003e，\u003cversion\u003e。当版本需要更新的时候，使用 maven 插件中的命令实现父子模块 pom 递归修改：mvn versions:set -DnewVersion=1.0-RELEASE\n方式二 注意：该方式只支持升级 SNAPSHOT 版本，不支持对RELEASE版本的操作。高级操作搜索: Maven 最佳实践：版本管理\n官方文档 update-versions\n在顶级父模块根目录执行下方命令，maven 会给出输入框，对每个模块的版本进行修改\n1 mvn release:update-versions 如果确定每个子模块的版本都是和其父模块版本相同的，可以添加 autoVersionSubmodules 选项，此时只需要输入一次版本\n1 mvn release:update-versions -DautoVersionSubmodules=true 还可以将版本直接放在命令行中，此时就不需要再手动输入版本号了\n1 mvn --batch-mode release:update-versions -DdevelopmentVersion=1.2.0-SNAPSHOT ","description":"","tags":["Java","Maven"],"title":"Maven 多模块版本升级","uri":"/posts/java/maven-multi-module-version-upgrade/"},{"categories":null,"content":"Spring Boot 基础系列目录 Spring Boot 入门 Spring Boot 配置文件 Spring Boot 与日志 Spring Boot 与 Web 开发 Spring Boot 与 Docker Spring Boot 与数据访问 Spring Boot 启动配置原理 Spring Boot 自定义 starters Spring Boot 热部署 SpringBoot 定时任务 ","description":"","tags":["Spring Boot","Java"],"title":"Spring Boot 基础系列目录","uri":"/posts/java/springboot%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97/spring-boot-table/"},{"categories":null,"content":"Spring 注解系列目录 Spring 注解：@Configuration 指定配置类和 @Bean 注册 Bean Spring 注解：@ComponentScan 包扫描 \u0026 指定扫描规则 Spring 注解：@Scope 设置组件作用域 Spring 注解：@Lazy 懒加载 Spring 注解：@Conditional 按照条件注册 Bean Spring 注解：@Import 给容器中快速导入一个组件 Spring 注解：使用 FactoryBean 接口注册组件 Spring 注解：向容器中注册组件的方式总结 Spring 注解：@Bean 指定初始化和销毁方法 Spring 注解：使用 InitializingBean 和 DisposableBean 接口初始化或销毁 Bean Spring 注解：使用 @PostConstruct 和 @PreDestroy Spring 注解：BeanPostProcessor 后置处理器 Spring 注解：BeanPostProcessor 原理 Spring 注解：BeanPostProcessor 在 Spring 底层的使用 Spring 注解：Bean 的生命周期总结 Spring 注解：@Value 属性赋值 Spring 注解：@PropertySource 加载外部配置文件 Spring 注解：属性赋值总结 Spring 注解：@Autowired，@Qualifier，@Primary 自动装配 Spring 注解：@Resource，@Inject 自动装配 Spring 注解：方法，构造器位置的自动装配 Spring 注解：向自定义组件中注入 Spring 底层组件及原理 Spring 注解：@Profile 自动装配 Spring 注解：自动装配总结 Spring 注解：AOP 功能测试 ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解系列目录","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-table/"},{"categories":null,"content":"Git 提交使用的图标 图标 缩写 描述 🆕 init 新建 ✨ feat 新功能 🐛 fix bug 📝 docs 文档 💇 style 代码格式(不影响代码运行的格式变动，注意不是指 CSS 的修改) 🔨 refactor 重构(既不是新增功能，也不是修改 bug 的代码变动) 🔎 test 提交测试代码(单元测试，集成测试等) 🧱 chore 构建或辅助工具的变动 😕 misc 一些未归类或不知道将它归类到什么地方的提交 🎉 release 发布 ","description":"","tags":["Git"],"title":"Git 提交使用的图标","uri":"/posts/git/git-push-icon/"},{"categories":null,"content":"Docker 运行 MySQL 占用太多内存 在 Fedora36 上使用 docker-ce-3:20.10.16-3.fc36.x86_64 运行 mysql:5.7.39 镜像，宿主机内存 16GB，镜像启动后就使用 13GB 左右的内存，或者直接被 systemd-oom 直接杀死进程。\n1 2 3 4 docker stats CONTAINER ID NAME CPU % MEM USAGE / LIMIT MEM % NET I/O BLOCK I/O PIDS 9ac2482a1a34 mysql5.7 93.37% 13.12GiB / 15.52GiB 84.52% 3.5kB / 0B 36.5MB / 0B 4 参考 docker-library/mysql/issues/579，在启动容器时，添加 --ulimit nofile=262144:262144 参数\n","description":"","tags":["Docker","MySQL"],"title":"Docker 运行 MySQL 占用太多内存","uri":"/posts/docker/docker-running-mysql-uses-to-much-memery/"},{"categories":null,"content":"借助 Spring AOP 在 Service 层对入参进行验证 Spring Boot 项目，公司对传入的参数使用了自己的框架进行封装，所以在 Controller 层无法使用传统的注解方式对入参进行校验。所以通过自定义注解 + AOP 在 Service 层对入参进行校验。参数校验基于 JSR 303 标准。\n引入依赖\n1 2 3 4 5 6 7 8 9 10 11 12 \u003c!-- 基于 JSR 303 标准开发出的接口包 --\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.validation\u003c/groupId\u003e \u003cartifactId\u003evalidation-api\u003c/artifactId\u003e \u003cversion\u003e2.0.1.Final\u003c/version\u003e \u003c/dependency\u003e \u003c!-- 对 validation-api 接口进行了实现 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.hibernate.validator\u003c/groupId\u003e \u003cartifactId\u003ehibernate-validator\u003c/artifactId\u003e \u003cversion\u003e7.0.1.Final\u003c/version\u003e \u003c/dependency\u003e 自定义校验注解\n1 2 3 4 5 6 7 8 9 10 import java.lang.annotation.*; /** * 只有对标注了该注解的类/方法/参数进行校验 */ @Target({ElementType.TYPE, ElementType.METHOD, ElementType.PARAMETER}) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface ServiceParamValidate { } 自定义异常类，可以对其做全局异常处理\n1 2 3 4 5 6 7 8 9 10 /** * 对服务层参数校验出错时, 抛出该异常 * * @author wangshuo */ public class ServiceParamValidatedException extends RuntimeException { public ServiceParamValidatedException(String message) { super(message); } } 自定义切面\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 import com.example.annotation.ServiceParamValidate; import com.example.exception.ServiceParamValidatedException; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.annotation.Pointcut; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.stereotype.Component; import org.springframework.util.Assert; import javax.validation.ConstraintViolation; import javax.validation.Validator; import java.lang.annotation.Annotation; import java.lang.reflect.Method; import java.util.Iterator; import java.util.Objects; /** * 服务层参数验证切面类 * * @author wangshuo */ @Component @Aspect public class ServiceParamValidateAspect { private final Validator validator; public ServiceParamValidateAspect(Validator validator) { Assert.notNull(validator, \"validator 不能为空\"); this.validator = validator; } /** * 对 service 包下以 Service 结尾的类进行拦截 */ @Pointcut(\"execution(* com.example..service.*Service.*(..))\") public void pointCut() { } /** * 在执行方法前对方法参数进行校验 * * @param joinPoint 切点 */ @Before(\"pointCut()\") public void doBefore(JoinPoint joinPoint) { // 获取方法参数 Object[] args = joinPoint.getArgs(); // 如果没有参数，不需要验证 if (args.length == 0) { return; } // 获取类信息 Class\u003c?\u003e clazz = joinPoint.getTarget().getClass(); ServiceParamValidate classAnnotation = clazz.getAnnotation(ServiceParamValidate.class); // 获取方法签名信息 MethodSignature signature = (MethodSignature) joinPoint.getSignature(); Method method = signature.getMethod(); ServiceParamValidate methodAnnotation = method.getAnnotation(ServiceParamValidate.class); // 类上或者方法上只要有一个包含 @ServiceParamValidate, 就对方法的所有参数都进行验证；否则只对标注了 @ServiceParamValidate 的参数验证 boolean hasGlobalAnnotation = Objects.nonNull(classAnnotation) || Objects.nonNull(methodAnnotation); if (hasGlobalAnnotation) { for (Object arg : args) { validate(arg); } } else { // 一维存的是参数, 二维存的是参数的注解 Annotation[][] annotations = method.getParameterAnnotations(); for (int i = 0; i \u003c annotations.length; i++) { Object param = args[i]; Annotation[] annos = annotations[i]; for (Annotation anno : annos) { if (ServiceParamValidate.class.isAssignableFrom(anno.annotationType())) { validate(param); } } } } } /** * 校验对象的属性 * * @param target 需要被校验的对象 */ private \u003cT\u003e void validate(T target) { // 不能对 null 对象进行验证 if (Objects.isNull(target)) { return; } Iterator\u003cConstraintViolation\u003cT\u003e\u003e iter = validator.validate(target).iterator(); StringBuilder errors = new StringBuilder(); while (iter.hasNext()) { ConstraintViolation\u003cT\u003e error = iter.next(); errors.append(error.getMessage()); } if (errors.length() \u003e 0) { throw new ServiceParamValidatedException(errors.toString()); } } } 使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 对该类的所有方法的所有参数都进行验证 // @ServiceParamValidate public class SampleServiceImpl implements SampleService { // 对该方法的所有参数都进行验证 @ServiceParamValidate public void sampleMethod(/** 只对该参数进行验证 @ServiceParamValidate */ SampleObject sample){ } } @Data public class SampleObject { @NotBlank(message = \"姓名不能为空\") private String name; @Email(message = \"邮箱格式不正确\") private String email; @Range(min = 0, max = 200, message = \"年龄越界\") private Integer age; } ","description":"","tags":["Spring","Spring Boot","Java"],"title":"借助 Spring AOP 在 Service 层对入参进行验证","uri":"/posts/java/spring-service-validate/"},{"categories":null,"content":"MongoDB 的索引 索引是一种特殊的数据结构，它以一种易于遍历的形式存储 collection 的一部分数据集\n索引存储特定字段或字段集的值，按字段的值排序。索引项的排序支持高效的等值匹配和基于范围的查询操作。\nMongoDB 定义了 collection 级别的索引，并且支持对 collection 中文档的任何字段或子字段进行索引。\n术语 索引覆盖 指一个查询所需要的字段都在索引中，就不再需要从数据页中加载数据了。\n索引扫描（IXSCAN） 只扫描建立了索引的数据\n集合扫描（COLLSCAN） 对集合中的所有数据都进行扫描。对应 MySQL 的全表扫描\n查询形状（Query Shape） 就是查询条件。\n例如\ndb.user.find({\"gender\":\"女\", \"age\":25}) {\"gender\":\"女\", \"age\":25} 就是该语句的 query shape\n索引前缀（Index Prefix） 例如创建如下索引\ndb.user.createIndex({a:1,b:1,c:1}) 使用下方三种查询形状进行查询的时候，都可以匹配索引，不需要单独创建额外的索引\n{a:1} {a:1,b:1} {a:1,b:1,c:1} 过滤性（Selectivity） 过滤性是指通过使用索引缩小查询结果范围的能力。\n示例\n数据准备：假设数据库中包含如下数据\n{ _id: ObjectId(), a: 1, b: \"ab\" } { _id: ObjectId(), a: 1, b: \"cd\" } { _id: ObjectId(), a: 1, b: \"ef\" } { _id: ObjectId(), a: 2, b: \"jk\" } { _id: ObjectId(), a: 2, b: \"lm\" } { _id: ObjectId(), a: 2, b: \"no\" } { _id: ObjectId(), a: 3, b: \"pq\" } { _id: ObjectId(), a: 3, b: \"rs\" } { _id: ObjectId(), a: 3, b: \"tv\" } 查询条件\n如果要查询 a=2 并且 b=\"no\" 的数据\n方式一：根据 a 字段创建索引\n因为 a 字段具备索引，所以 MongoDB 会优先根据 a=2 的条件进行查询，此时会查询出 3 条记录\n然后在从这 3 条记录中查询出 b=\"no\" 的这条数据\n方式二：根据 b 字段创建索引\n因为 b 字段具备索引，所以 MongoDB 会有限根据b=\"no\"的条件进行查询，此时可以直接就查询出所要的数据\n说明\n过滤性简而言之，就是说要对数据差异性较大的字段建立索引，这样根据该索引就可以查询出较少的初步结果，其他条件就可以从较少的初步结果中进行过滤\n索引原理 官网写的是 B tree，其实是 B+tree\n查询计划 查询计划（Query Plans）就是说，MongoDB 在执行一个查询的时候，它的执行流程是什么样的。\n查询优化器介绍 MongoDB 中有一个查询优化器（Query Optimizer），当一个查询到达 MongoDB 后，会按照查询优化器规定的流程来进行处理。\n查询优化器会根据已经建立，且对其可见的索引对 QueryShape 选择最有效的查询计划\n查询优化器的执行流程 查询优化器首先会从缓存中查询是否有符合该 QueryShape 的查询计划，如果存在，会对其进行评估，评估通过后，就会使用该查询计划生成文档结果。如果评估不通过，会清除缓存中的该查询计划，然后生成新的查询计划。\n如果缓存中不存在符合该 QueryShape 的查询计划，查询优化器会对其生成一些候选的查询计划，然后对这些候选的查询计划进行评估，选择出一个最优的查询计划，然后将其缓存后再生成文档结果。\n候选查询计划的评估\n先判断是否有索引 根据索引数量，分别启动一个线程，使用不同的索引进行查询，分别取出 1000 条数据，看使用哪个索引查询的块 缓存的查询计划失效 对于 MongoDB 已经缓存的缓存计划，在某些情况下，是会是小的\n对集合执行了 100 次写操作\n因为如果对某个集合进行了大量的数据写入，可能改变其索引字段对应数据的数据分布，从而导致之前的查询计划不再是最优的\nmongod 重启\n因为查询计划是在缓存中的，所以重启服务后会被清空\n索引重建/修改/删除\n索引都改变了，查询计划肯定要重新评估\n手动设置查询计划 生产环境，由于业务原因，可能出现按照 MongoDB 生成的查询计划查询的速度变慢了，此时通过 hint 命令强制指定使用哪些索引\ndb.collectionName.find().hint() 官方还提供了一种监听器的方式\n索引管理 创建索引 语法\ndb.collectionName.createIndex(keys,options) 参数 类型 描述 keys documents 指定要对哪些字段创建什么类型的索引。{col:val} 形式。其中 col 表示要对哪个字段建立索引；val 表示要对该字段建立升序索引还是降序索引。升序索引是 1，降序索引是 -1。比如 {\"name\":1} 表示对 name 字段建立升序索引。 options documents 可选。包含一组控制索引创建选项的文档。\n可选参数：background，unique\n- background：Boolean 类型，默认值 false。是否在后台建立索引。如果为 false，建立索引的时候会阻塞对数据库其他的操作。\n- unique：Boolean 类型，默认为 false。建立的索引是否唯一。如果为 true 则创建唯一索引。 使用技巧\n尽量将 background 设置为 true，通常 MongoDB 存储的数据量都很大（百万/千万/上亿），创建索引很耗费时间。如果为 false，会导致业务中断。 创建索引时，会先在 primary 节点上建立，此时可以将主节点与从节点断开连接，在主节点上创建索引时让从节点继续提供查询服务，等主节点创建完索引后，在让从节点创建索引 所有用于存储的组件，无论是 mysql 还是 mongodb 还是 es 或者 redis，如果你想干一些数据迁移，重新分片，重新分表等，都可能会影响线上业务。\n查看索引 db.collectionName.getIndexes() 删除索引 # 删除指定索引 db.collectionName.dropIndex(index) # 删除所有索引 db.collectionName.dropIndexes() 参数 类型 描述 index string/document 指定要删除的索引。可以通过索引名（string）或索引规范文档（document）来删除。若要删除文本索引，请指定索引名称。 示例\n# 测试数据 db.test.insertMany([{\"x\":5,\"y\":\"a\"},{\"x\":6,\"y\":\"b\"}]) # 对 x 字段创建索引 db.test.createIndex({x:1}) # 查询所有索引 db.test.getIndexes() # 通过索引名称删除索引 db.test.dropIndex(\"x_1\") # 通过索引规范文档删除索引 db.test.dropIndex({x:1}) 查询分析 db.collectionName.find().explain(verbose) verbose：可选参数。默认值是 queryPlanner，用于指定 explain 输出信息的详细程度 queryPlanner：MongoDB 运行查询优化器对当前的查询进行评估并选择一个最佳的查询计划 executionStats：MongoDB 运行查询优化器对当前的查询进行评估并选择一个最佳的查询计划进行执行。在执行完毕后返回这个最佳执行计划执行完成时的相关统计信息。对于写操作 db.collection.explain() 返回关于更新和删除操作的信息，但是并不将修改应用到数据库。 allPlansExecution：包括上述两种模式的所有信息。同时如果有多个查询计划会列出候选的查询计划。 测试\n插入测试数据\nfor(var i=0;i\u003c100000;i++){db.test.insert({name:i,age:i,date:new Date()})} 查看执行计划\ndb.test.find({name:1}).explain(\"executionStats\") 结果说明\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 { \"queryPlanner\" : { \"plannerVersion\" : 1, \"namespace\" : \"test.test\", \"indexFilterSet\" : false, \"parsedQuery\" : { \"name\" : { \"$eq\" : 1 } }, // 获胜的执行计划 \"winningPlan\" : { // 全表扫描 \"stage\" : \"COLLSCAN\", \"filter\" : { \"name\" : { \"$eq\" : 1 } }, \"direction\" : \"forward\" }, \"rejectedPlans\" : [ ] }, \"executionStats\" : { \"executionSuccess\" : true, // 返回的结果集数量 \"nReturned\" : 1, // 执行所需时间 \"executionTimeMillis\" : 37, // 检查了几个索引 \"totalKeysExamined\" : 0, // 检查的文档总数 \"totalDocsExamined\" : 100000, \"executionStages\" : { // 扫描方式：全表扫描 \"stage\" : \"COLLSCAN\", \"filter\" : { \"name\" : { \"$eq\" : 1 } }, \"nReturned\" : 1, \"executionTimeMillisEstimate\" : 3, \"works\" : 100002, \"advanced\" : 1, \"needTime\" : 100000, \"needYield\" : 0, \"saveState\" : 100, \"restoreState\" : 100, \"isEOF\" : 1, \"direction\" : \"forward\", \"docsExamined\" : 100000 } }, \"serverInfo\" : { \"host\" : \"ubuntu-01\", \"port\" : 27017, \"version\" : \"4.4.5\", \"gitVersion\" : \"ff5cb77101b052fa02da43b8538093486cf9b3f7\" }, \"ok\" : 1, \"$clusterTime\" : { \"clusterTime\" : Timestamp(1619077624, 1), \"signature\" : { \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"), \"keyId\" : NumberLong(0) } }, \"operationTime\" : Timestamp(1619077624, 1) } 对 name 字段创建索引\ndb.test.createIndex({\"name\":1}) 再次执行 db.test.find({name:1}).explain(\"executionStats\") 查看执行计划\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 { \"queryPlanner\" : { \"plannerVersion\" : 1, \"namespace\" : \"test.test\", \"indexFilterSet\" : false, \"parsedQuery\" : { \"name\" : { \"$eq\" : 1 } }, // 获胜的执行计划 \"winningPlan\" : { \"stage\" : \"FETCH\", \"inputStage\" : { // 索引扫描 \"stage\" : \"IXSCAN\", \"keyPattern\" : { \"name\" : 1 }, \"indexName\" : \"name_1\", \"isMultiKey\" : false, \"multiKeyPaths\" : { \"name\" : [ ] }, \"isUnique\" : false, \"isSparse\" : false, \"isPartial\" : false, \"indexVersion\" : 2, \"direction\" : \"forward\", \"indexBounds\" : { \"name\" : [ \"[1.0, 1.0]\" ] } } }, \"rejectedPlans\" : [ ] }, \"executionStats\" : { \"executionSuccess\" : true, // 返回 1 条数据 \"nReturned\" : 1, // 只耗费了 2 毫秒 \"executionTimeMillis\" : 2, // 只检查了 1 个索引 \"totalKeysExamined\" : 1, // 只查看了一个文档 \"totalDocsExamined\" : 1, \"executionStages\" : { \"stage\" : \"FETCH\", \"nReturned\" : 1, \"executionTimeMillisEstimate\" : 0, \"works\" : 2, \"advanced\" : 1, \"needTime\" : 0, \"needYield\" : 0, \"saveState\" : 0, \"restoreState\" : 0, \"isEOF\" : 1, \"docsExamined\" : 1, \"alreadyHasObj\" : 0, \"inputStage\" : { \"stage\" : \"IXSCAN\", \"nReturned\" : 1, \"executionTimeMillisEstimate\" : 0, \"works\" : 2, \"advanced\" : 1, \"needTime\" : 0, \"needYield\" : 0, \"saveState\" : 0, \"restoreState\" : 0, \"isEOF\" : 1, \"keyPattern\" : { \"name\" : 1 }, \"indexName\" : \"name_1\", \"isMultiKey\" : false, \"multiKeyPaths\" : { \"name\" : [ ] }, \"isUnique\" : false, \"isSparse\" : false, \"isPartial\" : false, \"indexVersion\" : 2, \"direction\" : \"forward\", \"indexBounds\" : { \"name\" : [ \"[1.0, 1.0]\" ] }, \"keysExamined\" : 1, \"seeks\" : 1, \"dupsTested\" : 0, \"dupsDropped\" : 0 } } }, \"serverInfo\" : { \"host\" : \"ubuntu-01\", \"port\" : 27017, \"version\" : \"4.4.5\", \"gitVersion\" : \"ff5cb77101b052fa02da43b8538093486cf9b3f7\" }, \"ok\" : 1, \"$clusterTime\" : { \"clusterTime\" : Timestamp(1619077834, 1), \"signature\" : { \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"), \"keyId\" : NumberLong(0) } }, \"operationTime\" : Timestamp(1619077834, 1) } 索引类型 单字段索引 组合（复合）索引 创建方法 db.collectionName.createIndex({col:val,col2:val2,col3:val3}) ESR 原则 创建组合索引要遵循 ESR 原则\nE（Equal）：精准匹配放在最前面 S（Sort）：排序条件放中间 R（Range）：范围匹配放最后 如果不能同时满足 ESR，那要满足 ES/ER（总之 E 要放前面）\n示例 假如有如下查询语句\ndb.user.find({gender:\"F\",age:{$gte:25}}).sort(\"birthday\":1) 此时可以对 user 表的 gender，age，birthday 三个字段创建联合索引\n有如下 6 种排列组合\n1 2 3 4 5 6 {\"gender\":1,\"age\":1,\"birthday\":1} {\"gender\":1,\"birthday\":1,\"age\":1} {\"age\":1,\"gender\":1,\"birthday\":1} {\"age\":1,\"birthday\":1,\"gender\":1} {\"birthday\":1,\"age\":1,\"gender\":1} {\"birthday\":1,\"gender\":1,\"age\":1} 按照 ESR 原则，应该使用如下方式创建索引\ndb.user.createIndex({\"gender\":1,\"birthday\":1,\"age\":1}) 多值索引 针对数组创建的索引\n索引数组字段 示例数据\n1 db.user.insert({\"address\": {\"city\": \"Los Angeles\",\"state\": \"California\",\"pincode\": \"123\"},\"tags\": [\"music\",\"cricket\",\"blogs\"],\"name\": \"Tom Benzamin\"}) 对 tags 字段建立索引\ndb.user.createIndex({\"tags\":1}) 创建索引后可以通过如下方式查询\ndb.user.find({tags:\"cricket\"}) 可以通过explain查看索引是否生效\ndb.user.find({tags:\"cricket\"}).explain(\"executionStats\") 针对子文档索引 针对 address 的子文档创建索引\ndb.user.createIndex({\"address.city\":1,\"address.state\":1,\"address.pincode\":1}) 使用子文档的字段来进行查询\ndb.user.find({\"address.city\":\"Los Angeles\"}) 可以通过 explain 查看索引是否生效\ndb.user.find({\"address.city\":\"Los Angeles\"}).explain(\"executionStats\") 地理位置索引 参考：https://docs.mongodb.com/manual/core/geohaystack/\n全文索引 类似于 ES 的功能\nTTL 索引 带有失效期的索引\n部分索引 只对部分数据添加索引，可以减少索引的数量，从而加快查询速度\n例如 2020 年旧的数据只有 name 和 age 字段，在 2021 年后添加了 tel 字段，此时可以只对 tel 字段添加索引。\n因为旧的数据没有该字段，所以如果对旧数据也添加该索引，会影响索引的性能\n例如只对 2021 年的数据添加索引，对 2020 年的数据不加索引，如果大部分查询都是查 2021 年的数据，此时可以加快数据的查询速度\n使用方式 db.collectionName.createIndex(keys,{partialFilterExpression:condition}) keys：需要添加索引的字段，例如 {\"createTime\":1} conodition：过滤条件，例如 {\"createTime\":{$gte:\"2021-01-01\"}} 示例 只对 2021 年 01 月 01 日之后的数据的 createTime 列添加索引\ndb.test.createIndex( {\"createTime\":1}, {partialFilterExpression:{createTime:{$gte:\"2020-01-01\"}}} ) 哈希索引 Hash 结构的索引\n注意事项 创建索引启用 background 参考 创建索引\n索引失效 正则表达式查询 非操作符：$nin，​$not 算数运算符：$mod $where 子句 解决方案\n索引失效添加 hint\n","description":"","tags":["MSB","Database","MongoDB","Java"],"title":"MongoDB 的索引","uri":"/posts/msb/mongodb/"},{"categories":null,"content":"JUC 中新的锁 ReentranLock ReentranLock：可重入锁，是用来替代 synchronized 的。\nReentranLock 和 synchronized 的区别\nsynchronized 有锁升级的过程，ReentranLock 底层是 CAS，不会锁升级。它们两个都是可重入的。 synchronized 加锁之后，当程序执行结束或抛异常后，会自动释放锁；ReentranLock 必须在 finally 中手动释放锁，否则会造成死锁 ReentranLock 有 tryLock 方法，可以进行尝试加锁 ReentranLock 有 lockInterruptibly 方法，可以使用 interrupt 方法来中断获取锁 ReentranLock 可以指定公平锁/非公平锁，synchronized 只有非公平锁 示例\nReentranLock\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 import java.util.concurrent.TimeUnit; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; /** * ReentranLock 是用来替代 synchronized 的 * synchronized 中如果出现异常或者执行结束，jvm 会自动释放锁，但是 lock 必须在 finally 代码块中手动释放锁 */ public class D01_ReentrantLock { Lock lock = new ReentrantLock(); void m1() { lock.lock(); try { for (int i = 0; i \u003c 10; i++) { TimeUnit.SECONDS.sleep(1); System.out.println(i); if (i == 2) { m2(); } } } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } void m2() { lock.lock(); try { System.out.println(\"m2......\"); } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } public static void main(String[] args) { new D01_ReentrantLock().m1(); } } tryLock\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 /** * ReentrantLock 相比 synchronized 还多了 tryLock 方法 * 可以尝试加锁，加锁成功返回 true，否则返回 false */ public class D02_TryLock { Lock lock = new ReentrantLock(); void m1() { lock.lock(); try { for (int i = 0; i \u003c 3; i++) { TimeUnit.SECONDS.sleep(1); System.out.println(i); } } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } /** * 使用 tryLock 进行尝试锁定，不管锁定与否，方法都将继续执行 * 可以根据 tryLock 的返回值来判断是否锁定 * 也可以指定 tryLock 的时间 */ void m2() { // boolean locked = lock.tryLock(); // System.out.println(\"m2... \" + locked); // if (locked) { // lock.unlock(); // } boolean locked = false; try { // 在 5 秒内不断尝试获取锁，只要获取到锁就返回 true，否则返回 false locked = lock.tryLock(5, TimeUnit.SECONDS); System.out.println(\"m2... \" + locked); } catch (InterruptedException e) { e.printStackTrace(); } finally { if (locked) { lock.unlock(); } } } public static void main(String[] args) { D02_TryLock tl = new D02_TryLock(); new Thread(tl::m1).start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } new Thread(tl::m2).start(); } } lockInterruptibly\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 public class D03_LockInterruptibly { static Lock lock = new ReentrantLock(); public static void main(String[] args) { // 线程 1 获取锁之后, 一直 sleep new Thread(() -\u003e { lock.lock(); try { System.out.println(\"t1...\"); TimeUnit.DAYS.sleep(Integer.MAX_VALUE); System.out.println(\"t1 end...\"); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } }).start(); Thread t2 = new Thread(() -\u003e { try { // 线程 2 通过 lockInterruptibly 方法获取锁 lock.lockInterruptibly(); System.out.println(\"t2...\"); } catch (Exception e) { System.out.println(\"t2 interrupted...\"); } finally { lock.unlock(); } }); t2.start(); try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); } // 因为线程 1 一直在 sleep，所以线程 2 是获取不到锁的 // 因为线程 2 使用了 lockInterruptibly 方法获取锁，所以可以通过 interrupt 方法打断线程 2 t2.interrupt(); } } 公平锁\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 /** * 当多个线程在队列中等待获取锁的时候 * \u003cli\u003e公平锁：新来的线程也会进入到队列中进行等待 * \u003cli\u003e非公平锁：新来的线程会直接去抢占该锁 */ public class D04_FairLock { /** 设置使用公平锁 */ Lock lock = new ReentrantLock(true); void m() { for (int i = 0; i \u003c 100; i++) { // 非公平锁：谁抢到锁谁执行，所以是乱序输出 // 公平锁：如果队列中有排队的，那新来的线程也去排队，所以会出现交替输出的现象 // 同时因为多个线程排队也会有争抢，所以也可能出现同一个线程连续输出的情况 lock.lock(); try { System.out.println(Thread.currentThread().getName() + \" 获取到锁\"); } finally { lock.unlock(); } } } public static void main(String[] args) { D04_FairLock fl = new D04_FairLock(); Thread t1 = new Thread(fl::m); Thread t2 = new Thread(fl::m); Thread t3 = new Thread(fl::m); t1.start(); t2.start(); t3.start(); } } CountDownLatch CountDownLatch 代表倒数的门闩，在创建的时候设置一个数值，每当调用一次它的 countDown 方法，就会将该数值减一，直到减到 0 后，await 方法才会向下执行，否则一直阻塞\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import java.util.concurrent.CountDownLatch; public class D01_CountDownLatch { public static void main(String[] args) { Thread[] threads = new Thread[100]; // 创建一个门闩，阈值设置为 100 CountDownLatch latch = new CountDownLatch(threads.length); // 创建 100 个线程，每个线程都执行一次 countDown 方法，就是每个线程结束后对门闩都减 1 for (int i = 0; i \u003c threads.length; i++) { threads[i] = new Thread(() -\u003e { System.out.println(Thread.currentThread().getName() + \" run...\"); latch.countDown(); } ); } // 启动线程 for (Thread thread : threads) { thread.start(); } try { // 让线程阻塞，直到门闩中的值变为0，才向下执行 latch.await(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"latch end...\"); } } CyclicBarrier CyclicBarrier 是循环栅栏。是设置一个阈值，然后通过 await 方法拦截到来的线程，当拦截的线程数到达阈值之后，将这些线程一起放行，然后将栅栏再立起来。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import java.util.concurrent.BrokenBarrierException; import java.util.concurrent.CyclicBarrier; /** * 模拟一个人满发车的场景, 当拦截了20个线程之后, 才将它们一起放行 */ public class D01_CyclicBarrier { public static void main(String[] args) { // CyclicBarrier barrier = new CyclicBarrier(20); // 第一个参数是阈值，当有该阈值个线程到来后，执行第二个参数中的方法，第二个参数是一个 Runnable 的实现类 // 第二个参数也可以不传，代表什么也不做 CyclicBarrier barrier = new CyclicBarrier(20, () -\u003e { System.out.println(\"满人了，发车...\"); }); Thread[] threads = new Thread[100]; for (int i = 0; i \u003c threads.length; i++) { threads[i] = new Thread(() -\u003e { try { // 在线程中调用 await 方法，使得 barrier 拦截当前线程的执行 barrier.await(); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } }); } for (Thread thread : threads) { thread.start(); } } } 应用场景：比如说某个复杂操作，需要查询数据库，还需要访问文件，访问网络，然后才能向下执行，此时就可以使用 CyclicBarrier 并行执行，当这三个步骤都执行完之后，才能向下执行，注意这里的三个步骤是独立的没有依赖关系的， 因为 CyclicBarrier 并不能保证线程的执行顺序\nPhaser Phaser 是阶段锁。所有线程都执行完第一个流程，然后才能开始第二个流程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 import java.util.concurrent.Phaser; /** * Phaser 是阶段锁。所有线程都执行完第一个流程，然后才能开始第二个流程。 * * @author wangshuo * @date 2021/04/06 */ public class D01_Phaser { static class MyPhaser extends Phaser { @Override protected boolean onAdvance(int phase, int registeredParties) { // 要让 Phaser 终止，则返回 true，否则返回 false boolean flag = false; // 第一次调用 arriveAndAwaitAdvance 对应的 phase 就是 0，第二次就是 1，以此类推 switch (phase) { case 0: System.out.println(\"所有线程都执行完了第一阶段，已注册的线程数：\" + registeredParties); break; case 1: System.out.println(\"所有线程都执行完了第二阶段，已注册的线程数：\" + registeredParties); break; case 2: System.out.println(\"所有线程都执行完了第三阶段，已注册的线程数：\" + registeredParties); break; default: flag = true; break; } return flag; } } static class Task implements Runnable { private Phaser phaser; public Task(Phaser phaser) { this.phaser = phaser; } @Override public void run() { t1(); // 等待所有线程都执行到该方法后，会去执行 phaser 的 onAdvance 方法，然后才会一起放行 phaser.arriveAndAwaitAdvance(); t2(); phaser.arriveAndAwaitAdvance(); t3(); phaser.arriveAndAwaitAdvance(); } void t1() { System.out.println(Thread.currentThread().getName() + \" 执行了第一阶段\"); } void t2() { System.out.println(Thread.currentThread().getName() + \" 执行了第二阶段\"); } void t3() { System.out.println(Thread.currentThread().getName() + \" 执行了第三阶段\"); } } public static void main(String[] args) { MyPhaser phaser = new MyPhaser(); Thread[] threads = new Thread[5]; for (int i = 0; i \u003c threads.length; i++) { threads[i] = new Thread(new Task(phaser), \"Thread\" + i); // 单个注册线程数 phaser.register(); } // 可以通过该方法批量注册多个线程数量 // phaser.bulkRegister(threads.length); for (Thread thread : threads) { thread.start(); } } } ReadWriteLock ReadWriteLock 是读写锁，分为读锁和写锁。读锁是共享锁，写锁是排他锁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 import java.util.concurrent.TimeUnit; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReadWriteLock; import java.util.concurrent.locks.ReentrantLock; import java.util.concurrent.locks.ReentrantReadWriteLock; /** * ReadWriteLock 是读写锁，分为读锁和写锁。读锁是共享锁，写锁是排他锁 * \u003cp\u003e * 多线程情况下， * 当一个线程进行写的时候，我们要阻止其他线程进行写和读，防止出现写错误和读到不正确的数据。 * 当一个线程进行读的时候，我们要阻止其他线程进行写，但是不需要阻止其他线程进行读。 * 所以引入了读锁和写锁的概念。 * 读锁允许其他线程也进行读操作，但是不允许其他线程进行写操作。 * 写锁不允许其他线程进行读和写操作。 * 使用读锁可以提高读的效率。 */ public class D01_ReadWriteLock { private static int value; static int read(Lock lock) { lock.lock(); try { TimeUnit.SECONDS.sleep(1); System.out.println(\"read over...\"); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } return value; } static void write(Lock lock, int v) { lock.lock(); try { TimeUnit.SECONDS.sleep(1); value = v; System.out.println(\"write over...\"); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } public static void main(String[] args) { // 排他锁 Lock lock = new ReentrantLock(); // 读写锁 ReadWriteLock readWriteLock = new ReentrantReadWriteLock(); Lock readLock = readWriteLock.readLock(); Lock writeLock = readWriteLock.writeLock(); for (int i = 0; i \u003c 5; i++) { // 如果使用 ReentrantLock，因为它是排他锁，所以 5 个线程要执行 5 秒 // new Thread(() -\u003e read(lock)).start(); // 如果使用读锁，因为读锁是共享锁，所以 5 个线程只需要执行 1 秒 new Thread(() -\u003e read(readLock)).start(); } for (int i = 0; i \u003c 5; i++) { // new Thread(() -\u003e write(lock, (int) (Math.random() * 10))).start(); // 写锁是排他锁，所以 5 个线程要执行 5 秒 new Thread(() -\u003e write(writeLock, (int) (Math.random() * 10))).start(); } } } 多线程情况下，当一个线程进行写的时候，我们要阻止其他线程进行写和读，防止出现写错误和读到不正确的数据。当一个线程进行读的时候，我们要阻止其他线程进行写，但是不需要阻止其他线程进行读。所以引入了读锁和写锁的概念。 读锁允许其他线程也进行读操作，但是不允许其他线程进行写操作。写锁不允许其他线程进行读和写操作。使用读锁可以提高读的效率\nSemaphore Semaphore 是信号量。用来设置允许多少个线程同时执行，可理解为“限流”。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 import java.util.concurrent.Semaphore; import java.util.concurrent.TimeUnit; /** * Semaphore 是信号量。用来设置允许多少个线程同时执行，可理解为“限流”。 */ public class D01_Semaphore { public static void main(String[] args) { // 限流，限制同时只能 2 个线程同时执行 Semaphore s = new Semaphore(2); // 一共启动 10 个线程，每个线程睡 1 秒，所以所有线程执行结束需要 5 秒 Thread[] threads = new Thread[10]; for (int i = 0; i \u003c threads.length; i++) { threads[i] = new Thread(() -\u003e { try { // 从 Semaphore 中获取许可，获取不到就阻塞，直到获取到许可。可以通过 tryAcquire 设置超时时间 s.acquire(); System.out.println(Thread.currentThread().getName() + \" run...\"); TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread().getName() + \" end...\"); } catch (InterruptedException e) { e.printStackTrace(); } finally { // 释放许可 s.release(); } }); } for (Thread thread : threads) { thread.start(); } } } Exchanger Exchanger 是交换器。用于两个线程间交换数据的时候使用的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import java.util.concurrent.Exchanger; /** * Exchanger 是交换器。用于两个线程间交换数据的时候使用的。 */ public class D01_Exchanger { public static void main(String[] args) { Exchanger\u003cString\u003e exchanger = new Exchanger\u003c\u003e(); new Thread(() -\u003e { String s = \"T1\"; try { // exchange 方法是阻塞的，当两个线程间的值进行交换结束后，才会向下执行 s = exchanger.exchange(s); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \" s = \" + s); }, \"T1\").start(); new Thread(() -\u003e { String s = \"T2\"; try { s = exchanger.exchange(s); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \" s = \" + s); }, \"T2\").start(); } } ","description":"","tags":["MSB","JUC","Java"],"title":"JUC 中新的锁","uri":"/posts/msb/juc/juc-newlock/"},{"categories":null,"content":"CAS（Compare And Set），无锁优化/自旋锁 cas(V, Expected, NewValue)\nif(V == E) // 判断原始的值 V 和期望的原始值 E 是否相同 V = N // 如果相等才将结果值 N 赋值给原始值 V otherwise try again or fail // 否则，重新尝试或失败 CAS 是由 CPU 原语（lock cmpxchg）支持的，所以在执行 CAS 的过程时不会被打断。\nJava 中 AtomicInteger.incrementAndGet() 调用 Unsafe.getAndAddInt() 方法，其实现如下\n@HotSpotIntrinsicCandidate public final int getAndAddInt(Object o, long offset, int delta) { int v; do { // 先获取值 v = getIntVolatile(o, offset); // 调用系统的 CAS 操作 } while (!weakCompareAndSetInt(o, offset, v, v + delta)); return v; } 示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 import java.util.ArrayList; import java.util.List; import java.util.concurrent.atomic.AtomicInteger; public class D01_AtomicInteger { private static final int THREAD_NUM = 10; private static final int NUM = 100_000; /** * volatile 可以保证线程间的可见性，但是不能保证原子性，count++ 不是一个原子操作， * 在 JVM 层面，其分为多个步骤，见 {@link CountPlusPlus}，因此会有执行 iadd 后， * 还没有 putfield 时，其他线程就来拿 count 值，然后对其 iadd 后，再次 putfield， * 此时相当于对原来数值进行了两次重复 add，然后 put 回去的数值是相同的，造成两次 * 相加的结果与一次相加的结果相同，从而总数小于 threadNum*num */ private volatile int count; /** * AtomicInteger 的 incrementAndGet() 方法是原子的，并且使用了 CAS 操作， * 如果期望值不符合要求，其会进入自旋状态，直到期望值符合要求时，才将新值写入。 */ private final AtomicInteger atomicCount = new AtomicInteger(0); private void m() { for (int i = 0; i \u003c NUM; i++) { // count++ 不是原子操作 count++; // 增加并获取, 是原子操作 atomicCount.incrementAndGet(); } } public static void main(String[] args) { D01_AtomicInteger d = new D01_AtomicInteger(); List\u003cThread\u003e threads = new ArrayList\u003c\u003e(THREAD_NUM); for (int i = 0; i \u003c THREAD_NUM; i++) { threads.add(new Thread(d::m)); } threads.forEach(Thread::start); threads.forEach(o -\u003e { try { o.join(); } catch (InterruptedException e) { e.printStackTrace(); } }); // 最终 count 的值可能会小于 THREAD_NUM * NUM System.out.println(d.count); // 最终 atomicCount 的值一定为 THREAD_NUM * NUM System.out.println(d.atomicCount); } } class CountPlusPlus { private int count; public void plusMethod() { /* 0 aload_0 1 dup 2 getfield #2 \u003cicu/intelli/c007_casandatomic/CountPlusPlus.count\u003e 5 iconst_1 6 iadd 7 putfield #2 \u003cicu/intelli/c007_casandatomic/CountPlusPlus.count\u003e 10 return */ count++; } } CAS 中的 ABA 问题 CAS 操作时，程序需要先从内存中取出数据（由程序完成，不能保证原子性），然后再进行 CAS 操作（由 CPU 支持，保证原子性），在这两个步骤之间，假设按照如下顺序进行执行，即会发生 ABA 问题。\n线程 1 从内存位置 V 中取出 A 线程 1 进行了写操作，将 B 写入内存位置 V 线程 1 将 A 再次写入内存位置 V 线程 2 从内存位置 V 中取出 A 线程 2 进行 CAS 操作，发现 V 中仍然是 A，交换成功 尽管线程 2 的 CAS 操作成功，但是其并不知道内存位置 V 的数据之前被修改过。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 package icu.intelli.c007_casandatomic; import java.util.concurrent.TimeUnit; import java.util.concurrent.atomic.AtomicInteger; /** * ABA问题 * \u003cli\u003e1. 线程 1 从内存位置V中取出A * \u003cli\u003e2. 线程 1 进行了写操作, 将B写入内存位置V * \u003cli\u003e3. 线程 1 将A再次写入内存位置V * \u003cli\u003e4. 线程 2 从内存位置V中取出A * \u003cli\u003e5. 线程 2 进行CAS操作, 发现V中仍然是A, 交换成功, 线程2在进行CAS时, 不知道V之前被修改过 */ public class D02_ABA { private static final AtomicInteger INDEX = new AtomicInteger(10); public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread(() -\u003e { boolean b = INDEX.compareAndSet(10, 11); System.out.println(Thread.currentThread().getName() + \"：修改结果：\" + b + \", 值为：\" + INDEX.get()); b = INDEX.compareAndSet(11, 10); System.out.println(Thread.currentThread().getName() + \"：修改结果：\" + b + \", 值为：\" + INDEX.get()); }); Thread t2 = new Thread(() -\u003e { try { TimeUnit.MILLISECONDS.sleep(200); } catch (InterruptedException e) { e.printStackTrace(); } boolean b = INDEX.compareAndSet(10, 12); System.out.println(Thread.currentThread().getName() + \"：修改结果：\" + b + \", 值为：\" + INDEX.get()); }); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(Thread.currentThread().getName() + \"：值为：\" + INDEX.get()); } } 解决办法\n加 version，在 Java 中可以使用 AtomicStampedReference\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 /** * 使用 AtomicStampedReference 类，在每次修改时都添加对版本号（stamp）的验证， * 解决 ABA 问题，需要期望值 expectedReference 和期望版本号 expectedStamp 均符合要求才能成功 */ public class D03_AtomicStampedReference { private static final AtomicStampedReference ASR = new AtomicStampedReference(10, 1); public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread(() -\u003e { boolean b = ASR.compareAndSet(10, 11, 1, ASR.getStamp() + 1); System.out.println(Thread.currentThread().getName() + \"：修改结果\" + b + \", 值为：\" + ASR.getReference() + \", 版本号：\" + ASR.getStamp()); b = ASR.compareAndSet(11, 10, 2, ASR.getStamp() + 1); System.out.println(Thread.currentThread().getName() + \"：修改结果\" + b + \", 值为：\" + ASR.getReference() + \", 版本号：\" + ASR.getStamp()); }); Thread t2 = new Thread(() -\u003e { // 只有期望的版本号 expectedStamp 为 3 的时候，才能修改成功 boolean b = ASR.compareAndSet(10, 12, 3, ASR.getStamp() + 1); System.out.println(Thread.currentThread().getName() + \"：修改结果\" + b + \", 值为：\" + ASR.getReference() + \", 版本号：\" + ASR.getStamp()); }); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(Thread.currentThread().getName() + \"值为：\" + ASR.getReference() + \", 版本号：\" + ASR.getStamp()); } } AtomicLong，Synchronized，LongAdder 的比较 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 import java.util.ArrayList; import java.util.List; import java.util.concurrent.atomic.AtomicLong; import java.util.concurrent.atomic.LongAdder; /** * 使用 AtomicLong，Synchronized，LongAdder 对一个数进行递增，对比性能 * \u003cp\u003eLongAdder：将多个线程进行了分组，然后每组内的线程争抢同一个锁，不同组之间使用不同的锁， * 这样每组内线程获取到锁的几率就会高于所有线程争抢同一把锁时的几率，每组线程计算结束后，再将计算结果加到一起， * 得到最终结果. 争抢锁的机制与 AtomicLong 相同，均使用 CAS 操作。当线程数较多时，应该会比 AtomicLong 有更高的效率。 */ public class D04_AtomicLongVsSynchronizedVsLongAdder { private final AtomicLong count1 = new AtomicLong(0); private long count2; private final LongAdder count3 = new LongAdder(); private static final int THREAD_NUM = 1_000; private static final int NUM = 100_000; public static void main(String[] args) { D04_AtomicLongVsSynchronizedVsLongAdder o = new D04_AtomicLongVsSynchronizedVsLongAdder(); List\u003cThread\u003e threads = new ArrayList\u003c\u003e(THREAD_NUM); // ----------Atomic---------- for (int i = 0; i \u003c THREAD_NUM; i++) { threads.add(new Thread(() -\u003e { for (int j = 0; j \u003c NUM; j++) { o.count1.incrementAndGet(); } })); } long start = System.currentTimeMillis(); threads.forEach(Thread::start); threads.forEach(t -\u003e { try { t.join(); } catch (InterruptedException e) { e.printStackTrace(); } }); long end = System.currentTimeMillis(); System.out.println(\"AtomicLong，count1：\" + o.count1 + \"，time：\" + (end - start)); // ----------synchronized---------- threads.clear(); for (int i = 0; i \u003c THREAD_NUM; i++) { threads.add(new Thread(() -\u003e { for (int j = 0; j \u003c NUM; j++) { synchronized (D04_AtomicLongVsSynchronizedVsLongAdder.class) { o.count2++; } } })); } start = System.currentTimeMillis(); threads.forEach(Thread::start); threads.forEach(t -\u003e { try { t.join(); } catch (InterruptedException e) { e.printStackTrace(); } }); end = System.currentTimeMillis(); System.out.println(\"count++，count2：\" + o.count2 + \"，time：\" + (end - start)); // ----------LongAdder---------- threads.clear(); for (int i = 0; i \u003c THREAD_NUM; i++) { threads.add(new Thread(() -\u003e { for (int j = 0; j \u003c NUM; j++) { o.count3.increment(); } })); } start = System.currentTimeMillis(); threads.forEach(Thread::start); threads.forEach(t -\u003e { try { t.join(); } catch (InterruptedException e) { e.printStackTrace(); } }); end = System.currentTimeMillis(); System.out.println(\"LongAdder，count3：\" + o.count3 + \"，time：\" + (end - start)); } } ","description":"","tags":["MSB","JUC","Java"],"title":"CAS（Compare And Set），无锁优化/自旋锁","uri":"/posts/msb/juc/cas-and-atomic/"},{"categories":null,"content":"MarkWord 和 Synchronized 细节 MarkWord 对象在 64 位 HotSpot 虚拟机中的存储方式如下，分为三块区域：对象头，实例数据，对齐填充。\n对象头：对象头占用 12 个字节，包含Mark Word和Class Pointer Mark Word：占用 8 个字节，记录了对象的 HashCode，GC 信息，锁信息 Class Pointer：占用 4 个字节，用于存储对象指向它的类元数据的首地址。 实例数据：存储本类对象的实例成员变量和其所有可见的父类成员变量。 实例成员变量占用空间计算：基本数据类型占用空间与其类型相关，引用数据类型只计算其引用变量的空间（均为 4 个字节）， 静态变量在类加载时即分配内存，所以与实例对象容积无关，方法代码也不占用实例对象的任何空间。 对齐填充：存储空间分配必须是 8 字节的倍数，如果达不到，使用对齐填充补齐。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 /** * 64 位 HotSpot 虚拟机，计算对象占用空间大小的示例 */ public class D01_HotSpotObject { // 对象头最小占用空间 12 个字节 /** 下方 4 个 byte 变量，共 4 个字节 */ byte b1; byte b2; byte b3; byte b4; /** 下方每个引用变量占用 4 个字节，共 20 个字节 */ Object o1; Object o2; Object o3; Object o4; /** RefObjOther 实例占用空间并不计算在本对象内，依然只计算引用变量的大小 4 个字节，共 8 个字节 */ RefObjOther ro1 = new RefObjOther(); RefObjOther ro2 = new RefObjOther(); // 综上,D01_HotSpotObject 对象占用 12+4+20+8=44 个字节 // 取 8 的倍数后是 48 个字节，所以一个 D01_HotSpotObject 对象占用 48 个字节 } class RefObjOther { /** * 这是一个数组引用变量，因此只占用 4 个字节 * 加上对象头的 12 个字节，该对象共占用 16 个字节，不需要对齐填充 */ double[] d = new double[1000]; } JDK8 64 位 HotSpot 的 MarkWord 实现 使用 MarkWord 最低 3 位来标识锁\nJOL（Java Object Layout） 添加依赖\n1 compile group: 'org.openjdk.jol', name: 'jol-core', version: '0.13' 查看对象信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import org.openjdk.jol.info.ClassLayout; /** * 使用JOL, 查看对象在加锁前后的变化, 输出格式是小端输出 */ public class D02_HelloJol { public static void main(String[] args) { Object o = new Object(); System.out.println(ClassLayout.parseInstance(o).toPrintable()); synchronized (o) { System.out.println(ClassLayout.parseInstance(o).toPrintable()); } } } Synchronized 锁升级细节 锁升级过程主线 New -\u003e 偏向锁 -\u003e 轻量级锁（自旋锁） -\u003e 重量级锁\n偏向锁：被 synchronized 修饰的代码段，大部分时间并不会被多线程访问，所以没必要设计竞争机制。 当第一个线程获取到该锁后，就将自己的线程 ID 标记在对象的 MarkWord 上，并将 MarkWord 的最低 3 位设置为 101，即对对象添加了偏向锁。 JDK8 默认没有开启偏向锁，可添加 JVM 参数 -XX:BiasedLockingStartupDelay=0 开启，并设置偏向锁启动的时延（JDK11 默认开启并有 4 秒的时延，因为 JVM 内部包含一些 synchronized 代码块，确认在启动时会有线程竞争，防止在添加偏向锁后因竞争出现锁撤销/锁升级的情况，造成效率降低）\n轻量级锁：也叫自旋锁，当有多个线程轻微竞争同一把锁时，先把偏向锁撤销，每个线程在自己的线程栈中生成一个 LockRecord，然后通过自旋机制争抢锁，抢到锁的线程就将自己的 LockRecord 添加到 MarkWord 中，并将 MarkWord 的最低两位设置为 00。在 JDK1.6 之后添加了自适应自旋机制，由 JVM 来判断竞争的强度和控制自旋次数。\n重量级锁：多线程情况下对锁的竞争激烈时，自旋锁会升级为重量级锁，重量级锁会通过内核获取 Object Monitor，将需要获取该锁的线程放到 Object Monitor 的 WaitSet 中，当某个线程获取到锁后，会撤销偏向锁/自旋锁，然后将 Object Monitor 放到 MarkWord 中，并将 MarkWord 的最低两位设置为 10\n匿名偏向：如果在启动时开启了偏向锁，此时新 NEW 的对象默认是带偏向锁的，但是 MarkWord 中并没有线程 ID，称此状态为匿名偏向。\n示例\n关闭偏向锁（JDK8 默认关闭）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 import org.openjdk.jol.info.ClassLayout; import java.util.concurrent.TimeUnit; /** * 关闭偏向锁（JDK8 默认关闭） * \u003cp\u003eNew -\u003e 普通对象（001） -\u003e 轻量级锁（00） -\u003e 重量级锁（10） */ public class D01_TurnOffBiasLock { public static void main(String[] args) throws InterruptedException { Object o = new Object(); System.out.println(\"普通对象 001 \\n\" + ClassLayout.parseInstance(o).toPrintable()); synchronized (o) { System.out.println(\"轻量级 00 \\n\" + ClassLayout.parseInstance(o).toPrintable()); } Thread t1 = new Thread(() -\u003e { for (int i = 0; i \u003c 5; i++) { if (i \u003c 3) { try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); } } synchronized (o) { System.out.println(\"轻量级锁 00/重量级锁 10 \\n\" + ClassLayout.parseInstance(o).toPrintable()); } } }); Thread t2 = new Thread(() -\u003e { for (int i = 0; i \u003c 5; i++) { if (i \u003c 3) { try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } } synchronized (o) { System.out.println(\"轻量级锁 00/重量级锁 10 \\n\" + ClassLayout.parseInstance(o).toPrintable()); } } }); t1.start(); t2.start(); t1.join(); t2.join(); } } 匿名偏向\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 import org.openjdk.jol.info.ClassLayout; import java.util.concurrent.TimeUnit; /** * 匿名偏向（使用 -XX:BiasedLockingStartupDelay=0 开启偏向锁，并设置延时时间） * \u003cp\u003eNew -\u003e 匿名偏向（101） -\u003e 偏向锁（101） -\u003e 轻量级（00） -\u003e 重量级（10） */ public class D02_AnonymousBiasLock { public static void main(String[] args) throws InterruptedException { Object o = new Object(); // 匿名偏向，101，不存放线程指针 System.out.println(\"匿名偏向 101 \\n\" + ClassLayout.parseInstance(o).toPrintable()); synchronized (o) { // 存放线程指针 System.out.println(\"偏向锁 101 \\n\" + ClassLayout.parseInstance(o).toPrintable()); } Thread t1 = new Thread(() -\u003e { for (int i = 0; i \u003c 5; i++) { if (i \u003c 3) { try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { e.printStackTrace(); } } synchronized (o) { System.out.println(\"轻量级锁 00/重量级锁 10 \\n\" + ClassLayout.parseInstance(o).toPrintable()); } } }); Thread t2 = new Thread(() -\u003e { for (int i = 0; i \u003c 5; i++) { if (i \u003c 3) { try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } } synchronized (o) { System.out.println(\"轻量级锁 00/重量级锁 10 \\n\" + ClassLayout.parseInstance(o).toPrintable()); } } }); t1.start(); t2.start(); t1.join(); t2.join(); } } 延迟启动偏向锁\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * 将偏向锁设置为延迟 10 启动，-XX:BiasedLockingStartupDelay=10，在对象NEW出后15秒对对象加锁， * 预期对象从普通对象变为偏向锁对象，但是结果是普通对象直接变为轻量级锁 * \u003cp\u003eNEW -\u003e 普通对象（001） -\u003e 偏向锁（101） -\u003e 轻量级锁（00） -\u003e 重量级锁（10） */ public class D03_DelayBiasLock { public static void main(String[] args) throws InterruptedException { Object o = new Object(); System.out.println(\"普通对象 001 \\n\" + ClassLayout.parseInstance(o).toPrintable()); TimeUnit.SECONDS.sleep(15); synchronized (o) { System.out.println(\"轻量级 00 \\n\" + ClassLayout.parseInstance(o).toPrintable()); } } } 偏向锁的重偏向机制\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 import org.openjdk.jol.info.ClassLayout; import java.util.ArrayList; import java.util.List; import static java.lang.System.out; /** * 开启偏向锁，-XX:BiasedLockingStartupDelay=4 * \u003cp\u003e使用 -XX:+PrintFlagsFinal 可打印 JVM 默认参数，使用 -XX:BiasedLockingBulkRebiasThreshold 设置批量重偏向的阈值 * \u003cp\u003e当一个线程创建了大量对象并执行了初始的操作，后来另一个线程也来将这些对象作为锁对象进行操作，就会触发重偏向 * \u003cp\u003e因为同一个线程中，使用偏向锁的开销很小，如果一个线程多次使用同一个类的对象作为锁，则将该锁偏向该线程，可以提高性能 */ public class D04_BulkRebias { private static class A { } public static void main(String[] args) throws Exception { // 延时产生可偏向对象 Thread.sleep(5000); // 创造 100 个偏向线程 t1 的偏向锁 List\u003cA\u003e listA = new ArrayList\u003c\u003e(); Thread t1 = new Thread(() -\u003e { for (int i = 0; i \u003c 100; i++) { A a = new A(); synchronized (a) { listA.add(a); } } try { // 为了防止 JVM 线程复用，在创建完对象后，保持线程 t1 状态为存活 Thread.sleep(100000000); } catch (InterruptedException e) { e.printStackTrace(); } }); t1.start(); // 睡眠 3s 钟保证线程 t1 创建对象完成 Thread.sleep(3000); out.println(\"打印t1线程，list中第20个对象的对象头：\"); // 🚀此时 list 中应该都是偏向 t1 的偏向锁 -101 out.println((ClassLayout.parseInstance(listA.get(19)).toPrintable())); // 创建线程 t2 竞争线程 t1 中已经退出同步块的锁 Thread t2 = new Thread(() -\u003e { // 这里面只循环了 30 次！！！ for (int i = 0; i \u003c 30; i++) { A a = listA.get(i); synchronized (a) { // 分别打印第 19 次和第 20 次偏向锁重偏向结果 if (i == 18 || i == 19 || i == 29) { // 🚀第 19 个应该是轻量级锁 00，第 20 个开始到第 30 个都是偏向 t2 的偏向锁 out.println(\"第\" + (i + 1) + \"次偏向结果\"); out.println((ClassLayout.parseInstance(a).toPrintable())); } } } try { Thread.sleep(10000000); } catch (InterruptedException e) { e.printStackTrace(); } }); t2.start(); Thread.sleep(3000); out.println(\"打印 list 中第 11 个对象的对象头：\"); // 🚀前 20 个对象应该是普通对象，因为该值没有达到重偏向的阈值，线程 t2 释放同步锁后，转为无锁状态 out.println((ClassLayout.parseInstance(listA.get(10)).toPrintable())); out.println(\"打印 list 中第 26 个对象的对象头：\"); // 🚀第 20-31 个应该是偏向 t2 的偏向锁，因为超过了重偏向阈值，触发了批量重偏向 out.println((ClassLayout.parseInstance(listA.get(25)).toPrintable())); // 🚀第 31 个之后应该是偏向 t1 的偏向锁，因为超过了 t2 中 for 循环的次数 30，没有触发批量重偏向 out.println(\"打印 list 中第 32 个对象的对象头：\"); out.println((ClassLayout.parseInstance(listA.get(30)).toPrintable())); } } 偏向锁的批量撤销机制\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 import org.openjdk.jol.info.ClassLayout; import java.util.ArrayList; import java.util.List; import static java.lang.System.out; /** * 开启偏向锁，-XX:BiasedLockingStartupDelay=4 * \u003cp\u003e使用 -XX:+PrintFlagsFinal 可打印 JVM 默认参数，使用 -XX:BiasedLockingBulkRevokeThreshold 设置批量锁撤销的阈值 * \u003cp\u003e在多线程竞争剧烈的情况下，使用偏向锁将会降低效率，于是乎产生了批量撤销机制 */ public class D05_BulkRevoke { private static class A { } public static void main(String[] args) throws Exception { Thread.sleep(5000); List\u003cA\u003e listA = new ArrayList\u003c\u003e(); Thread t1 = new Thread(() -\u003e { for (int i = 0; i \u003c 100; i++) { A a = new A(); synchronized (a) { listA.add(a); } } try { Thread.sleep(100000000); } catch (InterruptedException e) { e.printStackTrace(); } }); t1.start(); Thread.sleep(3000); Thread t2 = new Thread(() -\u003e { // 这里循环了40次。达到了批量撤销的阈值 for (int i = 0; i \u003c 40; i++) { A a = listA.get(i); synchronized (a) { } } try { Thread.sleep(10000000); } catch (InterruptedException e) { e.printStackTrace(); } }); t2.start(); // ———————————分割线，前面代码不再赘述——————————— Thread.sleep(3000); out.println(\"打印 list 中第 11 个对象的对象头：\"); // 🚀前 20 个应该是普通对象，没有达到重偏向阈值，t2同步块结束后，变为无锁状态 out.println((ClassLayout.parseInstance(listA.get(10)).toPrintable())); out.println(\"打印 list 中第 26 个对象的对象头：\"); // 🚀第 20-40 应该是偏向 t2 的重偏向，达到了重偏向阈值，触发了重偏向 out.println((ClassLayout.parseInstance(listA.get(25)).toPrintable())); out.println(\"打印 list 中第 90 个对象的对象头：\"); // 🚀第 40-100 应该是偏向 t1 的偏向状态，超过了 t2 中 for 循环的 40，没有触发重偏向 out.println((ClassLayout.parseInstance(listA.get(89)).toPrintable())); Thread t3 = new Thread(() -\u003e { for (int i = 20; i \u003c 40; i++) { A a = listA.get(i); synchronized (a) { if (i == 20 || i == 22) { out.println(\"thread3 第\" + i + \"次\"); // 🚀第 20-40 个已经是重偏向状态，并且 t2 循环了 40 次已经达到了批量锁撤销的阈值，此时触发批量撤销，锁膨胀为轻量级锁 out.println((ClassLayout.parseInstance(a).toPrintable())); } } } }); t3.start(); Thread.sleep(10000); out.println(\"重新输出新实例 A\"); // 🚀本应该为可偏向状态偏向锁的新对象，在经历过批量重偏向和批量撤销后直接在实例化后转为无锁 out.println((ClassLayout.parseInstance(new A()).toPrintable())); } } 使用 JOL 工具输出对象信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import org.openjdk.jol.info.ClassLayout; /** * 使用 JOL，查看对象在加锁前后的变化，输出格式是小端输出 */ public class D02_HelloJol { public static void main(String[] args) { Object o = new Object(); System.out.println(ClassLayout.parseInstance(o).toPrintable()); synchronized (o) { System.out.println(ClassLayout.parseInstance(o).toPrintable()); } } } 使用 JDK8 编译运行的输出结果：JDK8 默认是没有开启偏向锁的，对象 NEW 出来后默认是无锁的，使用 synchronized 加锁后，首先添加了轻量级锁\njava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE // 001: 无锁 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external = 4 bytes total java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE // 000: 轻量级锁 0 4 (object header) 70 99 3c cf (01110000 10011001 00111100 11001111) (-818112144) 4 4 (object header) 3c 7f 00 00 (00111100 01111111 00000000 00000000) (32572) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external = 4 bytes total 使用 JDK11 编译运行的输出结果：JDK11 默认是开启偏向锁的，对象 NEW 出来后就是匿名偏向，只有一个线程访问时添加 synchronized，依旧是偏向锁\njava.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE // 101: 偏向锁 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 00 10 00 00 (00000000 00010000 00000000 00000000) (4096) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external = 4 bytes total java.lang.Object object internals: ","description":"","tags":["MSB","JUC","Java"],"title":"MarkWord 和 Synchronized 细节","uri":"/posts/msb/juc/markword-and-synchronized-detail/"},{"categories":null,"content":"synchronized 简介 示例 对象锁\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /** * synchronized 使用创建的 Object 对象作为锁 */ public class D01_LockObject { private int count; private Object o = new Object(); public void m() { synchronized (o) { count++; System.out.println(Thread.currentThread().getName() + \", count=\" + count); } } } this 锁\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 /** * 每次都 new 一个对象作为锁太麻烦, 所以 synchronized 可以把 this 作为锁 */ public class D02_LockThis { private int count; public void m() { synchronized (this) { count++; System.out.println(Thread.currentThread().getName() + \", count=\" + count); } } } 方法锁\n1 2 3 4 5 6 7 8 9 10 11 12 /** * 如果整个方法都需要上锁, 可以直接将 synchronized 加在方法定义上, 锁定的依旧是 this */ public class D03_LockThisMethod { private int count; public synchronized void m() { count++; System.out.println(Thread.currentThread().getName() + \", count=\" + count); } } 静态方法锁\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * 对于静态方法，是没有this的，此时在方法上添加 synchronized 锁定的是当前类对应的 Class 对象 * \u003cp\u003e * 问题：T.class 是单例的吗？ * \u003cp\u003e * 在同一个 ClassLoader 空间中，T.class 是单例的。在不同的 ClassLoader 空间就是多例的。 * 而不同 ClassLoader 是不能互相访问的，所以 T.class 一定是单例的。 * */ public class D04_LockStaticMethod { private static int count; // 等同于 synchronized(D04_LockStaticMethod.class) public static synchronized void m() { count++; System.out.println(Thread.currentThread().getName() + \", count=\" + count); } } count++ 不是原子操作\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /** * 如果不在 run 方法上加 synchronized，程序输出结可能会小于 sum，添加后可以解决 * \u003cp\u003e因为 count++ 不是一个原子操作 */ public class D05_CountPlusPlus implements Runnable { private static final int sum = 100000; private int count; @Override public synchronized void run() { count++; System.out.println(Thread.currentThread().getName() + \", count=\" + count); } public static void main(String[] args) { D05_CountPlusPlus cpp = new D05_CountPlusPlus(); for (int i = 0; i \u003c sum; i++) { new Thread(cpp).start(); } } } 同步方法和非同步方法可以同时调用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 /** * 同步方法和非同步方法可以同时调用 */ public class D06_NormalMethod { private synchronized void syncMethod() { System.out.println(\"syncMethod run...\"); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"syncMethod end...\"); } private void normalMethod() { System.out.println(\"normalMethod run...\"); try { Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"normalMethod end...\"); } public static void main(String[] args) { D06_NormalMethod m = new D06_NormalMethod(); /*new Thread(() -\u003e m.syncMethod()).start(); new Thread(() -\u003e m.normalMethod()).start();*/ new Thread(m::syncMethod, \"t1\").start(); new Thread(m::normalMethod, \"t2\").start(); } } 脏读\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 /** * 模拟银行账户，其中一个线程对账户的余额进行修改，另一线程获取余额， * 对写方法添加了锁，对读方法不加锁，所以会出现脏读的情况，也是普通方法和同步方法同时调用 * 如需解决，在将读方法也加锁即可。 */ public class D07_Account { /** 余额 */ private int balance; private /*synchronized*/ int getBalance() { return this.balance; } private synchronized void setBalance(int balance) { try { Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } this.balance = balance; } public static void main(String[] args) throws InterruptedException { D07_Account account = new D07_Account(); new Thread(() -\u003e account.setBalance(1000)).start(); Thread.sleep(1000); System.out.println(account.getBalance()); Thread.sleep(3000); System.out.println(account.getBalance()); } } 可重入锁\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /** * 一个同步方法可以调用另一个同步方法，一个线程已经拥有某个对象的锁，再次申请的时候仍会得到该对象的锁 * \u003cp\u003e * 所以说 synchronized 是可重入的 */ public class D08_Reentry { private synchronized void m1() { System.out.println(\"m1 run......\"); m2(); } private synchronized void m2() { System.out.println(\"m2 run......\"); } public static void main(String[] args) { new D08_Reentry().m1(); } } 继承关系的重入锁\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 /** * 子类重写父类方法，均带锁， * 因为 synchronized 是可重入的，所以可以在子类方法中调用父类方法； * 如果不可重入，则会死锁 */ public class D09_Extends { static class Parent { protected synchronized void method() { System.out.println(\"parent method run...\"); System.out.println(\"parent method end...\"); } } static class Son extends Parent { @Override protected synchronized void method() { System.out.println(\"son method run...\"); super.method(); System.out.println(\"son method end...\"); } } public static void main(String[] args) { new Son().method(); } } 异常释放锁\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 /** * 当线程在执行同步方法过程中抛出了异常，会释放锁，此时其他线程就会进入同步代码区，可能访问到共享资源，因此在同步区中要谨慎处理异常 */ public class D10_Exception { private int count; private synchronized void method() { for (int i = 0; i \u003c 5; i++) { System.out.println(Thread.currentThread().getName() + \", count=\" + count++); if (i == 3) { // 此处抛出异常，锁将会被释放，要想不被释放，可以在这里进行 try-catch，然后让循环继续 int e = 1 / 0; } } } public static void main(String[] args) { D10_Exception d10 = new D10_Exception(); for (int i = 0; i \u003c 3; i++) { new Thread(() -\u003e d10.method()).start(); } } } 底层实现 jdk 早期的时候，synchronized 使用的是 重量级锁，每个线程都要去操作系统那申请锁，造成高并发时效率很低。所以，后期的 HotSpot 对 synchronized 使用 锁升级 的机制。\n锁升级：第一个访问锁的线程，会在该锁对象的 markword 中记录该线程（偏向锁），当有其他线程来竞争这把锁的时候，就升级为 自旋锁，即将这些线程放到一个队列中，然后使用 while 循环进行对锁的获取，此时是在用户空间的，在自旋锁转了十次以后还没有获取到锁，就会将锁升级为 重量级锁，由内核来分配锁。\n参考文档：深入并发-Synchronized\n需要注意，并不是自旋锁就一定比重量级锁效率高，要分情况\n加锁代码执行时间短，线程数少，使用自旋锁 加锁代码执行时间长，线程数多，用重量级锁 原因\n自旋锁：while 循环占用 cpu，但是不存在用户态内核态切换 重量级锁：将线程放入内核的等待队列，由内核进行调度，不占用 cpu，但是有一次状态的切换 ","description":"","tags":["MSB","JUC","Java"],"title":"synchronized 简介","uri":"/posts/msb/juc/synchronized/"},{"categories":null,"content":"volatile 简介 volatile 的作用 1. 保证线程可见性\nHotSpot 虚拟机中堆内存是线程共享的，同时每个线程都有自己的工作区域，当线程对共享内存中的数据进行操作时，是先将其 copy 到自己的工作区域中一份，然后先在自己工作区域对该数据进行修改，然后再写会共享区域，这就可能出现，A 线程对数据进行了修改，但是还没有写回堆内存，B 线程就已经读取了旧的数据，这是不可行的，使用 volatile 可以保证 A 线程对数据进行了修改，其他线程立马可以对自己工作区域的数据进行更新。\n该特性的本质是依赖于 CPU 底层的缓存一致性协议（MESI）\n2. 禁止指令重排序\nCPU 早期的时候对指令是一条一条按顺序执行的，现代 CPU 为了提高效率，会把指令并发的执行，即一条指令执行一半，就去执行另一条指令了，这叫做流水线式的执行。\n一行 Java 代码通常会被 JVM 解析为多条 CPU 指令进行执行，因为 CPU 会乱序执行，所以在多线程的情况下，对一行 Java 代码的执行也可能出现问题。使用 volatile 标注的属性，可以让 CPU 按顺序执行与该属性相关的语句。\n示例代码 线程可见性\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 /** * A，B 两个线程都要使用到一个共享变量，Java 默认是在 A，B 线程中均保留一份 copy，这样，如果 B 线程对该变量进行了修改，A 线程未必会知道，使用 `volatile`，可以让所有线程得到被修改的值（保证线程可见性） * \u003cp\u003e不加 volatile, 程序不会执行到 m stop, 加 volatile 后, 才会在 1s 后执行 m stop */ public class D01_HelloVolatile { private /*volatile*/ boolean running = true; private void m() { System.out.println(\"m run...\"); while (running) { } System.out.println(\"m stop...\"); } public static void main(String[] args) { D01_HelloVolatile t = new D01_HelloVolatile(); new Thread(() -\u003e t.m()).start(); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } t.running = false; } } 禁止指令重排序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 public class D04_CmdReordering { /** 给 a 和 b 加上 volatile，即可保证代码按顺序执行 */ private static /* volatile */ int a; private static /* volatile */ int b; private static int x; private static int y; public static void main(String[] args) throws InterruptedException { long s = System.currentTimeMillis(); for (int i = 0; ; i++) { Thread t1 = new Thread(() -\u003e { a = 1; x = b; }); Thread t2 = new Thread(() -\u003e { b = 1; y = a; }); t1.start(); t2.start(); t1.join(); t2.join(); /* 预期只会出现 3 种情况： 1. t1 先执行完，t2 再执行：a = 1, x = 0, b = 1, y = 1 2. t2 先执行完，t1 再执行：b = 1, y = 0, a = 1, x = 1 3. t1，t2 交替执行：a = 1, b = 1, x = 1, y = 1 上述 3 种情况不会出现 x 和 y 均为 0 的情况，但由于 CPU 的乱序执行，就会出现 x = y = 0 的情况 */ if (x == 0 \u0026\u0026 y == 0) { long e = System.currentTimeMillis(); System.out.printf(\"执行了 %d 次，耗时：%f 秒，x = %d, y = %d\", i, (e - s) / 1000.0, x, y); break; } // 每次执行后重置 a，b，x，y 为 0 a = b = x = y = 0; } } } 双重检查锁（Double Check Lock）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 /** * 单例模式（双重检查锁 DCL） * \u003cp\u003e面试题：DCL 单例模式，是否需要添加 volatile * \u003cp\u003e答案：DCL 单例模式必须添加volatile * \u003cp\u003e解析: 查看{@link NewObject}, 如果不加 volatile，A 线程拿到锁正在执行 new D05_SingletonV5()， * 此时其执行的 3 个指令可能是乱序的，如果先执行了 astore_1，然后再执行 invokespecial，在 A 执行完 astore_1 时， * B 线程执行了 if(INSTANCE == null) 的判断，此时返回的是 false，此时 B 线程就会拿到一个没有初始化完成的 INSTANCE 对象。 * 所以，一定要加 volatile，禁止初始化 INSTANCE 时指令重排序，保证对象初始化完成后，才将引用和对象进行连接。 */ public class D05_SingletonV5 { private volatile static D05_SingletonV5 INSTANCE; private D05_SingletonV5() { } public static D05_SingletonV5 getInstance() { if (INSTANCE == null) { synchronized (D05_SingletonV5.class) { if (INSTANCE == null) { INSTANCE = new D05_SingletonV5(); } } } return INSTANCE; } } /** * 使用 jclasslib 查看 NewObject.class 文件，可以看到 new 一个对象的时候在 JVM 中是主要分为 3 个步骤的： * \u003cli\u003e1. 给指令申请内存：new * \u003cli\u003e2. 给成员变量初始化：invokespecial * \u003cli\u003e3. 把这块内存的内容赋值给对象：astore_1 */ class NewObject { public static void main(String[] args) { /* 0 new #2 \u003cjava/lang/Object\u003e 3 dup 4 invokespecial #1 \u003cjava/lang/Object.\u003cinit\u003e\u003e 7 astore_1 8 return */ Object o = new Object(); } } ","description":"","tags":["MSB","JUC","Java"],"title":"volatile 简介","uri":"/posts/msb/juc/volatile/"},{"categories":null,"content":"Git 修改已经提交的用户名和邮箱 1 git rebase -i HEAD~n 把 pick 修改为 e\n1 git commit --amend --author=\"userName \u003cxxx@qq.com\u003e\" 1 git rebase --continue ","description":"","tags":["Git"],"title":"Git 修改已经提交的用户名和邮箱","uri":"/posts/git/git-modify-committed-user-and-email/"},{"categories":null,"content":"分布式锁 模拟司机抢单场景，用户向司机服务发送请求，司机服务调用订单服务集群，订单服务需要对订单状态进行修改\nOrderController\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @RestController @RequestMapping(\"/order\") public class OrderController { // 无锁 //@Qualifier(\"noLockService\") // JVM 锁 //@Qualifier(\"jvmLockService\") // MySQL 锁 //@Qualifier(\"mySqlLockService\") // Redis 锁 //@Qualifier(\"redisLockService\") // Redisson //@Qualifier(\"redissonLockService\") // 红锁 //@Qualifier(\"redissonRedLockService\") // redis lua 脚本 //@Qualifier(\"redisLuaLockService\") // redis aop @Qualifier(\"redisAopLockService\") @Autowired private OrderService orderService; @GetMapping(\"/grab\") public String grab(@RequestParam Integer driverId) { System.out.println(\"司机：\" + driverId + \" 开始抢单\"); Boolean grab = orderService.grab(1, driverId); System.out.println(\"司机：\" + driverId + \" 抢单\" + (Objects.equals(true, grab) ? \"成功\" : \"失败\")); return \"end\"; } } 不同锁方式 不加锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Service(\"noLockService\") public class NoLockServiceImpl implements OrderService { @Autowired private TblOrderDAO tblOrderDAO; @Override public Boolean grab(Integer orderId, Integer driverId) { System.out.println(\"司机：\" + driverId + \" 执行抢单逻辑\"); TblOrder tblOrder = tblOrderDAO.selectByPrimaryKey(orderId); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } if (tblOrder.getStatus() == 0) { tblOrder.setStatus((byte) 1); tblOrderDAO.updateByPrimaryKey(tblOrder); return true; } return false; } } 不加锁，启动单个项目也会出现同一个订单，被多个司机抢走的情况\nJVM 锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 @Service(\"jvmLockService\") public class JvmLockServiceImpl implements OrderService { @Autowired private TblOrderDAO tblOrderDAO; @Override public Boolean grab(Integer orderId, Integer driverId) { // 加 jvm 锁 synchronized (this) { System.out.println(\"司机：\" + driverId + \" 执行抢单逻辑\"); // 模拟查询出同一个订单 TblOrder tblOrder = tblOrderDAO.selectByPrimaryKey(orderId); try { // 模拟其他业务耗时 TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } // status=0 表示没有被抢走 if (tblOrder.getStatus() == 0) { // 修改状态为已被抢 tblOrder.setStatus((byte) 1); tblOrderDAO.updateByPrimaryKey(tblOrder); return true; } return false; } } } 使用 JVM 锁，可以保证单个项目没问题，但是如果是集群，则依旧会出现多个司机抢走同一单的情况\nMySQL 锁 创建一个数据表 tbl_order_driver_lock\n使用 orderId 作为主键。\n当某个线程能把某个 orderId 插入进数据表的时候，就表明其获取到了锁。\n由于主键约束，其他线程不能再将相同 orderId 的记录插入到表\n1 2 3 4 5 6 7 create table tbl_order_driver_lock ( orderId int not null comment '订单 ID 作为主键，利用主键约束来保证不会重复插入' primary key, driverId int null comment '司机 Id' ) comment '订单表和司机的锁表'; 自己写一个 MySQL 锁类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 @Data @Component public class MySqlLock implements Lock { private ThreadLocal\u003cTblOrderDriverLock\u003e threadLocal; @Autowired private TblOrderDriverLockDAO tblOrderDriverLockDAO; /** * 阻塞式获取锁 */ @Override public void lock() { while (!tryLock()) { } } /** * 非阻塞式获取锁 * * @return 获取到锁返回 true，否则返回 false */ @Override public boolean tryLock() { try { TblOrderDriverLock tblOrderDriverLock = threadLocal.get(); tblOrderDriverLockDAO.insertSelective(tblOrderDriverLock); return true; } catch (Exception e) { return false; } } /** * 带超时时间的非阻塞式获取锁 * * @param time 超时时间 * @param unit 时间单位 * @return 获取到锁返回 true，超时没有获取到锁返回 true * @throws InterruptedException */ @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException { long deadline = System.currentTimeMillis() + unit.toMillis(time); while (!tryLock()) { if (System.currentTimeMillis() \u003e deadline) { return false; } TimeUnit.MILLISECONDS.sleep(10); } return true; } /** * 解锁 */ @Override public void unlock() { tblOrderDriverLockDAO.deleteByPrimaryKey(threadLocal.get().getOrderid()); threadLocal.remove(); } @Override public void lockInterruptibly() throws InterruptedException { } @Override public Condition newCondition() { return null; } } 在业务中使用 MySQL 锁\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 @Service(\"mySqlLockService\") public class MySqlLockServiceImpl implements OrderService { @Autowired private TblOrderDAO tblOrderDAO; private ThreadLocal\u003cTblOrderDriverLock\u003e threadLocal = new ThreadLocal\u003c\u003e(); @Autowired private MySqlLock mySqlLock; @Override public Boolean grab(Integer orderId, Integer driverId) { // 1. 生成 锁 TblOrderDriverLock lock = new TblOrderDriverLock(); lock.setOrderid(orderId); lock.setDriverid(driverId); threadLocal.set(lock); mySqlLock.setThreadLocal(threadLocal); // 上锁 mySqlLock.lock(); try { System.out.println(\"司机：\" + driverId + \" 执行抢单逻辑\"); TblOrder tblOrder = tblOrderDAO.selectByPrimaryKey(orderId); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } if (tblOrder.getStatus() == 0) { tblOrder.setStatus((byte) 1); tblOrderDAO.updateByPrimaryKey(tblOrder); return true; } return false; } finally { // 解锁 mySqlLock.unlock(); } } } 并发量小的时候可以用，并发量高不要用，性能低。\n还需要添加一个触发器，用来定时将长时间存在 tbl_order_driver_lock 表中的记录删除。因为可能某个线程获取到锁后，数据库宕机了，这样该线程释放锁的时候就没法将该记录删除，导致该订单没有被抢到，同时其他线程也没法获取到这个订单的锁\nRedis 锁 Redis 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 @Service(\"redisLockService\") public class RedisLockServiceImpl implements OrderService { @Autowired private TblOrderDAO tblOrderDAO; @Autowired private RedisTemplate\u003cString, Object\u003e redisTemplate; @Override public Boolean grab(Integer orderId, Integer driverId) { // 1. 生成锁 String lockKey = \"grab_order_\" + orderId; String lockVal = String.valueOf(driverId); // 2. 插入锁 int timeout = 10; TimeUnit unit = TimeUnit.MINUTES; Boolean lockStatus = redisTemplate.opsForValue().setIfAbsent(lockKey, lockVal, timeout, unit); if (lockStatus == null || !lockStatus) { // 加锁失败，返回 false return false; } // 使用守护线程，定时对 key 续期 // TODO 此处可使用线程池进行优化 Thread t = new Thread(() -\u003e { while(true){ Object val = redisTemplate.opsForValue().get(lockKey); if (lockVal.equals(val)) { int sleepTime = timeout / 3; try { unit.sleep(sleepTime); } catch (InterruptedException e) { e.printStackTrace(); } if(redisTemplate.hasKey(lockKey)){ redisTemplate.expire(lockKey, timeout, unit); } } } }); t.setDaemon(true); t.start(); // 3. 业务代码 try { System.out.println(\"司机：\" + driverId + \" 执行抢单逻辑\"); TblOrder tblOrder = tblOrderDAO.selectByPrimaryKey(orderId); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } if (tblOrder.getStatus() == 0) { tblOrder.setStatus((byte) 1); tblOrderDAO.updateByPrimaryKey(tblOrder); return true; } return false; } finally { // 4. 释放锁，此处判断防止释放掉别人加的锁 if (lockVal.equals(redisTemplate.opsForValue().get(lockKey))) { redisTemplate.delete(lockKey); } } } } 注意事项：\n在插入锁的时候，一定要使用原子性操作来设置过期时间，防止过期时间设置失败\n释放锁的时候一定要进行判断，防止释放掉别人加的锁，val 可以是业务中的数据等\n要使用守护线程对锁进行续期，防止业务执行时间超过锁过期时间，释放掉别人加的锁\n例如抢单业务，设置了锁失效时间是 10 分钟，第一个抢到锁的线程执行了 12 分钟，在 10 分钟的时候锁失效了，所以另一个线程也抢到了同一个订单，并加了自己的锁，等 12 分钟的时候，第一个线程释放锁，如果不加判断，就会释放掉后面线程给加的锁\n该方式在生产环境不推荐使用，仅用于面试\nRedission 引入依赖\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003eorg.redisson\u003c/groupId\u003e \u003cartifactId\u003eredisson-all\u003c/artifactId\u003e \u003cversion\u003e3.15.0\u003c/version\u003e \u003c/dependency\u003e 配置 Redisson\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import org.redisson.Redisson; import org.redisson.api.RedissonClient; import org.redisson.config.Config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class RedissonConfig { @Bean public RedissonClient redissonClient() { Config config = new Config(); config.useSingleServer() .setAddress(\"redis://localhost:6379\") .setDatabase(0); return Redisson.create(config); } } 业务代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @Service(\"redissonLockService\") public class RedissonLockServiceImpl implements OrderService { @Autowired private TblOrderDAO tblOrderDAO; @Autowired private RedissonClient redissonClient; @Override public Boolean grab(Integer orderId, Integer driverId) { // 1. 生成锁 String lockKey = \"grab_order_\" + orderId; RLock lock = redissonClient.getLock(lockKey); try { // 2. 加锁。默认的超时时间是 30 秒，每过 1/3 x 30 秒会自动续期 lock.lock(); // 3. 业务代码 System.out.println(\"司机：\" + driverId + \" 执行抢单逻辑\"); TblOrder tblOrder = tblOrderDAO.selectByPrimaryKey(orderId); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } if (tblOrder.getStatus() == 0) { tblOrder.setStatus((byte) 1); tblOrderDAO.updateByPrimaryKey(tblOrder); return true; } return false; } finally { // 4. 释放锁 lock.unlock(); } } } Redission 红锁 引入依赖\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003eorg.redisson\u003c/groupId\u003e \u003cartifactId\u003eredisson-all\u003c/artifactId\u003e \u003cversion\u003e3.15.0\u003c/version\u003e \u003c/dependency\u003e 配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import org.redisson.Redisson; import org.redisson.api.RedissonClient; import org.redisson.config.Config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class RedissonRedLockConfig { @Bean public RedissonClient redissonRedClient1() { Config config = new Config(); config.useSingleServer() .setAddress(\"redis://127.0.0.1:6379\") .setDatabase(0); return Redisson.create(config); } @Bean public RedissonClient redissonRedClient2() { Config config = new Config(); config.useSingleServer() .setAddress(\"redis://127.0.0.1:6479\") .setDatabase(0); return Redisson.create(config); } @Bean public RedissonClient redissonRedClient3() { Config config = new Config(); config.useSingleServer() .setAddress(\"redis://127.0.0.1:6579\") .setDatabase(0); return Redisson.create(config); } } 业务代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 @Service(\"redissonRedLockService\") public class RedissonRedLockServiceImpl implements OrderService { @Autowired private TblOrderDAO tblOrderDAO; @Autowired @Qualifier(\"redissonRedClient1\") private RedissonClient redissonRedClient1; @Autowired @Qualifier(\"redissonRedClient2\") private RedissonClient redissonRedClient2; @Autowired @Qualifier(\"redissonRedClient3\") private RedissonClient redissonRedClient3; @Override public boolean grab(Integer orderId, Integer driverId) { // 1. 生成锁 String lockKey = \"grab_order_\" + orderId; // 2. 红锁 RLock lock1 = redissonRedClient1.getLock(lockKey); RLock lock2 = redissonRedClient2.getLock(lockKey); RLock lock3 = redissonRedClient3.getLock(lockKey); RedissonRedLock redLock = new RedissonRedLock(lock1, lock2, lock3); try { // 3. 加锁。默认的超时时间是 30 秒，每过 1/3 x 30 秒会自动续期 redLock.lock(); // 4. 业务代码 System.out.println(\"司机：\" + driverId + \" 执行抢单逻辑\"); TblOrder tblOrder = tblOrderDAO.selectByPrimaryKey(orderId); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } if (tblOrder.getStatus() == 0) { tblOrder.setStatus((byte) 1); tblOrderDAO.updateByPrimaryKey(tblOrder); return true; } return false; } finally { // 5. 释放锁 redLock.unlock(); } } } 使用了 3 台独立的 redis，也可以自己扩容，但是必须是奇数个\nRedis Lua 脚本 RedisTemplate 执行 lua 脚本的时候，lua 脚本中的代码是原子性的\nset 锁的 lua 脚本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 --- 获取 key local key = KEYS[1] --- 获取 value local val = KEYS[2] --- 获取一个参数 local expire = ARGV[1] --- 如果 redis 找不到这个 key 就去插入 if redis.call(\"get\", key) == false then --- 如果插入成功，就去设置过期值 if redis.call(\"set\", key, val) then --- 由于 lua 脚本接收到参数都会转为 String，所以要转成数字类型才能比较 if tonumber(expire) \u003e 0 then --- 设置过期时间 redis.call(\"expire\", key, expire) end return true end return false else return false end 删除锁的 lua 脚本\n1 2 3 4 5 if redis.call(\"get\", KEYS[1]) == ARGV[1] then return redis.call(\"del\", KEYS[1]) else return 0 end lua 脚本配置类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.io.ClassPathResource; import org.springframework.data.redis.core.script.DefaultRedisScript; import org.springframework.scripting.support.ResourceScriptSource; @Configuration public class RedisLuaConfig { @Bean(name = \"redisSetScript\") public DefaultRedisScript\u003cBoolean\u003e redisSetScript() { DefaultRedisScript\u003cBoolean\u003e redisScript = new DefaultRedisScript\u003c\u003e(); redisScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(\"luascript/lock-set.lua\"))); redisScript.setResultType(Boolean.class); return redisScript; } @Bean(name = \"redisDelScript\") public DefaultRedisScript\u003cBoolean\u003e redisDelScript() { DefaultRedisScript\u003cBoolean\u003e redisScript = new DefaultRedisScript\u003c\u003e(); redisScript.setScriptSource(new ResourceScriptSource(new ClassPathResource(\"luascript/lock-del.lua\"))); redisScript.setResultType(Boolean.class); return redisScript; } } 业务代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 package com.example.dlorder.service.impl; import com.example.dlorder.dao.TblOrderDAO; import com.example.dlorder.entity.TblOrder; import com.example.dlorder.service.OrderService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.core.script.DefaultRedisScript; import org.springframework.stereotype.Service; import java.util.Arrays; import java.util.List; import java.util.concurrent.TimeUnit; /** * @author wangshuo * @date 2021/03/26 */ @Service(\"redisLuaLockService\") public class RedisLuaLockServiceImpl implements OrderService { @Autowired private TblOrderDAO tblOrderDAO; @Autowired @Qualifier(\"redisSetScript\") private DefaultRedisScript\u003cBoolean\u003e redisSetScript; @Autowired @Qualifier(\"redisDelScript\") private DefaultRedisScript\u003cBoolean\u003e redisDelScript; @Autowired private RedisTemplate\u003cString, String\u003e redisTemplate; @Override public Boolean grab(Integer orderId, Integer driverId) { // 1. 生成锁 String lockKey = \"grab_order_\" + orderId; String lockVal = \"driverId_\" + driverId; String expireTime = \"1000\"; List\u003cString\u003e keys = Arrays.asList(lockKey, lockVal); try { // 2. 执行加锁的脚本 Boolean lockStatus = redisTemplate.execute(redisSetScript, keys, expireTime); if (!lockStatus) { // 锁定失败，直接返回 false return false; } // 使用守护线程，定时对 key 续期 // TODO 此处可使用线程池进行优化 Thread t = new Thread(() -\u003e { while(true){ Object val = redisTemplate.opsForValue().get(lockKey); if (lockVal.equals(val)) { int sleepTime = timeout / 3; try { unit.sleep(sleepTime); } catch (InterruptedException e) { e.printStackTrace(); } if(redisTemplate.hasKey(lockKey)){ redisTemplate.expire(lockKey, timeout, unit); } } } }); t.setDaemon(true); t.start(); // 3. 业务代码 System.out.println(\"司机：\" + driverId + \" 执行抢单逻辑\"); TblOrder tblOrder = tblOrderDAO.selectByPrimaryKey(orderId); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } if (tblOrder.getStatus() == 0) { tblOrder.setStatus((byte) 1); tblOrderDAO.updateByPrimaryKey(tblOrder); return true; } return false; } finally { // 4. 释放锁 redisTemplate.execute(redisDelScript, Arrays.asList(lockKey), lockVal); } } } 注意事项：RedisTemplate\u003cString, String\u003e的泛型都使用了 String，所以传参的时候也要都是 String 类型，这样传到 lua 脚本中的也都是 String 类型\nSpringIntegrationRedis+AOP 引入依赖\n1 2 3 4 5 6 7 8 9 10 11 12 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-integration\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.integration\u003c/groupId\u003e \u003cartifactId\u003espring-integration-redis\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-data-redis\u003c/artifactId\u003e \u003c/dependency\u003e 配置 RedisLockRegistry\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.RedisConnectionFactory; import org.springframework.integration.redis.util.RedisLockRegistry; import java.util.concurrent.TimeUnit; @Configuration public class RedisLockRegistryConf { @Bean public RedisLockRegistry redisLockRegistry(RedisConnectionFactory redisConnectionFactory) { return new RedisLockRegistry(redisConnectionFactory, \"REGISTRY_KEY\"); } /** * 可根据不同的业务设置不同的 registryKey * 此处模拟抢单场景，所以设置 registryKey 为 GRAB_ORDER * 实际存储到 redis 中的 key 是 registryKey:lockKey 形式 * lockKey 在业务中调用 RedisLockRegistry 的 obtain(lockKey)方法时，手动设置 */ @Bean public RedisLockRegistry grabOrderRlr(RedisConnectionFactory redisConnectionFactory) { return new RedisLockRegistry(redisConnectionFactory, \"GRAB_ORDER\", TimeUnit.SECONDS.toMillis(15)); } } 添加自定义注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; import java.util.concurrent.TimeUnit; @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) public @interface DistributeLock { /** * RedisLockRegistry 的 Bean 名称 */ String redisLockRegistry() default \"redisLockRegistry\"; /** * 等待时长，为 0 表示不等待 */ long waitTime() default 0; /** * 时间单位 */ TimeUnit timeUnit() default TimeUnit.SECONDS; /** * 锁的 key * 支持 SPEL 表达式 * 为空则使用方法签名 */ String key() default \"\"; } 添加 AOP 切面，对标注了上方的 DistributeLock 注解的方法进行拦截\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 import com.example.dlorder.annotation.DistributeLock; import com.google.gson.Gson; import lombok.extern.slf4j.Slf4j; import org.apache.commons.lang.StringUtils; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Pointcut; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.core.LocalVariableTableParameterNameDiscoverer; import org.springframework.expression.EvaluationContext; import org.springframework.expression.Expression; import org.springframework.expression.ExpressionParser; import org.springframework.expression.spel.standard.SpelExpressionParser; import org.springframework.expression.spel.support.StandardEvaluationContext; import org.springframework.integration.redis.util.RedisLockRegistry; import org.springframework.stereotype.Component; import org.springframework.web.context.WebApplicationContext; import java.lang.reflect.Method; import java.util.concurrent.locks.Lock; @Slf4j @Aspect @Component public class DistributeLockAop { private final ExpressionParser parser = new SpelExpressionParser(); private final LocalVariableTableParameterNameDiscoverer discoverer = new LocalVariableTableParameterNameDiscoverer(); @Autowired private WebApplicationContext webApplicationContext; @Pointcut(\"@annotation(com.example.dlorder.annotation.DistributeLock)\") private void pointcut() { } @Around(\"pointcut()\") public Object around(ProceedingJoinPoint pjp) throws Throwable { MethodSignature signature = (MethodSignature) pjp.getSignature(); Method method = signature.getMethod(); String className = pjp.getTarget().getClass().getName(); Object[] args = pjp.getArgs(); DistributeLock annotation = method.getAnnotation(DistributeLock.class); String rlrName = annotation.redisLockRegistry(); RedisLockRegistry redisLockRegistry = (RedisLockRegistry) webApplicationContext.getBean(rlrName); // 把 key 中的 SPEL 表达式进行转换 String key = annotation.key(); Object oKey = parseSpel(method, args, key, Object.class, key); // 如果 key 是空值，就用签名做 key String lockKey = StringUtils.isEmpty(key) ? signature.toString() : new Gson().toJson(oKey); /* 放到 redis 中的锁的 key 格式是 registryKey:lockKey registryKey 是在创建 RedisLockRegistry 的 Bean 的时候设置的，lockKey 是该方法的入参 */ Lock lock = redisLockRegistry.obtain(lockKey); // 尝试加锁 boolean lockStatus = lock.tryLock(annotation.waitTime(), annotation.timeUnit()); Object proceed = null; // 获取到锁了 if (lockStatus) { try { /* TODO 此处应该定时对 key 续期，防止业务执行时间超过 redisKey 的失效时间，出现提前释放锁的情况 但是 Spring Integration 的 RedisLockRegistry 本身并没有提供自动续期机制 在这里也不能通过 RedisLockRegistry 动态获取到 registryKey，所以手动续期代码需要写死代码 考虑可以不使用 Spring Integration，使用其他方式(redisTemplate/lua 脚本+手写续期代码 或 redisson) 如果使用该方式，需保证业务执行时间必须小于锁失效时间 */ // 执行业务方法 proceed = pjp.proceed(); } catch (Exception e) { log.error(\"执行业务发生错误，class={}，method={}，args={}\", className, method, args); throw e; } finally { try { // 解锁 lock.unlock(); } catch (Exception e) { log.error(\"解锁发生异常\", e); } } } return proceed; } /** * 解析 spel 表达式 * * @param method 方法 * @param agrs 方法参数 * @param spel 表达式 * @param clazz 返回结果的类型 * @param defaultResult 默认结果 * @return 执行 spel 表达式后的结果 */ private \u003cT\u003e T parseSpel(Method method, Object[] agrs, String spel, Class\u003cT\u003e clazz, T defaultResult) { String[] params = discoverer.getParameterNames(method); EvaluationContext context = new StandardEvaluationContext(); if (params != null) { for (int i = 0; i \u003c params.length; i++) { context.setVariable(params[i], agrs[i]); } } try { Expression expression = parser.parseExpression(spel); return expression.getValue(context, clazz); } catch (Exception e) { return defaultResult; } } } 业务方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import com.example.dlorder.annotation.DistributeLock; import com.example.dlorder.dao.TblOrderDAO; import com.example.dlorder.entity.TblOrder; import com.example.dlorder.service.OrderService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import java.util.concurrent.TimeUnit; @Service(\"redisAopLockService\") public class RedisAopLockServiceImpl implements OrderService { @Autowired private TblOrderDAO tblOrderDAO; // 添加 DistributeLock 注解即可 @DistributeLock(redisLockRegistry = \"grabOrderRlr\", key = \"#orderId\") @Override public Boolean grab(Integer orderId, Integer driverId) { System.out.println(\"司机：\" + driverId + \" 执行抢单逻辑\"); TblOrder tblOrder = tblOrderDAO.selectByPrimaryKey(orderId); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } if (tblOrder.getStatus() == 0) { tblOrder.setStatus((byte) 1); tblOrderDAO.updateByPrimaryKey(tblOrder); return true; } return false; } } AOP 整合 可以参考 SpringIntegrationRedis+AOP，将 SpringIntegrationRedis 替换为其他方式，来达到对业务无侵入式的加锁\n设计分布式锁的注意事项 互斥锁：同时只能有一个服务能获取锁\n防死锁：不要发生死锁，也不要让之后的客户端加不上锁\n自己的锁自己解：防止自己加的锁被其他服务给解除了\n容错性：例如可以使用多个 redis，提高系统稳定性\n不同锁方式对比 锁类型 单服务线程安全 多服务线程安全 性能 自动续期 稳定性 不加锁 不安全 不安全 - 无 JVM 锁 安全 不安全 - 不需要 MySQL 锁 安全 安全 低 不需要 Redis 安全 安全 - 需要自己写自动续期代码 Redission 安全 安全 - 自带自动续期，不需要自己写 Redission 红锁 安全 安全 - 自带自动续期，不需要自己写 稳定性高（使用多个单独的 Redis） Redis Lua 脚本 安全 安全 - 需要自己写自动续期代码 Spring Integration Redis + AOP 安全 安全 - 未提供自动续期代码，需要在切面类中写“死”代码 Redisson 红锁细节 源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 public boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException { long newLeaseTime = -1; if (leaseTime != -1) { if (waitTime == -1) { newLeaseTime = unit.toMillis(leaseTime); } else { newLeaseTime = unit.toMillis(waitTime)*2; } } // 获取系统当前时间 long time = System.currentTimeMillis(); long remainTime = -1; if (waitTime != -1) { remainTime = unit.toMillis(waitTime); } long lockWaitTime = calcLockWaitTime(remainTime); int failedLocksLimit = failedLocksLimit(); List\u003cRLock\u003e acquiredLocks = new ArrayList\u003c\u003e(locks.size()); // 遍历所有的 RLock for (ListIterator\u003cRLock\u003e iterator = locks.listIterator(); iterator.hasNext();) { RLock lock = iterator.next(); boolean lockAcquired; try { // 对每个 RLock 都进行加锁 if (waitTime == -1 \u0026\u0026 leaseTime == -1) { lockAcquired = lock.tryLock(); } else { long awaitTime = Math.min(lockWaitTime, remainTime); lockAcquired = lock.tryLock(awaitTime, newLeaseTime, TimeUnit.MILLISECONDS); } } catch (RedisResponseTimeoutException e) { unlockInner(Arrays.asList(lock)); lockAcquired = false; } catch (Exception e) { lockAcquired = false; } if (lockAcquired) { acquiredLocks.add(lock); } else { // 所有锁的数量 - 锁成功的锁的数量 // failedLocksLimit() = 所有锁数量 - (所有锁数量/2 + 1) // 锁成功的锁数量 == 所有锁数量/2 + 1 if (locks.size() - acquiredLocks.size() == failedLocksLimit()) { break; } if (failedLocksLimit == 0) { unlockInner(acquiredLocks); if (waitTime == -1) { return false; } failedLocksLimit = failedLocksLimit(); acquiredLocks.clear(); // reset iterator while (iterator.hasPrevious()) { iterator.previous(); } } else { failedLocksLimit--; } } if (remainTime != -1) { // 当前时间 - 开始加锁的时间 remainTime -= System.currentTimeMillis() - time; time = System.currentTimeMillis(); if (remainTime \u003c= 0) { unlockInner(acquiredLocks); return false; } } } if (leaseTime != -1) { List\u003cRFuture\u003cBoolean\u003e\u003e futures = new ArrayList\u003c\u003e(acquiredLocks.size()); for (RLock rLock : acquiredLocks) { RFuture\u003cBoolean\u003e future = ((RedissonLock) rLock).expireAsync(unit.toMillis(leaseTime), TimeUnit.MILLISECONDS); futures.add(future); } for (RFuture\u003cBoolean\u003e rFuture : futures) { rFuture.syncUninterruptibly(); } } return true; } 锁流程 加成功锁的数量一定要超过一半，最终才是加锁成功。\n可以启 5 台 redis 用 shell 手动向 2 个 redis 中插入 lock，然后使用 Redisson 红锁向 5 个 redis 中加锁，最终是可以成功的 用 shell 手动向 3 个 redis 中插入 lock，然后使用 Redisson 红锁向 5 个 redis 中加锁，最终是失败的 生产环境问题 线程 1 给 1、2、3 加锁成功了，最终获取到锁 3 号故障了，并且没有做持久化 恢复 3 号之后，3 号中没有 1 号的锁数据了。此时线程 2 给 3、4、5 加锁成功了，最终也获取到了锁 出现了线程 1 和线程 2 同时都获取到了锁，打破了互斥性 需要运维在恢复 3 号的时候做延时启动（延时时间 \u003e 锁失效时间）\n秒杀问题 并发读和并发写特别多\n前提：首先，已有的交易系统功能要完善，稳定\n特点：短时间内高并发\n准：不多卖，不少卖（分布式锁）\n快：服务响应速度要快\n稳：服务的可用性\n防止少买，使用阻塞锁，然后把库存分段\n请求量要少：接口数据少\n请求链路要短：\n依赖要少：\n不要单点：\nCDN：\n动静分离\n提前预估\n削峰：放到消息队列等着\n网络（请求转发），CPU（并发），内存（redis），硬盘（mysql）\n","description":"","tags":["MSB","Project","网约车三期","Java"],"title":"分布式锁","uri":"/posts/msb/%E7%BD%91%E7%BA%A6%E8%BD%A6%E4%B8%89%E6%9C%9F/distributed-lock/"},{"categories":null,"content":"分布式事务 数据库的本地事务如何保证?\n锁, redo, undo\nACID\nAD: 依靠日志文件\nCI: 依靠锁\n刚性事务(acid), 柔性事务(base).\nXA 协议：事务管理器(TM), 资源管理器(RM)\n模型 第三方支付回调支付系统，支付系统调用订单系统，支付系统和订单系统需要事务一致。\n其中支付系统和订单系统，需要保持事务一致的系统称为资源管理器\n为了保证 RM 的事务，就需要一个第三方来进行管理，所以引入了事务管理器\n事务管理器与资源管理器间进行协作，保证资源管理器间的事务。\n2PC 模型 1 阶段 TM 向所有参与事务的 RM 发送事务内容，询问是否可以提交事务，等待 RM 回应 RM 收到 TM 的询问，开始执行 sql 语句，将 undo 和 redo 信息写入日志，但是不提交本地事务 如果 RM 执行成功，会给 TM 返回 yes, 表示可以进行事务提交；否则返回 no, 表示不可提交事务。 如果 TM 在任一阶段收到了 RM 返回的 no 或者超时没有收到响应，就通知所有 RM 执行回滚, RM 通过之前写入的 undo 信息执行回滚，并释放在整个事务期间占用的资源，并反馈回滚结果, TM 中断事务\n2 阶段 如果在 1PC 阶段, TM 收到的都是 yes, 则向 RM 发送提交消息；否则只要有 1 个 no, 或者超时就向所有参与的 RM 发送回滚消息\nRM 收到提交/回滚消息，开始提交/回滚本地事务\nRM 提交事务提交成功后，会给 TM 返回 yes/no\n在 2 阶段中，如果 RM 执行提交后就故障了，这样就没办法回滚了。\n在 2PC 模型中，如果在第 2 阶段, TM 通知提交后, A 系统提交本地事务后, B 系统还未提交本地事务, B 系统和 TM 就都宕机了，这时，就成了 A 系统和 B 系统的数据不一致，即使可以通过其他手段解决这个问题，但是此时已经出现了数据不一致的情况, 2PC 解决不了这个问题\n3PC 模型 3PC 和 2PC 的区别 引入超时机制。同时在 TM(超时，中断事务)和 RM(超时，在 pre 中断，在 do 提交)中都引入超时机制。\n2PC 中只有 TM 有超时机制\n在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与 RM 的状态是一致的。降低锁资源的概率和时长\n1 阶段 在 2PC 中，只要一开始，就会锁定资源，所以 3PC 在 2PC 之前添加了一个新的阶段\nTM 向参与事务的 RM 先发送一个请求，询问他们是否能 commit RM 尝试获取锁，此时不执行 sql, 所以不锁定资源。如果能获取锁就返回 yes TM 收到所有 yes 后，才开始执行下一阶段 柔性事务 CAP 理论 CAP 是一个已经被证实的理论：一个分布式系统最多只能满足一致性(Consistency), 可用性(Availability)和分区容错性(Partition tolerance)这三项中的两项。它可以作为我们架构设计，技术选型的考量标准。对于多数大型互联网应用的场景，节点众多，部署分散，而且现在的集群规模越来越大，所以节点故障，网络故障是常态，而且要保证服务可用性达到 N 个 9(99.99%), 并要达到良好的响应性能来提高用户体验, 因此一般都会做出如下选择：保证 P 和 A, 舍弃 C 强一致性，保证最终一致性\nBASE 理论 BASE 是 Basically Availbale(基本可用), Soft state(软状态)和 Eventually consistent(最终一致性)三个短语的缩写. BASE 理论是对 CAP 中 AP 的一个扩展，通过牺牲强一致性来获得可用性，当出现故障允许部分不可用但是要保证核心功能可用，允许数据在一段时间内是不一致的，但最终达到一致状态。满足 BASE 理论的事务，我们称之为\"柔性事务\".\n基本可用：分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。如电商网址交易付款出现问题了，商品依然可以正常浏览。\n软状态：由于不要求强一致性，所以 BASE 允许系统中存在中间状态(也叫软状态), 这个状态不影响系统可用性，如订单中的\"支付中\", \"数据同步中\"等状态，待数据最终一致后改为\"成功\"状态\n最终一致性：最终一致性是指经过一段时间后都将会达到一致。如订单中的\"支付中\"状态，最终会变为\"支付成功\"或者\"支付失败\", 使订单状态与实际交易结果达成一致，但需要一定时间的延迟，等待。\n消息队列+事件表 不适用：数据量特别大的情况\n幂等：通过消息中事件的 id, 主键约束，来保证消息重复消费的问题\n支付系统自己的业务更新支付表，然后创建一个支付事件，插入到事件表 支付系统的定时任务从事件表中查询出 new 状态的事件，将其更新为 published, 发送给消息队列 订单系统监听到消息队列中的消息，将事件状态更新为 received 订单系统的定时任务从事件表中查询出 received 状态的事件，将其更新为 processed, 并执行订单系统自己的业务，更新订单表 实现 环境准备 准备消息队列 activemq, 修改 activemq.xml 添加如下代码，开启死信队列\n1 2 3 4 5 6 7 8 9 10 11 12 \u003cdestinationPolicy\u003e \u003cpolicyMap\u003e \u003cpolicyEntries\u003e \u003c!-- 死信队列 --\u003e \u003cpolicyEntry queue=\"\u003e\"\u003e \u003cdeadLetterStrategy\u003e \u003cindividualDeadLetterStrategy queuePrefix=\"DLQ.\" useQueueForQueueMessages=\"true\" processNonPersistent=\"true\"/\u003e \u003c/deadLetterStrategy\u003e \u003c/policyEntry\u003e \u003c/policyMap\u003e \u003c/policyEntries\u003e \u003c/destinationPolicy\u003e 创建事件表\n两个系统可以使用同一张事件表，也可以使用两张事件表，结构相同\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 create table `online-taxi-three`.tbl_pay_event ( id int auto_increment, pay_type varchar(32) null comment '事件类型(支付表支付完成，订单表修改状态)', process varchar(32) null comment '事件环节(new, published, received, processed)', content varchar(255) null comment '事件内容，保存事件发生时需要传递的数据', create_time datetime null, update_time datetime null, constraint tbl_order_event_id_uindex unique (id) ); alter table `online-taxi-three`.tbl_pay_event add primary key (id); 支付系统 引入依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 \u003c!-- mybatis --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.mybatis.spring.boot\u003c/groupId\u003e \u003cartifactId\u003emybatis-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e2.1.4\u003c/version\u003e \u003c/dependency\u003e \u003c!-- mysql --\u003e \u003cdependency\u003e \u003cgroupId\u003emysql\u003c/groupId\u003e \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- activemq --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-activemq\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.activemq\u003c/groupId\u003e \u003cartifactId\u003eactivemq-pool\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- web --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- lombok --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003coptional\u003etrue\u003c/optional\u003e \u003c/dependency\u003e 配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 server: port: 8080 spring: application: name: service-pay activemq: broker-url: tcp://127.0.0.1:61616 user: admin password: admin pool: enabled: true max-connections: 100 datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/online-taxi-three?characterEncoding=utf-8\u0026serverTimezone=Asia/Shanghai username: root password: root dbcp2: initial-size: 5 min-idle: 5 max-total: 5 max-wait-millis: 200 validation-query: SELECT 1 test-while-idle: true test-on-borrow: false test-on-return: false mybatis: mapper-locations: - classpath:mapper/*.xml ActiveMQ 配置类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package com.example.servicepay.config; import org.apache.activemq.ActiveMQConnectionFactory; import org.apache.activemq.command.ActiveMQQueue; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import javax.jms.Queue; /** * @author wangshuo * @date 2021/03/13 */ @Configuration public class ActiveMqConfig { @Value(\"${spring.activemq.broker-url}\") private String brokerUrl; @Bean public Queue payOrderQueue() { return new ActiveMQQueue(\"PayOrderQueue\"); } @Bean public ActiveMQConnectionFactory connectionFactory() { return new ActiveMQConnectionFactory(brokerUrl); } } 使用 mybatis-generator 生成 entity, dao, mapper\n创建 Controller, 模拟支付业务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package com.example.servicepay.controller; import com.example.servicepay.dao.TblPayEventDAO; import com.example.servicepay.entity.TblPayEvent; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.transaction.annotation.Transactional; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import java.util.Date; /** * @author wangshuo * @date 2021/03/13 */ @RestController @RequestMapping(\"/pay\") @Slf4j public class PayController { @Autowired private TblPayEventDAO tblPayEventDAO; @GetMapping(\"/pay-success\") @Transactional(rollbackFor = Exception.class) public String paySuccess() { // 支付成功，将支付信息插入到支付表 // 向事件表中插入一条新数据 TblPayEvent event = new TblPayEvent(); event.setProcess(\"new\"); event.setPayType(\"支付成功，订单表修改状态\"); event.setContent(\"相关支付信息\"); event.setCreateTime(new Date()); event.setUpdateTime(new Date()); int insert = tblPayEventDAO.insert(event); return insert \u003e 0 ? \"success\" : \"fail\"; } } 添加定时任务，定时将数据库中 new 状态的事务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 package com.example.servicepay.task; import com.example.servicepay.dao.TblPayEventDAO; import com.example.servicepay.entity.TblPayEvent; import com.fasterxml.jackson.core.JsonProcessingException; import com.fasterxml.jackson.databind.ObjectMapper; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.jms.core.JmsMessagingTemplate; import org.springframework.scheduling.annotation.Scheduled; import org.springframework.stereotype.Component; import org.springframework.transaction.annotation.Transactional; import javax.jms.Queue; import java.util.List; /** * @author wangshuo * @date 2021/03/13 */ @Component @Slf4j public class ProducerTask { @Autowired private TblPayEventDAO tblPayEventDAO; @Autowired private Queue payOrderQueue; @Autowired private JmsMessagingTemplate jmsMessagingTemplate; @Autowired private ObjectMapper objectMapper; /** * 定时将事件表中为 new 状态的事件发送到消息队列 * Transactional: 在发生异常时回滚数据库中的数据 */ @Scheduled(cron = \"0/5 * * * * ?\") @Transactional(rollbackFor = Exception.class) public void task() throws JsonProcessingException { log.info(\"定时任务，将 new 状态的事件发送到消息队列\"); List\u003cTblPayEvent\u003e events = tblPayEventDAO.selectByProcess(\"new\"); for (TblPayEvent event : events) { // 更新事件表状态 event.setProcess(\"published\"); tblPayEventDAO.updateByPrimaryKey(event); log.info(\"修改 pay 事件表状态为 已发布到消息队列\"); // 把该事件发送到消息队列 jmsMessagingTemplate.convertAndSend(payOrderQueue, objectMapper.writeValueAsString(event)); } } } 在启动类上添加 @EnableScheduling 和 @EnableJms 注解\n订单系统 引入依赖\n与支付系统相同\n添加配置文件\n与支付系统相同，只需要修改端口和服务名即可\n如果支付系统和订单系统使用了不同的两个库，还需要修改数据库连接\n1 2 3 4 5 server: port: 8081 spring: application: name: service-order ActiveMQ 配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 package com.example.serviceorder.config; import org.apache.activemq.ActiveMQConnectionFactory; import org.apache.activemq.RedeliveryPolicy; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.jms.config.DefaultJmsListenerContainerFactory; import org.springframework.jms.config.JmsListenerContainerFactory; /** * @author wangshuo * @date 2021/03/13 */ @Configuration public class ActiveMqConfig { @Value(\"${spring.activemq.user}\") private String username; @Value(\"${spring.activemq.password}\") private String password; @Value(\"${spring.activemq.broker-url}\") private String brokerURL; /** * 连接工厂 * * @param redeliveryPolicy * @return */ @Bean public ActiveMQConnectionFactory activeMQConnectionFactory(RedeliveryPolicy redeliveryPolicy) { ActiveMQConnectionFactory activeMQConnectionFactory = new ActiveMQConnectionFactory(username, password, brokerURL); activeMQConnectionFactory.setRedeliveryPolicy(redeliveryPolicy); return activeMQConnectionFactory; } /** * 重发策略 * * @return */ @Bean public RedeliveryPolicy redeliveryPolicy() { return new RedeliveryPolicy(); } /** * 设置消息队列 确认机制 * * @param activeMQConnectionFactory * @return */ @Bean public JmsListenerContainerFactory jmsListenerContainerFactory(ActiveMQConnectionFactory activeMQConnectionFactory) { DefaultJmsListenerContainerFactory defaultJmsListenerContainerFactory = new DefaultJmsListenerContainerFactory(); defaultJmsListenerContainerFactory.setConnectionFactory(activeMQConnectionFactory); // 1: 自动确认, 2: 客户端手动确认, 3: 自动批量确认, 4: 事务提交并确认 defaultJmsListenerContainerFactory.setSessionAcknowledgeMode(2); return defaultJmsListenerContainerFactory; } } 使用 mybatis-generater 生成 entity, dao, mapper\n添加 ActiveMQ 的监听器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 package com.example.serviceorder.listener; import com.example.serviceorder.dao.TblPayEventDAO; import com.example.serviceorder.entity.TblPayEvent; import com.fasterxml.jackson.databind.ObjectMapper; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.jms.annotation.JmsListener; import org.springframework.stereotype.Component; import javax.jms.JMSException; import javax.jms.Session; import javax.jms.TextMessage; /** * @author wangshuo * @date 2021/03/13 */ @Component @Slf4j public class PayOrderQueueListener { @Autowired private ObjectMapper objectMapper; @Autowired private TblPayEventDAO tblPayEventDAO; /** * 监听 PayOrderQueue 中的消息 * * @param textMessage * @param session * @throws JMSException */ @JmsListener(destination = \"PayOrderQueue\", containerFactory = \"jmsListenerContainerFactory\") public void receive(TextMessage textMessage, Session session) throws JMSException { log.info(\"收到消息: \" + textMessage.getText()); try { TblPayEvent event = objectMapper.readValue(textMessage.getText(), TblPayEvent.class); event.setProcess(\"received\"); tblPayEventDAO.updateByPrimaryKey(event); // 告诉消息队列，消息已被消费 textMessage.acknowledge(); } catch (Exception e) { e.printStackTrace(); // 如果出现异常，要把该消息放回消息队列 session.rollback(); } } } 添加定时任务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 package com.example.serviceorder.task; import com.example.serviceorder.dao.TblPayEventDAO; import com.example.serviceorder.entity.TblPayEvent; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.scheduling.annotation.Scheduled; import org.springframework.stereotype.Component; import org.springframework.transaction.annotation.Transactional; import java.util.List; /** * @author wangshuo * @date 2021/03/13 */ @Component @Slf4j public class ConsumerTask { @Autowired private TblPayEventDAO tblPayEventDAO; /** * 获取事件表中已接收的事件，调用订单服务 */ @Scheduled(cron = \"0/5 * * * * ?\") @Transactional(rollbackFor = Exception.class) public void task() { log.info(\"定时任务获取已接收事件，更新订单信息\"); // 查询出所有状态是 received 的事件 List\u003cTblPayEvent\u003e events = tblPayEventDAO.selectByProcess(\"received\"); log.info(\"获取到{}个已接收事件\", events.size()); for (TblPayEvent event : events) { // 修改事件状态 event.setProcess(\"processed\"); tblPayEventDAO.updateByPrimaryKey(event); // 调用订单服务，更新订单 } } } 在启动类上添加 @EnableScheduling 和 @EnableJms 注解\n相关扩展说明 事件表可以是同一张表，也可以是两个数据库中的两张表 定时任务可以使用分布式定时任务，来提高系统稳定性 tx-lcn 框架 tx-lcn github 官网\nLCN 模式 Lock, Confirm, Notify\nXA 协议, Oracle 提出的, 2PC 的\nLock: 锁定事务单元\nConfirm: 确认事务\nNotify: 通知事务\n流程图 假设调用放调用服务 A, 服务 A 调用服务 B, 服务 B 调用服务......调用服务 N.\nLCN 的调用流程\n黑色线是假如没有添加事务管理时的执行流程。\n红色线+黑色线是添加了事务管理时的执行流程\n通过灰色虚线可以将该过程分为两个阶段，类似于上方的 [2PC 模型](#2PC 模型)\n协调机制 创建事务组和把服务添加到事务组都很容易，但是事务通知模块怎么能通知服务去提交/回滚事务，是重点。因为服务是依次调用，然后从后向前通知提交/回滚的，所以前面的服务已经提交事务了，才会去调用后面的事务。\n所以解决办法就是让前面的服务不真正的提交事务，而是把它与数据库的连接保存起来，等最后一个服务被调用结束后，在从保存的数据库连接中依次取出连接，进行提交/回滚。\nsql 操作完了，提交了, connection 释放了, close(connection.close())\n假释放 close, 存储到一个 Map\u003c请求 Id, connection\u003e\n目的：对应调用和连接\n协调机制本质: 代理了 DataSource, 保持了请求和 DB 连接的对应.\n补偿机制 第二阶段如果由于网络原因会造成提交/回滚的通知提交失败，此时 lcn 会将通知的具体事项和需要执行的 sql 操作记录下来，用来做后续的补偿\n架构图 代码 TX-Manager 引入依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u003c!--tm manager--\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.codingapi.txlcn\u003c/groupId\u003e \u003cartifactId\u003etxlcn-tm\u003c/artifactId\u003e \u003cversion\u003e${txlcn.version}\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.codingapi.txlcn\u003c/groupId\u003e \u003cartifactId\u003etxlcn-tc\u003c/artifactId\u003e \u003cversion\u003e${txlcn.version}\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.codingapi.txlcn\u003c/groupId\u003e \u003cartifactId\u003etxlcn-txmsg-netty\u003c/artifactId\u003e \u003cversion\u003e${txlcn.version}\u003c/version\u003e \u003c/dependency\u003e 生成数据库表，在 txlcn-tm 的包中有一个 tx-manager.sql 文件，包含了建表语句\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 /* Navicat Premium Data Transfer Source Server : local Source Server Type : MySQL Source Server Version : 100309 Source Host : localhost:3306 Source Schema : tx-manager Target Server Type : MySQL Target Server Version : 100309 File Encoding : 65001 Date: 29/12/2018 18:35:59 */ CREATE DATABASE IF NOT EXISTS `tx-manager` DEFAULT CHARSET utf8 COLLATE utf8_general_ci; USE `tx-manager`; SET NAMES utf8mb4; SET FOREIGN_KEY_CHECKS = 0; -- ---------------------------- -- Table structure for t_tx_exception -- ---------------------------- DROP TABLE IF EXISTS `t_tx_exception`; CREATE TABLE `t_tx_exception` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `group_id` varchar(64) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, `unit_id` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, `mod_id` varchar(128) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL, `transaction_state` tinyint(4) NULL DEFAULT NULL, `registrar` tinyint(4) NULL DEFAULT NULL, `ex_state` tinyint(4) NULL DEFAULT NULL COMMENT '0 待处理 1 已处理', `remark` varchar(10240) NULL DEFAULT NULL COMMENT '备注', `create_time` datetime(0) NULL DEFAULT NULL, PRIMARY KEY (`id`) USING BTREE ) ENGINE = InnoDB AUTO_INCREMENT = 967 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic; SET FOREIGN_KEY_CHECKS = 1; 配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # TM 事务管理器的服务端 WEB 访问端口。提供一个可视化的界面，端口自定义 server: port: 7970 spring: application: name: tx-lcn-transaction-manager # TM 事务管理器，需要访问数据库，实现分布式事务状态记录 datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/tx-manager?characterEncoding=UTF-8\u0026setTimeZone=Asia/Shanghai username: root password: root # TM 事务管理器，是依赖 redis 使用分布式事务协调的。尤其是 TCC 和 TXC 两种事务模型 redis: host: 127.0.0.1 port: 6379 database: 0 tx-lcn: manager: # TM 事务管理器，提供的 WEB 管理平台的登录密码。无用户名。默认是 codingapi admin-key: codingapi # 日志。 logger: # 如果需要 TM 记录日志，则开启，赋值为 true, 并提供后续的配置。 enabled: true # 为日志功能提供数据库连接。和之前配置的分布式事务管理器管理依赖使用的数据源不同 driver-class-name: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql://localhost:3306/tx-manager?characterEncoding=UTF-8\u0026setTimeZone=Asia/Shanghai username: root password: root 在启动类上添加 @EnableTransactionManagerServer 注解\nResourceManager 引入依赖\n1 2 3 4 5 6 7 8 9 10 11 12 \u003c!-- lcn, TX-Client --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.codingapi.txlcn\u003c/groupId\u003e \u003cartifactId\u003etxlcn-tc\u003c/artifactId\u003e \u003cversion\u003e${txlcn.version}\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.codingapi.txlcn\u003c/groupId\u003e \u003cartifactId\u003etxlcn-txmsg-netty\u003c/artifactId\u003e \u003cversion\u003e${txlcn.version}\u003c/version\u003e \u003c/dependency\u003e 配置类\n1 2 3 4 tx-lcn: client: # TM 的 IP 地址和端口 manager-address: 127.0.0.1:7970 在启动类上添加 @EnableDistributedTransaction 注解\n创建业务数据库\n1 2 3 4 5 6 7 8 9 10 create table lcn_order.tbl_order ( id int not null, order_name varchar(32) null, constraint tbl_order_id_uindex unique (id) ); alter table lcn_order.tbl_order add primary key (id); 生成 entity, dao, mapper\n需要使用分布式事务的地方添加 @LcnTransaction 注解\nServiceA 远程调用 ServiceB\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Service public class ServiceA { @Autowired private ValueDao valueDao; //远程 B 模块业务 @Autowired private ServiceB serviceB; //分布式事务注解 @LcnTransaction //本地事务注解 @Transactional(rollbackFor = Exception.class) public String execute(String value) throws BusinessException { // step1. 调用远程服务 String result = serviceB.rpc(value); // step2. 本地事务操作。 valueDao.save(value); valueDao.saveBackup(value); return result + \" \u003e \" + \"ok-A\"; } } ServiceB\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Service public class ServiceB { @Autowired private ValueDao valueDao; //分布式事务注解 @LcnTransaction //本地事务注解 @Transactional public String rpc(String value) throws BusinessException { valueDao.save(value); valueDao.saveBackup(value); return \"ok-B\"; } } TX-Manager 集群 TX-Manager 集群配置 其他配置都可以不变，只需要把端口修改即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 spring: application: name: tx-lcn-transaction-manager # TM 事务管理器，需要访问数据库，实现分布式事务状态记录 datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/tx-manager?characterEncoding=UTF-8\u0026setTimeZone=Asia/Shanghai username: root password: root # TM 事务管理器，是依赖 redis 使用分布式事务协调的。尤其是 TCC 和 TXC 两种事务模型 redis: host: 127.0.0.1 port: 6379 database: 0 tx-lcn: manager: # TM 事务管理器，提供的 WEB 管理平台的登录密码。无用户名。默认是 codingapi admin-key: msb # 日志。 logger: # 如果需要 TM 记录日志，则开启，赋值为 true, 并提供后续的配置。 enabled: true # 为日志功能提供数据库连接。和之前配置的分布式事务管理器管理依赖使用的数据源不同 driver-class-name: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql://localhost:3306/tx-manager?characterEncoding=UTF-8\u0026setTimeZone=Asia/Shanghai username: root password: root --- spring: profiles: TM_01 # TM 事务管理器的服务端 WEB 访问端口。提供一个可视化的界面，端口自定义 server: port: 7971 --- spring: profiles: TM_02 # TM 事务管理器的服务端 WEB 访问端口。提供一个可视化的界面，端口自定义 server: port: 7972 TX-Client 配置 需要去 TX-Manager 的管理页面 查看，与管理页面的端口不一样\n1 2 3 tx-lcn: client: manager-address: 127.0.0.1:8071,127.0.0.1:8072 源码 代理 Connection 通过 Spring 的 AOP 方式，拦截 javax.sql.DataSource.getConnection() 方法，返回 LCN 的代理连接对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package com.codingapi.txlcn.tc.aspect; import com.codingapi.txlcn.tc.aspect.weave.DTXResourceWeaver; import com.codingapi.txlcn.tc.config.TxClientConfig; import lombok.extern.slf4j.Slf4j; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.springframework.core.Ordered; import org.springframework.stereotype.Component; import java.sql.Connection; /** * create by lorne on 2018/1/5 */ @Aspect @Component @Slf4j public class DataSourceAspect implements Ordered { private final TxClientConfig txClientConfig; private final DTXResourceWeaver dtxResourceWeaver; public DataSourceAspect(TxClientConfig txClientConfig, DTXResourceWeaver dtxResourceWeaver) { this.txClientConfig = txClientConfig; this.dtxResourceWeaver = dtxResourceWeaver; } @Around(\"execution(* javax.sql.DataSource.getConnection(..))\") public Object around(ProceedingJoinPoint point) throws Throwable { // 获取连接对象，返回的是被 tx-lcn 框架接管的 Connection return dtxResourceWeaver.getConnection(() -\u003e (Connection) point.proceed()); } } LcnConnectionProxy 对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 package com.codingapi.txlcn.tc.core.transaction.lcn.resource; import com.codingapi.txlcn.txmsg.dto.RpcResponseState; import lombok.extern.slf4j.Slf4j; import java.sql.*; import java.util.Map; import java.util.Properties; import java.util.concurrent.Executor; @Slf4j // 代理模式，实现了 java.sql.Connection 接口 public class LcnConnectionProxy implements Connection { private Connection connection; public LcnConnectionProxy(Connection connection) { this.connection = connection; } /** * notify connection * * @param state transactionState * @return RpcResponseState RpcResponseState */ public RpcResponseState notify(int state) { try { if (state == 1) { log.debug(\"commit transaction type[lcn] proxy connection:{}.\", this); // 手动提交 connection.commit(); } else { log.debug(\"rollback transaction type[lcn] proxy connection:{}.\", this); // 手动回滚 connection.rollback(); } connection.close(); log.debug(\"transaction type[lcn] proxy connection:{} closed.\", this); return RpcResponseState.success; } catch (Exception e) { log.error(e.getLocalizedMessage(), e); return RpcResponseState.fail; } } // 关闭自动提交 @Override public void setAutoCommit(boolean autoCommit) throws SQLException { connection.setAutoCommit(false); } // commit 方法是空方法，通过 notify 手动提交 @Override public void commit() throws SQLException { //connection.commit(); } // rollback 方法是空方法，通过 notify 手动回滚 @Override public void rollback() throws SQLException { //connection.rollback(); } // close 方法是空方法，假关闭连接 @Override public void close() throws SQLException { //connection.close(); } } @LcnTransaction 生效 事务拦截器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 package com.codingapi.txlcn.tc.aspect; /** * LCN 事务拦截器 * create by lorne on 2018/1/5 */ @Aspect @Component @Slf4j public class TransactionAspect implements Ordered { private final TxClientConfig txClientConfig; private final DTXLogicWeaver dtxLogicWeaver; public TransactionAspect(TxClientConfig txClientConfig, DTXLogicWeaver dtxLogicWeaver) { this.txClientConfig = txClientConfig; this.dtxLogicWeaver = dtxLogicWeaver; } /** * DTC Aspect (Type of LCN) */ @Pointcut(\"@annotation(com.codingapi.txlcn.tc.annotation.LcnTransaction)\") public void lcnTransactionPointcut() { } @Around(\"txTransactionPointcut()\") public Object transactionRunning(ProceedingJoinPoint point) throws Throwable { DTXInfo dtxInfo = DTXInfo.getFromCache(point); TxTransaction txTransaction = dtxInfo.getBusinessMethod().getAnnotation(TxTransaction.class); dtxInfo.setTransactionType(txTransaction.type()); dtxInfo.setTransactionPropagation(txTransaction.propagation()); return dtxLogicWeaver.runTransaction(dtxInfo, point::proceed); } @Around(\"lcnTransactionPointcut() \u0026\u0026 !txcTransactionPointcut()\" + \"\u0026\u0026 !tccTransactionPointcut() \u0026\u0026 !txTransactionPointcut()\") public Object runWithLcnTransaction(ProceedingJoinPoint point) throws Throwable { // 创建分布式事务信息对象，内部包含 groupId 等信息 DTXInfo dtxInfo = DTXInfo.getFromCache(point); LcnTransaction lcnTransaction = dtxInfo.getBusinessMethod().getAnnotation(LcnTransaction.class); // 标记事务单元的事务类型 dtxInfo.setTransactionType(Transactions.LCN); dtxInfo.setTransactionPropagation(lcnTransaction.propagation()); // 重点: return dtxLogicWeaver.runTransaction(dtxInfo, point::proceed); } } 分布式事务信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 package com.codingapi.txlcn.tc.aspect; /** * Description: * Date: 19-1-11 下午 1:21 * * @author ujued */ @AllArgsConstructor @Data public class DTXInfo { private static final Map\u003cString, DTXInfo\u003e dtxInfoCache = new ConcurrentReferenceHashMap\u003c\u003e(); private String transactionType; private DTXPropagation transactionPropagation; private TransactionInfo transactionInfo; /** * 用户实例对象的业务方法（包含注解信息） */ private Method businessMethod; private String unitId; public static DTXInfo getFromCache(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { String signature = proceedingJoinPoint.getSignature().toString(); // 获取事务 id String unitId = Transactions.unitId(signature); // 获取该事务 id 的信息，放置在该事务调用中有多个事务单元的信息 DTXInfo dtxInfo = dtxInfoCache.get(unitId); if (Objects.isNull(dtxInfo)) { MethodSignature methodSignature = (MethodSignature) proceedingJoinPoint.getSignature(); Method method = methodSignature.getMethod(); Class\u003c?\u003e targetClass = proceedingJoinPoint.getTarget().getClass(); Method thisMethod = targetClass.getMethod(method.getName(), method.getParameterTypes()); dtxInfo = new DTXInfo(thisMethod, proceedingJoinPoint.getArgs(), targetClass); // 事务单元 ID 和事务信息放在缓存中 dtxInfoCache.put(unitId, dtxInfo); } dtxInfo.reanalyseMethodArgs(proceedingJoinPoint.getArgs()); return dtxInfo; } } runTransaction\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 package com.codingapi.txlcn.tc.aspect.weave; /** * Description: * Company: CodingApi * Date: 2018/11/29 * * @author ujued */ @Component @Slf4j public class DTXLogicWeaver { private final DTXServiceExecutor transactionServiceExecutor; private final TCGlobalContext globalContext; @Autowired public DTXLogicWeaver(DTXServiceExecutor transactionServiceExecutor, TCGlobalContext globalContext) { this.transactionServiceExecutor = transactionServiceExecutor; this.globalContext = globalContext; } public Object runTransaction(DTXInfo dtxInfo, BusinessCallback business) throws Throwable { if (Objects.isNull(DTXLocalContext.cur())) { DTXLocalContext.getOrNew(); } else { return business.call(); } log.debug(\"\u003c---- TxLcn start ----\u003e\"); DTXLocalContext dtxLocalContext = DTXLocalContext.getOrNew(); TxContext txContext; // ---------- 保证每个模块在一个 DTX 下只会有一个 TxContext ---------- // if (globalContext.hasTxContext()) { // 有事务上下文的获取父上下文 txContext = globalContext.txContext(); dtxLocalContext.setInGroup(true); log.debug(\"Unit[{}] used parent's TxContext[{}].\", dtxInfo.getUnitId(), txContext.getGroupId()); } else { // 没有的开启本地事务上下文 txContext = globalContext.startTx(); } // 本地事务调用 if (Objects.nonNull(dtxLocalContext.getGroupId())) { dtxLocalContext.setDestroy(false); } dtxLocalContext.setUnitId(dtxInfo.getUnitId()); dtxLocalContext.setGroupId(txContext.getGroupId()); dtxLocalContext.setTransactionType(dtxInfo.getTransactionType()); // 事务参数 TxTransactionInfo info = new TxTransactionInfo(); info.setBusinessCallback(business); info.setGroupId(txContext.getGroupId()); info.setUnitId(dtxInfo.getUnitId()); info.setPointMethod(dtxInfo.getBusinessMethod()); info.setPropagation(dtxInfo.getTransactionPropagation()); info.setTransactionInfo(dtxInfo.getTransactionInfo()); info.setTransactionType(dtxInfo.getTransactionType()); info.setTransactionStart(txContext.isDtxStart()); //LCN 事务处理器 try { // 重点: return transactionServiceExecutor.transactionRunning(info); } finally { // 线程执行业务完毕清理本地数据 if (dtxLocalContext.isDestroy()) { // 通知事务执行完毕 synchronized (txContext.getLock()) { txContext.getLock().notifyAll(); } // TxContext 生命周期是？ 和事务组一样（不与具体模块相关的） if (!dtxLocalContext.isInGroup()) { globalContext.destroyTx(); } DTXLocalContext.makeNeverAppeared(); TracingContext.tracing().destroy(); } log.debug(\"\u003c---- TxLcn end ----\u003e\"); } } } startTx()和 destroyTx()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 package com.codingapi.txlcn.tc.core.context; /** * Description: * Date: 19-1-22 下午 6:17 * * @author ujued * @see AttachmentCache * @see PrimaryKeysProvider */ @Component @Slf4j public class DefaultGlobalContext implements TCGlobalContext { private final AttachmentCache attachmentCache; private final List\u003cPrimaryKeysProvider\u003e primaryKeysProviders; private final TxClientConfig clientConfig; @Override public TxContext startTx() { TxContext txContext = new TxContext(); // 事务发起方判断 txContext.setDtxStart(!TracingContext.tracing().hasGroup()); if (txContext.isDtxStart()) { TracingContext.tracing().beginTransactionGroup(); } txContext.setGroupId(TracingContext.tracing().groupId()); String txContextKey = txContext.getGroupId() + \".dtx\"; attachmentCache.attach(txContextKey, txContext); log.debug(\"Start TxContext[{}]\", txContext.getGroupId()); return txContext; } /** * 在用户业务前生成，业务后销毁 * * @param groupId groupId */ @Override public void destroyTx(String groupId) { attachmentCache.remove(groupId + \".dtx\"); log.debug(\"Destroy TxContext[{}]\", groupId); } } transactionRunning()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 /* * Copyright 2017-2019 CodingApi . * * Licensed under the Apache License, Version 2.0 (the \"License\"); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package com.codingapi.txlcn.tc.core; import com.codingapi.txlcn.common.exception.TransactionException; import com.codingapi.txlcn.common.util.Transactions; import com.codingapi.txlcn.logger.TxLogger; import com.codingapi.txlcn.tc.core.propagation.DTXPropagationResolver; import com.codingapi.txlcn.tc.support.TxLcnBeanHelper; import com.codingapi.txlcn.tc.core.context.TCGlobalContext; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import java.util.Set; /** * LCN 分布式事务业务执行器 * Created by lorne on 2017/6/8. */ @Component @Slf4j public class DTXServiceExecutor { private static final TxLogger txLogger = TxLogger.newLogger(DTXServiceExecutor.class); private final TCGlobalContext globalContext; private final TxLcnBeanHelper txLcnBeanHelper; private final DTXPropagationResolver propagationResolver; @Autowired public DTXServiceExecutor(TxLcnBeanHelper txLcnBeanHelper, TCGlobalContext globalContext, DTXPropagationResolver propagationResolver) { this.txLcnBeanHelper = txLcnBeanHelper; this.globalContext = globalContext; this.propagationResolver = propagationResolver; } /** * 事务业务执行 * * @param info info * @return Object * @throws Throwable Throwable */ public Object transactionRunning(TxTransactionInfo info) throws Throwable { // 1. 获取事务类型 String transactionType = info.getTransactionType(); // 2. 获取事务传播状态 DTXPropagationState propagationState = propagationResolver.resolvePropagationState(info); // 2.1 如果不参与分布式事务立即终止 if (propagationState.isIgnored()) { return info.getBusinessCallback().call(); } // 3. 获取本地分布式事务控制器 DTXLocalControl dtxLocalControl = txLcnBeanHelper.loadDTXLocalControl(transactionType, propagationState); // 4. 织入事务操作 try { // 4.1 记录事务类型到事务上下文 Set\u003cString\u003e transactionTypeSet = globalContext.txContext(info.getGroupId()).getTransactionTypes(); transactionTypeSet.add(transactionType); dtxLocalControl.preBusinessCode(info); // 4.2 业务执行前 txLogger.txTrace( info.getGroupId(), info.getUnitId(), \"pre business code, unit type: {}\", transactionType); // 4.3 执行业务 // 事务发起者会走 XXStartingTransaction, 事务参与者会走 XXRunningTransaction Object result = dtxLocalControl.doBusinessCode(info); // 4.4 业务执行成功 txLogger.txTrace(info.getGroupId(), info.getUnitId(), \"business success\"); dtxLocalControl.onBusinessCodeSuccess(info, result); return result; } catch (TransactionException e) { txLogger.error(info.getGroupId(), info.getUnitId(), \"before business code error\"); throw e; } catch (Throwable e) { // 4.5 业务执行失败 txLogger.error(info.getGroupId(), info.getUnitId(), Transactions.TAG_TRANSACTION, \"business code error\"); dtxLocalControl.onBusinessCodeError(info, e); throw e; } finally { // 4.6 业务执行完毕 dtxLocalControl.postBusinessCode(info); } } } TCC 模式 Try: 尝试执行业务\nConfirm: 确认执行业务\nCancel: 取消执行业务\n流程图 在支付系统中调用订单系统，保证支付系统和订单系统的分布式事务。\n两个系统都执行成功才会提交提交完整事务，执行 confirmXX 方法。\n只要有一方执行失败，参与者都会执行 cancelXX 方法\n代码 TX-Manager 单点配置 和 [集群配置](#TX-Manager 集群配置) 都与 LCN 模式中 TX-Manager 的配置方式相同\nResourceManager 单点配置 和 [集群配置](#TX-Manager 集群配置) 都与 LCN 模式中 ResourceManager 的配置方式相同\n只有第 6 步中业务代码需要修改\n首先把 LcnTransaction 注解修改为 @TccTransaction 注解 然后添加 confirmXX 方法和 cancelXX 方法 ServiceA\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @Service public class ServiceA { @Autowired private ValueDao valueDao; //远程 B 模块业务 @Autowired private ServiceB serviceB; //分布式事务注解 @TccTransaction //本地事务注解 @Transactional(rollbackFor = Exception.class) public String execute(String value) throws BusinessException { // step1. 调用远程服务 String result = serviceB.rpc(value); // step2. 本地事务操作。 valueDao.save(value); valueDao.saveBackup(value); return result + \" \u003e \" + \"ok-A\"; } /** * 在需要保证分布式事务的方法名上添加 confirm 前缀。 * 如果 execute 方法正常执行结束，则执行该方法 */ public String confirmExecute(String value){ System.out.println(\"执行成功\"); return \"执行成功\"; } /** * 在需要保证分布式事务的方法名上添加 cancel 前缀。 * 如果 execute 方法执行过程中发生异常，则执行该方法 * 需要手动编写 execute 中执行的 sql 的反 sql 来进行回滚 */ public String cancelExecute(String value){ // 要根据 execute()方法中执行的本地 sql 编写反 sql,来手动进行更新 valueDao.delete(value); return \"执行失败\"; } } ServiceB\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @Service public class ServiceB { @Autowired private ValueDao valueDao; //分布式事务注解 @TccTransaction //本地事务注解 @Transactional public String rpc(String value) throws BusinessException { valueDao.save(value); valueDao.saveBackup(value); return \"ok-B\"; } public String confirmRpc(String value){ System.out.println(\"执行成功\"); return \"执行成功\"; } public String cancelRpc(String value){ // 要根据 execute()方法中执行的本地 sql 编写反 sql,来手动进行更新 valueDao.delete(value); return \"执行失败\"; } } 补充说明 TCC 模式适合分布式业务简单的场景，因为对每个分布式业务的方法，都要添加相应的 confirm 和 cancel 方法，会写更多的代码。\n该种方式(TCC+MySQL)通常不在生产环境中使用。\n通常带事务的中间件用 lcn, 比如 MySQL. 其他没有事务的中间件用 tcc, 例如 redis. 在业务代码中可以 insert/update/delete 之后，将该对象存储到 Map 中，然后在 cancel 中获取该对象来执行反 sql\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Service public class ServiceB { @Autowired private ValueDao valueDao; // 创建一个 Map 来存储对象, key 使用机器名+方法名+输入参数等 private static Map\u003cString, Object\u003e objs = new HashMap\u003c\u003e(); //分布式事务注解 @TccTransaction //本地事务注解 @Transactional public String rpc(String value) throws BusinessException { Value v = valueDao.save(value); objs.put(hostname + \"_rpc_\" + value, v); valueDao.saveBackup(value); return \"ok-B\"; } public String confirmRpc(String value){ objs.remove(hostname + \"_rpc_\" + value); System.out.println(\"执行成功\"); return \"执行成功\"; } public String cancelRpc(String value){ Value v = (Value)objs.get(hostname + \"_rpc_\" + value); // 要根据 execute()方法中执行的本地 sql 编写反 sql,来手动进行更新 valueDao.delete(v.getId); objs.remove(hostname + \"_rpc_\" + value); return \"执行失败\"; } } TCC+MySQL+Redis 模式 LCN 模式只能应用于本地存在连接对象且可通过连接对象控制事务的模块，例如 MySQL 等，对于 Redis 等没有本地事务控制的中间件是无效的。所以如果需要保证 MySQL 和 Redis 的双写一致性，可以用这种方式\n如果需要保证 redis 和 MySQL 的双写一致性，只需要在 try 方法中编写代码即可，然后在 cancel 方法中编写 redis 和 MySQL 的反操作/sql\n源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 package com.codingapi.txlcn.tc.core.transaction.tcc.control; /** * Description: * Date: 2018/12/13 * * @author 侯存路 */ @Component @Slf4j public class TccTransactionCleanService implements TransactionCleanService { private final ApplicationContext applicationContext; private final TMReporter tmReporter; private final TCGlobalContext globalContext; @Autowired public TccTransactionCleanService(ApplicationContext applicationContext, TMReporter tmReporter, TCGlobalContext globalContext) { this.applicationContext = applicationContext; this.tmReporter = tmReporter; this.globalContext = globalContext; } @Override public void clear(String groupId, int state, String unitId, String unitType) throws TransactionClearException { Method exeMethod; boolean shouldDestroy = !TracingContext.tracing().hasGroup(); try { TccTransactionInfo tccInfo = globalContext.tccTransactionInfo(unitId, null); Object object = applicationContext.getBean(tccInfo.getExecuteClass()); // 将要移除。 if (Objects.isNull(DTXLocalContext.cur())) { DTXLocalContext.getOrNew().setJustNow(true); } if (shouldDestroy) { TracingContext.init(Maps.of(TracingConstants.GROUP_ID, groupId, TracingConstants.APP_MAP, \"{}\")); } DTXLocalContext.getOrNew().setGroupId(groupId); DTXLocalContext.cur().setUnitId(unitId); exeMethod = tccInfo.getExecuteClass().getMethod( state == 1 ? tccInfo.getConfirmMethod() : tccInfo.getCancelMethod(), tccInfo.getMethodTypeParameter()); try { exeMethod.invoke(object, tccInfo.getMethodParameter()); log.debug(\"User confirm/cancel logic over.\"); } catch (Throwable e) { log.error(\"Tcc clean error.\", e); tmReporter.reportTccCleanException(groupId, unitId, state); } } catch (Throwable e) { throw new TransactionClearException(e.getMessage()); } finally { if (DTXLocalContext.cur().isJustNow()) { DTXLocalContext.makeNeverAppeared(); } if (shouldDestroy) { TracingContext.tracing().destroy(); } } } } LCN+TCC 混合使用 LCN 和 TCC 两种模式也可以混合使用，例如在 A 服务中使用 LCN 模式，在 B 服务中使用 TCC 模式。只需要在 A 服务中使用 @LcnTransaction 注解，在 B 服务中使用 @TccTransaction 注解即可\nLCN 模式和 TCC 模式对比 LCN 原理介绍: LCN 模式是通过代理 Connection 的方式实现对本地事务的操作，然后在由 TxManager 统一协调控制事务。当本地事务提交回滚或者关闭连接时将会执行假操作，该代理的连接将由 LCN 连接池管理。\n模式特点\n该模式对代码的嵌入性为低。 该模式仅限于本地存在连接对象且可通过连接对象控制事务的模块。 该模式下的事务提交与回滚是由本地事务方控制，对于数据一致性上有较高的保障。 该模式缺陷在于代理的连接需要随事务发起方一共释放连接，增加了连接占用的时间。 TCC 原理介绍: TCC 事务机制相对于传统事务机制（X/Open XA Two-Phase-Commit），其特征在于它不依赖资源管理器(RM)对 XA 的支持，而是通过对（由业务系统提供的）业务逻辑的调度来实现分布式事务。主要由三步操作，Try: 尝试执行业务、Confirm:确认执行业务、Cancel: 取消执行业务。\n模式特点\n该模式对代码的嵌入性高，要求每个业务需要写三种步骤的操作。 该模式对有无本地事务控制都可以支持使用面广。 数据一致性控制几乎完全由开发者控制，对业务开发难度要求高。 Seata Seata 官网\n注意这里的 TC 和 TM 的概念与 tx-lcn 中的概念有区别\nTC: Transaction Coordinator, 事务协调者\nTM: Transaction Manager, 事务管理者，也叫事务发起者。\n注意：在 seata 中 TM 和 lcn 中 TM 的功能不同。在 seata 中的 TM 也是 RM 的一种, TC 类似于 lcn 中的 TM\nRM: Resource Manager, 资源管理者\nAT 模式 只适用于基于本地 ACID 事务的关系型数据库.\n整体机制 两阶段提交协议的演变：\n一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源。 二阶段： 提交异步化，非常快速地完成。 回滚通过一阶段的回滚日志进行反向补偿。 写隔离 引入了全局锁, 只有持有全局锁, 才能进行提交，提交后释放全局锁. 如果超时没获取到全局锁就会回滚\n正常流程(二阶段是全局提交)\n首先事务 1 先执行，获取本地锁，执行 SQL, 然后获取全局锁, 执行本地提交，最后释放本地锁。 然后事务 2 开始执行，获取本地锁，执行 SQL 在事务 1 全局提交前，事务 2 一直尝试获取全局锁 事务 1 在二阶段全局提交后释放全局锁, 事务 2 拿到全局锁, 开始进行本地提交，释放本地锁 回滚流程(二阶段是全局回滚)\n如果在事务 2 尝试获取全局锁期间，事务 1 的二阶段不是全局提交而是全局回滚，则会出现下方回滚流程\n首先事务 1 先执行，获取本地锁，执行 SQL, 然后获取全局锁，执行本地提交，最后释放本地锁 然后事务 2 开始执行，获取本地锁，执行 SQL 在事务 2 尝试获取全局锁的时候，事务 1 收到有服务返回 no, 所以需要执行全局回滚，此时事务 1 需要获取本地锁，但是此时本地锁被事务 2 持有，全局锁被事务 1 持有，所以会出现死锁状态。 等事务 2 获取全局锁超时后，执行本地回滚并释放本地锁 事务 1 获取到本地锁，开始执行本地回滚。至此全局回滚结束 因为在事务 1 执行结束前，事务 1 一直持有全局锁, 所以事务 2 不能进行本地提交，所以不会出现脏读的问题\n读隔离 在数据库本地事务隔离级别 读已提交（Read Committed） 或以上的基础上，Seata（AT 模式）的默认全局隔离级别是 读未提交（Read Uncommitted）。\n如果应用在特定场景下，必需要求全局的 读已提交，目前 Seata 的方式是通过 SELECT FOR UPDATE 语句的代理。\nSELECT FOR UPDATE 语句的执行会申请 全局锁，如果 全局锁 被其他事务持有，则释放本地锁（回滚 SELECT FOR UPDATE 语句的本地执行）并重试。这个过程中，查询是被 block 住的，直到 全局锁 拿到，即读取的相关数据是 已提交 的，才返回。\n出于总体性能上的考虑，Seata 目前的方案并没有对所有 SELECT 语句都进行代理，仅针对 FOR UPDATE 的 SELECT 语句。\n项目搭建 相关的配置脚本，github 位置 https://github.com/seata/seata/tree/develop/script\n搭建 TC 下载 seata-server\nhttp://seata.io/zh-cn/blog/download.html\n修改 registry.conf 配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 注册中心配置 registry { # file、nacos、eureka、redis、zk、consul、etcd3、sofa # 要让 seata 注册到 eureka 上，所以修改成 eureka type = \"eureka\" # 上方 type 设置为了 eureka，所以修改 eureka 的配置，设置成 eureka-server 的地址 eureka { serviceUrl = \"http://localhost:7900/eureka\" application = \"eureka-server\" weight = \"1\" } } # 配置中心的配置 config { # file、nacos、apollo、zk、consul、etcd3 # 如果 type 类型是 file，则从本地 file.conf 中获取配置参数 type = \"file\" # 因为 config.type=file，所以此处指定配置文件名称 file { name = \"file.conf\" } } 修改 file.conf 文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 service { # transaction server group mapping # 事务组的名称，相当于 spring.application.name vgroup_mapping.my_tx_group = \"seata-server\" disableGlobalTransaction = true } ## transaction log store, only used in seata-server store { ## store mode: file、db、redis # 存储类型 mode = \"db\" ## database store property # 因为 store.mode 设置为了 db，所以修改 db 的配置 db { ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp)/HikariDataSource(hikari) etc. datasource = \"druid\" ## mysql/oracle/postgresql/h2/oceanbase etc. dbType = \"mysql\" driverClassName = \"com.mysql.cj.jdbc.Driver\" url = \"jdbc:mysql://127.0.0.1:3306/seata-server?useUnicode=true\u0026useSSL=false\u0026characterEncoding=utf8\u0026serverTimezone=Asia/Shanghai\" user = \"root\" password = \"root\" minConn = 5 maxConn = 100 globalTable = \"global_table\" branchTable = \"branch_table\" lockTable = \"lock_table\" queryLimit = 100 maxWait = 5000 } } 创建数据表\n因为使用的是 db 模式，所以需要创建数据库表：https://github.com/seata/seata/blob/develop/script/server/db/mysql.sql\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 -- -------------------------------- The script used when storeMode is 'db' -------------------------------- -- the table to store GlobalSession data CREATE TABLE IF NOT EXISTS `global_table` ( `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `status` TINYINT NOT NULL, `application_id` VARCHAR(32), `transaction_service_group` VARCHAR(32), `transaction_name` VARCHAR(128), `timeout` INT, `begin_time` BIGINT, `application_data` VARCHAR(2000), `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`xid`), KEY `idx_gmt_modified_status` (`gmt_modified`, `status`), KEY `idx_transaction_id` (`transaction_id`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8; -- the table to store BranchSession data CREATE TABLE IF NOT EXISTS `branch_table` ( `branch_id` BIGINT NOT NULL, `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `resource_group_id` VARCHAR(32), `resource_id` VARCHAR(256), `branch_type` VARCHAR(8), `status` TINYINT, `client_id` VARCHAR(64), `application_data` VARCHAR(2000), `gmt_create` DATETIME(6), `gmt_modified` DATETIME(6), PRIMARY KEY (`branch_id`), KEY `idx_xid` (`xid`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8; -- the table to store lock data CREATE TABLE IF NOT EXISTS `lock_table` ( `row_key` VARCHAR(128) NOT NULL, `xid` VARCHAR(96), `transaction_id` BIGINT, `branch_id` BIGINT NOT NULL, `resource_id` VARCHAR(256), `table_name` VARCHAR(32), `pk` VARCHAR(36), `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`row_key`), KEY `idx_branch_id` (`branch_id`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8; 启动 Eureka-Server\n启动 seata-server\n1 ./bin/seata-server.sh 搭建 TM 引入依赖\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-alibaba-seata\u003c/artifactId\u003e \u003cversion\u003e2.2.0.RELEASE\u003c/version\u003e \u003c/dependency\u003e 添加配置\n1 2 3 4 5 6 spring: cloud: alibaba: seata: # 对应 TC 的配置文件 file.conf 中的 service.vgroup_mapping.my_tx_group tx-service-group: my_tx_group 根据业务场景创建数据库和 entity，mapper，dao\n此处创建三个项目：seata-one，seata-two，seata-three\n三个数据库：seata-rm-one, seata-rm-two, seata-rm-three\n三个数据表，分别在对应的数据库里：tbl_one, tbl_two, tbl_three\n在每个 TM 的数据库中都要创建 seata 用的 undo_log 数据表\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 -- 注意此处 0.3.0+ 增加唯一索引 ux_undo_log CREATE TABLE `undo_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `branch_id` bigint(20) NOT NULL, `xid` varchar(100) NOT NULL, `context` varchar(128) NOT NULL, `rollback_info` longblob NOT NULL, `log_status` int(11) NOT NULL, `log_created` datetime NOT NULL, `log_modified` datetime NOT NULL, `ext` varchar(100) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`) ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 在事务发起方的方法上添加 @GlobalTransactional 注解，即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /** * 在事务发起方上添加 GlobalTransactional 注解即可 */ @GlobalTransactional(rollbackFor = Exception.class) public String rm1() { TblOne o = new TblOne(); o.setId(1); o.setVal(\"rm1\"); tblOneDAO.insert(o); // 调用 seata-two 和 seata-three 服务 restTemplate.postForObject(\"http://seata-two/rm-two\", null, String.class); restTemplate.postForObject(\"http://seata-three/rm-three\", null, String.class); // System.out.println(1/0); return \"rm1 success\"; } TCC 模式 流程 TCC 的问题 幂等 RM 在执行完 confirm/cancel 的时候，会通知 TC, 如果 TC 没有收到该通知，就会再次通知 RM 执行 confirm/cancel, 就会出现多次执行 confirm/cancel 的情况\n空回滚 RM 向 TC 注册完分支事务后，该事务已经落库，但是由于网络抖动等原因，TC 检测到超时后，通知 RM 执行了 cancel 方法，出现还没有执行 try 方法，就执行了 cancel 中的回滚方法，从而发生异常\n资源悬挂 在空回滚的基础上，TC 检测超时后，已经通知了所有 RM 执行了 cancel 方法，之后发起方对参与方的 Try 才开始执行，由于此时分布式事务已经结束，执行 Try 方法使用的锁资源等无法在被释放，从而造成资源悬挂\n无论是幂等，空回滚，还是资源悬挂吗，都可以通过使用事务状态控制表来解决\n加 事务状态控制表(全局事务 Id, 分支事务 Id, 分支事务状态), 全局事务 Id 和分支事务 Id 构成表的联合主键，全局事务状态有 3 种: INIT(I), CONFIRMED(C), ROLLBACKED(R), 在执行 try 的时候将事务标记为 I, 在执行 confirm/cancel 的时候将事务标记为 C/R.\n项目搭建 http://seata.io/zh-cn/blog/integrate-seata-tcc-mode-with-spring-cloud.html\n搭建 TC 和 AT 模式的 [搭建 TC](#搭建 TC) 相同\n搭建 TM 引入依赖\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-alibaba-seata\u003c/artifactId\u003e \u003cversion\u003e2.2.0.RELEASE\u003c/version\u003e \u003c/dependency\u003e 添加配置\n1 2 3 4 5 6 spring: cloud: alibaba: seata: # 对应 TC 的配置文件 file.conf 中的 service.vgroup_mapping.my_tx_group tx-service-group: my_tx_group 业务接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 package com.example.one.service; import com.example.one.entity.TblOne; import io.seata.rm.tcc.api.BusinessActionContext; import io.seata.rm.tcc.api.BusinessActionContextParameter; import io.seata.rm.tcc.api.LocalTCC; import io.seata.rm.tcc.api.TwoPhaseBusinessAction; /** * LocalTCC 一定要定义在接口上 */ @LocalTCC public interface RmOneTccService { /** * 定义两阶段提交 * name = 该 tcc 的 bean 名称，全局唯一 * commitMethod = 二阶段的确认方法 * rollbackMethod = 二阶段的取消方法 * BusinessActionContextParameter 注解 可以将参数传递到第二阶段中 */ @TwoPhaseBusinessAction(name = \"rm1TccAction\", commitMethod = \"rm1TccConfirm\", rollbackMethod = \"rm1TccCancel\") String rm1Tcc(@BusinessActionContextParameter(paramName = \"param\") TblOne o); /** * 确认方法，方法名要与 commitMethod 方法指定的一致 * context 可以传递 try 方法中使用 BusinessActionContextParameter 注解指定的方法参数 */ String rm1TccConfirm(BusinessActionContext context); String rm1TccCancel(BusinessActionContext context); } 业务实现类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 package com.example.one.service.impl; import com.example.one.dao.TblOneDAO; import com.example.one.entity.TblOne; import com.example.one.service.RmOneTccService; import io.seata.rm.tcc.api.BusinessActionContext; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import org.springframework.transaction.annotation.Transactional; import org.springframework.web.client.RestTemplate; @Service(\"rmOneTccService\") public class RmOneTccServiceImpl implements RmOneTccService { @Autowired private TblOneDAO tblOneDAO; @Autowired private RestTemplate restTemplate; /** * 根据实际业务场景选择实际业务执行逻辑或资源预留逻辑 * 结合 Spring 的 Transactional 注解，在二阶段的 cancel 方法中只需对非关系型数据库进行手动回滚即可 */ @Override @Transactional(rollbackFor = Exception.class) public String rm1Tcc(TblOne o) { int id = tblOneDAO.insert(o); o.setId(id); // TODO 操作中间件，非关系型数据库 restTemplate.postForObject(\"http://seata-two/rm-two\", null, String.class); restTemplate.postForObject(\"http://seata-three/rm-three\", null, String.class); // System.out.println(1/0); return \"rm1 success\"; } /** * 若一阶段采用资源预留，在二阶段确认时要提交预留的资源 */ @Override public String rm1TccConfirm(BusinessActionContext context) { return null; } @Override public String rm1TccCancel(BusinessActionContext context) { // 从 context 中获取 try 方法中的参数 Object param = context.getActionContext(\"param\"); // TODO 操作中间件，非关系型数据库的回滚操作 return null; } } 源码 SeataAutoConfiguration\n2PC vs TCC vs 消息队列 2PC TCC 消息队列 一致性 强 最终一致 最终一致 吞吐量 低 中 高 复杂度 简单 复杂 中 使用 2PC 和 TCC 需要调用所有事务参与者后才返回，使用消息队列，只需要调用一次消息队列即可返回，所以使用消息队列的吞吐量更高\n可靠消息 最终一致性解决方案 如果 1-1 发送完待确认消息，1-2 将其入库后，长时间没有收到支付服务的消息，就会在数据库中长时间包含待确认状态的消息，所以支付服务提供一个查询接口，可靠消息服务使用定时任务定时回调该接口去查询业务状态，从而将待确认消息修改为已确认/已取消状态。这样还可以将支付服务和可靠消息服务间的分布式事务进行解耦。\n如果只依靠 1-6 向消息队列发送一次消息，可能会发送失败，所以可靠消息服务可以使用定时任务，定时将已确认状态的消息发送到消息队列，并将其修改为已发送状态。\n依靠 2-4 订单服务通知可靠消息服务修改消息状态为已完成，也会造成订单服务和可靠消息服务的分布式事务耦合，所以订单服务提供回调接口，可靠消息服务使用定时任务来获取订单状态，进而修改消息状态，可以将订单服务和可靠消息服务间分布式事务进行解耦\n消息列表+事件表方案与可靠消息服务的对比\n消息列表+事件表的方案，在每个微服务的数据库中都包含了一张事件表\n而可靠消息服务将事务的控制抽离成了一个单独的服务，该服务中只需要有一张事件表即可，并可以对外提供对多个不同服务间的事务控制\n最大努力通知方案 应用场景：第三方系统调用\n尽最大努力通知调用方 提供接口给调用方调用 例如支付宝支付回调，25 小时内回调 8 次。\n事务消息方案 RocketMQ 的回查机制：RocketMQ 本身包含一个定时任务，会定时对 half 消息进行扫描，然后回调相应的服务接口，如果服务返回已经成功，则将该 half 消息提交，否则，将其删除。\n代码 RocketMQ 安装 下载 RocketMQ\nhttps://rocketmq.apache.org/\n启动 RocketMQ 和 RocketMQ-Externals\n1 2 3 4 # 启动 nameserver sh ./bin/mqnamesrv # 启动 broker sh bin/mqbroker -n 127.0.0.1:9876 autoCreateTopicEnable=true JDK11 需要修改 RocketMQ 的启动文件：https://www.zhuyc.vip/archives/2020010716144722086\n下载启动控制台 RocketMQ-Console-NG\nhttps://github.com/apache/rocketmq-externals/tree/master/rocketmq-console\n1 2 3 4 # 拉取镜像 docker pull apacherocketmq/rocketmq-console:2.0.0 # 启动容器 docker run -e \"JAVA_OPTS=-Drocketmq.namesrv.addr=172.17.0.1:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false\" -p 8080:8080 --name rocketmq-console -d apacherocketmq/rocketmq-console:2.0.0 事务发起方 添加 RocketMQ 依赖\n1 2 3 4 5 6 \u003c!-- RocketMQ --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.rocketmq\u003c/groupId\u003e \u003cartifactId\u003erocketmq-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e2.2.0\u003c/version\u003e \u003c/dependency\u003e 配置事务监听器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 package com.example.producer.listener; import com.alibaba.fastjson.JSONObject; import com.example.producer.dao.TransactionLogDAO; import com.example.producer.entity.TblOrder; import com.example.producer.service.TblOrderService; import lombok.extern.slf4j.Slf4j; import org.apache.rocketmq.client.producer.LocalTransactionState; import org.apache.rocketmq.client.producer.TransactionListener; import org.apache.rocketmq.common.message.Message; import org.apache.rocketmq.common.message.MessageExt; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; /** * 事务监听器 * 发送 half msg 返回 send ok 后，执行 executeLocalTransaction 方法，即执行本地事务 * RocketMQ 定时回查时，执行 checkLocalTransaction 方法, 对 * * @author wangshuo * @date 2021/03/24 */ @Component @Slf4j public class OrderTransactionListener implements TransactionListener { /** * 本地业务服务 */ @Autowired private TblOrderService tblOrderService; /** * 事务日志表，便于回查 */ @Autowired private TransactionLogDAO transactionLogDAO; /** * 发送 half msg 返回 send ok 后执行该方法 */ @Override public LocalTransactionState executeLocalTransaction(Message message, Object o) { log.info(\"开始执行本地事务\"); LocalTransactionState state; try { // 本地业务 String body = new String(message.getBody()); TblOrder order = JSONObject.parseObject(body, TblOrder.class); // 在创建订单的时候，同时向事务日志表中插入一条记录，便于回查时使用 tblOrderService.createOrder(order, message.getTransactionId()); // 只有返回 commit 后，消息才能被消费者消费 state = LocalTransactionState.COMMIT_MESSAGE; log.info(\"本地事务已提交. {}\", message.getTransactionId()); } catch (Exception e) { log.info(\"执行本地事务失败.\", e); state = LocalTransactionState.ROLLBACK_MESSAGE; } return state; } /** * 回查 走的方法 */ @Override public LocalTransactionState checkLocalTransaction(MessageExt messageExt) { // TODO 回查多次失败 人工补偿。给管理员发邮件 log.info(\"开始回查本地事务状态. {}\", messageExt.getTransactionId()); LocalTransactionState state; String transactionId = messageExt.getTransactionId(); if (transactionLogDAO.selectCount(transactionId) \u003e 0) { state = LocalTransactionState.COMMIT_MESSAGE; } else { // 查到 UNKNOW 后，过一会还会再来回查 state = LocalTransactionState.UNKNOW; } log.info(\"结束本地事务状态查询: {}\", state); return state; } } 配置事务生产者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 package com.example.producer.producer; import com.example.producer.listener.OrderTransactionListener; import lombok.extern.slf4j.Slf4j; import org.apache.rocketmq.client.exception.MQClientException; import org.apache.rocketmq.client.producer.TransactionMQProducer; import org.apache.rocketmq.client.producer.TransactionSendResult; import org.apache.rocketmq.common.message.Message; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import javax.annotation.PostConstruct; import javax.annotation.PreDestroy; import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; /** * 对外提供 sendMessage 方法，以供业务调用，向 RocketMQ 发送 half message * * @author wangshuo * @date 2021/03/23 */ @Slf4j @Component public class OrderTransactionProducer { /** * 事务消息生产者 */ private TransactionMQProducer producer; /** * 用于执行本地事务和事务状态回查的监听器 */ @Autowired private OrderTransactionListener orderTransactionListener; /** * 执行任务的线程池 */ ThreadPoolExecutor executor = new ThreadPoolExecutor( 5, 5, 60, TimeUnit.SECONDS, new ArrayBlockingQueue\u003c\u003e(50)); @PostConstruct public void init() { String producerGroup = \"order_trans_group\"; String namesrvAddr = \"127.0.0.1:9876\"; producer = new TransactionMQProducer(producerGroup); producer.setNamesrvAddr(namesrvAddr); producer.setSendMsgTimeout(Integer.MAX_VALUE); producer.setExecutorService(executor); producer.setTransactionListener(orderTransactionListener); try { producer.start(); } catch (MQClientException e) { log.error(\"producer 启动失败.\", e); } } @PreDestroy public void stop() { if (producer != null) { producer.shutdown(); } } /** * 对外提供方法，发送 half message */ public TransactionSendResult sendMessage(String topic, String data) throws MQClientException { log.info(\"发送 half message\"); Message message = new Message(topic, data.getBytes()); TransactionSendResult result = this.producer.sendMessageInTransaction(message, null); log.info(\"half message 发送成功\"); return result; } } 订单服务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 package com.example.producer.service.impl; import com.alibaba.fastjson.JSONObject; import com.example.producer.dao.TblOrderDAO; import com.example.producer.dao.TransactionLogDAO; import com.example.producer.entity.TblOrder; import com.example.producer.entity.TransactionLog; import com.example.producer.producer.OrderTransactionProducer; import com.example.producer.service.TblOrderService; import lombok.extern.slf4j.Slf4j; import org.apache.rocketmq.client.exception.MQClientException; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import org.springframework.transaction.annotation.Transactional; /** * @author wangshuo * @date 2021/03/24 */ @Slf4j @Service(\"tblOrderService\") public class TblOrderServiceImpl implements TblOrderService { @Autowired private TblOrderDAO tblOrderDAO; @Autowired private TransactionLogDAO transactionLogDAO; @Autowired private OrderTransactionProducer orderTransactionProducer; /** * 供 Controller 调用，给 RocketMQ 发送 half message * * @param order 订单对象 */ @Override public void createOrder(TblOrder order) { try { orderTransactionProducer.sendMessage(\"order\", JSONObject.toJSONString(order)); } catch (MQClientException e) { log.info(\"创建订单失败\", e); } } /** * 在 half message 返回 send ok 后, TransactionListener 中执行该业务方法 * * @param order 订单信息 * @param transactionId RocketMQ 生成的事务 Id */ @Override @Transactional(rollbackFor = Exception.class) public void createOrder(TblOrder order, String transactionId) { // 1. 创建订单 tblOrderDAO.insert(order); // 2. 写入事务日志 TransactionLog log = new TransactionLog(); log.setBusiness(\"order\"); log.setForeignKey(String.valueOf(order.getId())); transactionLogDAO.insert(log); } } 事务参与方 添加 RocketMQ 依赖\n1 2 3 4 5 6 \u003c!-- RocketMQ --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.rocketmq\u003c/groupId\u003e \u003cartifactId\u003erocketmq-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e2.2.0\u003c/version\u003e \u003c/dependency\u003e 订单监听器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 package com.example.consumer.listener; import com.alibaba.fastjson.JSONObject; import com.example.consumer.entity.TblOrder; import com.example.consumer.service.TblPayService; import lombok.extern.slf4j.Slf4j; import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext; import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus; import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently; import org.apache.rocketmq.common.message.MessageExt; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import java.util.List; /** * @author wangshuo * @date 2021/03/24 */ @Slf4j @Component public class OrderMessageListener implements MessageListenerConcurrently { @Autowired private TblPayService tblPayService; @Override public ConsumeConcurrentlyStatus consumeMessage(List\u003cMessageExt\u003e list, ConsumeConcurrentlyContext consumeConcurrentlyContext) { log.info(\"消费者线程监听到消息。\"); try { for (MessageExt message : list) { log.info(\"开始处理订单数据，准备增加积分....\"); TblOrder order = JSONObject.parseObject(message.getBody(), TblOrder.class); tblPayService.increasePoints(order); } return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; } catch (Exception e) { log.error(\"处理消费者数据发生异常。\", e); return ConsumeConcurrentlyStatus.RECONSUME_LATER; } } } 订单消费者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 package com.example.consumer.consumer; import com.example.consumer.listener.OrderMessageListener; import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer; import org.apache.rocketmq.client.exception.MQClientException; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import javax.annotation.PostConstruct; /** * @author wangshuo * @date 2021/03/24 */ @Component public class OrderConsumer { private DefaultMQPushConsumer consumer; @Autowired private OrderMessageListener orderMessageListener; @PostConstruct public void init() throws MQClientException { String consumerGroup = \"order-consumer-group\"; String namesrvAddr = \"127.0.0.1:9876\"; consumer = new DefaultMQPushConsumer(consumerGroup); consumer.setNamesrvAddr(namesrvAddr); consumer.subscribe(\"order\", \"*\"); consumer.registerMessageListener(orderMessageListener); // 2 次失败 就进私信队列 consumer.setMaxReconsumeTimes(2); consumer.start(); } } 死信队列中的订单监听器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 package com.example.consumer.listener; import com.alibaba.fastjson.JSONObject; import com.example.consumer.entity.TblOrder; import com.example.consumer.service.TblPayService; import lombok.extern.slf4j.Slf4j; import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext; import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus; import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently; import org.apache.rocketmq.common.message.MessageExt; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import java.util.List; /** * 监听死信队列中的消息 * * @author wangshuo * @date 2021/03/24 */ @Slf4j @Component public class OrderDldMessageListener implements MessageListenerConcurrently { @Autowired TblPayService tblPayService; @Override public ConsumeConcurrentlyStatus consumeMessage(List\u003cMessageExt\u003e list, ConsumeConcurrentlyContext context) { log.info(\"死信队列：消费者线程监听到消息。\"); try { for (MessageExt message : list) { log.info(\"死信队列：开始处理订单数据，准备增加积分....\"); TblOrder order = JSONObject.parseObject(message.getBody(), TblOrder.class); tblPayService.increasePoints(order); } return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; } catch (Exception e) { log.error(\"死信队列：处理消费者数据发生异常\", e); return ConsumeConcurrentlyStatus.RECONSUME_LATER; } } } 死信队列中订单消费者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 package com.example.consumer.consumer; import com.example.consumer.listener.OrderDldMessageListener; import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer; import org.apache.rocketmq.client.exception.MQClientException; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import javax.annotation.PostConstruct; /** * 对死信队列中的消息进行消费 * * @author wangshuo * @date 2021/03/24 */ @Component public class OrderDldConsumer { DefaultMQPushConsumer consumer; @Autowired private OrderDldMessageListener orderDldMessageListener; @PostConstruct public void init() throws MQClientException { String consumerGroup = \"consumer-order-dld-group\"; String namesrvAddr = \"127.0.0.1:9876\"; consumer = new DefaultMQPushConsumer(consumerGroup); consumer.setNamesrvAddr(namesrvAddr); consumer.subscribe(\"%DLQ%consumer-order-group\", \"*\"); consumer.registerMessageListener(orderDldMessageListener); consumer.setMaxReconsumeTimes(2); consumer.start(); } } 业务代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package com.example.consumer.service.impl; import com.example.consumer.dao.TblPayDAO; import com.example.consumer.entity.TblOrder; import com.example.consumer.entity.TblPay; import com.example.consumer.service.TblPayService; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; @Slf4j @Service(\"tblPayService\") public class TblPayServiceImpl implements TblPayService { @Autowired private TblPayDAO tblPayDAO; @Override public void increasePoints(TblOrder order) { TblPay pay = new TblPay(); pay.setVal(\"12345\"); tblPayDAO.insert(pay); log.info(\"增加积分成功\"); } } 分布式事务总结 2PC 只有协调者超时，超时就回滚 一开始就占用资源 3PC 把 2PC 的第一阶段拆成了两个阶段 协调者和参与者都会超时(协调者超时回滚，参与者 pre 超时回滚, do 超时提交) 从第二阶段开始才占用资源 TCC 是把 2PC 的第二阶段拆成了两个阶段 不占用连接，性能高 LCN(LCN, TCC) seata(AT, TCC) 消息队列 + 事件表 最大努力通知 可靠消息服务 消息事务 ","description":"","tags":["MSB","Project","网约车三期","Java"],"title":"分布式事务","uri":"/posts/msb/%E7%BD%91%E7%BA%A6%E8%BD%A6%E4%B8%89%E6%9C%9F/distributed-transaction/"},{"categories":null,"content":"二进制和简单排序 原码，反码，补码 计算机中对整型数字的存储和计算都是使用其二进制补码的形式。以 int 为例，共使用 32 位进行存储，其中最高位是符号位（1 代表负数，0 代表非负数）。\n原码 原码就是符号位加真值\n十进制 二进制原码（int） 5 0000 0000 0000 0000 0000 0000 0000 0101 0 0000 0000 0000 0000 0000 0000 0000 0000 -5 1000 0000 0000 0000 0000 0000 0000 0101 反码 非负数的反码与原码相同；负数的反码是其原码符号位不变，其余位取反\n十进制 二进制反码（int） 5 0000 0000 0000 0000 0000 0000 0000 0101 0 0000 0000 0000 0000 0000 0000 0000 0000 -5 1111 1111 1111 1111 1111 1111 1111 1010 补码 非负数的补码与原码相同；负数的补码是其反码加一\n十进制 二进制补码（int） 5 0000 0000 0000 0000 0000 0000 0000 0101 0 0000 0000 0000 0000 0000 0000 0000 0000 -5 1111 1111 1111 1111 1111 1111 1111 1011 总结 非负数的反码，补码与原码相同；负数的反码是原码符号位不变，其余位取反；负数的补码是其反码加一。\n思考 为什么负数的补码要用反码加一\n因为计算机只能处理二进制位，所以对算数运算（+、-、*、/）都是使用位运算（\u0026、|、^、~）进行组合实现的。为了保证无论是正数和正数，正数和负数，负数和负数间进行某一算数运算时都使用同一套逻辑，所以将负数的补码设计为了其反码加一。（如果有多套逻辑，就会造成每次做算数运算的时候都需要进行判断，从而使得效率降低）\nint 型整数的取值范围计算\nint 使用 32 位对其值进行存储，其中最高位是符号位，所以有 31 位表示其真实的数值。所以 int 的最大值就是$2^{31}-1$，其中 -1 表示的是数字 0。而 int 的最小值就是。$-2^{31}$ 所以 int 的取值范围是 $-2^{31}$ ~ $2^{31}-1$\n位运算 取反（~） 0 变成 1，1 变成 0\n原码 取反 0000 0000 0000 0000 1111 1111 1111 1111 0011 0101 1010 1010 1100 1010 0101 0101 1100 0011 1010 0101 0011 1100 0101 1010 与（\u0026） 全是 1 才是 1，否则就是 0\n0010 1001 1100 0011 \u0026 1011 0111 0111 0101 = 0010 0001 0100 0001 或（|） 有 1 就是 1，否则就是 0\n0010 1001 1100 0011 | 1011 0111 0111 0101 = 1011 1111 1111 0111 异或（^） 不相同为 1，相同为 0\n0010 1001 1100 0011 ^ 1011 0111 0111 0101 = 1001 1110 1011 0110 左移（\u003c\u003c） 整体向左移动，低位补 0\n0000 0000 0000 0101 5 \u003c\u003c1 0000 0000 0000 1010 10 = 5*2^1 \u003c\u003c2 0000 0000 0001 0100 20 = 5*2^2 \u003c\u003c34 0000 0000 0001 0100 20 = 5*2^(34%16) 1111 1111 1111 1011 -5 \u003c\u003c1 1111 1111 1111 0110 -10 = 5*2^1 \u003c\u003c2 1111 1111 1110 1100 -20 = 5*2^2 \u003c\u003c34 1111 1111 1110 1100 -20 = 5*2^(34%16) 任意一个整数 N 左移 K 位，结果是 $N2^K$，即 $N\u003c\u003cK=N2K$ 在 Java 中，当左移的位数 K 超出该类型的最大位数后，会对 K 进行取模。例如对 short 类型的数左移 34 位，实际上移动的位数是 2 位（34%16=2） 右移（\u003e\u003e） 整体向右移动，高位补符号位\n0000 0000 0000 0101 5 \u003e\u003e1 0000 0000 0000 0010 2 = 5/2^1 \u003e\u003e2 0000 0000 0000 0001 1 = 5/2^2 \u003e\u003e4 0000 0000 0000 0000 0 = 5/2^4 \u003e\u003e34 0000 0000 0000 0000 0 = 5/2^(34%16) 1111 1111 1111 1011 -5 \u003e\u003e1 1111 1111 1111 1101 -3 \u003e\u003e2 1111 1111 1111 1110 -2 \u003e\u003e34 1111 1111 1111 1110 -2 = -5\u003e\u003e(34%16) 非负整数 N 右移 K 位，结果是 $N/2^K$，即 $N\u003e\u003eK=N/2^K(N\\ge0)$ 在 Java 中，当右移的位数 K 超出该类型的最大位数后，会对 K 进行取模。例如对 short 类型的数右移 34 位，实际上移动的位数是 2 位（34%16=2） 无符号右移（\u003e\u003e\u003e） 整体向右移动，高位补 0\n0000 0000 0000 0101 5 \u003e\u003e\u003e1 0000 0000 0000 0010 2 = 5/2^1 \u003e\u003e\u003e2 0000 0000 0000 0001 1 = 5/2^2 \u003e\u003e\u003e4 0000 0000 0000 0000 0 = 5/2^4 \u003e\u003e\u003e34 0000 0000 0000 0000 0 = 5/2^(34%16) 1111 1111 1111 1011 -5 \u003e\u003e\u003e1 0111 1111 1111 1101 2147483645 \u003e\u003e\u003e2 0011 1111 1111 1110 1073741822 \u003e\u003e\u003e34 0011 1111 1111 1110 1073741822 = -5\u003e\u003e\u003e(34%16) 非负整数的无符号右移和右移是相同的，都符合 $N\u003e\u003eK=N/2^K(N\\ge0)$ 在 Java 中，当无符号右移的位数 K 超过该类型最大位数后，会对 K 进行取模。例如对 short 类型的数右移 34 位，实际上移动的位数是 2 位（34%16=2） 练习题 打印一个整数的二进制表现形式\n在计算机中，整数 1 的二进制是：0000 0000 0000 0000 0000 0000 0000 0001 所以 N\u00261 的结果，只有最低位可能出现两种情况，其余位都是 0。 如果 N 的最低位是 0，则 N\u00261 就是 0；如果 N 的最低位是 1，则 N\u00261 就是 1 同理，如果将 1 左移 1 位，其二进制变为：0000 0000 0000 0000 0000 0000 0000 0010 此时 N\u0026(1\u003c\u003c1) 的结果就只受 N 的二进制倒数第二位的影响。 如果 N 的二进制的倒数第二位是 0，则 N\u0026(1\u003c\u003c1) 就是 0；如果 N 的二进制的倒数第二位是 1，则 N\u0026(1\u003c\u003c1) 就是 2 所以，如果 N\u0026(1\u003c\u003cK) 等于 0，就说明 N 的二进制的 K 位是 0；如果 N\u0026(1\u003c\u003cK) 不等于 0，就说明 N 的二进制的 K 位是 1 所以要想获取一个数的二进制表现形式，我们可以让这个数依次和 1\u003c\u003c31、1\u003c\u003c30、……、1\u003c\u003c0 进行与运算，判断其每一位上是 0 还是 1 1 2 3 4 5 6 7 private static void printBinary(int num) { for (int i = 31; i \u003e= 0; i--) { int b = (num \u0026 (1 \u003c\u003c i)) == 0 ? 0 : 1; System.out.print(b); } System.out.println(); } 简单排序 选择排序\n基本思想\n在未排序的数组中找到最小数的下标，将其放在数组的第 1 个元素位置；然后在剩余未排序的数组中找到最小数的下标，依次放在已排序数组的后面\n实现过程\n第一轮：用 arr[0] 依次与其后面的数进行比较，找到最小数所在位置的下标，然后将二者进行交换 第二轮：用 arr[1] 依次与其后面的数进行比较，找到最小数所在位置的下标，然后将二者进行交换 依次类推…… 第 N 轮：用 arr[N-1] 依次与其后面的数进行比较，找到最小数所在位置的下标，然后将二者进行交换 边界条件\n传入的数组为 null，或者数组长度小于 2 的时候，不需要对其进行排序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 private static void selectSort(int[] arr){ if(arr == null || arr.length \u003c 2){ return; } for(int i = 0; i \u003c arr.length - 1; i++){ int minNumIndex = i; for(int j = i + 1; j \u003c arr.length; j++){ minNumIndex = arr[minNumIndex] \u003e arr[j] ? j : minNumIndex; } } } private static void swap(int[] arr, int i, int j){ int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } 冒泡排序\n基本思想\n在未排序的数组中，相邻两数进行比较，较大的数向后移动\n实现过程\n第一轮：在 [0, N-1] 范围上，依次比较相邻的两个数，较大的数向后移动，最终在下标为 N-1 的位置上即为最大数\n第二轮：在 [0, N-2] 范围上，依次比较相邻的两个数，较大的数向后移动，最终从下标 N-2 的位置开始有序\n以此类推……\n第 N-1 轮：在 [0, 1] 范围上，依次比较相邻的两个数，较大的向后移动，最终整体有序\n边界条件\n传入的数组为 null，或者数组长度小于 2 的时候，不需要对其进行排序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 private static void bubbleSort(int[] arr) { if(arr == null || arr.length \u003c 2){ return; } for (int end = arr.length - 1; end \u003e 0; end--) { for (int i = 0; i \u003c end; i++) { if (arr[i] \u003e arr[i + 1]) { swap(arr, i, i + 1); } } } } private static void swap(int[] arr, int i, int j){ int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } 插入排序\n基本思想\n保证第 [0, i] 位置是有序的。类似于抓扑克牌，手中的牌都是有序的，当抓到一张新牌的时候，从后向前依次比较，将其插入在适当的位置\n实现过程\n第一轮：arr[0] 本身就是有序的，不需要判断\n第二轮：用 arr[1] 与 arr[0] 进行比较，如果 arr[1]\u003carr[0]，将 arr[1]与 arr[0] 交换，此时在 [0, 1] 上有序\n第三轮：用 arr[2] 与 arr[1] 进行比较，如果 arr[2]\u003carr[1]，将 arr[2]与 arr[1] 交换；然后用 arr[1] 与 arr[0] 进行比较，如果 arr[1]\u003carr[0]，将 arr[1] 与 arr[0] 进行交换，此时在 [0,2] 上有序\n以此类推……\n第 N 轮：用 arr[N-1] 与 arr[N-2] 进行比较，如果 arr[N-1]\u003carr[N-2]，将 arr[N-1] 与 arr[N-2] 交换；然后用 arr[N-2] 与 arr[N-3] 进行比较，如果 arr[N-2]\u003carr[N-3]，将 arr[N-2] 与 arr[N-3] 交换；……；此时在 [0, N-1] 上有序\n边界条件\n传入的数组为 null，或者数组长度小于 2 的时候，不需要对其进行排序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 private static void insertSort(int[] arr){ if(arr == null || arr.length \u003c 2){ return; } for(int end = 1; end \u003c arr.length; end++){ for(int curNumIndex = end; curNumIndex - 1 \u003e= 0 \u0026\u0026 arr[curNumIndex] \u003c arr[curNumIndex - 1]; curNumIndex--){ swap(arr, curNumIndex, curNumIndex - 1); } } } private static void swap(int[] arr, int i, int j){ int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } ","description":"","tags":["MSB","Algorithm","Binary","Java"],"title":"二进制和简单排序","uri":"/posts/msb/%E7%AE%97%E6%B3%95/binary-and-simple-sort/"},{"categories":null,"content":"internal-common 1 2 3 4 5 6 7 \u003cartifactId\u003einternal-common\u003c/artifactId\u003e \u003c!-- 如果一个项目依赖于带-SNAPSHOT 的 jar，例如 XXX-SNAPSHOT.jar，那么每次构建该项目的时候它都会优先去远程仓库检查是否有更新，如果有就将它拉取过来，可以保证使用的 jar 包是最新的，在开发的时候使用，可以提高团队协作效率；但是不能在生产环境中使用，否则可能会将没有经过测试的 jar 打包到了生产环境中。 如果一个项目依赖与不带-SNAPSHOT 的 jar，例如 XXX.jar，那么每次构建该项目的时候如果本地有该 jar，就不会去判断远程仓库上是否有更新了。 --\u003e \u003cversion\u003e0.0.1-SNAPSHOT\u003c/version\u003e \u003cname\u003einternal-common\u003c/name\u003e api-passenger：发送验证码\nURI：sms/verify-code/send\n参数：\n1 2 3 { \"phoneNumber\": \"13812345678\" } service-verification-code：生成验证码\nURI：`verify-code/generate/{身份}/{手机号} 身份：司机，乘客，用于区分乘客类型 手机号： service-sms：发送短信（通用），腾讯短信通，阿里短信服务，华信\nURL：send/sms-template\n参数：\n1 2 3 4 5 6 7 8 9 10 11 { \"receivers\":[13812345678], \"data\":[ { \"id\":\"SMS 144145499\", \"templateMap\":{ \"code\":\"018900\" } } ] } data.id：短信模板 id\n模板内容为：您正在申请手机注册，验证码为：${code}，5 分钟内有效！。 模板变量为：${code}。 随机数生成代码\n1 2 3 4 5 6 7 8 9 10 // method2 会比 method1 提高大约 10 背效率 int sum = 1000000; // method1 230ms 左右 for (int i = 0; i \u003c sum; i++) { String code = (Math.random() + \"\").substring(2, 8); } // method2 30ms 左右 for (int i = 0; i \u003c sum; i++) { String code = String.valueOf((int) ((Math.random() * 9 + 1) * 100000)); } 常用的，不变的用缓存，不要每次都用 DB，例如短信模板\n提升 QPS\n提高并发数： 能用多线程使用多线程 增加各种连接数：tomcat，mysql，redis 等连接数 服务无状态，便于横向扩张（添加机器） 让服务能力对等（eureka server 的 url 乱序） 减少响应时间 异步（保证最终一致性即可，不需要及时的，例如下单成功的邮件），流量削峰 缓存：减少磁盘 IO，适合读多写少的场景 数据库优化 大量数据分批次返回 减少调用链（微服务中，同一功能如果用到的模块少，不需要提取到 common 工程），减少网络 IO 长连接。不要轮询 减少 IO，I/O 瓶颈：网络，磁盘\n估算线程数\n8 核 16 线程，应该开几个线程\n线程数 = CPU 可用核数 / (1 - 阻塞系数)\n阻塞系数：io 密集型接近 1，计算（CPU）密集型接近 0\n登录功能 通过网关 Zuul 来验证 Token\nZuul 设置 ZuulFilter 不执行后面的 ZuulFilter\n三级等保：手机号，身份证号脱敏\n听单，SSE（server sent events） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003cscript\u003e console.info(\"司机听单中\"); var source = new EventSource(\"/sse/listen/driver/1\"); source.onmessage = function (evt) { console.info(\"听单\"); console.info(evt.data); document.getElementById(\"rdiv\").innerText = evt.data; } \u003c/script\u003e \u003c/head\u003e \u003cbody\u003e 听单：\u003cspan id=\"rdiv\"\u003e\u003c/span\u003e \u003c/body\u003e \u003c/html\u003e 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(\"/sse\") public class SseController { @GetMapping(value = \"/listen/driver/{driverId}\", produces = \"text/event-stream;charset=utf-8\") public String getStream(@PathVariable String driverId) { // 要带\\n\\n return \"data:\" + Math.random() + \"\\n\\n\"; } } 本地事务，柔性事务，分布式事务 seata\n虚拟小号：阿里小号，可以把电话录音都存到 oss 上，方便后续审查\n数据结构 + 算法\n原料 + 规则 + 操作\n灰度发布 又叫金丝雀发布，指在黑与白之间，能够平滑过渡的一种发布方式。\n让大部分用户依旧使用旧的系统，选出小部分符合条件的用户来访问新系统。依据测试条件，逐步对所有用户开放新系统。\n借助灰度发布可以进行A/B 测试，步骤：\n制定灰度规则，区分哪些用户，走哪些服务 eureka 的 metadata 可以通过 github wiki 提供的 url 进行动态修改，所以可以通过修改 metadata 和用户的信息进行匹配，来进行 A/B 测试。\nZuul 灰度发布 可以通过在 eureka client 的 metadata 中设置 version 属性，并在 zuulFilter 中对请求进行过滤\n通过设置 eureka 的 matedata-map 来表示服务的版本\n1 2 3 4 eureka: instance: metadata-map: version: v1 通过数据库记录灰度发布用户的信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 create table common_gray_rule ( id int not null, user_id int null, service_name varchar(32) null, meta_version varchar(32) null, constraint common_gray_rule_id_uindex unique (id) ); alter table common_gray_rule add primary key (id); INSERT INTO `online-taxi-three`.common_gray_rule (id, user_id, service_name, meta_version) VALUES (1, 1, 'api-passenger', 'v2'); 在 ZuulFilter 中对用户进行过滤\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 package com.example.cloudzuul.filter; import com.example.cloudzuul.dao.CommonGrayRuleDAO; import com.example.cloudzuul.entity.CommonGrayRule; import com.netflix.zuul.ZuulFilter; import com.netflix.zuul.context.RequestContext; import com.netflix.zuul.exception.ZuulException; import io.jmnarloch.spring.cloud.ribbon.support.RibbonFilterContextHolder; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.cloud.netflix.zuul.filters.support.FilterConstants; import org.springframework.stereotype.Component; import javax.servlet.http.HttpServletRequest; import java.util.List; @Component public class GrayFilter extends ZuulFilter { @Autowired private CommonGrayRuleDAO commonGrayRuleDAO; @Override public String filterType() { return FilterConstants.ROUTE_TYPE; } @Override public int filterOrder() { return 0; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { // 从请求头中获取 token，然后根据 token 里存的用户信息，查库 RequestContext context = RequestContext.getCurrentContext(); HttpServletRequest request = context.getRequest(); String requestURI = request.getRequestURI(); Integer userid = Integer.parseInt(request.getHeader(\"userid\")); List\u003cCommonGrayRule\u003e rules = commonGrayRuleDAO.selectByUserId(userid); String version = \"v1\"; // 如果有灰度测试资格 if (!rules.isEmpty()) { for (CommonGrayRule rule : rules) { if (requestURI.contains(rule.getServiceName())) { version = rule.getMetaVersion(); break; } } } // 将请求转发到指定版本的服务上 RibbonFilterContextHolder.getCurrentContext().add(\"version\", version); return null; } } Ribbon 灰度实现 自定义 Rule 规则（根据用户信息，选择合适的服务）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 package org.example.apipassenger.config; import com.netflix.client.config.IClientConfig; import com.netflix.loadbalancer.AbstractLoadBalancerRule; import com.netflix.loadbalancer.ILoadBalancer; import com.netflix.loadbalancer.Server; import com.netflix.niws.loadbalancer.DiscoveryEnabledServer; import org.example.apipassenger.util.RibbonParametersUtil; import org.springframework.beans.factory.annotation.Autowired; import java.util.List; import java.util.Map; /** * @author wangshuo * @date 2021/03/08 */ public class GrayRule extends AbstractLoadBalancerRule { @Autowired private RibbonParametersUtil ribbonParametersUtil; @Override public void initWithNiwsConfig(IClientConfig clientConfig) { } @Override public Server choose(Object key) { return choose(getLoadBalancer(), key); } public Server choose(ILoadBalancer lb, Object key) { Server grayServer = null; Server normalServer = null; // 获取所有可达的服务 List\u003cServer\u003e reachableServers = lb.getReachableServers(); // 根据用户选服务 // 根据当前线程取用户 id，此处使用 version 代替 String grayVersion = \"v2\"; String userVersion = null; Map\u003cString, String\u003e map = ribbonParametersUtil.get(); if (map != null \u0026\u0026 map.containsKey(\"version\")) { userVersion = map.get(\"version\"); } // 根据用户选服务 for (int i = 0; i \u003c reachableServers.size(); i++) { DiscoveryEnabledServer des = (DiscoveryEnabledServer) reachableServers.get(i); Map\u003cString, String\u003e metadata = des.getInstanceInfo().getMetadata(); if (grayVersion.equals(metadata.get(\"version\")) \u0026\u0026 grayVersion.equals(userVersion)) { grayServer = des; break; } else { normalServer = des; } } return grayServer == null ? normalServer : grayServer; } } 拦截用户请求，将用户的信息存储到 ThreadLocal 中，以便在上方 IRule 中获取\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package org.example.apipassenger.aspect; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.annotation.Pointcut; import org.example.apipassenger.util.RibbonParametersUtil; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; import org.springframework.web.context.request.RequestContextHolder; import org.springframework.web.context.request.ServletRequestAttributes; import javax.servlet.http.HttpServletRequest; import java.util.HashMap; import java.util.Map; /** * @author wangshuo * @date 2021/03/08 */ @Aspect @Component public class RequestAspect { @Autowired private RibbonParametersUtil ribbonParametersUtil; @Pointcut(\"execution(* org.example.apipassenger.controller..*Controller*.*(..))\") private void anyMethod() { } @Before(\"anyMethod()\") public void before(JoinPoint joinPoint) { HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); String version = request.getHeader(\"version\"); Map\u003cObject, Object\u003e map = new HashMap\u003c\u003e(16); map.put(\"version\", version); ribbonParametersUtil.set(map); } } ThreadLocal 工具类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package org.example.apipassenger.util; import org.springframework.stereotype.Component; /** * @author wangshuo * @date 2021/03/08 */ @Component public class RibbonParametersUtil { public static final ThreadLocal LOCAL = new ThreadLocal(); public \u003cT\u003e T get() { return (T) LOCAL.get(); } public \u003cT\u003e void set(T t) { LOCAL.set(t); } } 配置类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package org.example.apipassenger.config; import com.netflix.loadbalancer.IRule; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * @author wangshuo * @date 2021/03/08 */ @Configuration public class GrayRibbonConfig { @Bean public IRule iRule() { return new GrayRule(); } } 简单方式 引入依赖\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003eio.jmnarloch\u003c/groupId\u003e \u003cartifactId\u003eribbon-discovery-filter-spring-cloud-starter\u003c/artifactId\u003e \u003cversion\u003e2.1.0\u003c/version\u003e \u003c/dependency\u003e 在 Aspect 中定义灰度发布的规则进行请求转发\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package org.example.apipassenger.aspect; import io.jmnarloch.spring.cloud.ribbon.api.RibbonFilterContext; import io.jmnarloch.spring.cloud.ribbon.support.RibbonFilterContextHolder; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.aspectj.lang.annotation.Pointcut; import org.springframework.stereotype.Component; import org.springframework.web.context.request.RequestContextHolder; import org.springframework.web.context.request.ServletRequestAttributes; import javax.servlet.http.HttpServletRequest; /** * @author wangshuo * @date 2021/03/08 */ @Aspect @Component public class RequestAspect { @Pointcut(\"execution(* org.example.apipassenger.controller..*Controller*.*(..))\") private void anyMethod() { } @Before(\"anyMethod()\") public void before(JoinPoint joinPoint) { HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); // 从数据库中查询出用户的灰度发布相关信息 String version = request.getHeader(\"version\"); RibbonFilterContext context = RibbonFilterContextHolder.getCurrentContext(); // 制定灰度发布规则，将请求转发到响应的服务器 context.add(\"version\", version); } } 蓝绿发布 小规模发布，用户都在白天用，可以在晚上挺服务更新\n如果用户规模大，白天晚上都会有很多人用，怎么做到不停服更新\n绿色环境表示当前正常运行的已上线版本，蓝色环境表示需要被上线的新版本。\n将蓝色环境的服务都启动起来，并进行测试 如果测试没问题，修改网关层，把请求转发到蓝色环境 如果上线没问题，即可把绿色环境的服务器全部删除 通过蓝绿部署需要扩充 2 倍的服务器，费钱。\n滚动发布 由于蓝绿发布需要扩充 2 倍的服务器，太费钱，所以出现了滚动发布的方式。\n先将绿色环境的服务器停 1 台 然后将蓝色环境的服务器启动 1 台，替换掉停掉的绿色服务器 然后依次停 1 台绿色，启一台蓝的，直到所有都换成蓝的 会出现新服务和老服务混在一起的情况，如果发布过程中有一个请求报错了，是老服务出的错，此时就又需要把所有老服务再恢复回去。\n网关 Zuul 在生产中的问题 网关 Zuul 生产中的问题：3 个问题：\ntoken 不向后传（单体项目-\u003e微服务）\n在网关中添加如下配置即可\n1 2 3 zuul: # 表示忽略下面的值向微服务传播。以下配置为空，表示所有请求头都透传到后面的微服务 sensitive-headers: 如果是微服务的话，不应该通过该方式全部传过去。应该将鉴权提到网关层来处理。\n默认不传下方三个头信息\n老项目改造中的路由问题（原来 url 不能变，通过网关去适应）\nhttps://www.cnblogs.com/logan-w/p/12498943.html\n前端已经写好了调用接口的 url，例如：/account/xx，但是服务端真实提供的是/account/xxx 接口，需要将前端向/account/xx 发送的请求路由到/account/xxx 上\n可以在 Zuul 中添加自定义 Filter，在 Filter 中对请求进行转发 动态路由\n在 Filter 中可以根据用户的地域等信息做动态路由\n网关要做的事\n分发服务 身份认证（鉴权） 过滤请求 监控 路由（动态） 限流 后面服务要重复做的事情，可以放到网关来做\n可以将过滤器是否生效存储到数据库中，然后在后台提供页面，动态控制。\n比如新项目，前期需要拉新，所以允许一个设备注册多个帐号。后期不需要拉新了，就让设备黑名单过滤器生效，限制设备的注册用户数。\n","description":"","tags":["MSB","Project","网约车三期","Java"],"title":"internal-common","uri":"/posts/msb/%E7%BD%91%E7%BA%A6%E8%BD%A6%E4%B8%89%E6%9C%9F/internal-common/"},{"categories":null,"content":"AESUtils 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 /** * @author wangshuo * @date 2021/03/06 */ import javax.crypto.Cipher; import javax.crypto.KeyGenerator; import javax.crypto.SecretKey; import javax.crypto.spec.SecretKeySpec; import java.security.NoSuchAlgorithmException; import java.security.SecureRandom; import java.util.Base64; public class AESUtils { private static final String ALGORITHM = \"AES\"; /** * @param content 需要加密的字符串 * @param key 密钥 * @return 密文 */ public static String encrypt(String content, String key) { try { // 转换为 AES 专用密钥 SecretKeySpec keySpec = generateKeySpec(key); // 创建密码器 Cipher cipher = Cipher.getInstance(ALGORITHM); cipher.init(Cipher.ENCRYPT_MODE, keySpec); return Base64.getEncoder().encodeToString(cipher.doFinal(content.getBytes())); } catch (Exception e) { e.printStackTrace(); } return null; } /** * @param content AES 加密过的密文 * @param key 密钥 * @return 明文 */ public static String decrypt(String content, String key) { try { // 转换为 AES 专用密钥 SecretKeySpec keySpec = generateKeySpec(key); // 创建密码器 Cipher cipher = Cipher.getInstance(ALGORITHM); cipher.init(Cipher.DECRYPT_MODE, keySpec); return new String(cipher.doFinal(Base64.getDecoder().decode(content.getBytes()))); } catch (Exception e) { e.printStackTrace(); } return null; } private static SecretKeySpec generateKeySpec(String key) throws NoSuchAlgorithmException { // 创建 AES 的 Key 生产者 KeyGenerator keyGenerator = KeyGenerator.getInstance(ALGORITHM); /* SecureRandom 实现完全随操作系统本身的內部状态， 除非调用方先调用 getInstance 方法，然后调用 setSeed 方法； 该实现在 windows 上每次生成的 key 都相同，但是在 solaris 或部分 linux 系统上则不同。 关于 SecureRandom 类的详细介绍，见 http://yangzb.iteye.com/blog/325264 */ SecureRandom secureRandom = SecureRandom.getInstance(\"SHA1PRNG\"); secureRandom.setSeed(key.getBytes()); keyGenerator.init(128, secureRandom); SecretKey secretKey = keyGenerator.generateKey(); byte[] enCodeFormat = secretKey.getEncoded(); return new SecretKeySpec(enCodeFormat, ALGORITHM); } public static void main(String[] args) { String miwen = \"xxx\"; String key = \"I don't know.\"; System.out.println(decrypt(miwen, key)); } } ","description":"","tags":["Java"],"title":"AESUtils","uri":"/posts/java/aesutils/"},{"categories":null,"content":"装饰者模式（Decorator） 在不改变已存在类的情况下，给该类添加新功能。\nJava 中装饰者模式的使用 IO 流。OutputStream，InputStream 代码 创建被装饰者和装饰者的顶层接口\n1 2 public interface Person { void dressUp(); }\n2. 创建被装饰者的具体实现 ```java public class Programer implements Person { @Override public void dressUp() { System.out.println(\"程序员穿格子衬衫\"); } } 创建装饰者抽象类\n1 2 3 4 5 6 7 8 9 10 11 12 public abstract class PersonDecorator implements Person { /** * 被装饰对象的引用 */ protected Person person; /** * 通过构造方法将被装饰对象传入进来 */ public PersonDecorator(Person person) { this.person = person; } } 创建具体的装饰者类\n给被装饰对象加个帽子的装饰者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class HatDecorator extends PersonDecorator{ /* * 通过构造方法传入被装饰对象 */ public HatDecorator(Person person) { super(person); } @Override public void dressUp() { // 先调用被装饰对象的方法 person.dressUp(); // 执行我们的扩展逻辑 System.out.println(\"给 Person 戴个帽子\"); } } 给被装饰者加个眼镜的装饰者\n1 2 3 4 5 6 7 8 9 10 public class GlassesDecorator extends PersonDecorator { public GlassesDecorator(Person person) { super(person); } @Override public void dressUp() { person.dressUp(); System.out.println(\"给 Person 戴个眼镜\"); } } 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class Main { public static void main(String[] args) { // 不进行任何装饰 Person person = new Programer(); person.dressUp(); System.out.println(\"--------------------------\"); // 给 person 加帽子 Person hatPerson = new HatDecorator(new Programer()); hatPerson.dressUp(); System.out.println(\"--------------------------\"); // 给 person 加帽子和眼镜 Person glassesPerson = new GlassesDecorator(new HatDecorator(new Programer())); glassesPerson.dressUp(); } } 类图和说明 创建被装饰者和装饰者的顶层接口 创建被装饰者的具体实现 创建装饰者抽象类，包含被装饰者的引用，并通过构造方法将被装饰者传入进来 创建具体的装饰者实现 如需扩展，只需添加具体的装饰者实现即可 ","description":"","tags":["MSB","Design Pattern","Java"],"title":"装饰者模式（Decorator）","uri":"/posts/msb/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/decorator/"},{"categories":null,"content":"责任链模式（Chain Of Responsibility） 将多个处理流程连接到一起形成链式结构，依次对请求进行处理。\n可根据需要，选择处理方式：\n只要有一个流程处理成功/失败，就不执行后续其他流程。例如 Filter 执行所有流程 代码 创建需要被处理的对象类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 /** * 需要被责任链处理的对象类 */ public class Request { /** * 请求类型 */ private String type; /** * 请求消息 */ private String message; public Request(String type, String message) { this.type = type; this.message = message; } public String getType() { return type; } public void setType(String type) { this.type = type; } public String getMessage() { return message; } public void setMessage(String message) { this.message = message; } } 创建责任链中流程的抽象类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 /** * 责任链中流程的抽象类 */ public abstract class Filter { /** * 下一个流程 */ private Filter nextFilter; /** * 处理请求的方法 * * @param request 需要被处理的对象 */ public abstract void doFilter(Request request); public Filter getNextFilter() { return nextFilter; } public Filter setNextFilter(Filter nextFilter) { this.nextFilter = nextFilter; return this; } } 责任链中流程的具体实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 /* * 只处理 A 类型的 Request，其他类型的请求交给后续处理 */ public class AFilter extends Filter { @Override public void doFilter(Request request) { System.out.println(\"AFilter doFilter...\"); // 只处理 A 类型的 Request，其他类型的请求交给后续处理 if (\"A\".equals(request.getType())) { System.out.println(\"AFilter 处理了请求，请求的 message 是：\" + request.getMessage()); } else { Filter nextFilter = this.getNextFilter(); if (nextFilter != null) { nextFilter.doFilter(request); } } } } /* * 只处理 B 类型的 Request，其他类型的请求交给后续处理 */ public class BFilter extends Filter { @Override public void doFilter(Request request) { System.out.println(\"BFilter doFilter...\"); if (\"B\".equals(request.getType())) { System.out.println(\"BFilter 处理了请求，请求的 message 是：\" + request.getMessage()); } else { Filter nextFilter = this.getNextFilter(); if (nextFilter != null) { nextFilter.doFilter(request); } } } } /* * 只处理 A 类型的 Request，其他类型的请求交给后续处理 */ public class CFilter extends Filter { @Override public void doFilter(Request request) { System.out.println(\"CFilter doFilter...\"); if (\"C\".equals(request.getType())) { System.out.println(\"CFilter 处理了请求，请求的 message 是：\" + request.getMessage()); } else { Filter nextFilter = this.getNextFilter(); if (nextFilter != null) { nextFilter.doFilter(request); } } } } 测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class Main { public static void main(String[] args) { Filter aFilter = new AFilter(); Filter bFilter = new BFilter(); Filter cFilter = new CFilter(); // 按照 AFilter，BFilter，CFilter 的顺序将他们组成一条责任链 Filter filterChain = aFilter.setNextFilter(bFilter.setNextFilter(cFilter)); // A 类型的请求在 AFitler 处处理成功，就不会继续向后执行了 filterChain.doFilter(new Request(\"A\", \"我是 A 类型的请求\")); System.out.println(\"-------------------------------\"); // B 类型的请求会先经过 AFilter，AFilter 处理不了，交给 BFilter 处理 filterChain.doFilter(new Request(\"B\", \"我是 B 类型的请求\")); System.out.println(\"-------------------------------\"); filterChain.doFilter(new Request(\"C\", \"我是 C 类型的请求\")); System.out.println(\"-------------------------------\"); } } 类图和说明 创建需要被责任链处理的对象类 创建责任链中每个流程的抽象类，该类包含它的下一个流程的引用和处理请求的方法 创建各个流程的具体实现 可根据需要设置流程何时返回或执行下一流程 如需扩展，只需实现责任链接口，并将其添加到相应链条中即可 ","description":"","tags":["MSB","Design Pattern","Java"],"title":"责任链模式（Chain Of Responsibility）","uri":"/posts/msb/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/chain-of-responsibility/"},{"categories":null,"content":"中介/调停者模式（Mediator） 多个对象/类间进行通讯，会很复杂\n使用 Mediator 后，所有对象/类只与 Mediator 进行通讯，彼此之间不直接进行通讯。降低了复杂度，并减少耦合\n代码 创建 Colleague 接口\n1 2 public interface Customer { } 创建 Mediator 接口\n1 2 3 public interface AbstractMediator { String transaction(Customer customer); } 创建 Colleague 的具体实现，各个实现间是需要相互通讯的，各个实现间通过 Mediator 进行通讯\n买家\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class Buyer implements Customer { private int houses; /** * 客户持有中介的引用 */ private AbstractMediator mediator; public Buyer(int houses, AbstractMediator mediator) { this.houses = houses; this.mediator = mediator; } public void buyHouse() { System.out.println(\"买家通过中介买房子\"); // 通过中介来与其他客户交互 String msg = mediator.transaction(this); System.out.println(msg); } public int getHouses() { return houses; } public void setHouses(int houses) { this.houses = houses; } } 卖家\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public class Seller implements Customer { private int houses; /** * 客户持有中介的引用 */ private AbstractMediator mediator; public Seller(int houses, AbstractMediator mediator) { this.houses = houses; this.mediator = mediator; } public void sell() { System.out.println(\"卖家通过中介卖房子\"); // 通过中介来与其他客户交互 String msg = mediator.transaction(this); System.out.println(msg); } public int getHouses() { return houses; } public void setHouses(int houses) { this.houses = houses; } } 创建 Mediator 的具体实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 import java.util.LinkedList; import java.util.List; /** * 房产中介 */ public class RealEstateMediator implements AbstractMediator { /** * 中介里持有客户的引用 */ private List\u003cCustomer\u003e buyers = new LinkedList\u003c\u003e(); private List\u003cCustomer\u003e sellers = new LinkedList\u003c\u003e(); @Override public String transaction(Customer customer) { Buyer buyer = null; Seller seller = null; if (customer instanceof Buyer) { buyer = (Buyer) customer; buyers.add(buyer); if (sellers.isEmpty()) { return \"没有卖家\"; } seller = (Seller) sellers.get((int) (Math.random() * sellers.size())); } if (customer instanceof Seller) { seller = (Seller) customer; sellers.add(seller); if (buyers.isEmpty()) { return \"没有买家\"; } buyer = (Buyer) buyers.get((int) (Math.random() * buyers.size())); } if (seller.getHouses() == 0) { return \"卖家没有房子\"; } seller.setHouses(seller.getHouses() - 1); buyer.setHouses(buyer.getHouses() + 1); sellers.remove(seller); buyers.remove(buyer); return \"交易成功\"; } } 测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class Main { public static void main(String[] args) { // 中介者 RealEstateMediator mediator = new RealEstateMediator(); // 卖家内部通过 mediator 对象与买家交互 Seller seller = new Seller(10, mediator); seller.sell(); // 买家内部通过 mediator 对象与卖家交互 Buyer buyer = new Buyer(0, mediator); buyer.buyHouse(); } } 类图和说明 创建 Mediator 接口，其中规定 Mediator 需要实现的方法 创建 Mediator 的具体实现，在该实现中，持有需要交互对象的引用 创建 Colleague 接口，Colleague 的具体实现是需要交互的对象 创建 Colleague 的具体实现，在具体实现中包含 Mediator 的引用 需要交互的 Colleague 间没有关联关系，都是通过 Mediator 来进行通讯 如需扩展，只需要实现 Colleague 接口即可 关键点是每个 Colleague 中包含 Mediator 的引用，在 Colleague 中通过 Mediator 与其他 Colleague 进行交互\n和门面模式区别 门面模式是在具体服务前添加了一层门面，客户通过门面访问具体服务，是单向访问\n中介者模式是让所有同事通过中介进行通讯，是双向访问\n","description":"","tags":["MSB","Design Pattern","Java"],"title":"中介/调停者模式（Mediator）","uri":"/posts/msb/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/mediator/"},{"categories":null,"content":"外观/门面模式（Facade） 当某些业务需要多个模块进行协作时，创建一个门面，在门面中处理各个子系统间的关系，客户端只需要与门面进行沟通即可，不需要挨个调用各个模块。\n假如 Client 为了完成某个业务，需要调用 SubSystem01、SubSystem02、SubSystem03、SubSystem04，如果不使用门面模式，所有处理代码都在 Client 中进行，如果后期业务变化了，就需要修改 Client 中的代码，不方便维护。 使用门面模式后，将 SubSystem 间的关系封装在 Facade 中，客户端仅于 Facade 交互，后期如果业务逻辑变更，只需修改 Facade 即可 代码 创建子系统\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 /** * 注册系统 */ public class RegistrySystem { public void registry() { System.out.println(\"注册房产信息……\"); } } /** * 估值系统 */ public class ValuationSystem { public void valuation() { System.out.println(\"房价估值……\"); } } /** * 交易系统 */ public class TradingSystem { public void trading() { System.out.println(\"交易成功……\"); } } 创建门面\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /** * 房产局门面 */ public class RealEstateBureauFacade { private RegistrySystem registrySystem = new RegistrySystem(); private ValuationSystem valuationSystem = new ValuationSystem(); private TradingSystem tradingSystem = new TradingSystem(); public void buyHouse() { System.out.println(\"购买房屋……\"); registrySystem.registry(); valuationSystem.valuation(); tradingSystem.trading(); } } 调用\n1 2 3 4 5 6 7 8 9 10 public class Main { public static void main(String[] args) { // 使用门面前 new RegistrySystem().registry(); new ValuationSystem().valuation(); new TradingSystem().trading(); // 使用门面后 new RealEstateBureauFacade().buyHouse(); } } 类图和说明 创建子系统：ReigstrySystem，ValustionSystem，TradingSystem 创建门面，包含子系统的引用 在门面添加方法，按需调用多个子系统 客户端只需调用门面即可完成工作，不需依次调用所需的子系统 如需扩展只需要修改门面类即可 ","description":"","tags":["MSB","Design Pattern","Java"],"title":"外观/门面模式（Facade）","uri":"/posts/msb/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/facade/"},{"categories":null,"content":"工厂模式（Factory） 任何可以产生对象的方法或类，都可以称之为工厂\n单例也是一种工厂\n不可咬文嚼字，死扣概念\n为什么有了 new 之后，还要有工厂\n灵活控制生产过程 权限，修饰，日志…… 简单工厂/静态方法模式 通过向工厂传入参数来创建对应的对象\n代码 产品对象的接口，例如可移动的 Moveable\n1 2 3 4 public interface Moveable { void move(); } 具体的产品实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class Car implements Moveable{ @Override public void move() { System.out.println(\"cat move ...\"); } } public class Broom implements Moveable { @Override public void move() { System.out.println(\"broom move ...\"); } } 创建相应 Moveable 对象的工厂\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class VehicleFactory { public static Moveable create(String type) { Moveable move; // before processing... switch (type) { case \"car\": move = new Car(); break; case \"broom\": move = new Broom(); break; default: move = null; break; } // after processing... return move; } } 使用\n1 2 3 4 5 6 7 8 9 10 public class Main { public static void main(String[] args) { // 使用工厂生产 Car Moveable car = VehicleFactory.create(\"car\"); car.move(); // 使用工厂生产 Broom Moveable broom = VehicleFactory.create(\"broom\"); broom.move(); } } 类图\u0026说明 创建产品对象的接口 创建产品对象接口的具体实现 工厂类，静态方法中根据传入类型参数创建相应的对象，可以在创建对象的前后进行额外处理 工厂方法 与简单工厂中工厂负责生产所有产品相比，工厂方法模式将生产具体产品的任务分发给了对应的产品工厂\n产品对象的接口，例如可移动的 Moveable\n1 2 3 public interface Moveable { void move(); } 产品对象的具体实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class Car implements Moveable{ @Override public void move() { System.out.println(\"car move ...\"); } } public class Broom implements Moveable { @Override public void move() { System.out.println(\"broom move ...\"); } } 工厂的接口\n1 2 3 public interface VehicleFactory { Moveable create(); } 工厂的具体实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class CarFactory implements VehicleFactory { @Override public Moveable create() { // before processing Car car = new Car(); // after processing return car; } } public class BroomFactory implements VehicleFactory { @Override public Moveable create() { // before processing Broom broom = new Broom(); // after processing return broom; } } 使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class Main { public static void main(String[] args) { // 创建 Car 工厂，创建 Car 对象 VehicleFactory carFactory = new CarFactory(); Moveable car = carFactory.create(); car.move(); // 创建 Broom 工厂，创建 Broom 对象 VehicleFactory broomFactory = new BroomFactory(); Moveable broom = broomFactory.create(); broom.move(); } } 类图\u0026说明 创建产品对象接口 创建产品对象接口的具体实现 创建工厂接口 根据具体的产品对象，创建对应的工厂实现 抽象工厂 与工厂方法相比，抽象工厂模式提供了“产品族”的概念\n代码 魔法族和军人族都包含食物，交通工具，武器。\n创建一组产品的接口\n1 2 3 4 5 6 7 8 9 10 11 12 // 食物 public abstract class Food { public abstract void scent(); } // 交通工具 public abstract class Vehicle { public abstract void run(); } // 武器 public abstract class Weapon { public abstract void attack(); } 创建产品的具体实现\n食物\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 面包 public class Bread extends Food { @Override public void scent() { System.out.println(\"面包的香味……\"); } } // 蘑菇 public class Mushroom extends Food{ @Override public void scent() { System.out.println(\"蘑菇的香味……\"); } } 交通工具\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 小汽车 public class Car extends Vehicle { @Override public void run() { System.out.println(\"小汽车跑……\"); } } // 扫帚 public class Broom extends Vehicle { @Override public void run() { System.out.println(\"魔法扫帚飞……\"); } } 武器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 枪 public class Gun extends Weapon{ @Override public void attack() { System.out.println(\"枪攻击……\"); } } // 魔法棒 public class MagicStick extends Weapon { @Override public void attack() { System.out.println(\"魔法棒攻击……\"); } } 创建工厂接口\n1 2 3 4 5 6 7 8 public abstract class AbstractFactory { public abstract Food createFood(); public abstract Vehicle createVehicle(); public abstract Weapon createWeapon(); } 工厂的具体实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 // 军人族 public class SoldierFactory extends AbstractFactory { @Override public Food createFood() { // 军人族吃面包 return new Bread(); } @Override public Vehicle createVehicle() { // 军人族开车 return new Car(); } @Override public Weapon createWeapon() { // 军人族用枪 return new Gun(); } } // 魔法族 public class MagicianFactory extends AbstractFactory { @Override public Food createFood() { // 魔法族吃蘑菇 return new Mushroom(); } @Override public Vehicle createVehicle() { // 魔法族骑扫帚飞 return new Broom(); } @Override public Weapon createWeapon() { // 魔法族用魔法棒 return new MagicStick(); } } 使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class Main { public static void main(String[] args) { // 新建军人族工厂 AbstractFactory soldierFactory = new SoldierFactory(); // 通过军人族工厂创建军人的食物，交通工具，武器一组产品 Food brand = soldierFactory.createFood(); Vehicle car = soldierFactory.createVehicle(); Weapon gun = soldierFactory.createWeapon(); brand.scent(); car.run(); gun.attack(); // 新建魔法族工厂 AbstractFactory magicianFactory = new MagicianFactory(); // 使用魔法族工厂创建魔法族的食物，交通工具，武器一组产品 Food mushroom = magicianFactory.createFood(); Vehicle broom = magicianFactory.createVehicle(); Weapon magicStick = magicianFactory.createWeapon(); mushroom.scent(); broom.run(); magicStick.attack(); } } 类图\u0026说明 创建 Food, Vehicle, Weapon 产品接口 创建产品接口的具体实现，其中 Bread, Car, Gun 属于 Soldier 族, Mushroom, Broom, MagicStick 属于 Magician 族 创建工厂接口，包含三个方法，分别是创建 Food, Vehicle, Weapon 的方法 按不同族创建工厂的具体实现，不同族生产的一组产品不同 工厂方法 vs 抽象工厂 工厂方法方便针对单一产品进行扩展，抽象工厂方便针对产品族进行扩展，不适合对单一产品进行扩展。\n工厂方法扩展 创建新的产品具体实现，实现产品接口 创建相应的产品工厂，实现工厂接口 使用新的产品工厂生产新的产品 抽象工厂扩展 创建一族新的产品具体实现，实现产品接口 创建新的族工厂，实现工厂接口 新的族工厂生产这一族的一系列产品 Spring IOC 中工厂模式的使用 Spring 通过控制反转（IOC）和依赖注入（DI）从配置文件中动态加载 Bean 到 BeanFactory 中，然后通过 BeanFactory 来获取相应的 Bean 实例\napplication.xml\n1 2 3 4 5 6 7 \u003c!-- IOC --\u003e \u003cbean id=\"driver\" class=\"com.example.factory.springfactory.Driver\"/\u003e \u003cbean id=\"tank\" class=\"com.example.factory.springfactory.Tank\"\u003e \u003c!-- DI --\u003e \u003cproperty name=\"driver\" ref=\"driver\"/\u003e \u003c/bean\u003e 测试类\n1 2 3 4 5 6 7 public class Main { public static void main(String[] args) { ApplicationContext context = new ClassPathXmlApplicationContext(\"application.xml\"); Tank tank = (Tank) context.getBean(\"tank\"); System.out.println(tank); } } ","description":"","tags":["MSB","Design Pattern","Java"],"title":"工厂模式（Factory）","uri":"/posts/msb/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/factory/"},{"categories":null,"content":"策略模式（Strategy） Java 中策略模式的使用 Comparator 应用场景 对同一个事有不同的处理策略\n代码 例如：要对 Dog 对象进行比较，可以根据重量进行比较，也可以根据体重进行比较。\nDog 类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 public class Dog { private int weight; private int height; public Dog(int weight, int height) { this.weight = weight; this.height = height; } public int getWeight() { return weight; } public void setWeight(int weight) { this.weight = weight; } public int getHeight() { return height; } public void setHeight(int height) { this.height = height; } @Override public String toString() { return \"Dog{\" + \"weight=\" + weight + \", height=\" + height + '}'; } } 策略接口\n1 2 3 4 5 public interface Comparator\u003cT\u003e { int compare(T o1, T o2); } 不同的策略实现\n根据体重进行比较的策略\n1 2 3 4 5 6 7 8 public class DogWeightComparator implements Comparator\u003cDog\u003e { @Override public int compare(Dog o1, Dog o2) { return o1.getWeight() - o2.getWeight(); } } 根据身高进行比较的策略\n1 2 3 4 5 6 7 8 public class DogHeightComparator implements Comparator\u003cDog\u003e { @Override public int compare(Dog o1, Dog o2) { return o1.getHeight() - o2.getHeight(); } } 排序类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class Sort\u003cT\u003e { public void sort(T[] arr, Comparator\u003cT\u003e comparator) { for (int i = 0; i \u003c arr.length; i++) { int minIndex = i; for (int j = i + 1; j \u003c arr.length; j++) { minIndex = comparator.compare(arr[i], arr[j]) \u003e 0 ? j : i; } swap(arr, i, minIndex); } } private void swap(T[] arr, int i, int j) { T t = arr[i]; arr[i] = arr[j]; arr[j] = t; } } 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import java.util.Arrays; public class Main { public static void main(String[] args) { Dog[] dogs = {new Dog(1, 5), new Dog(3, 3), new Dog(5, 1)}; Sort\u003cDog\u003e sort = new Sort\u003c\u003e(); // 根据体重策略进行排序 sort.sort(dogs, new DogWeightComparator()); System.out.println(Arrays.toString(dogs)); // 根据高度策略进行排序 sort.sort(dogs, new DogHeightComparator()); System.out.println(Arrays.toString(dogs)); } } 类图及说明 创建一个策略接口，该接口中包含某些抽象方法 不同的策略实现该策略接口，并根据相应策略重写接口中的方法 在其它类中根据不同业务场景，使用不同的策略对象 当需要扩展的时候，只需实现策略接口，并重写方法即可 ","description":"","tags":["MSB","Design Pattern","Java"],"title":"策略模式（Strategy）","uri":"/posts/msb/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/strategy/"},{"categories":null,"content":"单例模式（Singleton） 应用场景 只需要一个实例\n各种 Manager 各种 Factory 代码 饿汉式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * 饿汉模式 * \u003cp\u003e * 类加载到内存后，就实例化一个单例，JVM 保证线程安全 * 简单实用，推荐使用 * 唯一缺点：不管用到与否，类装载时就完成实例化 * （话说你不用的，你装载它干啥） */ public class Mgr01 { private static final Mgr01 INSTANCE = new Mgr01(); private Mgr01() { } public static Mgr01 getInstance() { return INSTANCE; } } 或者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package com.example.singleton; /** * 与 Mgr01 是一个意思 */ public class Mgr02 { private static final Mgr02 INSTANCE; static { INSTANCE = new Mgr02(); } private Mgr02() { } public static Mgr02 getInstance() { return INSTANCE; } } 懒汉式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * 懒汉式 lazy loading * 虽然达到了按需初始化的目的，但是多线程访问的时候会出问题 */ public class Mgr03 { private static Mgr03 INSTANCE; private Mgr03() { } public static Mgr03 getInstance() { // 当 1 号线程执行完该 if 判断后，2 号线程获得执行权，此时 INSTANCE 仍然是空，此时 1 号线程和 2 号线程会对 INSTANCE 初始化两遍 if (INSTANCE == null) { INSTANCE = new Mgr03(); } return INSTANCE; } } 验证多线程访问问题\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import java.util.HashSet; import java.util.Set; public class Mgr03 { private static Mgr03 INSTANCE; private Mgr03() { } public static Mgr03 getInstance() { if (INSTANCE == null) { // 线程执行速度太快了，手动让其切换下线程 try { Thread.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } INSTANCE = new Mgr03(); } return INSTANCE; } public static void main(String[] args) { Set\u003cInteger\u003e set = new HashSet\u003c\u003e(); for (int i = 0; i \u003c 100; i++) { new Thread(() -\u003e set.add(Mgr03.getInstance().hashCode())).start(); } if(set.size() \u003e 1){ System.out.println(set); } } } 加 synchronized 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /** * 懒汉式 * 通过 synchronized 解决多线程下的访问问题，但是会带来性能的下降 * * @author wangshuo * @date 2021/02/18 */ public class Mgr04 { private static Mgr04 INSTANCE; private Mgr04() { } public synchronized static Mgr04 getInstance() { if (INSTANCE == null) { INSTANCE = new Mgr04(); } return INSTANCE; } } 加 synchronized 代码块 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /** * 懒汉式 * \u003cp\u003e * 妄图通过 synchronized 同步代码块提高效率并解决多线程访问的问题，然而不可行 */ public class Mgr05 { private static Mgr05 INSTANCE; private Mgr05() { } public static Mgr05 getInstance() { // 当 1 号线程执行完该 if 判断后，2 号线程获得执行权，此时 INSTANCE 仍然是空，此时 1 号线程和 2 号线程依旧会对 INSTANCE 初始化两遍 if (INSTANCE == null) { synchronized (Mgr05.class) { INSTANCE = new Mgr05(); } } return INSTANCE; } } 双重检查锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 /** * 懒汉式 * \u003cp\u003e * 双重检查锁 */ public class Mgr06 { private static volatile Mgr06 INSTANCE; private Mgr06() { } public static Mgr06 getInstance() { // 该判断用来提高效率，如果实例已经初始化过了，该处判断可以直接将实例返回 if (INSTANCE == null) { // 在实例还未初始化成功的时候，如果 1 号线程和 2 号线程都执行到了这里 synchronized (Mgr06.class) { // 如果两个线程都通过了第一重判断，在该代码块中再进行一次判断，可以保证对象只初始化一次 if (INSTANCE == null) { INSTANCE = new Mgr06(); } } } return INSTANCE; } } 双重检查锁是否需要添加 volatile?\n需要。因为 INSTANCE = new Mgr06(); 并不是一个原子操作，其包含四个指令，对应三个过程：\n分配内存； 调用构造方法，执行初始化； 将对象引用赋值给变量。 由于 CPU 执行指令是乱序执行的，所以可能出现先执行第 3 步，然后执行第 2 步的情况。如果 1 号线程在执行第 3 步的时候，2 号线程执行了第一重判断，此时 INSTANCE 已经不是 null 了，所以会将未初始化的对象返回，从而引发错误。 INSTANCE = new Mgr06() 的字节码指令\n1 2 3 4 5 6 7 8 // 分配内存，创建对象实例 0: new #5 // 复制栈顶地址，并再将其压入栈顶 3: dup // 调用构造器方法，初始化对象 4: invokespecial #6 // 存入局部方法变量表 7: astore_1 静态内部类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package com.example.singleton; /** * 静态内部类方式 * JVM 保证单例 * 加载外部类时不会加载内部类，在调用内部类的时候才会加载内部类，这样可以实现懒加载 * * @author wangshuo * @date 2021/02/19 */ public class Mgr07 { private Mgr07() { } private static class Mgr07Holder { private static final Mgr07 INSTANCE = new Mgr07(); } public static Mgr07 getInstance() { return Mgr07Holder.INSTANCE; } } 枚举 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package com.example.singleton; /** * 枚举方式 * 不仅可以解决线程同步，还可以防止反序列化 */ public enum Mgr08 { INSTANCE; public static Mgr08 getInstance() { return INSTANCE; } } 破坏单例模式 以上 7 种方式，除了枚举方式，都可以通过反射或反序列化进行破坏。因为枚举类没有构造方法\n使用反射破坏 1 2 3 4 5 6 7 8 public static void main(String[] args) throws NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException { Constructor\u003cMgr06\u003e constructor = Mgr06.class.getDeclaredConstructor(); constructor.setAccessible(true); Mgr06 instance01 = constructor.newInstance(); Mgr06 instance02 = Mgr06.getInstance(); System.out.println(instance01.hashCode()); System.out.println(instance02.hashCode()); } 解决方式\n可以添加一个计数器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 /** * 懒汉式 * \u003cp\u003e * 双重检查锁 */ public class Mgr06 { private static int count; private static volatile Mgr06 INSTANCE; private Mgr06() { // 在创建对象的时候对计数器进行判断 synchronized (Mgr06.class) { if (count \u003e 0) { throw new RuntimeException(\"不允许破坏单例模式!!!\"); } } count++; } public static Mgr06 getInstance() { if (INSTANCE == null) { synchronized (Mgr06.class) { if (INSTANCE == null) { INSTANCE = new Mgr06(); } } } return INSTANCE; } } 使用反序列化破坏 首先需要单例类实现 Serializable 接口\n1 2 3 public class Mgr06 implements Serializable{ } 序列化后反序列化即可创建出第二个对象\n1 2 3 4 5 6 7 8 9 public static void main(String[] args) throws IOException, ClassNotFoundException { Mgr06 instance01 = Mgr06.getInstance(); ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(\"./obj\")); oos.writeObject(instance01); ObjectInputStream ois = new ObjectInputStream(new FileInputStream(\"./obj\")); Mgr06 instance02 = (Mgr06) ois.readObject(); System.out.println(instance01.hashCode()); System.out.println(instance02.hashCode()); } 解决方式\n单例类中添加 readResolve 方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import java.io.Serializable; /** * 懒汉式 * \u003cp\u003e * 双重检查锁 */ public class Mgr06 implements Serializable { private static volatile Mgr06 INSTANCE; private Mgr06() { } public static Mgr06 getInstance() { if (INSTANCE == null) { synchronized (Mgr06.class) { if (INSTANCE == null) { INSTANCE = new Mgr06(); } } } return INSTANCE; } /** * 添加该方法，在反序列化的时候即可返回我们指定的实例 */ private Object readResolve() { return INSTANCE; } } 推荐使用 饿汉式\n最简单，除了没有懒加载，没啥其他问题。需要手动防止反射/反序列化破坏。\n双重检查锁\n没任何问题。即达到了懒加载的目的，也保证了线程安全。需要手动防止反射/反序列化破坏。\n静态内部类\n没任何问题。即达到了懒加载的目的，也保证了线程安全。需要手动防止反射/反序列化破坏。\n枚举\n最完美的方式。即保证了懒加载的目的，也保证了线程安全，同时不会被反射/反序列化破坏。\n","description":"","tags":["MSB","Design Pattern","Java"],"title":"单例模式（Singleton）","uri":"/posts/msb/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/singleton/"},{"categories":null,"content":"Eureka-Client Eureka-Client 启动原理 引入 EurekaClientAutoConfiguration 自动配置类即可 1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-client\u003c/artifactId\u003e \u003c/dependency\u003e 在spring-cloud-netflix-eureka-client-2.2.2.RELEASE.jar的spring.factories中\n1 2 3 4 5 6 7 8 9 10 11 12 # 在 SpringBoot 启动时，会自动将一下的类自动注入到容器中 org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ org.springframework.cloud.netflix.eureka.config.EurekaClientConfigServerAutoConfiguration,\\ org.springframework.cloud.netflix.eureka.config.EurekaDiscoveryClientConfigServiceAutoConfiguration,\\ org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration,\\ org.springframework.cloud.netflix.ribbon.eureka.RibbonEurekaAutoConfiguration,\\ org.springframework.cloud.netflix.eureka.EurekaDiscoveryClientConfiguration,\\ org.springframework.cloud.netflix.eureka.reactive.EurekaReactiveDiscoveryClientConfiguration,\\ org.springframework.cloud.netflix.eureka.loadbalancer.LoadBalancerEurekaAutoConfiguration org.springframework.cloud.bootstrap.BootstrapConfiguration=\\ org.springframework.cloud.netflix.eureka.config.EurekaDiscoveryClientConfigServiceBootstrapConfiguration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // EurekaClientConfig 对应 eureka.client 配置，用于保存客户端与服务端交互的一些配置 @ConditionalOnClass(EurekaClientConfig.class) // 默认是 true @ConditionalOnProperty(value = \"eureka.client.enabled\", matchIfMissing = true) // 在加载完以下类之后，再加载该类 @AutoConfigureAfter(name = { \"org.springframework.cloud.autoconfigure.RefreshAutoConfiguration\", /* 关键点 2 */ \"org.springframework.cloud.netflix.eureka.EurekaDiscoveryClientConfiguration\", \"org.springframework.cloud.client.serviceregistry.AutoServiceRegistrationAutoConfiguration\" }) public class EurekaClientAutoConfiguration { // 静态内部类，在类加载的时候就执行了 @Configuration(proxyBeanMethods = false) @ConditionalOnMissingRefreshScope protected static class EurekaClientConfiguration { // 关键点 1：向容器中注入了 EurekaClient @Bean(destroyMethod = \"shutdown\") @ConditionalOnMissingBean(value = EurekaClient.class, search = SearchStrategy.CURRENT) public EurekaClient eurekaClient(ApplicationInfoManager manager, EurekaClientConfig config) { return new CloudEurekaClient(manager, config, this.optionalArgs, this.context); } 1 2 // 关键点 1：CloudEurekaClient 继承自 com.netflix.discovery.DiscoveryClient, DiscoveryClient 是 Eureka Client 的入口 public class CloudEurekaClient extends DiscoveryClient { 1 2 3 4 5 6 7 package com.netflix.discovery; @Singleton public class DiscoveryClient implements EurekaClient { // 重点：该构造方法作为程序启动的入口，包含了 eureka client 启动时的初始化逻辑 @Inject DiscoveryClient(ApplicationInfoManager applicationInfoManager, EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs args, Provider\u003cBackupRegistry\u003e backupRegistryProvider, EndpointRandomizer endpointRandomizer) { 1 2 3 4 5 6 7 8 9 10 11 // 关键点 2：对 Eureka 提供的 DiscoveryClient 进行包装，作为 Spring 提供的 DiscoveryClient public class EurekaDiscoveryClientConfiguration { // 重点：向容器中注入包装后的 EurekaDiscoveryClient 对象 @Bean @ConditionalOnMissingBean public EurekaDiscoveryClient discoveryClient(EurekaClient client, EurekaClientConfig clientConfig) { return new EurekaDiscoveryClient(client, clientConfig); } } 1 2 3 4 5 6 7 8 9 10 11 12 // 此处实现的是 org.springframework.cloud.client.discovery.DiscoveryClient，是 Spring 提供的一套标准 public class EurekaDiscoveryClient implements DiscoveryClient { private final EurekaClient eurekaClient; private final EurekaClientConfig clientConfig; public EurekaDiscoveryClient(EurekaClient eurekaClient, EurekaClientConfig clientConfig) { this.clientConfig = clientConfig; this.eurekaClient = eurekaClient; } 1 2 3 4 eureka: client: # 通过设置该属性为 false，可以让 Eureka Client 不需要与 Eureka Server 交互，常在本地调试时使用 enabled: false Eureka Client 源码 Eureka Client 启动的时候，主要做了服务注册，注册表拉取，以及定时刷新注册表，定时心跳/续约，自动更新实例信息 3 个定时任务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class EurekaClientAutoConfiguration { // 静态内部类，在类加载的时候就执行了 @Configuration(proxyBeanMethods = false) @ConditionalOnMissingRefreshScope protected static class EurekaClientConfiguration { // 向容器中注入了 EurekaClient，在其销毁的时候，会执行 shutdown 方法 @Bean(destroyMethod = \"shutdown\") @ConditionalOnMissingBean(value = EurekaClient.class, search = SearchStrategy.CURRENT) public EurekaClient eurekaClient(ApplicationInfoManager manager, EurekaClientConfig config) { return new CloudEurekaClient(manager, config, this.optionalArgs, this.context); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 // Eureka Client 初始化 /** * ApplicaitonInfoManager 中包含 EurekaInstanceConfig，其对应 eureka.instance 的配置信息，用于保存当前实例的信息 * EurekaClientConfig 对应 eureka.client 的配置信息，其保存的是 eureka client 与 eureka server 交互的配置信息 */ @Inject DiscoveryClient(ApplicationInfoManager applicationInfoManager, EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs args, Provider\u003cBackupRegistry\u003e backupRegistryProvider, EndpointRandomizer endpointRandomizer) { // ... // 取出 InstanceInfo InstanceInfo myInfo = applicationInfoManager.getInfo(); // 赋值给全局属性 clientConfig = config; staticClientConfig = clientConfig; transportConfig = config.getTransportConfig(); instanceInfo = myInfo; // ... // 是否需要从 eureka server 拉取注册表，eureka.client.fetch-registry，默认为 true if (config.shouldFetchRegistry()) { this.registryStalenessMonitor = new ThresholdLevelsMetric(this, METRIC_REGISTRY_PREFIX + \"lastUpdateSec_\", new long[]{15L, 30L, 60L, 120L, 240L, 480L}); } else { this.registryStalenessMonitor = ThresholdLevelsMetric.NO_OP_METRIC; } // 是否将自己注册到 eureka server，eureka.client.register-with-eureka，默认为 true if (config.shouldRegisterWithEureka()) { this.heartbeatStalenessMonitor = new ThresholdLevelsMetric(this, METRIC_REGISTRATION_PREFIX + \"lastHeartbeatSec_\", new long[]{15L, 30L, 60L, 120L, 240L, 480L}); } else { this.heartbeatStalenessMonitor = ThresholdLevelsMetric.NO_OP_METRIC; } // 如果即不需要向 eureka server 注册自己，也不需要从 eureka server 拉取注册表，那就不需要设置下面的心跳，拉取注册表等定时任务了 if (!config.shouldRegisterWithEureka() \u0026\u0026 !config.shouldFetchRegistry()) { logger.info(\"Client configured to neither register nor query for data.\"); scheduler = null; heartbeatExecutor = null; cacheRefreshExecutor = null; eurekaTransport = null; instanceRegionChecker = new InstanceRegionChecker(new PropertyBasedAzToRegionMapper(config), clientConfig.getRegion()); // This is a bit of hack to allow for existing code using DiscoveryManager.getInstance() // to work with DI'd DiscoveryClient DiscoveryManager.getInstance().setDiscoveryClient(this); DiscoveryManager.getInstance().setEurekaClientConfig(config); initTimestampMs = System.currentTimeMillis(); logger.info(\"Discovery Client initialized at timestamp {} with initial instances count: {}\", initTimestampMs, this.getApplications().size()); // 不需要设置与 Eureka erver 相关的任务直接返回 return; // no need to setup up an network tasks and we are done } // 如果需要与 Eureka erver 进行交互 try { // default size of 2 - 1 each for heartbeat and cacheRefresh scheduler = Executors.newScheduledThreadPool(2, new ThreadFactoryBuilder() .setNameFormat(\"DiscoveryClient-%d\") .setDaemon(true) .build()); // 定时给 eureka server 发送心跳的线程池 heartbeatExecutor = new ThreadPoolExecutor( // eureka.client.heartbeat-executor-thread-pool-size，默认为 2 1, clientConfig.getHeartbeatExecutorThreadPoolSize(), 0, TimeUnit.SECONDS, new SynchronousQueue\u003cRunnable\u003e(), new ThreadFactoryBuilder() .setNameFormat(\"DiscoveryClient-HeartbeatExecutor-%d\") .setDaemon(true) .build() ); // use direct handoff // 定时从 eureka server 拉取注册表的线程池 cacheRefreshExecutor = new ThreadPoolExecutor( // eureka.client.cache-refresh-executor-thread-pool-size，默认为 2 1, clientConfig.getCacheRefreshExecutorThreadPoolSize(), 0, TimeUnit.SECONDS, new SynchronousQueue\u003cRunnable\u003e(), new ThreadFactoryBuilder() .setNameFormat(\"DiscoveryClient-CacheRefreshExecutor-%d\") .setDaemon(true) .build() ); // use direct handoff // 用来和 eureka server 交互的对象 eurekaTransport = new EurekaTransport(); scheduleServerEndpointTask(eurekaTransport, args); // ... } catch (Throwable e) { throw new RuntimeException(\"Failed to initialize DiscoveryClient!\", e); } // 如果需要从 eureka server 拉取注册表，执行 fetchRegistry if (clientConfig.shouldFetchRegistry() \u0026\u0026 !fetchRegistry(false)) { fetchRegistryFromBackup(); } // call and execute the pre registration handler before all background tasks (inc registration) is started if (this.preRegistrationHandler != null) { this.preRegistrationHandler.beforeRegistration(); } // shouldEnforceRegistrationAtInit 设置初始化的时候是否强制注册，默认是 false, 此时不注册，在后面定时任务进行心跳的时候会自动注册 if (clientConfig.shouldRegisterWithEureka() \u0026\u0026 clientConfig.shouldEnforceRegistrationAtInit()) { try { if (!register() ) { throw new IllegalStateException(\"Registration error at startup. Invalid server response.\"); } } catch (Throwable th) { logger.error(\"Registration error at startup: {}\", th.getMessage()); throw new IllegalStateException(th); } } // finally, init the schedule tasks (e.g. cluster resolvers, heartbeat, instanceInfo replicator, fetch // 初始化定时任务 initScheduledTasks(); // ... // This is a bit of hack to allow for existing code using DiscoveryManager.getInstance() // to work with DI'd DiscoveryClient DiscoveryManager.getInstance().setDiscoveryClient(this); DiscoveryManager.getInstance().setEurekaClientConfig(config); initTimestampMs = System.currentTimeMillis(); logger.info(\"Discovery Client initialized at timestamp {} with initial instances count: {}\", initTimestampMs, this.getApplications().size()); } if (clientConfig.shouldFetchRegistry() \u0026\u0026 !fetchRegistry(false)) {\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 // 拉取注册表 private boolean fetchRegistry(boolean forceFullRegistryFetch) { Stopwatch tracer = FETCH_REGISTRY_TIMER.start(); try { // If the delta is disabled or if it is the first time, get all // applications Applications applications = getApplications(); if (clientConfig.shouldDisableDelta() || (!Strings.isNullOrEmpty(clientConfig.getRegistryRefreshSingleVipAddress())) || forceFullRegistryFetch || (applications == null) || (applications.getRegisteredApplications().size() == 0) || (applications.getVersion() == -1)) //Client application does not have latest library supporting delta { logger.info(\"Disable delta property : {}\", clientConfig.shouldDisableDelta()); logger.info(\"Single vip registry refresh property : {}\", clientConfig.getRegistryRefreshSingleVipAddress()); logger.info(\"Force full registry fetch : {}\", forceFullRegistryFetch); logger.info(\"Application is null : {}\", (applications == null)); logger.info(\"Registered Applications size is zero : {}\", (applications.getRegisteredApplications().size() == 0)); logger.info(\"Application version is -1: {}\", (applications.getVersion() == -1)); // 全量拉取 getAndStoreFullRegistry(); } else { // 增量拉取 getAndUpdateDelta(applications); } applications.setAppsHashCode(applications.getReconcileHashCode()); logTotalInstances(); } catch (Throwable e) { logger.error(PREFIX + \"{} - was unable to refresh its cache! status = {}\", appPathIdentifier, e.getMessage(), e); return false; } finally { if (tracer != null) { tracer.stop(); } } // Notify about cache refresh before updating the instance remote status onCacheRefreshed(); // Update remote status based on refreshed data held in the cache updateInstanceRemoteStatus(); // registry was fetched successfully, so return true return true; } getAndStoreFullRegistry();\n1 2 3 4 5 6 7 8 9 10 11 // 全量拉取 private void getAndStoreFullRegistry() throws Throwable { long currentUpdateGeneration = fetchRegistryGeneration.get(); logger.info(\"Getting all instance registry info from the eureka server\"); Applications apps = null; EurekaHttpResponse\u003cApplications\u003e httpResponse = clientConfig.getRegistryRefreshSingleVipAddress() == null // 全量拉取注册表 ? eurekaTransport.queryClient.getApplications(remoteRegionsRef.get()) : eurekaTransport.queryClient.getVip(clientConfig.getRegistryRefreshSingleVipAddress(), remoteRegionsRef.get()); // ... } 1 2 3 4 5 6 7 8 9 public EurekaHttpResponse\u003cApplications\u003e getApplications(final String... regions) { return execute(new RequestExecutor\u003cApplications\u003e() { @Override public EurekaHttpResponse\u003cApplications\u003e execute(EurekaHttpClient delegate) { // 全量拉取注册表 return delegate.getApplications(regions); } }); } 1 2 3 4 public EurekaHttpResponse\u003cApplications\u003e getApplications(String... regions) { // 向 eureka server 发送 apps 请求 return getApplicationsInternal(\"apps/\", regions); } getAndUpdateDelta(applications);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // 增量拉取 private void getAndUpdateDelta(Applications applications) throws Throwable { long currentUpdateGeneration = fetchRegistryGeneration.get(); Applications delta = null; EurekaHttpResponse\u003cApplications\u003e httpResponse = // 增量拉取注册表 eurekaTransport.queryClient.getDelta(remoteRegionsRef.get()); if (httpResponse.getStatusCode() == Status.OK.getStatusCode()) { delta = httpResponse.getEntity(); } if (delta == null) { logger.warn(\"The server does not allow the delta revision to be applied because it is not safe. \" + \"Hence got the full registry.\"); // 如果增量拉取失败，会再次进行全量拉取 getAndStoreFullRegistry(); } else if (fetchRegistryGeneration.compareAndSet(currentUpdateGeneration, currentUpdateGeneration + 1)) { logger.debug(\"Got delta update with apps hashcode {}\", delta.getAppsHashCode()); String reconcileHashCode = \"\"; if (fetchRegistryUpdateLock.tryLock()) { try { updateDelta(delta); reconcileHashCode = getReconcileHashCode(applications); } finally { fetchRegistryUpdateLock.unlock(); } } else { logger.warn(\"Cannot acquire update lock, aborting getAndUpdateDelta\"); } // There is a diff in number of instances for some reason if (!reconcileHashCode.equals(delta.getAppsHashCode()) || clientConfig.shouldLogDeltaDiff()) { reconcileAndLogDifference(delta, reconcileHashCode); // this makes a remoteCall } } else { logger.warn(\"Not updating application delta as another thread is updating it already\"); logger.debug(\"Ignoring delta update with apps hashcode {}, as another thread is updating it already\", delta.getAppsHashCode()); } } 1 2 3 4 5 6 7 8 9 10 @Override public EurekaHttpResponse\u003cApplications\u003e getDelta(final String... regions) { return execute(new RequestExecutor\u003cApplications\u003e() { @Override public EurekaHttpResponse\u003cApplications\u003e execute(EurekaHttpClient delegate) { // 增量拉取注册表，是从 recentlyChangedQueue 中获取 return delegate.getDelta(regions); } }); } 1 2 3 4 5 @Override public EurekaHttpResponse\u003cApplications\u003e getDelta(String... regions) { // 向 eureka server 发送 apps/delta 请求 return getApplicationsInternal(\"apps/delta\", regions); } initScheduledTasks();\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 // 初始化定时任务 private void initScheduledTasks() { if (clientConfig.shouldFetchRegistry()) { // registry cache refresh timer // 拉取注册表的时间间隔，eureka.client.registry-fetch-interval-seconds，默认是 30 int registryFetchIntervalSeconds = clientConfig.getRegistryFetchIntervalSeconds(); int expBackOffBound = clientConfig.getCacheRefreshExecutorExponentialBackOffBound(); // 定时拉取注册表 cacheRefreshTask = new TimedSupervisorTask( \"cacheRefresh\", scheduler, cacheRefreshExecutor, registryFetchIntervalSeconds, TimeUnit.SECONDS, expBackOffBound, new CacheRefreshThread() ); scheduler.schedule( cacheRefreshTask, registryFetchIntervalSeconds, TimeUnit.SECONDS); } if (clientConfig.shouldRegisterWithEureka()) { // 心跳/续约时间间隔，eureka.instance.lease-renewal-interval-in-seconds，默认 30 秒 int renewalIntervalInSecs = instanceInfo.getLeaseInfo().getRenewalIntervalInSecs(); int expBackOffBound = clientConfig.getHeartbeatExecutorExponentialBackOffBound(); logger.info(\"Starting heartbeat executor: \" + \"renew interval is: {}\", renewalIntervalInSecs); // Heartbeat timer // 定时心跳 heartbeatTask = new TimedSupervisorTask( \"heartbeat\", scheduler, heartbeatExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new HeartbeatThread() ); scheduler.schedule( heartbeatTask, renewalIntervalInSecs, TimeUnit.SECONDS); // InstanceInfo replicator // 实例信息复制器 instanceInfoReplicator = new InstanceInfoReplicator( this, instanceInfo, clientConfig.getInstanceInfoReplicationIntervalSeconds(), 2); // burstSize // 实例状态改变的监听器，Eureka Client 支持动态刷新，该监听器可以在 Client 已经启动的情况下自动更新 Client 的信息 // 与 EurekaClient#registerHealthCheck, EurekaClient#registerEventListener 有关 statusChangeListener = new ApplicationInfoManager.StatusChangeListener() { @Override public String getId() { return \"statusChangeListener\"; } @Override public void notify(StatusChangeEvent statusChangeEvent) { if (InstanceStatus.DOWN == statusChangeEvent.getStatus() || InstanceStatus.DOWN == statusChangeEvent.getPreviousStatus()) { // log at warn level if DOWN was involved logger.warn(\"Saw local status change event {}\", statusChangeEvent); } else { logger.info(\"Saw local status change event {}\", statusChangeEvent); } instanceInfoReplicator.onDemandUpdate(); } }; if (clientConfig.shouldOnDemandUpdateStatusChange()) { applicationInfoManager.registerStatusChangeListener(statusChangeListener); } // 启动线程处理 Eureka Client 的自动更新 instanceInfoReplicator.start(clientConfig.getInitialInstanceInfoReplicationIntervalSeconds()); } else { logger.info(\"Not registering with Eureka server per configuration\"); } } new CacheRefreshThread()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 // 定时拉取注册表的逻辑 @VisibleForTesting void refreshRegistry() { try { boolean isFetchingRemoteRegionRegistries = isFetchingRemoteRegionRegistries(); boolean remoteRegionsModified = false; // This makes sure that a dynamic change to remote regions to fetch is honored. String latestRemoteRegions = clientConfig.fetchRegistryForRemoteRegions(); if (null != latestRemoteRegions) { String currentRemoteRegions = remoteRegionsToFetch.get(); if (!latestRemoteRegions.equals(currentRemoteRegions)) { // Both remoteRegionsToFetch and AzToRegionMapper.regionsToFetch need to be in sync synchronized (instanceRegionChecker.getAzToRegionMapper()) { if (remoteRegionsToFetch.compareAndSet(currentRemoteRegions, latestRemoteRegions)) { String[] remoteRegions = latestRemoteRegions.split(\",\"); remoteRegionsRef.set(remoteRegions); instanceRegionChecker.getAzToRegionMapper().setRegionsToFetch(remoteRegions); remoteRegionsModified = true; } else { logger.info(\"Remote regions to fetch modified concurrently,\" + \" ignoring change from {} to {}\", currentRemoteRegions, latestRemoteRegions); } } } else { // Just refresh mapping to reflect any DNS/Property change instanceRegionChecker.getAzToRegionMapper().refreshMapping(); } } // 拉取注册表 boolean success = fetchRegistry(remoteRegionsModified); if (success) { registrySize = localRegionApps.get().size(); lastSuccessfulRegistryFetchTimestamp = System.currentTimeMillis(); } if (logger.isDebugEnabled()) { StringBuilder allAppsHashCodes = new StringBuilder(); allAppsHashCodes.append(\"Local region apps hashcode: \"); allAppsHashCodes.append(localRegionApps.get().getAppsHashCode()); allAppsHashCodes.append(\", is fetching remote regions? \"); allAppsHashCodes.append(isFetchingRemoteRegionRegistries); for (Map.Entry\u003cString, Applications\u003e entry : remoteRegionVsApps.entrySet()) { allAppsHashCodes.append(\", Remote region: \"); allAppsHashCodes.append(entry.getKey()); allAppsHashCodes.append(\" , apps hashcode: \"); allAppsHashCodes.append(entry.getValue().getAppsHashCode()); } logger.debug(\"Completed cache refresh task for discovery. All Apps hash code is {} \", allAppsHashCodes); } } catch (Throwable e) { logger.error(\"Cannot fetch registry from server\", e); } } new HeartbeatThread()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // 定时心跳/续约的逻辑 boolean renew() { EurekaHttpResponse\u003cInstanceInfo\u003e httpResponse; try { // 发送心跳 httpResponse = eurekaTransport.registrationClient.sendHeartBeat(instanceInfo.getAppName(), instanceInfo.getId(), instanceInfo, null); logger.debug(PREFIX + \"{} - Heartbeat status: {}\", appPathIdentifier, httpResponse.getStatusCode()); if (httpResponse.getStatusCode() == Status.NOT_FOUND.getStatusCode()) { REREGISTER_COUNTER.increment(); logger.info(PREFIX + \"{} - Re-registering apps/{}\", appPathIdentifier, instanceInfo.getAppName()); long timestamp = instanceInfo.setIsDirtyWithTime(); boolean success = register(); if (success) { instanceInfo.unsetIsDirty(timestamp); } return success; } return httpResponse.getStatusCode() == Status.OK.getStatusCode(); } catch (Throwable e) { logger.error(PREFIX + \"{} - was unable to send heartbeat!\", appPathIdentifier, e); return false; } } instanceInfoReplicator.start(clientConfig.getInitialInstanceInfoReplicationIntervalSeconds());\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // 自动更新 Eureka Client 信息的逻辑 // InstanceInfoReplicator 实现了 Runnable 接口 class InstanceInfoReplicator implements Runnable { // eureka.client.initial-instance-info-replication-interval-seconds 默认是 40 public void start(int initialDelayMs) { if (started.compareAndSet(false, true)) { // 类似于 linux 上脏页的概念，当实例的某些信息被修改了，还没同步到 eureka server，此时就标记其是’脏‘的，等待同步后，会将其设置为’非脏‘的 instanceInfo.setIsDirty(); // for initial register // 执行完该方法后，每 40 秒执行一次下方的 run 方法 Future next = scheduler.schedule(this, initialDelayMs, TimeUnit.SECONDS); scheduledPeriodicRef.set(next); } } public void run() { try { // 动态更新 Client 的信息 discoveryClient.refreshInstanceInfo(); // 如果是’脏‘的返回时间戳，否则返回 null Long dirtyTimestamp = instanceInfo.isDirtyWithTime(); // 如果实例是’脏‘的 if (dirtyTimestamp != null) { // 向注册中心注册本地已经更新的实例 discoveryClient.register(); // 更新之后把实例信息标记为’非脏‘的 instanceInfo.unsetIsDirty(dirtyTimestamp); } } catch (Throwable t) { logger.warn(\"There was a problem with the instance info replicator\", t); } finally { Future next = scheduler.schedule(this, replicationIntervalSeconds, TimeUnit.SECONDS); scheduledPeriodicRef.set(next); } } } discoveryClient.refreshInstanceInfo();\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /** * 刷新当前本地的实例信息。 * Refresh the current local instanceInfo. Note that after a valid refresh where changes are observed, the * isDirty flag on the instanceInfo is set to true */ void refreshInstanceInfo() { // 刷新数据中心信息，主要是地址和 IP 信息 applicationInfoManager.refreshDataCenterInfoIfRequired(); // 刷新租约信息 applicationInfoManager.refreshLeaseInfoIfRequired(); InstanceStatus status; try { status = getHealthCheckHandler().getStatus(instanceInfo.getStatus()); } catch (Exception e) { logger.warn(\"Exception from healthcheckHandler.getStatus, setting status to DOWN\", e); status = InstanceStatus.DOWN; } if (null != status) { applicationInfoManager.setInstanceStatus(status); } } applicationInfoManager.refreshDataCenterInfoIfRequired();\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 public void refreshDataCenterInfoIfRequired() { String existingAddress = instanceInfo.getHostName(); String existingSpotInstanceAction = null; if (instanceInfo.getDataCenterInfo() instanceof AmazonInfo) { existingSpotInstanceAction = ((AmazonInfo) instanceInfo.getDataCenterInfo()).get(AmazonInfo.MetaDataKey.spotInstanceAction); } // 获取新的地址信息 String newAddress; if (config instanceof RefreshableInstanceConfig) { // Refresh data center info, and return up to date address newAddress = ((RefreshableInstanceConfig) config).resolveDefaultAddress(true); } else { newAddress = config.getHostName(true); } // 获取新的 IP 地址 String newIp = config.getIpAddress(); if (newAddress != null \u0026\u0026 !newAddress.equals(existingAddress)) { logger.warn(\"The address changed from : {} =\u003e {}\", existingAddress, newAddress); // 更新实例的信息，并把实例设置为’脏‘ updateInstanceInfo(newAddress, newIp); } if (config.getDataCenterInfo() instanceof AmazonInfo) { String newSpotInstanceAction = ((AmazonInfo) config.getDataCenterInfo()).get(AmazonInfo.MetaDataKey.spotInstanceAction); if (newSpotInstanceAction != null \u0026\u0026 !newSpotInstanceAction.equals(existingSpotInstanceAction)) { logger.info(String.format(\"The spot instance termination action changed from: %s =\u003e %s\", existingSpotInstanceAction, newSpotInstanceAction)); updateInstanceInfo(null , null ); } } } updateInstanceInfo(newAddress, newIp);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 private void updateInstanceInfo(String newAddress, String newIp) { // :( in the legacy code here the builder is acting as a mutator. // This is hard to fix as this same instanceInfo instance is referenced elsewhere. // We will most likely re-write the client at sometime so not fixing for now. InstanceInfo.Builder builder = new InstanceInfo.Builder(instanceInfo); // 更新新的地址和 IP 信息 if (newAddress != null) { builder.setHostName(newAddress); } if (newIp != null) { builder.setIPAddr(newIp); } builder.setDataCenterInfo(config.getDataCenterInfo()); // 设置’脏‘状态 instanceInfo.setIsDirty(); } applicationInfoManager.refreshLeaseInfoIfRequired();\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public void refreshLeaseInfoIfRequired() { LeaseInfo leaseInfo = instanceInfo.getLeaseInfo(); if (leaseInfo == null) { return; } int currentLeaseDuration = config.getLeaseExpirationDurationInSeconds(); int currentLeaseRenewal = config.getLeaseRenewalIntervalInSeconds(); if (leaseInfo.getDurationInSecs() != currentLeaseDuration || leaseInfo.getRenewalIntervalInSecs() != currentLeaseRenewal) { // 设置续约相关的信息 LeaseInfo newLeaseInfo = LeaseInfo.Builder.newBuilder() .setRenewalIntervalInSecs(currentLeaseRenewal) .setDurationInSecs(currentLeaseDuration) .build(); instanceInfo.setLeaseInfo(newLeaseInfo); // 设置’脏‘状态 instanceInfo.setIsDirty(); } } discoveryClient.register();\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 boolean register() throws Throwable { logger.info(PREFIX + \"{}: registering service...\", appPathIdentifier); EurekaHttpResponse\u003cVoid\u003e httpResponse; try { // 发送注册请求 httpResponse = eurekaTransport.registrationClient.register(instanceInfo); } catch (Exception e) { logger.warn(PREFIX + \"{} - registration failed {}\", appPathIdentifier, e.getMessage(), e); throw e; } if (logger.isInfoEnabled()) { logger.info(PREFIX + \"{} - registration status: {}\", appPathIdentifier, httpResponse.getStatusCode()); } return httpResponse.getStatusCode() == Status.NO_CONTENT.getStatusCode(); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 // Eureka Client 销毁 // 注意，在生产环境中，要先对 Eureka Client 进行停服，在对其进行下线，防止先下线后，Client 的心跳服务重新将其注册到 Server 上 // DiscoveryClient.java // 在销毁之前下线 @PreDestroy @Override public synchronized void shutdown() { if (isShutdown.compareAndSet(false, true)) { logger.info(\"Shutting down DiscoveryClient ...\"); if (statusChangeListener != null \u0026\u0026 applicationInfoManager != null) { applicationInfoManager.unregisterStatusChangeListener(statusChangeListener.getId()); } // 关闭定时任务 cancelScheduledTasks(); // If APPINFO was registered if (applicationInfoManager != null \u0026\u0026 clientConfig.shouldRegisterWithEureka() \u0026\u0026 clientConfig.shouldUnregisterOnShutdown()) { applicationInfoManager.setInstanceStatus(InstanceStatus.DOWN); // 取消在注册中心的注册信息 unregister(); } if (eurekaTransport != null) { eurekaTransport.shutdown(); } heartbeatStalenessMonitor.shutdown(); registryStalenessMonitor.shutdown(); Monitors.unregisterObject(this); logger.info(\"Completed shut down of DiscoveryClient\"); } } Eureka 配置优化总结 加快服务发现速度\n三级缓存，关闭 ReadOnlyCache\n降低服务拉取和心跳的时间间隔\n加快服务过期剔除速度\n降低服务过期剔除的时间间隔\n自我保护\n根据业务情况进行修改\n避免无效集群\neureka server 集群最多配 3 个，超过 3 个就没有用了\nserver 之间分担压力\neureka server 的 url 要乱序配置，防止第一个 server 压力过大\nEureka-Server 配置优化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 eureka: server: # 自我保护根据服务数量和网络情况选择性是否开启 enable-self-preservation: false # 自我保护阈值 renewal-percent-threshold: 0.85 # 剔除服务时间间隔 eviction-interval-timer-in-ms: 1000 # 关闭 ReadOnlyCache use-read-only-response-cache: false # ReadOnlyCache 和 ReadWriteCache 同步时间间隔 response-cache-update-interval-ms: 1000 # 生产中的问题： 1. 优化目的：减少服务上下线的延时 2. 自我保护的选择：根据服务数量和网络情况 3. 服务更新：先停止服务，再发送下线请求 Eureka-Client 配置优化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 client: # 拉取注册表的时间间隔，默认 30 秒 registry-fetch-interval-seconds: 30 service-url: # 多个 server 的时候，要打乱顺序，防止都注册到第一个注册中心，或者都从第一个注册中心进行注册表的拉取 # 此处如果配置多个，eureka 会按顺序进行注册，只要注册成功后，就不会向后面的进行注册了，而且最多配置三个即可，因为 RetryableEurekaHttpClient 中设置了只会重复注册 3 次 DEFAULT_NUMBER_OF_RETRIES = 3; # 如果配置多个，eureka 拉取注册表的时候会按顺序进行拉取，只要拉取成功，就不会从后面的进行拉取了，而且最多配置三个即可 # 所以微服务进行配置的时候，要把这里的顺序进行打乱，防止 client 都从同一个 server 注册和拉取 defaultZone: http://eureka-7900:7900/eureka/ instance: # 心跳/续约时间间隔，默认 30 秒 lease-renewal-interval-in-seconds: 30 ribbon: # 启动饥饿加载 eager-load: enabled: true clients: demo 其他点 区域配置 对服务进行分区，不同区域的客户端请求优先被在相同区域的服务端进行处理，可以减少网络延迟。当所在区服务故障的时候，可以自动切换到其他可用区来处理请求。\n1. EurekaServer 配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 spring: application: # 相同的服务，服务名相同 name: cloud-eureka eureka: client: # 向注册中心注册自己 register-with-eureka: true # 拉取注册表信息 fetch-registry: false # 地区设置 region: bj # 配置每个 zone 的注册中心地址 service-url: # 设置 z1 区中的两个 Eureka Server z1: http://cloud-eureka-bjz11:7911/eureka/,http://cloud-eureka-bjz12:7912/eureka/ # 设置 z2 区中的两个 Eureka Server z2: http://cloud-eureka-bjz21:7921/eureka/,http://cloud-eureka-bjz22:7922/eureka/ --- spring: profiles: 7911 server: port: 7911 eureka: client: availability-zones: # 设置 region 内的可用 zone，此处注意“,”号后面不能有空格，源码按“,”进行切割后并没有去空格 # 此处设置后，z1 和 z2 中的 4 个 Eureka Server 都是互为 peer 的 bj: z1,z2 instance: hostname: cloud-eureka-bjz11 --- spring: profiles: 7912 server: port: 7912 eureka: client: availability-zones: # 设置 region 内的可用 zone，此处注意“,”号后面不能有空格，源码按“,”进行切割后并没有去空格 # 此处设置后，z1 和 z2 中的 4 个 Eureka Server 都是互为 peer 的 bj: z1,z2 instance: hostname: cloud-eureka-bjz12 --- spring: profiles: 7921 server: port: 7921 eureka: client: availability-zones: # 设置 region 内的可用 zone，此处注意“,”号后面不能有空格，源码按“,”进行切割后并没有去空格 # 此处设置后，z1 和 z2 中的 4 个 Eureka Server 都是互为 peer 的 bj: z2,z1 instance: hostname: cloud-eureka-bjz21 --- spring: profiles: 7922 server: port: 7922 eureka: client: availability-zones: # 设置 region 内的可用 zone，此处注意“,”号后面不能有空格，源码按“,”进行切割后并没有去空格 # 此处设置后，z1 和 z2 中的 4 个 Eureka Server 都是互为 peer 的 bj: z2,z1 instance: hostname: cloud-eureka-bjz22 2. Eureka Client 服务提供者配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 spring: application: name: api-provider eureka: client: register-with-eureka: true fetch-registry: true # 设置地区 region: bj service-url: # eureka server 的 url z1: http://cloud-eureka-bjz11:7911/eureka/,http://cloud-eureka-bjz12:7912/eureka/ z2: http://cloud-eureka-bjz21:7921/eureka/,http://cloud-eureka-bjz22:7922/eureka/ # 设置优先使用相同区域的服务 prefer-same-zone-eureka: true --- spring: profiles: 9091 eureka: client: availability-zones: # 设置可用区，z1 在前，优先将该服务向 z1 的注册中心注册，向 z1 注册失败才会向 z2 注册 bj: z1,z2 instance: metadata-map: # 标记当前服务的区域是 z1，调用方可以获取到该信息 zone: z1 hostname: localhost zone: name: bjz1 --- spring: profiles: 9092 eureka: client: availability-zones: # 设置可用区，z2 在前，优先将该服务向 z2 的注册中心注册，向 z2 注册失败才会向 z1 注册 bj: z2,z1 instance: metadata-map: # 标记当前服务的区域是 z1，调用方可以获取到该信息 zone: z2 hostname: localhost zone: name: bjz2 测试代码\n1 2 3 4 5 6 7 8 9 10 11 @RestController public class ProviderController { @Value(\"${zone.name}\") private String zoneName; @GetMapping(\"zoneName\") public String getZoneName() { return zoneName; } } 3. Eureka Client 服务消费者配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 spring: application: name: api-consumer server: port: 8081 eureka: client: register-with-eureka: true fetch-registry: true region: bj availability-zones: # 拉取注册表时，也是先从 z1 拉取，z1 拉取失败才从 z2 拉取 bj: z1,z2 service-url: z1: http://cloud-eureka-bjz11:7911/eureka/, http://cloud-eureka-bjz12:7912/eureka/ z2: http://cloud-eureka-bjz21:7921/eureka/, http://cloud-eureka-bjz22:7922/eureka/ # 设置优先使用相同区域的服务 prefer-same-zone-eureka: true instance: hostname: localhost 测试代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Configuration @RestController public class ConsumerController { @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); } @Autowired private RestTemplate restTemplate; @GetMapping(\"test\") public String test() { return restTemplate.getForObject(\"http://api-provider/zoneName\", String.class); } } 4. DashBoard 效果 ","description":"","tags":["MSB","Project","网约车三期","Eureka","Java"],"title":"Eureka-Client","uri":"/posts/msb/%E7%BD%91%E7%BA%A6%E8%BD%A6%E4%B8%89%E6%9C%9F/eureka-client/"},{"categories":null,"content":"咚宝商城第一节课 项目模块介绍 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 msb-dongbao-mall-parent 父项目 msb-dongbao-common 公共包 msb-dongbao-common-base 公共基础类 msb-dongbao-common-util 工具类 msb-dongbao-api 业务模块接口层 msb-dongbao-oms-api 订单中心接口 msb-dongbao-pms-api 商品中心接口 msb-dongbao-ums-api 用户中心接口 msb-dongbao-pay-api 支付中心接口 msb-dongbao-cart-api 购物车接口 msb-dongbao-dictionary-api 基础字典接口 msb-dongbao-sms-api 优惠中心接口 msb-dongbao-cms-api 内容中心接口 msb-dongbao-service 业务模块实现层 msb-dongbao-oms 订单中心模块实现 msb-dongbao-pms 商品中心模块实现 msb-dongbao-ums 用户中心模块实现 msb-dongbao-pay 支付中心模块实现 msb-dongbao-cart 购物车模块实现 msb-dongbao-dictionary 基础字典模块实现 msb-dongbao-sms 优惠中心模块实现 msb-dongbao-cms 内容中心模块实现 msb-dongbao-application web 应用模块 msb-dongbao-manager-web 后台管理应用 msb-dongbao-portal-web 商城门户网站 msb-dongbao-job 定时任务模块 msb-dongbao-generator 代码生成器 maven 镜像 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 \u003cmirror\u003e \u003cid\u003ealiyunmaven\u003c/id\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003cname\u003e阿里云公共仓库\u003c/name\u003e \u003curl\u003ehttps://maven.aliyun.com/repository/public\u003c/url\u003e \u003c/mirror\u003e \u003cmirror\u003e \u003cid\u003ealiyunmaven\u003c/id\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003cname\u003e阿里云谷歌仓库\u003c/name\u003e \u003curl\u003ehttps://maven.aliyun.com/repository/google\u003c/url\u003e \u003c/mirror\u003e \u003cmirror\u003e \u003cid\u003ealiyunmaven\u003c/id\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003cname\u003e阿里云阿帕奇仓库\u003c/name\u003e \u003curl\u003ehttps://maven.aliyun.com/repository/apache-snapshots\u003c/url\u003e \u003c/mirror\u003e \u003cmirror\u003e \u003cid\u003ealiyunmaven\u003c/id\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003cname\u003e阿里云 spring 仓库\u003c/name\u003e \u003curl\u003ehttps://maven.aliyun.com/repository/spring\u003c/url\u003e \u003c/mirror\u003e \u003cmirror\u003e \u003cid\u003ealiyunmaven\u003c/id\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003cname\u003e阿里云 spring 插件仓库\u003c/name\u003e \u003curl\u003ehttps://maven.aliyun.com/repository/spring-plugin\u003c/url\u003e \u003c/mirror\u003e Docker 安装 MySQL 1 2 3 4 5 6 7 docker run \\ --name mysql57 \\ -p 3306:3306 \\ -v /home/wangshuo/Data/docker/mysql57/conf:/etc/mysql/conf.d \\ -v /home/wangshuo/Data/docker/mysql57/data:/var/lib/mysql \\ -v /home/wangshuo/Data/docker/mysql57/log:/var/log/mysql \\ -e MYSQL_ROOT_PASSWORD=root -d mysql:5.7 lombok 安装插件\n引入 jar 包\n1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003c/dependency\u003e SpringBoot 整合 Mybatis 引入依赖\n1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.mybatis.spring.boot\u003c/groupId\u003e \u003cartifactId\u003emybatis-spring-boot-starter\u003c/artifactId\u003e \u003c/dependency\u003e 使用 @MapperScan 扫描指定包下所有 Mapper，或者使用 @Mapper 注解标注所有 Mapper 接口\n配置文件中添加 mapper.xml 的路径配置\n1 2 3 4 5 6 mybatis: mapper-locations: - classpath:/com/example/dongbaoums/mapper/xml/*.xml # 设置开启自动驼峰命名规则映射（将表字段中的下划线自动映射为实体类中的驼峰格式） configuration: map-underscore-to-camel-case: true 如果 mapper.xml 不在 resources 目录下，需要将 mapper.xml 文件添加到编译路径\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u003c!-- 如果 mapper.xml 不是在 resources 目录下，而是在 src/main/java 下，需要添加该配置，否则编译的时候找不到该 xml，会报错 --\u003e \u003cbuild\u003e \u003cresources\u003e \u003cresource\u003e \u003cdirectory\u003esrc/main/resources\u003c/directory\u003e \u003c/resource\u003e \u003cresource\u003e \u003cdirectory\u003esrc/main/java\u003c/directory\u003e \u003cincludes\u003e \u003cinclude\u003e**/*.xml\u003c/include\u003e \u003c/includes\u003e \u003c/resource\u003e \u003c/resources\u003e \u003c/build\u003e 如果使用了 mybatis-plus 生成的代码，还需要添加如下依赖\n1 2 3 4 5 6 7 8 9 10 \u003cdependency\u003e \u003cgroupId\u003ecom.baomidou\u003c/groupId\u003e \u003cartifactId\u003emybatis-plus-boot-starter\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.baomidou\u003c/groupId\u003e \u003cartifactId\u003emybatis-plus-extension\u003c/artifactId\u003e \u003cscope\u003ecompile\u003c/scope\u003e \u003c/dependency\u003e 如果使用了 mybatis-plus，调用 mapper 的方法时报 Invalid bound statement (not found) 错误，还需要添加如下配置\n1 2 3 4 5 6 7 8 9 mybatis-plus: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl global-config: db-config: logic-delete-value: 1 logic-not-delete-value: 0 mapper-locations: - classpath:/com/example/dongbao/ums/mapper/xml/*.xml mybatis-plus 代码生成器 添加依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u003c!--代码生成器配置 https://mybatis.plus/guide/generator.html#%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B--\u003e \u003c!-- mybatis plus --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.baomidou\u003c/groupId\u003e \u003cartifactId\u003emybatis-plus-boot-starter\u003c/artifactId\u003e \u003cversion\u003e${mybatis-plus-boot-starter.version}\u003c/version\u003e \u003c/dependency\u003e \u003c!-- 代码生成器 --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.baomidou\u003c/groupId\u003e \u003cartifactId\u003emybatis-plus-generator\u003c/artifactId\u003e \u003cversion\u003e${mybatis-plus-generator.version}\u003c/version\u003e \u003c/dependency\u003e \u003c!-- 模板引擎 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.velocity\u003c/groupId\u003e \u003cartifactId\u003evelocity-engine-core\u003c/artifactId\u003e \u003cversion\u003e${velocity-engine-core.version}\u003c/version\u003e \u003c/dependency\u003e 代码生成器主类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 package org.example.dongbaogenerator; import com.baomidou.mybatisplus.annotation.FieldFill; import com.baomidou.mybatisplus.annotation.IdType; import com.baomidou.mybatisplus.generator.AutoGenerator; import com.baomidou.mybatisplus.generator.config.DataSourceConfig; import com.baomidou.mybatisplus.generator.config.GlobalConfig; import com.baomidou.mybatisplus.generator.config.PackageConfig; import com.baomidou.mybatisplus.generator.config.StrategyConfig; import com.baomidou.mybatisplus.generator.config.po.TableFill; import com.baomidou.mybatisplus.generator.config.rules.DateType; import com.baomidou.mybatisplus.generator.config.rules.NamingStrategy; import java.util.ArrayList; /** * @author wangshuo * @date 2021/01/27 */ public class DongbaoGenerator { public static void main(String[] args) { // 代码生成器 AutoGenerator mpg = new AutoGenerator(); // 全局配置，设置生成文件的输出路径以及格式等信息 GlobalConfig gc = new GlobalConfig(); // 设置输出文件夹 gc.setOutputDir(\"/home/wangshuo/Projects/mashibing/dongbao-mall/dongbao-mall-parent-v1/dongbao-service/dongbao-ums/src/main/java\"); gc.setAuthor(\"wangshuo\"); gc.setOpen(false); gc.setFileOverride(true); // 去掉 Service 的 I 前缀 gc.setServiceName(\"%sService\"); gc.setIdType(IdType.ASSIGN_ID); gc.setDateType(DateType.ONLY_DATE); // 实体属性 Swagger2 注解 gc.setSwagger2(false); mpg.setGlobalConfig(gc); // 数据源配置 DataSourceConfig dsc = new DataSourceConfig(); dsc.setUrl(\"jdbc:mysql://localhost:3306/dongbao_mall_v1?useUnicode=true\u0026useSSL=false\u0026characterEncoding=utf8\"); // dsc.setSchemaName(\"public\"); dsc.setDriverName(\"com.mysql.cj.jdbc.Driver\"); dsc.setUsername(\"root\"); dsc.setPassword(\"root\"); mpg.setDataSource(dsc); // 包配置 PackageConfig pc = new PackageConfig(); // pc.setModuleName(scanner(\"模块名\")); pc.setParent(\"com.example.dongbao.ums\"); pc.setEntity(\"entity\"); pc.setMapper(\"mapper\"); pc.setController(\"controller\"); mpg.setPackageInfo(pc); StrategyConfig sc = new StrategyConfig(); // 表名 sc.setInclude(\"ums_member\"); // 下划线转驼峰 sc.setNaming(NamingStrategy.underline_to_camel); // 列 下划线转驼峰 sc.setColumnNaming(NamingStrategy.underline_to_camel); // 开启 lombok sc.setEntityLombokModel(true); sc.setLogicDeleteFieldName(\"deleted\"); // 自动填充 TableFill gmtCreate = new TableFill(\"gmt_create\", FieldFill.INSERT); TableFill gmtModify = new TableFill(\"gmt_modified\", FieldFill.INSERT_UPDATE); ArrayList\u003cTableFill\u003e tableFills = new ArrayList\u003cTableFill\u003e(); tableFills.add(gmtCreate); tableFills.add(gmtModify); sc.setTableFillList(tableFills); // 乐观锁 sc.setVersionFieldName(\"version\"); // restcontroller sc.setRestControllerStyle(true); // localhost:xxx/hello_2 sc.setControllerMappingHyphenStyle(true); mpg.setStrategy(sc); mpg.execute(); } } 创建数据库 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 CREATE TABLE `ums_member` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `username` varchar(64) DEFAULT NULL, `password` varchar(64) DEFAULT NULL, `icon` varchar(500) DEFAULT NULL COMMENT '头像', `email` varchar(100) DEFAULT NULL COMMENT '邮箱', `nick_name` varchar(200) DEFAULT NULL COMMENT '昵称', `note` varchar(500) DEFAULT NULL COMMENT '备注信息', `gmt_create` datetime DEFAULT NULL COMMENT '创建时间', `gmt_modified` datetime DEFAULT NULL COMMENT '更新时间', `login_time` datetime DEFAULT NULL COMMENT '最后登录时间', `status` int(1) DEFAULT '1' COMMENT '帐号启用状态：0-\u003e禁用；1-\u003e启用', PRIMARY KEY (`id`), UNIQUE KEY `un_name` (`username`) USING BTREE COMMENT '用户名唯一' ) ENGINE=InnoDB AUTO_INCREMENT=61 DEFAULT CHARSET=utf8mb4 COMMENT='后台用户表'; 注意事项\n表必备的三个字段：id，gmt_create，gmt_modified\n更新时间的默认设置，不要让数据库来控制\n创建时间和更新时间，用 Mybatis Plus 的 MetaObjectHandler 控制\n添加 Handler\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package com.example.dongbao.ums.handler; import com.baomidou.mybatisplus.core.handlers.MetaObjectHandler; import org.apache.ibatis.reflection.MetaObject; import org.springframework.stereotype.Component; import java.util.Date; @Component public class MyMetaObjectHandler implements MetaObjectHandler { @Override public void insertFill(MetaObject metaObject) { System.out.println(\"insert 时，添加创建和更新时间\"); this.setFieldValByName(\"gmtCreate\", new Date(), metaObject); this.setFieldValByName(\"gmtModified\", new Date(), metaObject); } @Override public void updateFill(MetaObject metaObject) { System.out.println(\"update 的时候，添加更新时间\"); this.setFieldValByName(\"gmtModified\", new Date(), metaObject); } } 在实体类的创建和更新字段添加注解\n1 2 3 4 5 6 7 8 9 10 11 /** * 创建时间 */ @TableField(fill = FieldFill.INSERT) private Date gmtCreate; /** * 更新时间 */ @TableField(fill = FieldFill.INSERT_UPDATE) private Date gmtModified; Mybatis Plus 更新数据的原理\n1 2 3 \u003cif 字段!=null\u003e 字段=#{字段值} \u003c/if\u003e maven 本地打包的时候跳过测试代码 1 2 3 4 5 6 7 8 9 \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e \u003cartifactId\u003emaven-surefire-plugin\u003c/artifactId\u003e \u003cconfiguration\u003e \u003cskip\u003etrue\u003c/skip\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003c/plugins\u003e ","description":"","tags":["MSB","Project","Java"],"title":"咚宝商城第一节课","uri":"/posts/msb/%E5%92%9A%E5%AE%9D%E5%95%86%E5%9F%8E/dongbao-mall-01/"},{"categories":null,"content":"HTTPS 常用算法介绍 对称加密 有一个密钥，使用该密钥可以对数据进行加密和解密\n加密：明文 + 密钥 = 密文\n解密：密文 + 密钥 = 明文\n非对称加密 有两个密钥，公钥和私钥，使用公钥进行加密，私钥进行解密，或者使用私钥进行加密，公钥进行解密\n加密 解密 明文 + 公钥 = 密文 密文 + 私钥 = 明文 明文 + 私钥 = 密文 密文 + 公钥 = 明文 摘要算法 相同的数据经过计算得到的结果是相同的。可以通过该算法生成数字签名\n请求执行流程 客户端向服务端发送 http 请求，会经过多个路由器等设备，只要在其中一个节点拦截到交互的数据包，即可获取到数据包的内容。\n为什么不能使用对称加密 对称加密有一个密钥，服务端要把密钥发送给客户端，这样双方才能进行后续的通信。此时如果密钥被截取了，中间方就可以对双方传输的数据包进行操作。\n为什么不能使用非对称机密 非对称加密包含两个密钥，服务器要把公钥发送给客户端，这样双方才能进行后续的通信。此时如果公钥被截取了，中间方就可以伪造一组公钥和私钥，然后将伪造的公钥发送给客户端，从而在中间对传输的数据进行修改。\nHTTS 如何解决密钥泄漏问题 HTTPS 的全称是 HTTP over SSL，简单理解就是在 HTTP 传输的基础上增加了 SSL 协议的加密能力。\nSSL 证书 由受信任的数字证书颁发机构（CA）在验证服务器身份后颁发的，与服务器域名是进行绑定的，并通过私钥进行加密（私钥仅保存在 CA 机构，不会外漏）。知名可信的 CA 机构证书信息，在操作系统中默认都是有保存的，浏览器用其来对服务器发过来的证书进行校验。\n加入 SSL 证书后的请求流程 Client Hello：浏览器访问服务器，告诉服务器它的 SSL 版本和支持的加密算法 Server Hello：服务器接收到请求后，选择出一种加密算法，告诉浏览器 服务器把自己的 SSL 证书发送给浏览器，SSL 证书中包含服务器的公钥等信息 浏览器对该 SSL 证书进行验证，并从中获取到服务器的公钥。然后生成一个密钥使用服务器公钥进行加密后发送给服务器 服务器使用私钥对密文解密，获取到浏览器生成的密钥 之后浏览器和服务器间通过之前约定好的对称加密算法，以及浏览器生成的密钥对数据进行加密传输 第 3 步时，如果中间有黑客，它可以获取到服务器发送的 SSL 证书，也可以对 SSL 证书进行解密（因为 SSL 证书本来就是公开的），获取到服务器的公钥。但是其无法将 SSL 证书中的公钥进行替换后并重新生成伪造的 SSL 证书，因为 SSL 证书的签名是根据服务器公钥以及证书私钥生成的，如果其将服务器公钥替换，那么证书的签名就不匹配了，在第 4 步校验 SSL 证书的时候，就会出现错误。\nhttps://ke.qq.com/webcourse/398381/101809137#taid=7879177634452525\u0026vid=5285890804089720211\n","description":"","tags":["MSB","Session Manage","HTTPS","Java"],"title":"HTTPS","uri":"/posts/msb/%E4%BC%9A%E8%AF%9D%E7%AE%A1%E7%90%86/https/"},{"categories":null,"content":"Spring Security 集群环境下的使用 Spring Security 在集群环境下要解决的主要就是 SSO 问题，登录一次就可以访问所有相互信任的应用系统。\n有状态会话和无状态会话 用户在登录的时候，主要包含两个操作：认证和鉴权。认证通常指验证用户的用户名和密码；鉴权是给用户授权。\n会话是否有状态主要就是根据服务器端是否保留用户的信息来区分，有状态会话会保存，无状态会话不保存。\n有状态会话通常使用 session+cookie 的方式对用户进行认证，无状态会话通常使用 Token 的方式。\n有状态的会话会将用户的信息保存在服务端，并设置一个 sessionId，当客户端访问的时候，根据 sessionId 从服务端获取到用户的信息。\n无状态会话会将用户的信息保存在客户端，当客户端访问的时候，将客户端携带过来的 token 进行解析来获取到用户的信息。\nSession 共享 为了解决集群环境下，不能单点登录的问题，所以出现了 session 共享的解决方案。session 共享依旧属于有状态的会话。\nsession 共享有两种实现方案\n各个服务间自己进行复制：存在数据一致性的问题 把 session 放到中间件（如 redis）里：可以保证数据一致性，但由于需要与中间件进行通讯，会增加网络开销。 SpringSession + Redis 实现 Session 共享 依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-data-redis\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-security\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.session\u003c/groupId\u003e \u003cartifactId\u003espring-session-data-redis\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e 配置文件\n1 2 3 4 5 6 7 8 9 10 server: port: 8080 spring: redis: host: localhost port: 6379 security: user: name: admin password: 123456 JWT JSON Web Token，基于 JSON 的令牌安全验证（在某些特定场合可以替代 session 或 cookie），一次生成随处校验\nJWT 的组成 JWT 由三段信息构成，将三段信息用.连接在一起就构成了一个 JWT 字符串。例如\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c 三部分分别为头部（header），载荷（playload），签名（signature）\n头部信息（header） 用于记录 Token 的基本信息，header 包含两部分属性\nToken 类型 加密算法 示例 1 2 3 4 { \"alg\": \"HS256\", \"typ\": \"JWT\" } 将该 json 进行 base64 加密，即可得到 JWT 的第一部分\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9 载荷（playload） 用于存放数据的地方，自定义的数据都放在这里。该处存储的数据是可以被解密的，所以最好存储加密后的数据。\n存储在这里的数据称为 claims。有三种类型的 claims。\nJWT 标准中已注册的 claims（Registered Claims） 公共 claims（Public Claims） 私有 claims（Private Claims） Registered Claims JWT 标准中预先定义的 claims。提供了一系列常用的 claims。\niss：JWT 的发行人（issuer） sub：JWT 的主题（subject）。须在 iss 范围内唯一或全球唯一，用于标识该 token 应用于哪个特定应用程序 aud：JWT 的接收人（audience）。 exp：JWT 的到期时间（expiration time），到期时间必须大于签发时间 nbf：JWT 在某个时间之后（Not Before）才生效。该时间必须在签发时间和到期时间之间 jti：JWT 的唯一身份标识（JWT ID） Public Claims 可以添加任何信息。属性名不能冲突，所以推荐定义 IANA JSON Web Token Registry 里包含的属性名\nPrivate Claims 也可以添加任何信息。可以添加发行人和接收人协商好的数据。属性名即不在 Registered 里，也不在 Public 里。属性名可以冲突，所以要谨慎使用。\n示例 1 2 3 4 5 { \"sub\": \"1234567890\", \"name\": \"John Doe\", \"iat\": 1516239022 } 将该 json 进行 base64 加密，即可得到 JWT 的第二部分\neyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ 验证签名（VERIFY SIGNATURE） 将 Base64 加密后的 header 和 Base64 加密后的 payload 通过 . 进行连接，根据 header 中指定的加密算法加入自定义的密钥进行加密，即可得到 JWT 的第三部分\nTJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ 拼接 JWT 把得到的三部分用 . 连接在一起，即可得到完整的 JWT\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c JWT 的使用方式 客户端收到服务器返回的 JWT，可以储存在 Cookie 里面，也可以储存在 localStorage。\n此后，客户端每次与服务器通信，都要带上这个 JWT。你可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP 请求的头信息 Authorization 字段里面。\n1 Authorization: Bearer \u003ctoken\u003e 另一种做法是，跨域的时候，JWT 就放在 POST 请求的数据体里面。\nJWT 的使用 引入依赖\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003eio.jsonwebtoken\u003c/groupId\u003e \u003cartifactId\u003ejjwt\u003c/artifactId\u003e \u003cversion\u003e0.9.1\u003c/version\u003e \u003c/dependency\u003e 工具类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package com.example.jwt.util; import io.jsonwebtoken.Claims; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; import java.util.Date; import java.util.concurrent.TimeUnit; public class JwtUtils { private static final String SECRET = \"ko346134h_we]rg3in_yip1!\"; public static final SignatureAlgorithm SIGNATURE_ALGORITHM = SignatureAlgorithm.HS256; private static final Long TTL_MILLIS = TimeUnit.HOURS.toMillis(12); public static String createToken(String subject) { Date now = new Date(); return Jwts.builder() .setSubject(subject) .setIssuedAt(now) .setExpiration(new Date(now.getTime() + TTL_MILLIS)) .signWith(SIGNATURE_ALGORITHM, SECRET) .compact(); } public static String parseJWT(String jwt) { Claims claims = Jwts.parser() .setSigningKey(SECRET) .parseClaimsJws(jwt).getBody(); return claims.getSubject(); } } 在 Filter 中进行验证\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @WebFilter(\"/\") @Component public class JwtFilter implements Filter { @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest req = (HttpServletRequest) request; String token = req.getHeader(\"Authorization\"); String subject = JwtUtils.parseJWT(token); System.out.println(subject); chain.doFilter(request, response); } } Token 安全防御 Token 的携带方式 浏览器 HTTP HEADER URL Cookies Local Storage APP 本地存储 前后端签名，私钥存储 HMAC 数据在传输过程中对数据产生的摘要，用于防篡改\n攻击方式 XSS 重放攻击 CSRF 跨域攻击 防程序员 防范措施 防 XSS 和 CSRF\n防程序员：例如使用 Spring Cloud Config 作为配置中心，在 git 上使用 dev 和 prod 两个分支，让开发人员没有 prod 分支的权限。但是此时依旧可以通过打印日志的方式，打印出密钥。所以只能通过代码审查 + 制度双重制约。\nOAuth2.0 参考 理解 OAuth 2.0\nOAuth 2.0 Migration Guide\n","description":"","tags":["MSB","Session Manage","Spring Security","Java"],"title":"Spring Security 集群环境下的使用","uri":"/posts/msb/%E4%BC%9A%E8%AF%9D%E7%AE%A1%E7%90%86/spring-security-in-cluster/"},{"categories":null,"content":"Spring Security 密码存储 常见密文存储的几种方式\n明文 Hash(明文) Hash(明文 + 盐) 盐的几种实现\n固定盐 随机盐(存储到数据库) 随机盐(存在密码里) 防止破解 没有绝对安全的网络，即使拿不到密码，也可以发送重放攻击。\n多次加盐取 hash 使用更复杂的单向加密算法，如 BCrypt 使用 https 风控系统 二次安全校验 接口调用安全校验 异地登录校验 大额转账校验 常见加密算法 推荐使用 PBKDF2/BCrypt/SCrypt/Argon2 算法。解密难度依次增加\n算法分类 常见算法 原理 特点 有效破解方式 破解难度 明文保存 实现简单 无需破解 简单 对称加密 3DES, AES 明文 + 密钥 = 密文\n密文 + 密钥 = 明文 通过加密后的密文和密钥可以解密出明文 获取密钥 中 单向 HASH MD5, SHA1 把任意长的输入字符串变化成固定长的输出字符串。同一字符串加密后的密文是相同的 可以通过彩虹表获取到明文 碰撞，彩虹表 中 特殊 HASH 单向 HASH 算法+固定盐 同一字符串+固定盐加密后的密文是相同的 可以通过建立彩虹表，获取到明文 碰撞，彩虹表 中 PBKDF2, BCrypt, SCrypt, Argon2 多次加随机盐的单向 HASH 算法 因为使用随机盐，所以同一字符串每次加密后都是不同的。随机盐保存在密文中 不可解密出明文 难 SCrypt 算法论文中粗略估计了破解各个算法所需的时间\nAnt 风格路径表达式 通配符 通配符 说明 ? 匹配任何单字符 * 匹配 0 或者任意数量的字符 ** 匹配 0 或者更多的目录 最长匹配原则 例如：请求 URL 为 /app/dir/file.jsp, 现在存在种路径匹配模式 /*/.jsp 和 /app/dir/*.jsp, 那么会根据 /app/dir/*.jsp 来匹配\n匹配顺序 spring security 不能把 .anyRequest().authenticated() 写在其他规则前面\nSpring Security 的使用 最简单的使用 引入依赖\n1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-security\u003c/artifactId\u003e \u003c/dependency\u003e 此时启动项目会在控制台打印出随机生成的密码\nUsing generated security password: e7f4ce7d-321c-4a0d-ba7d-ee110debfda4 再次访问页面，就需要使用用户名和密码进行登录了，默认用户名是 user\n自定义用户名和密码登录 配置文件方式 在配置文件中设置登录名和密码\n1 2 3 4 5 spring: security: user: name: admin password: 123456 内存方式 在配置类中先创建出用户，保存到内存中，然后登录的时候通过 UserDetailService 的 loadUserByUsername 方法将用户查询出来，进行比对。\n方法一：通过重写 WebSecurityConfigurerAdapter 的 configure(AuthenticationManagerBuilder auth) 方法，调用 auth.inMemoryAuthentication()\n通过该方式配置后，配置文件中的 user.name 和 user.password 就失效了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.crypto.password.NoOpPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; /** * @EnableWebSecurity : 将其和 @Configuration 共同使用，注解在 WebSecurityConfigurer 的实现类上，来使自定义的配置生效 * 最常用的方式就是注解在 WebSecurityConfigurerAdapter 的子类上，通过重写其的方法，达到自定义的目的 * * @author wangshuo * @date 2021/01/19 */ @EnableWebSecurity @Configuration public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private PasswordEncoder passwordEncoder; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.inMemoryAuthentication() /* 向内存中添加用户信息 password() 方法中传入的是加密后的字符串，所以需要使用 passwordEncoder 对象对其进行加密 并且必须调用 roles() 方法，给用户设置一个角色 */ .withUser(\"admin\").password(passwordEncoder.encode(\"admin\")).roles(\"admin\") .and() .withUser(\"user\").password(passwordEncoder.encode(\"user\")).roles(\"user\"); } /** * 使用内存的方式进行身份验证必须配置一个 PasswordEncoder * * @return PasswordEncoder 的实现类对象 */ @Bean public PasswordEncoder passwordEncoder() { // 配置为对密码不加密 return NoOpPasswordEncoder.getInstance(); } } 方法二：向容器中注入 UserDetailsService 的实现类 InMemoryUserDetailsManager\n通过该方式配置后，配置文件中和上方 configure 方法中配置的用户和密码都会失效\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.core.authority.SimpleGrantedAuthority; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.password.NoOpPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; import org.springframework.security.provisioning.InMemoryUserDetailsManager; import java.util.Collections; @EnableWebSecurity @Configuration public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private PasswordEncoder passwordEncoder; @Bean public UserDetailsService userDetailsService() { /* 实现了 UserDetailsManager, SpringSecurity 还提供了 JdbcUserDetailsManager 用于通过数据库来进行身份认证。 可通过扩展 UserDetailsManager 接口实现将用户信息保存在其他地方，例如 redis 等 */ InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager(); /** * 可以通过如下两种方式创建 UserDetails 的实例对象 */ User user = new User(\"username\", passwordEncoder.encode(\"password\"), Collections.singletonList(new SimpleGrantedAuthority(\"admin\"))); UserDetails userDetails = User.withUsername(\"username2\").password(passwordEncoder.encode(\"password\")).roles(\"admin\").build(); // 向内存中添加用户 manager.createUser(user); manager.createUser(userDetails); return manager; } /** * 使用内存的方式进行身份验证必须配置一个 PasswordEncoder * * @return PasswordEncoder 的实现类对象 */ @Bean public PasswordEncoder passwordEncoder() { // 配置为对密码不加密 return NoOpPasswordEncoder.getInstance(); } } 数据库方式 引入依赖\n1 2 3 4 5 6 7 8 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-jdbc\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003emysql\u003c/groupId\u003e \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e \u003c/dependency\u003e 创建数据表\n1 2 3 4 5 6 7 8 9 -- Spring Security 默认需要两张数据表，建表语句存储在 org.springframework.security.core.userdetails.jdbc.users.ddl.users.ddl 中。 -- 语法不匹配，需要自行修改 create table users(username varchar_ignorecase(50) not null primary key,password varchar_ignorecase(500) not null,enabled boolean not null); create table authorities (username varchar_ignorecase(50) not null,authority varchar_ignorecase(50) not null,constraint fk_authorities_users foreign key(username) references users(username)); create unique index ix_auth_username on authorities (username,authority); -- mysql 用 create table users(username varchar(50) not null primary key,password varchar(500) not null,enabled boolean not null); create table authorities (username varchar(50) not null,authority varchar(50) not null,constraint fk_authorities_users foreign key(username) references users(username)); create unique index ix_auth_username on authorities (username,authority); 设置数据库连接\n1 2 3 4 5 spring: datasource: username: root password: root url: jdbc:mysql://localhost:3306/spring-security?useUnicode=true\u0026characterEncoding=UTF-8\u0026serverTimezone=Asia/Shanghai 自定义用户名和密码，包含两种方式，二选一即可\n方式一：重写 WebSecurityConfigurerAdapter 的 configure(AuthenticationManagerBuilder auth) 方法，调用 auth.jdbcAuthentication\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.crypto.password.NoOpPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; import org.springframework.security.provisioning.JdbcUserDetailsManager; import javax.sql.DataSource; import java.util.Collections; @EnableWebSecurity @Configuration public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private PasswordEncoder passwordEncoder; @Autowired private DataSource dataSource; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { /* 也可以调用 .getUserDetailsService() 获取 UserDetailsService 对象，然后调用方法创建。 inMemoryAuthentication 方法也可以通过这种方式使用 */ auth.jdbcAuthentication() // 使用数据库方式，必须指定数据源 .dataSource(dataSource) // 向数据库中添加用户 .withUser(\"admin\").password(passwordEncoder.encode(\"123456\")).roles(\"admin\") .and() .withUser(\"user\").password(passwordEncoder.encode(\"123456\")).roles(\"user\"); } /** * 使用数据库的方式进行身份验证也必须配置一个 PasswordEncoder * * @return PasswordEncoder 的实现类对象 */ @Bean public PasswordEncoder passwordEncoder() { // 配置为对密码不加密 return NoOpPasswordEncoder.getInstance(); } } 方式二：向容器中注入 UserDetailsService 的实现类 JdbcUserDetailsManager\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.core.authority.SimpleGrantedAuthority; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.password.NoOpPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; import org.springframework.security.provisioning.JdbcUserDetailsManager; import javax.sql.DataSource; import java.util.Collections; @EnableWebSecurity @Configuration public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private PasswordEncoder passwordEncoder; @Autowired private DataSource dataSource; @Override @Bean protected UserDetailsService userDetailsService() { JdbcUserDetailsManager manager = new JdbcUserDetailsManager(dataSource); User user = new User(\"username\", passwordEncoder.encode(\"password\"), Collections.singletonList(new SimpleGrantedAuthority(\"admin\"))); UserDetails userDetails = User.withUsername(\"username2\").password(passwordEncoder.encode(\"password\")).roles(\"admin\").build(); // 向数据库中添加用户 manager.createUser(user); manager.createUser(userDetails); return manager; } /** * 使用数据库的方式进行身份验证也必须配置一个 PasswordEncoder * * @return PasswordEncoder 的实现类对象 */ @Bean public PasswordEncoder passwordEncoder() { // 配置为对密码不加密 return NoOpPasswordEncoder.getInstance(); } } 自定义方式 可以通过实现 UserDetailsService 接口，来自定义查询用户的方法 loadUserByUsername(), 例如可以从 redis 等查询。\n还可以直接实现 UserDetailsManager 接口(UserDetailsManager 接口继承了 UserDetailsService 接口), 来自定义查找/创建/更新/删除用户的逻辑，以及修改密码，判断用户是否存在的逻辑，之后参照 InMemoryUserDetailsManager/JdbcUserDetailsManager 向容器中注入 UserDetailsService 实现类的方式使用即可。\n用到的类介绍\nUserDetailsService : 定义了根据用户名加载用户信息的方法。实现类有从内存/数据库等查询出用户的信息，然后包装成 UserDetails 对象进行返回。可通过自定义扩展，从其他持久化组件中(例如 redis)获取用户信息，或者使用 JPA/Mybatis 等方式从数据库查询用户信息 UserDetailsManager: 继承自 UserDetailsService 接口，包含了对用户信息的加载/创建/更新/删除/修改密码/存在的方法，常用的实现类有InMemoryUserDetailsManager 和 JdbcUserDetailsManager, 可通过自定义扩展，从其他持久化组件中(例如 redis)对用户信息进行操作，或者使用 JPA/Mybatis 等方式操作数据库中的信息 UserDetails: 提供了用户的核心信息。出于安全目的, Spring Security 不会直接使用它的实现类。它们只是存储用户信息，这些信息随后封装到 Authentication 对象中。这允许将与安全无关的用户信息(例如电子邮件地址，电话号码等)存储在该类的实现类中。 User: UserDetails 的实现类。包含了用户的用户名，密码，权限，以及相关状态信息。可通过扩展该类或者重新编写 UserDetails 的实现来加入相关的信息。 Spring Security 登录验证流程 参考 Spring Security 验证流程剖析及自定义验证方法\nSpring Security 本质上是一连串的 Filter, 然后又以单独的 Filter 形式插入到 Filter Chain 中，名称是 FilterChainProxy.\n实际上 FilterChainProxy 下面又多条 Filter Chain, 来针对不同的 URL 做验证，而 Filter Chain 中所拥有的 Filter 则会根据定义的服务自动递减。所以不需要显式再定义这些 Filter, 除非想要实现自己的逻辑。\n关键类 Authentication\nAuthentication 是一个接口，用来表示用户的认证信息，在用户登录认证之前，其相关信息会被封装为一个 Authentication 类型的具体实现对象，在登录认证成功之后又会生成一个信息更全面，包含用户权限等信息的 Authentication 对象，然后把它保存在 SecurityContextHolder 所持有的 SecurityContext 中，供后续进行调用。\nAuthenticationManager\n用来做验证的最主要的接口\n1 2 3 4 5 6 7 8 9 10 11 public interface AuthenticationManager { /** * 运行后有三种情况 * 1. 验证成功，返回一个带有用户详细信息的 Authentication 对象 * 2. 验证失败，抛出 AuthenticationException 异常 * 3. 无法判断，返回 null */ Authentication authenticate(Authentication authentication) throws AuthenticationException; } ProviderManager\nProviderManager 是上面 AuthenticationManager 的具体实现，它不自己处理验证，而是将验证委托给 AuthenticationProvider 列表，然后依次调用 AuthenticationProvider 进行认证，只要有一个 AuthenticationProvider 认证成功，就直接将该结果作为 ProviderManager 的认证结果返回。\n认证过程 用户使用用户名和密码进行登录 Sprnig Security 将传入的用户名和密码封装成一个未认证的 Authentication 接口实现类，最常见的是 UsernamePasswordAuthenticationToken 把上一步生成的 Authentication 交给 AuthenticationManager 的实现类 ProviderManager 进行验证 ProviderManager 依次调用 AuthenticationProvider 进行认证，认证成功后返回一个包含用户权限等信息的 Authentication 对象 把认证后的 Authentication 对象存储到 SpringSecurityContext 里 UsernamePassword 认证过程示例 UsernamePasswordAuthenticationFilter : 根据前端传入的用户名和密码生成一个未认证的令牌，并交给 AuthenticationManager 处理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public class UsernamePasswordAuthenticationFilter extends AbstractAuthenticationProcessingFilter { private static final AntPathRequestMatcher DEFAULT_ANT_PATH_REQUEST_MATCHER = new AntPathRequestMatcher(\"/login\",\"POST\"); public UsernamePasswordAuthenticationFilter() { // 匹配请求的 URL super(DEFAULT_ANT_PATH_REQUEST_MATCHER); } @Override public Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response) throws AuthenticationException { // 如果不是 POST 请求，直接抛异常 if (this.postOnly \u0026\u0026 !request.getMethod().equals(\"POST\")) { throw new AuthenticationServiceException(\"Authentication method not supported: \" + request.getMethod()); } // 从请求中拿登录名和密码 String username = obtainUsername(request); username = (username != null) ? username : \"\"; username = username.trim(); String password = obtainPassword(request); password = (password != null) ? password : \"\"; // 此时不知道用户名和密码是否是正确的，先构建一个未认证的 Token UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken(username, password); // Allow subclasses to set the \"details\" property // 先把这个 Token 存起来 setDetails(request, authRequest); // AuthenticationManager 把该 Token 交给适合的 uthenticationProvider 进行验证 return this.getAuthenticationManager().authenticate(authRequest); } } AuthenticationManager 会注册多个 AuthenticationProvider, AuthenticationManager 根据各个 AuthenticationProvider 的 supports() 方法的返回值，判断是否要将该 Token 交给该 AuthenticationProvider 处理\n1 2 3 4 5 6 public interface AuthenticationProvider { Authentication authenticate(Authentication var1) throws AuthenticationException; // 根据 Token 的类型，判断是否使用该 AuthenticationProvider 处理 boolean supports(Class\u003c?\u003e var1); } AuthenticationProvider 的实现类 AbstractUserDetailsAuthenticationProvider 和 UsernamePasswordAuthenticationToken. 主要就是对未认证的 Token 中的信息进行认证，从数据库/内存等地方查询出已保存过的用户信息，进行比对，匹配成功后返回一个认证过的令牌(Authentication 对象).\n所以如果我们进行扩展的时候，可以自定义一个 Provider, 来对前端传入的信息进行验证。注意此处加载已存在用户的 loadUserByUsername 方法，是 UserDetailsService 接口的方法，所以扩展的时候，也需要自定义一个该接口的实现类，自定义从何处查询已存在用户的信息。用户信息都被包装成了 UserDetails 类型的对象。\n如果其中一个 Provider 认证失败，会调用它的 parent 进行验证，参照 ProviderManager.authenticate() 方法，只要有一个验证成功就返回，当所有都验证失败才失败。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 public abstract class AbstractUserDetailsAuthenticationProvider implements AuthenticationProvider, InitializingBean, MessageSourceAware { @Override public Authentication authenticate(Authentication authentication) throws AuthenticationException { Assert.isInstanceOf(UsernamePasswordAuthenticationToken.class, authentication, () -\u003e this.messages.getMessage(\"AbstractUserDetailsAuthenticationProvider.onlySupports\", \"Only UsernamePasswordAuthenticationToken is supported\")); // 取出 Token 里保存的用户名 String username = determineUsername(authentication); boolean cacheWasUsed = true; // 从缓存里拿用户信息 UserDetails user = this.userCache.getUserFromCache(username); if (user == null) { cacheWasUsed = false; // 如果缓存里没有，使用该方法获取 user = retrieveUser(username, (UsernamePasswordAuthenticationToken) authentication); Object principalToReturn = user; if (this.forcePrincipalAsString) { principalToReturn = user.getUsername(); } // 创建一个认证过的令牌 return createSuccessAuthentication(principalToReturn, authentication, user); } // 在实现类 DaoAuthenticationProvider 中 @Override protected final UserDetails retrieveUser(String username, UsernamePasswordAuthenticationToken authentication) throws AuthenticationException { prepareTimingAttackProtection(); // 加载用户 UserDetails loadedUser = this.getUserDetailsService().loadUserByUsername(username); if (loadedUser == null) { throw new InternalAuthenticationServiceException( \"UserDetailsService returned null, which is an interface contract violation\"); } // 返回用户 return loadedUser; } // 支持处理 UsernamePasswordAuthenticationToken 类型的 Token @Override public boolean supports(Class\u003c?\u003e authentication) { return (UsernamePasswordAuthenticationToken.class.isAssignableFrom(authentication)); } } 自定义登录验证 自定义 UserDetails 接口的实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 package com.example.springsecurity.custom; import org.springframework.security.core.GrantedAuthority; import org.springframework.security.core.authority.AuthorityUtils; import org.springframework.security.core.userdetails.UserDetails; import java.util.Collection; /** * 自定义的用户对象，可以直接对应数据库中的用户表。 * 用户表也可以不对应 UserDetails 的实现对象，在需要用到 UserDetails 对象的时候将数据表对应的对象转为 UserDetails 对象也可以 * * @author wangshuo * @date 2021/01/21 */ public class CustomUser implements UserDetails { private String username; private String password; private String name; /** * 装填用户的角色列表 * * @return 用户角色列表 */ @Override public Collection\u003c? extends GrantedAuthority\u003e getAuthorities() { // 将用户对应的角色信息转为集合 return AuthorityUtils.createAuthorityList(\"ROLE_ADMIN\", \"ROLE_USER\"); } @Override public String getPassword() { return this.password; } @Override public String getUsername() { return this.username; } @Override public boolean isAccountNonExpired() { return true; } @Override public boolean isAccountNonLocked() { return true; } @Override public boolean isCredentialsNonExpired() { return true; } @Override public boolean isEnabled() { return true; } public CustomUser setUsername(String username) { this.username = username; return this; } public CustomUser setPassword(String password) { this.password = password; return this; } public String getName() { return name; } public CustomUser setName(String name) { this.name = name; return this; } } 实现 UserDetailsService 接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package com.example.springsecurity.custom; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.core.userdetails.UsernameNotFoundException; import org.springframework.stereotype.Service; import java.util.Collections; import java.util.Map; /** * @author wangshuo * @date 2021/01/21 */ @Service public class CustomUserDetailsService implements UserDetailsService { CustomUser customUser = new CustomUser(); { customUser.setUsername(\"admin\"); customUser.setPassword(\"123456\"); customUser.setName(\"管理员\"); } // 模拟数据库 Map\u003cString, CustomUser\u003e map = Collections.singletonMap(customUser.getUsername(), customUser); @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { // 可以使用 JPA/Mybatis 从数据库里根据账户名查询出用户信息，封装成 UserDetails 对象 CustomUser customUser = map.get(username); return customUser; } } 自定义 AuthenticationProvider\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 package com.example.springsecurity.custom; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.security.authentication.AuthenticationProvider; import org.springframework.security.authentication.BadCredentialsException; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.Authentication; import org.springframework.security.core.AuthenticationException; import org.springframework.security.core.GrantedAuthority; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.password.PasswordEncoder; import org.springframework.stereotype.Component; import java.util.Collection; /** * 用来对前端传入的用户名和凭证进行验证 * * @author wangshuo * @date 2021/01/21 */ @Component public class CustomAuthenticationProvider implements AuthenticationProvider { @Autowired private UserDetailsService customUserDetailsService; @Autowired private PasswordEncoder passwordEncoder; @Override public Authentication authenticate(Authentication authentication) throws AuthenticationException { // http 请求传入的用户名和密码 String username = authentication.getName(); String password = (String) authentication.getCredentials(); // 从内存/数据库中查询出用户信息 UserDetails userDetails = customUserDetailsService.loadUserByUsername(username); // 内存/数据库没有该用户信息，或者密码不匹配，抛出异常 if (userDetails == null || !passwordEncoder.matches(password, userDetails.getPassword())) { throw new BadCredentialsException(\"用户名或密码错误\"); } // 获取到用户的权限信息 Collection\u003c? extends GrantedAuthority\u003e authorities = userDetails.getAuthorities(); // 封装成 Authentication 类型的对象 return new UsernamePasswordAuthenticationToken(userDetails, password, authorities); } /** * 是否支持处理当前 Authentication 类型对象 * * @param aClass * @return */ @Override public boolean supports(Class\u003c?\u003e aClass) { return true; } } 在配置类中将自定义的 AuthenticationProvider 添加到 AuthenticationManager 里\n1 2 3 4 5 6 7 8 9 10 11 12 13 @EnableWebSecurity @Configuration public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private CustomAuthenticationProvider customAuthenticationProvider; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.authenticationProvider(new CustomAuthenticationProvider()); } } 忽略静态资源 有两种方式可以取消对静态资源的验证。\n方式一：通过 configure(AuthenticationManagerBuilder auth) 方法\n1 2 3 4 5 6 7 8 @EnableWebSecurity @Configuration public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.ignoring().antMatchers(\"/img/**\"); } } AuthenticationManagerBuilder 方式在 HttpSecurity 之前执行，所以配置在 AuthenticationManagerBuilder 中可以提前响应，从而提高响应速度。\n方式二：通过 configure(HttpSecurity http) 方法\n1 2 3 4 5 6 7 8 9 10 @EnableWebSecurity @Configuration public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() // permitAll: 无论是否登录都允许访问; anonymous: 仅允许匿名访问，不允许登录后访问 .antMatchers(\"/img/**\").permitAll(); } } 设置密码加密方式 在配置类中创建 PasswordEncoder 接口的实现类\n1 2 3 4 5 @Bean public PasswordEncoder passwordEncoder() { // 在这返回 PasswordEncoder 的不同实现类 return new BCryptPasswordEncoder(); } 可用通过扩展 PasswordEncoder 接口自定义加密算法\n记住我 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @EnableWebSecurity @Configuration public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { // 启用默认的表单登录 http.formLogin() .and() // 所有请求都需要验证 .anyRequest().authenticated() .and() // 开启记住我功能 .rememberMe(); } } Spring Security 默认 rememberMe 的实现是在 cookie 中放入一个名为 remember-me 的标识, Value 是使用 Base64 加密后的字符串，解密后的内容包含用户名，失效时间和签名，签名是根据用户名，失效时间，盐来计算出来的，用于验证该 cookie 是否被篡改。\n使用该方式的好处是：如果搭建分布式系统，不需要进行 session 同步或者将 session 保存在第三方(如 redis)中，即可对 remember-me 进行验证。\n同一用户多地点登录 此配置和记住我有冲突。\n策略一：踢掉其他已登录的用户\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @EnableWebSecurity @Configuration public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { // 启用默认的表单登录 http.formLogin() .and() // 所有请求都需要验证 .anyRequest().authenticated() .and() .sessionManagement() // 设置同一帐号同时最多只能有 1 个 session .maximumSessions(1); } /** * 及时清理过期的 session */ @Bean HttpSessionEventPublisher httpSessionEventPublisher() { return new HttpSessionEventPublisher(); } } 策略二：禁止其他终端登录\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @EnableWebSecurity @Configuration public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { // 启用默认的表单登录 http.formLogin() .and() // 所有请求都需要验证 .anyRequest().authenticated() .and() .sessionManagement() // 设置同一帐号同时最多只能有 1 个 session .maximumSessions(1) // 防止最大 session 外的用户登录 .maxSessionsPreventsLogin(true) } } 自定义配置信息 登录和注销相关配置 登录相关的配置在 formLogin() 里，注销相关的配置在 logout() 里\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 @EnableWebSecurity @Configuration public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.formLogin() // 设置登录页面 .loginPage(\"/login.html\") // 设置登录的 action .loginProcessingUrl(\"/login\") // 登录成功默认跳转到哪个 url. alwaysUse 默认是 false, 即如果是从 index.html 进行登录，那么登录成功后就会调转到 index.html .defaultSuccessUrl(\"/index.html\") // 设置表单登录的时候，传过来的用户名和密码的 name .usernameParameter(\"username\") .passwordParameter(\"password\") // 登录失败的时候跳转的 url .failureUrl(\"/error.html?error1\") // 登录失败的处理器 .failureHandler((httpServletRequest, httpServletResponse, e) -\u003e { // 可以在此处获取到登录失败时抛出的异常，并且可以在此处限制登录次数 e.printStackTrace(); System.out.println(\"登录失败\"); }) // 登录成功的处理器 .successHandler((httpServletRequest, httpServletResponse, authentication) -\u003e { // 可以在此处根据不同的用户角色跳转到不同的页面, authentication 里包含了用户的权限信息 System.out.println(\"登录成功\"); }) .and() // 退出登录的设置 .logout() // 退出登录的 url .logoutUrl(\"/logout\") // 成功退出后跳转到的页面 .logoutSuccessUrl(\"/index.html\") // 成功退出后会触发的事件 .logoutSuccessHandler((httpServletRequest, httpServletResponse, authentication) -\u003e { System.out.println(\"退出成功-1\"); }) // 成功对出后会触发的事件 .addLogoutHandler((httpServletRequest, httpServletResponse, authentication) -\u003e { System.out.println(\"退出成功-2\"); }); } } 常见登录异常\nLockedException 账户被锁定 CredentialsExpiredException 密码过期 AccountExpiredException 账户过期 DisabledException 账户被禁用 BadCredentialsException 密码错误 UsernameNotFoundException 用户名错误 授权请求 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @EnableWebSecurity @Configuration public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { // 授权请求 http.authorizeRequests() // antMatchers() 设置匹配的 url, 然后后方的设置访问权限 // permitAll: 允许所有人访问，无论是否登录 .antMatchers(\"/login\", \"/index.html\").permitAll() // anonymous: 仅允许匿名用户访问，登录后不可访问 .antMatchers(\"/xx\").anonymous() // hasRole: 指定有某个角色的用户才能访问 .antMatchers(\"/admin/**\").hasRole(\"ADMIN\") // denyAll: 不允许所有人访问 .antMatchers(\"/xxoo\").denyAll() // hasIpAddress: 指定 IP 访问不需要登录 .antMatchers(\"/ooxx\").hasIpAddress(\"127.0.0.1\") // anyRequest: 其他所有请求; authenticated: 均需要认证后访问。手动设置 url 权限一定要在其之前，否则会报错 .anyRequest().authenticated(); } } CSRF 问题 Spring Security 使用 CSRF Token 的方式解决 CSRF 问题。\nCSRF Token 原理 : 用户登录时，系统发放一个 CsrfToken，用户携带该 CsrfToken 与用户名和密码等参数完成登录。登录成功后，系统会记录该 CsrfToken，之后用户的任何请求都需要携带该 CsrfToken, 并由系统进行校验。\nSpring Security 默认提供了两种方式的 CSRF Token : HttpSessionCsrfTokenRepository, CookieCsrfTokenRepository\nHttpSessionCsrfTokenRepository\n默认情况下, Spring Security 加载的就是该 SessionCsrfToken, 其将 CsrfToken 存储在 HttpSession 中，并要求前端把 CsrfToken 放在名为 _csrf 的请求参数或者名为 X-CSRF-TOKEN 的请求头中。\nCookieCsrfTokenRepository\n把 CsrfToken 存储在用户的 Cookie 中。\n因为 cookie 的值只能被同域的网站读取，所以第三方网站无法获取到 cookie 的值。CSRS 攻击本身是不知道 cookie 的值的，只是利用了当请求自动携带 cookie 时可以通过身份验证的漏洞。CSRF Token 方式要求每次请求的时候通过参数或者请求头将 cookie 中保存的 CsrfToken 的值一起发送给服务端，所以需要前端手动把 cookie 中 CsrfToken 的值取出来作为参数放在请求中\n好处 :\n可以减少服务器 HttpSession 存储 CsrfToken 产生的内存消耗。 前端可以通过 JavaScript 读取 cookie 中的值(需要将 cookie 的 httpOnly 设置为 false), 而不需要服务端注入参数 CookieCsrfTokenRepository 默认会将 CsrfToken 放在名为 XSRF-TOKEN 的 cookie 中，并要求前端把 CsrfToken 放在名为 _csrf 的请求参数中或者名为 X-XSRF-TOKEN 的请求头中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.web.csrf.CookieCsrfTokenRepository; @EnableWebSecurity @Configuration public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.csrf() // 指定使用 CookieCsrfTokenRepository, 并将该 Cookie 的 HttpOnly 设置为 False, 使得 JavaScript 可以读取值 .csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse()); } } 防火墙 IP 白名单 指定 IP 可以不登录即可访问\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.web.csrf.CookieCsrfTokenRepository; @EnableWebSecurity @Configuration public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .anyRequest().authenticated() .antMatchers(\"/xxoo\").hasIpAddress(\"127.0.0.1\"); } } IP 黑名单 用 Filter（JavaEE 提供的）或者 HandlerInterceprot（SpringMVC 提供的）实现。通常 IP 黑名单都是在负载均衡/网关层尽早拦截，不让其打到真实的服务上。\nHttpFirewall Spring Security 提供了一个 HttpFirewall，用于处理 http 请求，包含两个实现 StrictHttpFirewall 和 DefaultHttpFirewall，默认使用严格的 StrictHttpFirewall\nMethod\n拒绝不允许的 HTTP 方法。默认被允许的 HTTP Method 有 [DELETE, GET, HEAD, OPTIONS, PATCH, POST, PUT]\nURL\n拒绝不规范的 URL, 在其 requestURI/contextPath/servletPath/pathInfo 中，必须不能包含以下字符串序列之一 :\n1 [\"//\", \"./\", \"/…/\", \"/.\"] requestURI: URL 中去除协议，主机名，端口之后其余的部分 contextPath: requetURI 中对应 webapp 的部分 servletPath: requestURI 中对应识别 Servlet 的部分 pathInfo: requestURI 中去掉 contextPath, servletPath 剩下的部分 拒绝包含非可打印的 ASCII 字符的 URL\n拒绝包含分号的 URL: ;, %3b, %3B\n1 setAllowSemicolon(boolean) 拒绝包含 URL 编码的单斜杠的 URL: %2f, %2F\n1 setAllowUrlEncodedSlash(boolean) 拒绝包含双斜杠的 URL : //, %2f%2f, %2F%2F, %2f%2F, %2F%2f\n1 setAllowUrlEncodedDoubleSlash(boolean) 拒绝包含反斜杠的 URL: \\, %5c, %5C\n1 setAllowBackSlash(boolean) 拒绝包含空字符的 URL :\n1 setAllowNull(boolean) 拒绝包含 URL 编码的百分号的 URL : %25\n1 setAllowUrlEncodedPercent(boolean) 默认不能包含英文句号 : %2e, %2E\n1 setAllowUrlEncodedPeriod(boolean) 其他\n拒绝不允许的主机。请参阅 setAllowedHostnames(Predicate) 拒绝不允许的标题名称。参见 setAllowedHeaderNames(Predicate) 拒绝不允许的标头值。参见 setAllowedHeaderValues(Predicate) 拒绝不允许的参数名称。参见 setAllowedParameterNames(Predicate) 拒绝不允许的参数值。参见 setAllowedParameterValues(Predicate) 防火墙与 SQL 注入 '、;、--、% 等多个非法字符已经在请求参数中被禁用，所以已经防止了 SQL 注入问题。这也是为什么用户名中不能含有特殊字符的原因之一。\n权限 RBAC 模型 参考 RBAC 模型：基于用户-角色-权限控制的一些思考\n最普通的权限管理方式是直接使用用户关联权限，来进行权限控制，但是使用该方式会降低扩展性，仅适合用户数量少，角色类型少的平台。\n最常用的权限管理方式就是 RBAC(Role-Based Access Control), 基于角色的权限控制。通过用户关联角色，角色关联权限(资源)的方式间接赋予用户权限。这种方式可以根据角色，批量的管理用户权限。\nRBAC 模型可以分为: RBAC0, RBAC1, RBAC2, RBAC3. 其中 RBAC0 是基础思想, RBAC1, RBAC2, RBAC3 都是以 RBAC0 为基础进行的升级。一般情况下, RBAC0 模型即可满足常规的权限系统管理了。\nRBAC0\n最简单的角色，用户，权限模型。包含了两种情况：\n用户和角色是多对一的关系，一个用户只能充当一种角色，一种角色可以有多个用户担当。 用户和角色是多对多的关系，一个用户可以同时充当多种角色，一个角色可以有多个用户担当。 如果系统功能单一，使用人员较少，岗位权限相对清晰且确保不会出现兼岗的情况，可以考虑用多对一的权限体系。其余情况尽量使用多对多的权限体系，保证系统的扩展性。\nRBAC1\n相对于 RBAC0 模型，引入了子角色和继承的概念，即子角色可以继承父角色的所有权限。\n使用场景：如某个业务部门，有经理、主管、专员。主管的权限不能大于经理，专员的权限不能大于主管，如果采用 RBAC0 模型做权限系统，极可能出现分配权限失误，最终出现主管拥有经理都没有的权限的情况。\nRBAC2\n基于 RBAC0 模型，增加了对角色的一些限制：角色互斥、基数约束、先决条件角色等。\n**角色互斥：**同一用户不能分配到一组互斥角色集合中的多个角色，互斥角色是指权限互相制约的两个角色。案例：财务系统中一个用户不能同时被指派给会计角色和审计员角色。 **基数约束：**一个角色被分配的用户数量受限，它指的是有多少用户能拥有这个角色。例如：一个角色专门为公司 CEO 创建的，那这个角色的数量是有限的。 **先决条件角色：**指要想获得较高的权限，要首先拥有低一级的权限。例如：先有副总经理权限，才能有总经理权限。 **运行时互斥：**例如，允许一个用户具有两个角色的成员资格，但在运行中不可同时激活这两个角色。 RBAC3\n称为统一模型，它包含了 RBAC1 和 RBAC2，利用传递性，也把 RBAC0 包括在内，综合了 RBAC0、RBAC1 和 RBAC2 的所有特点。\n配置类中的权限设置 antMatchers 中的路径就相当于 RBAC 模型中的资源，后方的 hasRole 是所需的角色。这种方式都是写死的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @EnableWebSecurity @Configuration public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { // 授权请求 http.authorizeRequests() // antMatchers() 设置匹配的 url, 然后后方的设置访问权限 // permitAll: 允许所有人访问，无论是否登录 .antMatchers(\"/login\", \"/index.html\").permitAll() // anonymous: 仅允许匿名用户访问，登录后不可访问 .antMatchers(\"/xx\").anonymous() // hasRole: 指定有某个角色的用户才能访问 .antMatchers(\"/admin/**\").hasRole(\"ADMIN\") // denyAll: 不允许所有人访问 .antMatchers(\"/xxoo\").denyAll() // hasIpAddress: 指定 IP 访问不需要登录 .antMatchers(\"/ooxx\").hasIpAddress(\"127.0.0.1\") // anyRequest: 其他所有请求; authenticated: 均需要认证后访问。手动设置 url 权限一定要在其之前，否则会报错 .anyRequest().authenticated(); } } 角色的继承 1 2 3 4 5 6 7 @Bean public RoleHierarchy roleHierarchy(){ RoleHierarchyImpl roleHierarchy = new RoleHierarchyImpl(); // ADMIN 角色大于 USER 角色，所以 ADMIN 包含 USER 的所有权限 roleHierarchy.setHierarchy(\"ADMIN \u003e USER\"); return roleHierarchy; } 方法级别的权限认证 在配置类上添加 @EnableGlobalMethodSecurity 注解，其包含如下属性 :\nsecuredEnabled : 是否应启用 Spring Security 的 Secured 注解 prePostEnabled : 是否应启用 Spring Security 的 PreAuthorize 和 PostAuthorize 注解 jsr250Enabled : 是否应启用 JSR-250 批注 在方法上使用注解可访问权限，包含多种注解\n@Secured : 可以设置角色列表，多个角色之间是“或”的关系\n1 @Secured({\"ROLE_ADMIN\", \"ROLE_USER\"}) @PreAuthorize : 前置认证，在方法执行前验证权限。可以根据 hasRole(), hasAnyRole(), permitAll() 等表达式的返回值来设置权限，支持 SPEL 表达式，可以通过 and, or 等关键字将多个表达式进行组合使用\n1 @PreAuthorize(\"hasAnyRole('ROLE_ADMIN') \u0026\u0026 hasRole('ROLE_USER')\") @PostAuthorize: 后置认证，在方法执行后验证权限。与 PreAuthorize 相似，可以根据 hasRole(), hasAnyRole(), permitAll() 等表达式的返回值来设置权限，支持 SPEL 表达式，可以通过 and, or 等关键字将多个表达式进行组合使用，还可以根据方法的返回值来判断是否有权限。\n1 2 // returnObejct 是注解内置的对象，代表方法的返回值 @PostAuthorize(\"returnObject==1\") 当前用户的认证信息 获取到 Spring Security 中当前登录用户的认证信息，包含用户的用户名，密码，权限等认证信息\n1 Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); 图形验证码 目的：防机器暴力登录\nKaptcha 参考 Kaptcha\nKaptcha 是一个可高度配置的实用验证码生成工具，可自由配置的选项如：\n验证码的字体 验证码字体的大小 验证码字体的字体颜色 验证码内容的范围(数字，字母，中文汉字！) 验证码图片的大小，边框，边框粗细，边框颜色 验证码的干扰线 验证码的样式(鱼眼样式、3D、普通模糊、...) Kaptcha 详细配置表\nConstant 描述 默认值 kaptcha.border 图片边框，合法值：yes , no yes kaptcha.border.color 边框颜色，合法值：r,g,b (and optional alpha) 或者 white,black,blue. black kaptcha.image.width 图片宽 200 kaptcha.image.height 图片高 50 kaptcha.producer.impl 图片实现类 com.google.code.kaptcha.impl.DefaultKaptcha kaptcha.textproducer.impl 文本实现类 com.google.code.kaptcha.text.impl.DefaultTextCreator kaptcha.textproducer.char.string 文本集合，验证码值从此集合中获取 abcde2345678gfynmnpwx kaptcha.textproducer.char.length 验证码长度 5 kaptcha.textproducer.font.names 字体 Arial, Courier kaptcha.textproducer.font.size 字体大小 40px. kaptcha.textproducer.font.color 字体颜色，合法值：r,g,b 或者 white,black,blue. black kaptcha.textproducer.char.space 文字间隔 2 kaptcha.noise.impl 干扰实现类 com.google.code.kaptcha.impl.DefaultNoise kaptcha.noise.color 干扰 颜色，合法值：r,g,b 或者 white,black,blue. black kaptcha.obscurificator.impl 图片样式：\n水纹 com.google.code.kaptcha.impl.WaterRipple 鱼眼 com.google.code.kaptcha.impl.FishEyeGimpy 阴影 com.google.code.kaptcha.impl.ShadowGimpy com.google.code.kaptcha.impl.WaterRipple kaptcha.background.impl 背景实现类 com.google.code.kaptcha.impl.DefaultBackground kaptcha.background.clear.from 背景颜色渐变，开始颜色 light grey kaptcha.background.clear.to 背景颜色渐变，结束颜色 white kaptcha.word.impl 文字渲染器 com.google.code.kaptcha.text.impl.DefaultWordRenderer kaptcha.session.key session key KAPTCHA_SESSION_KEY kaptcha.session.date session date KAPTCHA_SESSION_DATE Spring MVC 整合 Kaptcha\n引入依赖\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003ecom.github.penggle\u003c/groupId\u003e \u003cartifactId\u003ekaptcha\u003c/artifactId\u003e \u003cversion\u003e2.3.2\u003c/version\u003e \u003c/dependency\u003e 配置类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import com.google.code.kaptcha.Producer; import com.google.code.kaptcha.impl.DefaultKaptcha; import com.google.code.kaptcha.util.Config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import java.util.Properties; @Configuration public class KaptchaConfig { @Bean(name = \"captchaProducer\") public Producer captchaProducer() { DefaultKaptcha kaptcha = new DefaultKaptcha(); Properties properties = new Properties(); properties.setProperty(\"kaptcha.border\", \"yes\"); properties.setProperty(\"kaptcha.border.color\", \"105.179.90\"); properties.setProperty(\"kaptcha.textproducer.font.color\", \"blue\"); properties.setProperty(\"kaptcha.image.width\", \"125\"); properties.setProperty(\"kaptcha.image.height\", \"45\"); properties.setProperty(\"kaptcha.textproducer.font.size\", \"45\"); properties.setProperty(\"kaptcha.session.key\", \"code\"); properties.setProperty(\"kaptcha.textproducer.char.length\", \"4\"); properties.setProperty(\"kaptcha.textproducer.font.names\", \"宋体，楷体，微软雅黑\"); kaptcha.setConfig(new Config(properties)); return kaptcha; } } Controller 层\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 import com.google.code.kaptcha.Constants; import com.google.code.kaptcha.Producer; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.GetMapping; import javax.imageio.ImageIO; import javax.servlet.ServletOutputStream; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.awt.image.BufferedImage; import java.io.IOException; @Controller public class KaptchaController { @Autowired private Producer captchaProducer; @GetMapping(\"/verification\") public void verification(HttpServletRequest request, HttpServletResponse response) { response.setDateHeader(\"Expires\", 0); // Set standard HTTP/1.1 no-cache headers. response.setHeader(\"Cache-Control\", \"no-store, no-cache, must-revalidate\"); // Set IE extended HTTP/1.1 no-cache headers (use addHeader). response.addHeader(\"Cache-Control\", \"post-check=0, pre-check=0\"); // Set standard HTTP/1.0 no-cache header. response.setHeader(\"Pragma\", \"no-cache\"); // return a jpeg response.setContentType(\"image/jpeg\"); // create the text for the image String capText = captchaProducer.createText(); // store the text in the session request.getSession().setAttribute(Constants.KAPTCHA_SESSION_KEY, capText); // create the image with the text BufferedImage bi = captchaProducer.createImage(capText); try (ServletOutputStream out = response.getOutputStream()) { // write the data out ImageIO.write(bi, \"jpg\", out); } catch (IOException e) { } } } 添加一个 Filter, 提前校验验证码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 import com.google.code.kaptcha.Constants; import org.springframework.security.authentication.AuthenticationServiceException; import javax.servlet.*; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; public class CodeFilter implements Filter { @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest req = (HttpServletRequest) request; HttpServletResponse resp = (HttpServletResponse) response; String uri = req.getServletPath(); // 只拦截登录请求 if (uri.equals(\"/login\") \u0026\u0026 req.getMethod().equalsIgnoreCase(\"post\")) { // 拿到 session 中的验证码 String sessionCode = req.getSession().getAttribute(Constants.KAPTCHA_SESSION_KEY).toString(); // 获取用户传过来的验证码 String formCode = req.getParameter(\"code\").trim(); if (formCode.length() == 0) { throw new RuntimeException(\"验证码不能为空\"); } if (sessionCode.equalsIgnoreCase(formCode)) { // 验证通过 chain.doFilter(request, response); } throw new AuthenticationServiceException(\"验证码错误\"); } chain.doFilter(request, response); } } 配置 Filter\n1 2 3 4 5 6 7 8 9 @EnableWebSecurity @Configuration public class SpringSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { // 在验证用户名和密码之前执行验证码的 Filter http.addFilterBefore(new CodeFilter(), UsernamePasswordAuthenticationFilter.class); } } ","description":"","tags":["MSB","Session Manage","Spring Security","Java"],"title":"Spring Security","uri":"/posts/msb/%E4%BC%9A%E8%AF%9D%E7%AE%A1%E7%90%86/spring-security/"},{"categories":null,"content":"会话管理入门 什么是会话？会话管理常见的技术及框架 Session，Cookies，Token 浏览器使用 HTTP 协议请求后台服务的时候，由于 HTTP 协议是无状态的，所以需要一种方式让服务器可以识别每次发送请求的浏览器是谁。常用的方式包括 session 和 token。\nSession\u0026Cookies session 是会话级别的，sessionId 是保存在单个服务器本地的，如果搭建后端服务集群，sessionId 是不会共享的，所以浏览器从某个服务器获取 sessionId 后，去访问其他服务器是不行的。\n当然也可以使用 Spring Session 等框架进行 session 共享来达到在服务集群中保持会话的目的。还可以把 session 放到第三方中间件中（例如 redis）\nToken token 主要也是用于解决集群/微服务中身份验证的问题。同时其还可以支持跨平台。\n使用 token 的方式服务器端可以不保存 token，而是将 token 只保存在前端，token 中可以包含用户的 id 等信息，后端服务器拿到 token 后验证用户身份。如果单纯使用明文来设置 token，会存在安全风险，所以可以通过 jwt 来对 token 进行加密。\nJWT（Json Web Tokens） JWT 是由三段信息构成：header、payload、signature\n浏览器同源策略 同源：如果两个 URL 的 protocol、host、post 都相同的话，则这两个 URL 是同源的，否则就不是同源的。\n非同源网站间有三种行为受到限制\nCookie、LocalStorage 和 IndexDB 无法读取 DOM 无法获得 AJAX 请求不能发送 最常接触到的就是 AJAX 请求不能发送的问题：在做前后端分离的时候，如果前后端部署的时候是不同源的，例如前端部署在 8080 端口，后端部署在 9090 端口，那么就会出现前端发送 ajax 请求的时候报跨域请求的错误。\nAjax 跨域请求的解决方案 除了架设服务器代理外，还包括三种方法规避\nJSONP WebSocket CORS JSONP 它的基本思想是：网页添加一个 \u003cscript\u003e 标签，向服务器请求 JSON 数据，这种做法不受同源策略的限制。服务器收到请求后，将数据放在一个指定名字的回调函数里传过来。\nJSONP 新旧浏览器都支持，同时请求的时候会将 Cookie 信息也发送过去\n首先，网页插入 \u003cscript\u003e 元素，由它向跨源网址（example.com）发送请求\n1 2 3 4 5 6 \u003cscript type=\"text/javascript\" src=\"http://example.com/ip?callback=foo\"\u003e\u003c/script\u003e // 根据 example.com 提供的回调函数，在当前页面中添加该函数 function foo(data) { console.log('Your public IP address is: ' + data.ip); }; 上面代码通过 \u003cscript\u003e 元素，向服务器 example.com 发出请求。注意，该请求的查询字符串有一个 callback 参数，用来指定回调函数的名字，这对于 JSONP 是必需的。\n服务器收到这个请求以后，会将数据放在回调函数的参数位置返回。\n1 2 3 4 5 6 7 8 9 10 // example.com/ip 接口，可以是 js 实现，也可以是其他语言 \u003cbody onload='onload'\u003e\u003c/body\u003e \u003cscript type=\"text/javascript\"\u003e function onload(){ // 可以调用与 example.com 同源的服务 var data = {\"ip\": \"8.8.8.8\"}; // 调用 foo 方法，把返回值作为参数传递 foo(data); } \u003c/script\u003e 由于 \u003cscript\u003e 元素请求的脚本，直接作为代码运行。这时，只要浏览器定义了 foo 函数，该函数就会立即调用。作为参数的 JSON 数据被视为 JavaScript 对象，而不是字符串，因此避免了使用 JSON.parse 的步骤。\nCORS CORS（Cross-Origin Resource Sharing，跨源资源分享）是 W3C 标准，是跨源 AJAX 请求的根本解决方法。相比 JSONP 只能发 GET 请求，CORS 允许任何类型的请求。\n参考 跨域资源共享 CORS 详解\n简单请求和非简单请求 浏览器将 CORS 请求分成两类：简单请求（simple request）和非简单请求（not-so-simple request）。\n只要同时满足以下两大条件，就属于简单请求。凡是不同时满足下面两个条件，就属于非简单请求。\n请求方法是以下三种方法之一 HEAD GET POST HTTP 的头信息不超出以下几种字段 Accept Accept-Language Content-Language Last-Event-ID Content-Type：只限于三个值 application/x-www-form-urlencoded、multipart/form-data、text/plain 这是为了兼容表单（form），因为历史上表单一直可以发出跨域请求。AJAX 的跨域设计就是，只要表单可以发，AJAX 就可以直接发。\n浏览器对这两种请求的处理，是不一样的。\n简单请求 对于简单请求，浏览器直接发出 CORS 请求。具体来说，就是在头信息之中，增加一个 Origin 字段。\n下面是一个例子，浏览器发现这次跨源 AJAX 请求是简单请求，就自动在头信息之中，添加一个 Origin 字段。\n1 2 3 4 5 6 GET /cors HTTP/1.1 Origin: http://api.bob.com Host: api.alice.com Accept-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0... 上面的头信息中，Origin 字段用来说明，本次请求来自哪个源（协议 + 域名 + 端口）。服务器根据这个值，决定是否同意这次请求。\n如果 Origin 指定的源，不在许可范围内，服务器会返回一个正常的 HTTP 回应。浏览器发现，这个回应的头信息没有包含 Access-Control-Allow-Origin 字段（详见下文），就知道出错了，从而抛出一个错误，被 XMLHttpRequest 的 onerror 回调函数捕获。注意，这种错误无法通过状态码识别，因为 HTTP 回应的状态码有可能是 200。\n如果 Origin 指定的域名在许可范围内，服务器返回的响应，会多出几个头信息字段。\n1 2 3 4 Access-Control-Allow-Origin: http://api.bob.com Access-Control-Allow-Credentials: true Access-Control-Expose-Headers: FooBar Content-Type: text/html; charset=utf-8 上面的头信息之中，有三个与 CORS 请求相关的字段，都以 Access-Control- 开头。\n（1）Access-Control-Allow-Origin\n该字段是必须的。它的值要么是请求时 Origin 字段的值，要么是一个 *，表示接受任意域名的请求。\n（2）Access-Control-Allow-Credentials\n该字段可选。它的值是一个布尔值，表示是否允许发送 Cookie。默认情况下，Cookie 不包括在 CORS 请求之中。设为 true，即表示服务器明确许可，Cookie 可以包含在请求中，一起发给服务器。这个值也只能设为 true，如果服务器不要浏览器发送 Cookie，删除该字段即可。\n（3）Access-Control-Expose-Headers\n该字段可选。CORS 请求时，XMLHttpRequest 对象的 getResponseHeader() 方法只能拿到 6 个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在 Access-Control-Expose-Headers 里面指定。上面的例子指定 getResponseHeader('FooBar') 可以返回 FooBar 字段的值。\n非简单请求 预检请求\n非简单请求是那种对服务器有特殊要求的请求，比如请求方法是 PUT 或 DELETE，或者 Content-Type 字段的类型是 application/json。\n非简单请求的 CORS 请求，会在正式通信之前，增加一次 HTTP 查询请求，称为“预检”请求（preflight）。\n浏览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些 HTTP 动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的 XMLHttpRequest 请求，否则就报错。\n下面是一段浏览器的 JavaScript 脚本。\n1 2 3 4 5 var url = 'http://api.alice.com/cors'; var xhr = new XMLHttpRequest(); xhr.open('PUT', url, true); xhr.setRequestHeader('X-Custom-Header', 'value'); xhr.send(); 上面代码中，HTTP 请求的方法是 PUT，并且发送一个自定义头信息 X-Custom-Header。\n浏览器发现，这是一个非简单请求，就自动发出一个“预检”请求，要求服务器确认可以这样请求。下面是这个“预检”请求的 HTTP 头信息。\n1 2 3 4 5 6 7 8 OPTIONS /cors HTTP/1.1 Origin: http://api.bob.com Access-Control-Request-Method: PUT Access-Control-Request-Headers: X-Custom-Header Host: api.alice.com Accept-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0... “预检”请求用的请求方法是 OPTIONS，表示这个请求是用来询问的。头信息里面，关键字段是 Origin，表示请求来自哪个源。\n除了 Origin 字段，“预检”请求的头信息包括两个特殊字段。\n（1）Access-Control-Request-Method\n该字段是必须的，用来列出浏览器的 CORS 请求会用到哪些 HTTP 方法，上例是 PUT。\n（2）Access-Control-Request-Headers\n该字段是一个逗号分隔的字符串，指定浏览器 CORS 请求会额外发送的头信息字段，上例是 X-Custom-Header。\n预检请求的回应\n服务器收到“预检”请求以后，检查了 Origin、Access-Control-Request-Method 和 Access-Control-Request-Headers 字段以后，确认允许跨源请求，就可以做出回应。\n1 2 3 4 5 6 7 8 9 10 11 12 HTTP/1.1 200 OK Date: Mon, 01 Dec 2008 01:15:39 GMT Server: Apache/2.0.61 (Unix) Access-Control-Allow-Origin: http://api.bob.com Access-Control-Allow-Methods: GET, POST, PUT Access-Control-Allow-Headers: X-Custom-Header Content-Type: text/html; charset=utf-8 Content-Encoding: gzip Content-Length: 0 Keep-Alive: timeout=2, max=100 Connection: Keep-Alive Content-Type: text/plain 上面的 HTTP 回应中，关键的是 Access-Control-Allow-Origin 字段，表示 http://api.bob.com 可以请求数据。该字段也可以设为星号，表示同意任意跨源请求。\n1 Access-Control-Allow-Origin: * 如果服务器否定了“预检”请求，会返回一个正常的 HTTP 回应，但是没有任何 CORS 相关的头信息字段。这时，浏览器就会认定，服务器不同意预检请求，因此触发一个错误，被 XMLHttpRequest 对象的 onerror 回调函数捕获。控制台会打印出如下的报错信息。\n1 2 XMLHttpRequest cannot load http://api.alice.com. Origin http://api.bob.com is not allowed by Access-Control-Allow-Origin. 服务器回应的其他 CORS 相关字段如下。\n1 2 3 4 Access-Control-Allow-Methods: GET, POST, PUT Access-Control-Allow-Headers: X-Custom-Header Access-Control-Allow-Credentials: true Access-Control-Max-Age: 1728000 （1）Access-Control-Allow-Methods\n该字段必需，它的值是逗号分隔的一个字符串，表明服务器支持的所有跨域请求的方法。注意，返回的是所有支持的方法，而不单是浏览器请求的那个方法。这是为了避免多次“预检”请求。\n（2）Access-Control-Allow-Headers\n如果浏览器请求包括 Access-Control-Request-Headers 字段，则 Access-Control-Allow-Headers 字段是必需的。它也是一个逗号分隔的字符串，表明服务器支持的所有头信息字段，不限于浏览器在“预检”中请求的字段。\n（3）Access-Control-Allow-Credentials\n该字段与简单请求时的含义相同。\n（4）Access-Control-Max-Age\n该字段可选，用来指定本次预检请求的有效期，单位为秒。上面结果中，有效期是 20 天（1728000 秒），即允许缓存该条回应 1728000 秒（即 20 天），在此期间，不用发出另一条预检请求。\n浏览器的正常请求和回应\n一旦服务器通过了“预检”请求，以后每次浏览器正常的 CORS 请求，就都跟简单请求一样，会有一个 Origin 头信息字段。服务器的回应，也都会有一个 Access-Control-Allow-Origin 头信息字段。\n下面是“预检”请求之后，浏览器的正常 CORS 请求。\n1 2 3 4 5 6 7 PUT /cors HTTP/1.1 Origin: http://api.bob.com Host: api.alice.com X-Custom-Header: value Accept-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0... 上面头信息的 Origin 字段是浏览器自动添加的。\n下面是服务器正常的回应。\n1 2 Access-Control-Allow-Origin: http://api.bob.com Content-Type: text/html; charset=utf-8 上面头信息中，Access-Control-Allow-Origin 字段是每次回应都必定包含的。\nShiro Shiro 是 Java 的一个安全框架。目前，使用 Apache Shiro 的人越来越多，因为对比 Spring Security 它相当简单，可能没有 SpringSecuriry 功能强大，但是在实际工作时可能并不需要那么复杂的东西，所以使用小而简单的 Shiro 就足够了。\n核心功能 Authentication：身份认证/登录，验证用户是不是拥有相应的身份\nAuthorization：授权，即权限验证。验证某个已认证的用户是否拥有某个权限；即判断用户能否做事情，常见的如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户对某个资源是否具有某个权限。\nSession Manager：会话管理，即用户登录后就是一次会话，在没有退出之前，它的所有信息都在会话中；会话可以是普通 JAVASE 环境的，也可以是如 Web 环境的\nCryptography：加密，保护数据的安全性，如密码加密存储到数据库，而不是明文存储\nWeb Support：Web 支持，可以非常容易的集成到 Web 环境\nCaching：缓存，比如多用户登录后，其用户信息，拥有的角色/权限不必每次去查数据库，这样可以提高效率\nConcurrency：shiro 支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去\nTesting：提供测试支持\nRun As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问\nRemember Me：记住我，这是个非常常见的功能，即一次登录后，下次再来就不用登录了\n组件 Subject：主体，代表当前“用户”，这个用户不一定是具体的人，与当前应用交互的任何东西都是 Subject，如网络爬虫，机器人等；即一个抽象概念。所有 Subject 都绑定到 SecurityManager，与 Subject 的所有交互都会委托给 SecurityManager；可以把 Subject 认为是一个门面，SecurityManger 才是实际的执行者\nSecurityManager：安全管理器，即所有与安全有关的操作都会与 SecurityManager 交互，且它管理着所有 Subject；可以看出它是 Shiro 的核心，它负责与后面介绍的其他组件进行交互，如果学习过 SpringMVC，可以把它看成是 DispatcherServlet。\nRealm：域，Shiro 从 Realm 获取安全数据（如用户，角色，权限），就是说 SecurityManager 要验证用户身份，那么它需要从 Realm 获取相应的用户进行比较以确定用户身份是否合法；也需要从 Realm 得到用户相应的角色/权限进行验证用户是否能进行操作；可以把 Realm 看成 DataSource，即安全数据源\n记住一点，Shiro 不会去维护用户、维护权限；这些需要我们自己去设计 / 提供；然后通过 Realm 注入给 Shiro 即可。\nSpring Security Spring Security 是一个能够为基于 Spring 的企业应用系统提供声明式的安全访问控制解决方案的安全框架。它提供了一组可以在 Spring 应用上下文中配置的 Bean，充分利用了 Spring AOP 和 Servlet 过滤器的功能。它提供全面的安全性解决方案，同时在 Web 请求级和方法调用级处理身份确认和授权。\nSpring Security 的前身是 Acegi Security\nSSO Single Sign On，单点登录。在多个应用系统中，用户只需一次登录就可以访问所有相互信任的应用系统\n核心实现理念就是使用第三方应用来完成认证/鉴权\nSession 共享 集群中的服务共享 session。或者把 session 存放到第三方中间件（例如 redis）里\nOpenID OpenID，主要用于使用第三方帐号（例如微信）登录某个网站。比如在使用微信扫码登录某个网站的时候，该网站是可以获取到微信提供的当前用户的公开信息的，其中就包含一个 openId 属性，该属性并不是真实的微信帐号，也不是微信官方数据库中的主 ID，就是给其他网站使用的一个 ID，其他网站可以通过该 ID 来确定当前用户是谁。\nOAuth 参考 理解 OAuth 2.0\n名词定义 （1）Third-party application：第三方应用程序，本文中又称“客户端”（client），即上一节例子中的“云冲印”。\n（2）HTTP service：HTTP 服务提供商，本文中简称“服务提供商”，即上一节例子中的 Google。\n（3）Resource Owner：资源所有者，本文中又称“用户”（user）。\n（4）User Agent：用户代理，本文中就是指浏览器。\n（5）Authorization server：认证服务器，即服务提供商专门用来处理认证的服务器。\n（6）Resource server：资源服务器，即服务提供商存放用户生成的资源的服务器。它与认证服务器，可以是同一台服务器，也可以是不同的服务器。\nOAuth 的思路 OAuth 在“客户端”与“服务提供商”之间，设置了一个授权层（authorization layer）。“客户端”不能直接登录“服务提供商”，只能登录授权层，以此将用户与客户端区分开来。“客户端”登录授权层所用的令牌（token），与用户的密码不同。用户可以在登录的时候，指定授权层令牌的权限范围和有效期。\n“客户端”登录授权层以后，“服务提供商”根据令牌的权限范围和有效期，向“客户端”开放用户储存的资料。\n这个授权层\n运行流程 （A）用户打开客户端以后，客户端要求用户给予授权。\n（B）用户同意给予客户端授权。\n（C）客户端使用上一步获得的授权，向认证服务器申请令牌。\n（D）认证服务器对客户端进行认证以后，确认无误，同意发放令牌。\n（E）客户端使用令牌，向资源服务器申请获取资源。\n（F）资源服务器确认令牌无误，同意向客户端开放资源。\nOpenID 和 OAuth 的区别 OAuth 主要关注授权（authorization），OpenID 主要关注认证（authentication），前者关注“用户能做什么”，后者关注“用户是谁”. OAuth 是大于 OpenID 的，OAuth 可以提供更多的权限给客户端，OpenID 只是提供公开的信息给客户端。\nCAS Central Authentication Service，中央认证服务。对于完全不同域名的系统，cookie 是无法跨域名共享的，所以使用 CAS 是直接启用一个专门用于登录的域名来提供所有的系统登录。\nXSS 和 CSRF XSS Cross Site Scripting，跨站脚本攻击。攻击者将恶意脚本代码嵌入到正常用户会访问到的页面中，当用户访问该页面时，即可导致自动执行该恶意脚本，从而进行恶意攻击。\n常见的方式例如在论坛的发帖或回复的时候，在评论中添加 \u003cscript\u003e 等标签，引入恶意脚本，如果网站没有对评论中的标签进行转义等操作，当其他用户访问到该页面的时候，就会自动执行该恶意脚本。\n常用的 XSS 攻击手段和目的有\n盗用 cookie，获取敏感信息。 利用植入 Flash，通过 crossdomain 权限设置进一步获取更高权限；或者利用 Java 等得到类似的操作。 利用 iframe、frame、XMLHttpRequest 或上述 Flash 等方式，以（被攻击）用户的身份执行一些管理动作，或执行一些一般的如发微博、加好友、发私信等操作。 利用可被攻击的域受到其他域信任的特点，以受信任来源的身份请求一些平时不允许的操作，如进行不当的投票活动。 在访问量极大的一些页面上的 XSS 可以攻击一些小型网站，实现 DDoS 攻击的效果。 解决方法 常用的方法是添加过滤器，对输入框输入的数据进行转义，把其中的 html 标签进行转义，例如把 \u003c 转义为 \u0026lt;，\u003e 转义为 $gt; 等\nCSRF Cross-site request forgery，跨站请求伪造，也称为 one-click attack 或者 session riding。\n比如某个银行的转账操作 URL 地址为：http://www.examplebank.com/withdraw?account=AccoutName\u0026amount=1000\u0026for=PayeeName\n那么，一个恶意攻击者可以在另一个网站上使用 \u003cimg\u003e 标签放置一个 \u003cimg src=\"http://www.examplebank.com/withdraw?account=Alice\u0026amount=1000\u0026for=Badman\"\u003e\n如果有一个用户刚登录了该银行不久，登录信息尚未过期，此时他访问了该恶意站点，那么他就会损失 1000 资金\nCSRF 主要就是利用 img 等标签不受同源策略的限制，并且在恶意网站获取用户在某网站的 cookie 认证信息，从而模拟该用户向该网站发送请求。通过 img 标签的 src 属性发送的请求，会把 cookie 也携带过去。\n解决方法 由于 CSRF 主要针对的就是获取到用户的 cookie 信息，所以单独使用 cookie 已经是不安全的。\nCSRF Token 用户登录时，系统发放并一个 CsrfToken，用户携带该 CsrfToken 与用户名和密码等参数完成登录。登录成功后，系统会记录该 CsrfToken，之后用户的任何请求都需要携带该 CsrfToken（可以放到请求参数或请求头中），并由系统进行校验。\n使用请求头的 referer 通过请求头中的 referer 字段判断请求的来源。没一个发送给后端的请求，在请求头中都会包含一个 referer 字段，这个字段标识着请求的来源。在后端可以通过过滤器获取请求的 referer 字段，判断 referer 字段是否是以自己网站的域名开头或是信任网站。\n","description":"","tags":["MSB","Session Manage","Java"],"title":"会话管理入门","uri":"/posts/msb/%E4%BC%9A%E8%AF%9D%E7%AE%A1%E7%90%86/session-management-introduction/"},{"categories":null,"content":"Spring Cloud Config 概念 为什么需要配置中心 单体应用配置写在配置文件中，没有什么大问题，如果需要切换环境，可以切换不同的 profile，但在微服务中:\n微服务比较多。成百上千，配置很多，需要集中管理 管理不同环境的配置 动态调整配置参数时，服务不能停服 配置中心介绍 分布式配置中心包括 3 个部分:\n存放配置的地方: git，本地文件等 config server: 从 1 中读取配置 config client: 是 config server 的客户端，用于消费配置 服务搭建 基于 github 在 github 上创建一个仓库\n添加 prd 和 dev 分支\n在不同分支创建不同的配置文件\n在 master 分支上创建 eureka-consumer-master.yml\n1 my-config: \"eureka-consumer-master\" 在 prd 分支上创建 eureka-consumer-prd.yml\n1 my-config: \"eureka-consumer-prd\" 在 dev 分支上创建 eureka-consumer-dev.yml\n1 my-config: \"eureka-consumer-dev\" 服务端 配置中心服务端依赖\n1 2 3 4 5 \u003c!-- 配置中心服务端 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-config-server\u003c/artifactId\u003e \u003c/dependency\u003e 配置中心服务端配置文件\n1 2 3 4 5 6 7 8 9 10 spring: cloud: config: server: git: uri: https://github.com/swang-harbin/spring-cloud-config-center username: password: # 默认是秒，因为 git 慢 timeout: 15 启动类添加 @EnableConfigServer 注解\n测试访问 /eureka-consumer-master.yml，/master/eureka-consumer-master.yml，/dev/eureka-consumer-dev.yml，/prd/eureka-consumer-prd.yml\n获取配置的规则\n根据前缀匹配，从前缀开始\n/{name}-{profiles}.properties /{name}-{profiles}.yml /{name}-{profiles}.json /{label}/{name}-{profiles}.yml name: 服务名称\nprofiles: 环境名称。开发/测试/生产: dev/qa/prd\nlabel: 仓库分支。默认是 master 分支\n客户端 引入依赖\n1 2 3 4 5 \u003c!-- 配置中心客户端：config-client --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-config-client\u003c/artifactId\u003e \u003c/dependency\u003e 新建bootstrap.yml配置文件，**注意: **此处一定要创建该文件，否则会报找不到属性值的异常。\n在 SpringCloud 中，bootstrap.yml 最先加载，并且其中的配置不会被 application.yml 覆盖\n1 2 3 4 5 6 7 8 9 10 spring: cloud: config: # 配置中心 uri uri: - http://localhost:6666 # 开发环境 profile: master # 分支 label: master 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(\"/consumer/config\") public class ConfigController { @Value(\"${my-config}\") private String myConfig; @RequestMapping(\"/my-config\") public String getMyConfig() { return myConfig; } } 访问 /consumer/config/my-config 测试即可\n通过 Eureka 进行获取 上方的配置方式并没有使用 EurekaServer 和 EurekaClient，配置中心 URI 是写死的主机名和端口，并且没有负载均衡等。所以可以将配置中心服务端也注册到 EurekaServer，让 EurekaClient 通过注册中心获取配置中心的配置。\n**注意：**手动配置 URI 和使用 Eureka 相互冲突，所以只能二选一使用\n服务端 添加依赖\n1 2 3 4 5 6 7 8 9 10 \u003c!-- 配置中心服务端 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-config-server\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- eureka client starter--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-client\u003c/artifactId\u003e \u003c/dependency\u003e 配置中心服务端配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 spring: application: name: cloud-config-center cloud: config: server: git: uri: https://github.com/swang-harbin/spring-cloud-config-center username: password: # 默认是秒，因为 git 慢 timeout: 15 eureka: client: service-url: defaultZone: http://localhost:7900/eureka 启动类添加 @EnableConfigServer 注解\n客户端 引入依赖\n1 2 3 4 5 6 7 8 9 10 \u003c!-- 配置中心客户端：config-client --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-config-client\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- eureka client starter--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-client\u003c/artifactId\u003e \u003c/dependency\u003e 新建 bootstrap.yml 配置文件，**注意: **此处一定要创建该文件，否则会报找不到属性值的异常。\n在 SpringCloud 中，bootstrap.yml 最先加载，并且其中的配置不会被 application.yml 覆盖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 spring: cloud: config: discovery: enabled: true # 配置中心名称 service-id: cloud-config-center # 开发环境 profile: dev # 分支 label: dev eureka: client: register-with-eureka: true fetch-registry: true service-url: # EurekaServer 如果设置了密码，需要将该配置也提前到 bootstrap.yml 中进行配置 defaultZone: http://admin:123456@localhost:7900/eureka/ instance: hostname: localhost 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(\"/consumer/config\") public class ConfigController { @Value(\"${my-config}\") private String myConfig; @RequestMapping(\"/my-config\") public String getMyConfig() { return myConfig; } } 访问 /consumer/config/my-config 测试即可\n配置刷新 手动刷新 在配置中心客户端添加 actuator 依赖\n1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-actuator\u003c/artifactId\u003e \u003c/dependency\u003e 配置文件中开启 refresh 端点\n1 2 3 4 5 6 management: endpoints: web: exposure: # 此处把端点全开了 include: '*' 在需要刷新配置的类上添加 @RefreshScope 注解\n1 2 3 4 @RefreshScope @RestController @RequestMapping(\"/consumer/config\") public class ConfigController { 重启服务，修改 git 上的配置内容，然后访问 /consumer/config/my-config，会发现配置并没有更新\nPOST 请求服务的 /actuator/refresh 端点，再访问 /consumer/config/my-config，可见配置已经更新\n注意事项：\n手动刷新只能刷新单个微服务（即刷新 9090 端接口的 EurekaConsumer，9091 端口的 EurekaConsumer 的配置不会更新），所以需要手动为每个服务调用 refresh 端点，如果微服务过多，也是灾难，所以需要自动刷新\n自动刷新 如果需要批量更新（例如把所有 EurekaConsumer 的配置都进行更新），需要通过 ESB。在 Spring Cloud 中使用支持 AMQP 协议的消息队列（RabbitMQ，Kafka）可以更方便的建立 ESB。\n在 手动刷新 的基础上进行如下配置\n安装RabbitMQ\n普通方式\n安装 erlang\n安装 RabbitMQ\n开启 RabbitMQ 节点\n1 rabbitmactl start_app 开启 RabbitMQ 管理模块的插件，并配置到 RabbitMQ 节点上\n1 rabbitmq-plugins enable rabbitmq_management docker 方式\n1 docker run -it --rm --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3-management 通过 http://localhost:15672 访问 RabbitMQ 管理页面，用户名/密码默认均为 guest\n在配置中心的客户端添加依赖\n1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-bus-amqp\u003c/artifactId\u003e \u003c/dependency\u003e 配置中心客户端的 bootstrap.yml\n1 2 3 4 5 6 7 spring: rabbitmq: host: localhost # 此处端口是 5672，Web 界面的端口号是 15672 port: 5672 username: guest password: guest 更新配置，POST 请求 /actuator/bus-refresh 即可。查看各个 EurekaConsumer 节点，配置信息均已更改。\n注意，此处请求 /actuator/refresh，依旧只能更新单独节点\n按照上述配置，可以刷新某个服务集群的配置。但是这样违背了微服务的单一职责性原则，不应该在每个微服务中设置刷新配置，应该通过配置中心服务端来对各个微服务进行配置更新\n安装 RabbitMQ\n在配置中心的服务端添加依赖\n1 2 3 4 5 6 7 8 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-actuator\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-bus-amqp\u003c/artifactId\u003e \u003c/dependency\u003e 在配置中心服务端的 application.yml 中配置 RabbitMQ 并开放 actuator 的端点\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 management: endpoints: web: exposure: include: '*' endpoint: health: enabled: true show-details: always spring: rabbitmq: host: localhost # 此处端口是 5672，Web 界面的端口号是 15672 port: 5672 username: guest password: guest 在配置中心客户端添加依赖\n1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-bus-amqp\u003c/artifactId\u003e \u003c/dependency\u003e 在配置中心客户端的 bootstrap.yml 中配置 RabbitMQ\n1 2 3 4 5 6 7 spring: rabbitmq: host: localhost # 此处端口是 5672，Web 界面的端口号是 15672 port: 5672 username: guest password: guest 在需要刷新配置的类上添加 @RefreshScope 注解\n重启配置中心服务端和客户端，更新配置，POST 请求配置中心服务端的 /actuator/bus-refresh 即可更新所有微服务的配置文件，POST 请求配置中心服务端的 /actuator/bus-refresh/{destination} 可以局部刷新微服务。destination 是服务的 ApplicationContextID，可以使用 ** 进行匹配，例如 /actuator/bus-refresh/eureka-consumer:** 即代表刷新所有的 eureka-consumer 服务\n钩子（webhook） 对外提供一个用于更新配置的端点，将该端点配置在 Git 上，Git 通过监听某些事件（例如 push 等），当发生这些事件的时候回调我们提供的端点，从而更新微服务的配置。\n不要用自动刷新，万一哪个配置不对了，就是灾难\n","description":"","tags":["MSB","Spring Cloud","Java"],"title":"Spring Cloud Config","uri":"/posts/msb/spring-cloud/spring-cloud-config/"},{"categories":null,"content":"Sleuth 概念 分布式计算八大误区 网络可靠。\n延迟为零。\n带宽无限。\n网络绝对安全。\n网络拓扑不会改变。\n必须有一名管理员。\n传输成本为零。\n网络同质化。（操作系统，协议）\n链路追踪的必要性 如果能跟踪每个请求，中间请求经过哪些微服务，请求耗时，网络延迟，业务逻辑耗时等。我们就能更好地分析系统瓶颈、解决系统问题。因此链路跟踪很重要。\n链路追踪的目的：解决错综复杂的服务调用中链路的查看。排查慢服务\n市面上链路追踪产品，大部分都是基于 google 的 Dapper 论文\nzipkin：twitter 开源，严格按照 google 的 Dapper 论文 pinpoint：韩国的 Naver 公司 Cat：美团点评 EagleEye：淘宝 链路追踪要考虑的几个问题 探针的性能消耗。尽量不影响服务本尊 易用性。开发可以很快介入，别浪费太多精力 数据分析。要实时分析。维度足够 Sleuth 简介 Sleuth 是 Spring Cloud 的分布式跟踪解决方案\nspan（跨度）：基本工作单元。一次链路调用，创建一个 span。span 用一个 64 位 id 唯一标识。包括：id，描述，时间戳事件，spanId，span 父 Id\nspan 被启动和停止时，记录了时间信息，初始化 span 叫 root span，它的 spanId 和 traceId 相同\ntrace（跟踪）：一组共享“root span”的 span 组成的树状结构，trace 也有一个 64 位 ID，trace 中所有 span 共享一个 traceId。类似于一棵 span 树\nannotation（标签）：用于记录事件的存在。其中，核心 annotation 用来定义请求的开始和结束\nCS（Client Send 客户端发起请求）。客户端发起请求描述了 span 开始 SR（Server Received 服务端接收请求）。服务端获得请求并准备处理它。SR-CS=网络延迟 SS（Server Send 服务端处理完成，并将结果发送给客户端）。标识服务器完成请求处理，响应客户端。SS-SR=服务器处理请求的时间 CR（Client Received 客户端接收服务端信息）。span 结束的标识。客户端接收到服务器的响应。CR-CS=客户端发出请求到服务器响应的总时间 其实数据结构是一棵树，从 root span 开始\nSleuth 的使用 Sleuth 单独使用 引入依赖，注意：每个需要监控的系统都需要引入\n1 2 3 4 5 \u003c!-- 引入 sleuth 依赖 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-sleuth\u003c/artifactId\u003e \u003c/dependency\u003e 修改 sleuth 日志记录级别为 debug\n1 2 3 logging: level: org.springframework.cloud.sleuth: debug 任意访问一个接口，日志包含如下输出\nconsumer 日志：[eureka-consumer,1a409c98e7a3cdbf,1a409c98e7a3cdbf,false]\nprovider 日志：[eureka-provider,1a409c98e7a3cdbf,b3d93470b5cf8434,false\n格式说明\n[服务名称,traceID（一次请求调用链中唯一 ID）,spanID（基本的工作单元，获取数据等）,是否让 zipkin 收集和显示此信息]\n可以看到 consumer 和 provider 的 traceID 是相同的\n使用 Zipkin 单独使用 Sleuth 看日志很麻烦，zipkin 是 twitter 开源的分布式跟踪系统。原理是手机系统的时序数据，从而追踪微服务架构中系统延时等问题，并提供一个友好的图形页面。\nzipkin 包含 4 个部分\nController：采集器 Storage：存储器 RESTful API：接口 Web UI：UI 界面 原理\nsleuth 收集跟踪信息通过 http 请求发送给 zipkin server，zipkin 将跟踪信息存储，并提供 RESTful API 接口，zipkin UI 页面通过调用该 API 进行数据展示。默认使用内存存储，可以修改为使用 MySQL，ES 等存储。\nzipkin 最好和 rabbitmq，mysql 等配合使用\n操作步骤\n添加依赖，每个需要监控的系统都要添加\n1 2 3 4 5 \u003c!-- zipkin --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-zipkin\u003c/artifactId\u003e \u003c/dependency\u003e 修改配置，每个需要监听的系统都要添加\n1 2 3 4 5 6 7 8 9 spring: #zipkin zipkin: # zipkin 服务的地址 base-url: http://localhost:9411/ sleuth: sampler: # 采样比例默认是 0.1，设置为 1 表示全部上报 rate: 1 启动 zipkin\n方法 1，通过 jar 启动\n去 Zipkin 官网 下载 jar 包，通过 java -jar zipkin.jar 启动\n方法 2，通过 docker 启动\ndocker run -d --name=zipkin -p 9411:9411 openzipkin/zipkin\n访问 http://localhost:9411/zipkin 查看图形页面\n任意发送请求，查看页面的变化\n","description":"","tags":["MSB","Spring Cloud","Sleuth","Java"],"title":"Sleuth","uri":"/posts/msb/spring-cloud/sleuth/"},{"categories":null,"content":"Spring Cloud Admin spring cloud admin 包含服务端和客户端，需要二者配合使用\n配置使用 服务端添加依赖\n1 2 3 4 5 6 7 8 9 10 \u003c!-- Admin 服务 --\u003e \u003cdependency\u003e \u003cgroupId\u003ede.codecentric\u003c/groupId\u003e \u003cartifactId\u003espring-boot-admin-starter-server\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- Admin 界面 --\u003e \u003cdependency\u003e \u003cgroupId\u003ede.codecentric\u003c/groupId\u003e \u003cartifactId\u003espring-boot-admin-server-ui\u003c/artifactId\u003e \u003c/dependency\u003e 服务端启动类添加 @EnableAdminServer 注解\n客户端添加依赖，每个需要被监控的服务都需要添加\n1 2 3 4 5 6 7 8 9 10 11 \u003c!-- Admin 客户端--\u003e \u003cdependency\u003e \u003cgroupId\u003ede.codecentric\u003c/groupId\u003e \u003cartifactId\u003espring-boot-admin-starter-client\u003c/artifactId\u003e \u003cversion\u003e2.3.1\u003c/version\u003e \u003c/dependency\u003e \u003c!-- actuator 监控 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-actuator\u003c/artifactId\u003e \u003c/dependency\u003e 客户端配置文件，每个需要被监控的服务都需要加\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 spring: boot: admin: client: # admin 服务端地址，用于上报信息 url: http://localhost:6010 management: endpoints: web: exposure: # 暴露端点 include: '*' endpoint: health: enabled: true show-details: always 访问 http://localhost:6010，用户名密码默认都是 root\n注意事项\neureka-server 如果包含了用户名和密码验证，使用如下方式将用户名和密码传给 spring cloud admin\n1 2 3 4 5 6 7 8 9 10 11 spring: boot: admin: client: # admin 服务端地址，用于上报信息 url: http://localhost:6010 instance: metadata: # 把 erueka server 设置的用户名和密码传递给 spring cloud admin user.name: ${spring.security.user.name} user.password: ${spring.security.user.password} 添加 Spring Security spring cloud admin 也可以添加 spring security 验证\n引入依赖\n1 2 3 4 5 \u003c!-- spring security starter --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-security\u003c/artifactId\u003e \u003c/dependency\u003e 添加配置\n1 2 3 4 5 spring: security: user: name: username password: password 客户端对应的需要添加 spring cloud admin 用户名和密码的配置\n1 2 3 4 5 6 spring: boot: admin: client: username: username password: password 服务状态通知 邮件通知 在服务端添加依赖\n1 2 3 4 5 \u003c!-- 邮件服务 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-mail\u003c/artifactId\u003e \u003c/dependency\u003e 配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 spring: # 邮件设置 mail: host: smtp.qq.com # QQ 号 username: QQ 号 # 授权码 password: xxxxxxx 授权码 properties: mail: smpt: auth: true # https starttls: enable: true required: true #收件邮箱 spring.boot.admin.notify.mail.to: xxxxxxxx@qq.com # 发件邮箱 spring.boot.admin.notify.mail.from: xxxxxxx@qq.com 下线一个服务即可收到邮件\n钉钉群通知 钉钉开放平台\n自定义消息类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 package com.example.cloudadmin.notifier.dingding; public class Message { private String msgtype; private MessageInfo text; public String getMsgtype() { return msgtype; } public void setMsgtype(String msgtype) { this.msgtype = msgtype; } public MessageInfo getText() { return text; } public void setText(MessageInfo text) { this.text = text; } static class MessageInfo { private String content; public MessageInfo(String content) { this.content = content; } public String getContent() { return content; } public void setContent(String content) { this.content = content; } } } 消息工具类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 package com.example.cloudadmin.notifier.dingding; import com.fasterxml.jackson.databind.ObjectMapper; import java.io.InputStream; import java.io.OutputStream; import java.net.HttpURLConnection; import java.net.URL; public class DingDingMessageUtil { /** * 创建完钉钉机器人生成的地址和 token */ private static final String WEBHOOK = \"https://oapi.dingtalk.com/robot/send?access_token=\" + \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"; public static void sendTextMessage(String msg) { try { Message message = new Message(); message.setMsgtype(\"text\"); message.setText(new Message.MessageInfo(msg)); URL url = new URL(WEBHOOK); // 建立 http 连接 HttpURLConnection conn = (HttpURLConnection) url.openConnection(); conn.setDoOutput(true); conn.setDoInput(true); conn.setUseCaches(false); conn.setRequestMethod(\"POST\"); conn.setRequestProperty(\"Charset\", \"UTF-8\"); conn.setRequestProperty(\"Content-Type\", \"application/json; charset=UTF-8\"); conn.connect(); OutputStream out = conn.getOutputStream(); String textMessage = new ObjectMapper().writeValueAsString(message); byte[] data = textMessage.getBytes(); out.write(data); out.flush(); out.close(); InputStream in = conn.getInputStream(); byte[] data1 = new byte[in.available()]; in.read(data1); System.out.println(new String(data1)); } catch (Exception e) { e.printStackTrace(); } } } 服务状态改变监听器的实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 package com.example.cloudadmin.notifier.dingding; import com.fasterxml.jackson.core.JsonProcessingException; import com.fasterxml.jackson.databind.ObjectMapper; import de.codecentric.boot.admin.server.domain.entities.Instance; import de.codecentric.boot.admin.server.domain.entities.InstanceRepository; import de.codecentric.boot.admin.server.domain.events.InstanceEvent; import de.codecentric.boot.admin.server.notify.AbstractStatusChangeNotifier; import reactor.core.publisher.Mono; import java.util.Map; public class DingDingNotifier extends AbstractStatusChangeNotifier { /** * 自定义的 keywords，创建钉钉机器人的时候设置的 */ private static final String KEYWORDS = \"服务预警\"; public DingDingNotifier(InstanceRepository repository) { super(repository); } @Override protected Mono\u003cVoid\u003e doNotify(InstanceEvent event, Instance instance) { String serviceName = instance.getRegistration().getName(); String serviceUrl = instance.getRegistration().getServiceUrl(); String status = instance.getStatusInfo().getStatus(); Map\u003cString, Object\u003e details = instance.getStatusInfo().getDetails(); StringBuilder str = new StringBuilder(); str.append(KEYWORDS) .append(\"：【\") .append(serviceName) .append(\"】\") .append(\"【服务地址】\") .append(serviceUrl) .append(\"【状态】\") .append(status) .append(\"【详情】\"); try { str.append(new ObjectMapper().writeValueAsString(details)); } catch (JsonProcessingException e) { e.printStackTrace(); } return Mono.fromRunnable(() -\u003e DingDingMessageUtil.sendTextMessage(str.toString())); } } 配置类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package com.example.cloudadmin.config; import com.example.cloudadmin.notifier.dingding.DingDingNotifier; import de.codecentric.boot.admin.server.domain.entities.InstanceRepository; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class NotifierConfig { @Bean public DingDingNotifier dingDingNotifier(InstanceRepository repository) { return new DingDingNotifier(repository); } } ","description":"","tags":["MSB","Spring Cloud","Java"],"title":"Spring Cloud Admin","uri":"/posts/msb/spring-cloud/spring-cloud-admin/"},{"categories":null,"content":"Zuul 服务治理和注册发现（Eureka），服务调用（RestTemplate/Feign），负载均衡（Ribbon），熔断（Hystrix）等微服务基本模块已经有了，就可以做微服务了。微服务一般都在内网，相互之间不用做安全验证。\n网关是介于客户端（外部调用方，比如 H5，app 等）和微服务的中间层\n网关分类 普通网关和 DR 网关对比 普通网关：对数据包的接收和响应都需要经过它进行处理，此时如果服务端数量较多，网关会成为瓶颈，同时因为所有数据包都经过它，所以可以做一些额外处理\nDR 网关：只接收请求的数据包，然后把数据包进行修改后发送给服务端，服务端把响应结果直接返回给客户端。所以该网关只能做负载均衡\n组合使用 DR 网关和普通网关 使用 DR 网关为普通网关做一层负载均衡，然后具体的复杂功能由普通网关实现，既可以防止普通网关出现瓶颈，又可以附加额外功能。\n流量网关和业务网关 普通网关根据其提供的功能不同又可以分为流量网关和业务网关\n流量网关 业务网关 Zuul 的功能 Zuul 是 Netflix 开源的微服务网关，核心是一系列过滤器。这些过滤器可以完成以下功能：\n是所有微服务入口，进行分发。 身份认证与安全。识别合法的请求，拦截不合法的请求。 监控。在入口处监控，更全面。 动态路由。动态将请求分发到不同的后端集群。 压力测试。可以逐渐增加对后端服务的流量，进行测试。 负载均衡。也是用 ribbon。 限流。比如我每秒只要 1000 次，10001 次就不让访问了。 Zuul 默认集成了 Ribbon 和 Hyxtrix\nZuul 的使用 初步使用 添加依赖\n1 2 3 4 5 6 7 8 9 10 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-client\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!--zuul --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-zuul\u003c/artifactId\u003e \u003c/dependency\u003e 在启动类上添加 @EnableZuulProxy 注解，该注解声明这是一个 zuul 代理，使用 Ribbon 来定位注册到 Eureka Server 上的微服务，同时整合了 Hystrix 实现容错\n配置文件\n1 2 3 4 5 6 7 8 9 10 11 spring: application: name: zuul server: port: 9999 eureka: client: register-with-eureka: true fetch-registry: true service-url: defaultZone: http://admin:123456@localhost:7900/eureka/ 通过 zuul 即可访问 Eureka Server 中的微服务，http://网关 ip:网关端口/服务名/微服务路径，例如 http://localhost:9999/eureka-consumer/consumer/restTemplate/hystrix-fallback?millis=100\n负载均衡 1 2 3 ${spring.application.name}: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 监控 路由端点 引入 actuator 依赖\n1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-actuator\u003c/artifactId\u003e \u003c/dependency\u003e 修改配置\n1 2 3 4 5 6 7 8 9 10 11 management: endpoint: health: enabled: true show-details: always routes: enabled: true endpoints: web: exposure: include: '*' 访问 /actuator/routes\n返回结果，显示的是 eureka 中的网关和映射关系。如果 eureka 中没有实例，则只显示配置的映射。根据网关请求地址和映射关系可以排查错误\n1 2 3 4 { \"/eureka-consumer/**\": \"eureka-consumer\", \"/eureka-provider/**\": \"eureka-provider\" } 过滤器端点 访问 /actuator/filters，一共包含 error，post，pre，route四种过滤器。其中包含默认的和自定义的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 { \"error\": [ { \"class\": \"org.springframework.cloud.netflix.zuul.filters.post.SendErrorFilter\", \"order\": 0, \"disabled\": false, \"static\": true } ], \"post\": [ { \"class\": \"org.springframework.cloud.netflix.zuul.filters.post.SendResponseFilter\", \"order\": 1000, \"disabled\": false, \"static\": true } ], \"pre\": [ { \"class\": \"org.springframework.cloud.netflix.zuul.filters.pre.DebugFilter\", \"order\": 1, \"disabled\": false, \"static\": true }, { \"class\": \"org.springframework.cloud.netflix.zuul.filters.pre.FormBodyWrapperFilter\", \"order\": -1, \"disabled\": false, \"static\": true }, { \"class\": \"org.springframework.cloud.netflix.zuul.filters.pre.Servlet30WrapperFilter\", \"order\": -2, \"disabled\": false, \"static\": true }, { \"class\": \"org.springframework.cloud.netflix.zuul.filters.pre.ServletDetectionFilter\", \"order\": -3, \"disabled\": false, \"static\": true }, { \"class\": \"org.springframework.cloud.netflix.zuul.filters.pre.PreDecorationFilter\", \"order\": 5, \"disabled\": false, \"static\": true } ], \"route\": [ { \"class\": \"org.springframework.cloud.netflix.zuul.filters.route.SimpleHostRoutingFilter\", \"order\": 100, \"disabled\": false, \"static\": true }, { \"class\": \"org.springframework.cloud.netflix.zuul.filters.route.RibbonRoutingFilter\", \"order\": 10, \"disabled\": false, \"static\": true }, { \"class\": \"org.springframework.cloud.netflix.zuul.filters.route.SendForwardFilter\", \"order\": 500, \"disabled\": false, \"static\": true } ] } 配置指定微服务的访问路径 通过虚拟主机名 1 2 3 zuul: routes: eureka-consumer: /zuul-eureka-consumer/** 配置前：http://localhost:9999/eureka-consumer/consumer/zuul/fallback?millis=0\n配置后：http://localhost:9999/zuul-eureka-consumer/consumer/zuul/fallback?millis=0\n配置后也可以使用配置前的 url 进行访问\n自定义名称 1 2 3 4 5 6 7 8 zuul: routes: # 此处名字随便取 custom-zuul-name: # 自定义的网关路径 path: /custom-eureka-consumer/** # 上游服务的 url url: http://localhost:9090/ 配置后：http://localhost:9999/custom-eureka-consumer/consumer/zuul/fallback?millis=0\n此时 zuul 对上游服务的负载均衡（ribbon）就失效了\n解决 ribbon 失效\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 zuul: routes: # 此处名字随便取 custom-zuul-name: # 自定义的网关路径 path: /custom-eureka-consumer/** # 自定义一个 service-id service-id: custom-service-id # 对 custom-service-id 进行 ribbon 的配置 custom-service-id: ribbon: # 上游服务集群的主机（ip）和端口 listOfServers: localhost:9090,localhost:9091 ribbon: eureka: # 关闭 ribbon 和 eureka 的集成 enabled: false 类似于 ribbon 的独立使用\n通过 service-id 1 2 3 4 5 6 7 8 zuul: routes: #此处名字随便取 custom-zuul-name: # 自定义的网关路径 path: /custom-eureka-consumer/** # 微服务的 service-id service-id: eureka-consumer 将请求转发给自己 1 2 3 4 5 6 7 8 zuul: routes: # 此处名字随便取 xxx: # 自定义的网关路径 path: /forword/** # 把请求转发到网关中我们自己定义的 Controller 上 url: forward:/ownController 忽略微服务 根据服务名忽略 可结合通过虚拟主机名指定微服务的访问路径进行使用。可以让 zuul 不根据服务名请求上游服务，只能根据自定义的网关路径访问\n1 2 3 4 5 zuul: routes: eureka-consumer: /zuul-eureka-consumer/** ignored-services: - eureka-consumer 原始路径：http://localhost:9999/eureka-consumer/consumer/zuul/fallback?millis=0\n根据虚拟主机名配置后：http://localhost:9999/zuul-eureka-consumer/consumer/zuul/fallback?millis=0\n在不配置忽略的时候，两种方式都可以访问。配置之后只有 根据虚拟主机名配置后 的路径可以访问\n根据表达式忽略 1 2 3 4 5 zuul: routes: eureka-consumer: /zuul-eureka-consumer/** ignored-patterns: - /*consumer/** 此时原始路径和根据虚拟主机名配置后的路径就都不能访问了，因为都匹配/*consumer/**表达式\n忽略全部 忽略所有的服务，此时只有 zuul.routes 中配置的好使\n1 2 3 4 zuul: routes: eureka-consumer: /zuul-eureka-consumer/** ignored-services: '*' 添加前缀 微服务接口一般命名方式都是：/api/v1/xxx\n1 2 3 4 zuul: prefix: /api # 是否移除前缀 strip-prefix: true strip-prefix 为 true 时，访问时带上前缀，实际请求会将前缀去掉\n例如：访问 http://localhost:9999/api/eureka-consumer/consumer/zuul/fallback?millis=0\n实际：http://localhost:9090/eureka-consumer/consumer/zuul/fallback?millis=0\n敏感 Header 1 2 3 zuul: # 表示忽略下面的值向微服务传播。此时表示不会将请求头上的 token 传递给上游服务。如果为空，表示所有请求头都透传到上游服务 sensitive-headers: token Zuul 过滤器 [Zuul 的使用](#Zuul 的使用) 中主要都是其路由功能的使用\nZuul 的大部分功能都是通过过滤器实现的，其包含 4 种过滤器\nPRE：在请求被路由之前调用，可利用这种过滤器实现身份验证。选择微服务，记录日志。 ROUTING：在将请求路由到微服务调用，用于构建发送给微服务的请求，并用 http clinet（或者 ribbon）请求微服务。 POST：在调用微服务执行后。可用于添加 header，记录日志，将响应发给客户端。 ERROR：在上述每个阶段发生错误时，走此过滤器。 自定义过滤器 要自定义一个过滤器，只需要要继承 ZuulFilter，然后指定过滤类型、过滤顺序、是否执行这个过滤器、过滤逻辑就可以了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import com.netflix.zuul.ZuulFilter; import com.netflix.zuul.context.RequestContext; import org.springframework.cloud.netflix.zuul.filters.support.FilterConstants; import org.springframework.stereotype.Component; import javax.servlet.http.HttpServletRequest; @Component public class CustomPreFilter extends ZuulFilter { @Override public String filterType() { return FilterConstants.PRE_TYPE; } @Override public int filterOrder() { // 多个过滤器中的执行顺序，数值越小，优先级越高。 // 可以通过常量+/-1 来指定在其后/前 return FilterConstants.PRE_DECORATION_FILTER_ORDER + 1; } @Override public boolean shouldFilter() { // 该过滤器是否生效 return true; } @Override public Object run() { // 具体的执行逻辑 // 获取请求上下文 RequestContext currentContext = RequestContext.getCurrentContext(); HttpServletRequest request = currentContext.getRequest(); String requestURI = request.getRequestURI(); System.out.println(\"CustomPreFilter, requestURI: \" + requestURI); return null; } } 接口容错 在网关层即可进行 fallback\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 import com.netflix.hystrix.exception.HystrixTimeoutException; import org.springframework.cloud.netflix.zuul.filters.route.FallbackProvider; import org.springframework.http.HttpHeaders; import org.springframework.http.HttpStatus; import org.springframework.http.MediaType; import org.springframework.http.client.ClientHttpResponse; import org.springframework.stereotype.Component; import java.io.ByteArrayInputStream; import java.io.IOException; import java.io.InputStream; @Component public class CustomFallback implements FallbackProvider { /** * 表明为哪个微服务提供回退。 * 如果需要所有服务调用都支持回退，返回 null 或者 * 即可 * * @return 服务 id */ @Override public String getRoute() { // return \"eureka-consumer\"; return \"*\"; } @Override public ClientHttpResponse fallbackResponse(String route, Throwable cause) { if (cause instanceof HystrixTimeoutException) { return response(HttpStatus.GATEWAY_TIMEOUT); } else { return response(HttpStatus.INTERNAL_SERVER_ERROR); } } private ClientHttpResponse response(final HttpStatus status) { return new ClientHttpResponse() { @Override public HttpStatus getStatusCode() throws IOException { return status; } @Override public int getRawStatusCode() throws IOException { return status.value(); } @Override public String getStatusText() throws IOException { return status.getReasonPhrase(); } @Override public void close() { } @Override public InputStream getBody() throws IOException { String msg = \"{\\\"msg\\\":\\\"服务故障\\\"}\"; return new ByteArrayInputStream(msg.getBytes()); } @Override public HttpHeaders getHeaders() { HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); return headers; } }; } } 限流 Zuul 网关限流 令牌桶 假设进入高速公路的车辆需要在入口处领取到通行卡才能进入高速公路。为了节约人力成本，入口处放置自动出卡机。按照国家高速公路交通安全法的规定，在高速公路上行驶的车辆，车速超过 100km/h 时，应与同车道前车保持 100 米以上距离。为了保持最小安全行车距离 100 米，按车速 100km/h 计算，需要间隔至少 3.6 秒才能放行一辆车，因此出卡机每隔 3.6 秒出一张通行卡。在自动出卡机下放置一个盒子，自动出卡机按照 3.6 秒的间隔向盒子中投放通行卡。每辆进入高速公路的车辆，从盒子中领取通行卡之后才可以进入高速公路。\n令牌桶可以看作是一个存放一定数量令牌的容器。系统按设定的速度向桶中放置令牌。当桶中令牌满时，多出的令牌溢出，桶中令牌不再增加。在使用令牌桶对流量规格进行评估时，是以令牌桶中的令牌数量是否足够满足报文的转发为依据的。每个需要被转发的报文，都要从令牌桶中领取一定数量的令牌（具体数量视报文大小而定），才可以被正常转发。如果桶中存在足够的令牌可以用来转发报文，称流量遵守或符合约定值，否则称为不符合或超标。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 import com.google.common.util.concurrent.RateLimiter; import com.netflix.zuul.ZuulFilter; import com.netflix.zuul.context.RequestContext; import com.netflix.zuul.exception.ZuulException; import lombok.extern.slf4j.Slf4j; import org.springframework.cloud.netflix.zuul.filters.support.FilterConstants; import org.springframework.http.HttpStatus; import org.springframework.stereotype.Component; /** * 限流过滤器：令牌桶 * * @author wangshuo * @date 2021/03/10 */ @Component @Slf4j public class LimitFilter extends ZuulFilter { /** * google guava 提供的类 * create 的参数：2 表示每秒 2 个；0.1 表示每 10 秒 1 个 */ private static final RateLimiter RATE_LIMITER = RateLimiter.create(2); @Override public String filterType() { // 提前拒绝，所以放到 PRE 中 return FilterConstants.PRE_TYPE; } @Override public int filterOrder() { // 设置为最前面的过滤器 return Integer.MIN_VALUE; } @Override public boolean shouldFilter() { return true; } @Override public Object run() throws ZuulException { log.info(\"LimitFilter run......\"); RequestContext ctx = RequestContext.getCurrentContext(); // 可通过在 ctx 中设置值的方式，让后续过滤器不执行（提前退出） if (RATE_LIMITER.tryAcquire()) { ctx.set(\"limited\", false); } else { log.info(\"limited...\"); ctx.set(\"limited\", true); ctx.setSendZuulResponse(false); ctx.setResponseStatusCode(HttpStatus.TOO_MANY_REQUESTS.value()); // 可以通过自定义异常以及全局异常处理给客户端返回标准的 JSON 格式返回值 throw new RuntimeException(\"被限流啦\"); } return null; } } 微服务的限流 guava 依赖\n1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003ecom.google.guava\u003c/groupId\u003e \u003cartifactId\u003eguava\u003c/artifactId\u003e \u003c/dependency\u003e 自定义 Filter\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package org.example.apipassenger.filter; import com.google.common.util.concurrent.RateLimiter; import lombok.extern.slf4j.Slf4j; import org.springframework.stereotype.Component; import javax.servlet.*; import javax.servlet.http.HttpServletResponse; import java.io.IOException; import java.io.PrintWriter; /** * @author wangshuo * @date 2021/03/10 */ @Component @Slf4j public class LimitFilter implements Filter { private static final RateLimiter RATE_LIMITER = RateLimiter.create(2); @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { log.info(\"limit filter ......\"); if (RATE_LIMITER.tryAcquire()) { chain.doFilter(request, response); } else { HttpServletResponse resp = (HttpServletResponse) response; resp.setContentType(\"application/json\"); resp.setCharacterEncoding(\"UTF-8\"); PrintWriter pw = resp.getWriter(); pw.print(\"{\\\"code\\\":\\\"-1\\\", \\\"message\\\":\\\"限流啦\\\"}\"); pw.close(); } } } 高可用 一般做法是在 zuul 的前面加一层 nginx+keepalived\nZuul 的原理 Zuul 的本质就是 filter，通过 filter 解析来决定去访问哪个微服务。\n发请求访问微服务也是通过 filter 实现的。\n响应数据，也是通过 filter 实现\n请求过来 → PRE（一组，鉴权，限流之类的过滤器） → ROUTE（一组，路由到别的服务，具体微服务） → POST（一组，处理响应）\n源码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 /** * 实现了 HttpServlet */ public class ZuulServlet extends HttpServlet { /** * 重写了 service 方法，用自己的逻辑来处理请求 */ @Override public void service(javax.servlet.ServletRequest servletRequest, javax.servlet.ServletResponse servletResponse) throws ServletException, IOException { try { init((HttpServletRequest) servletRequest, (HttpServletResponse) servletResponse); // Marks this request as having passed through the \"Zuul engine\", as opposed to servlets // explicitly bound in web.xml, for which requests will not have the same data attached RequestContext context = RequestContext.getCurrentContext(); context.setZuulEngineRan(); // 第一种执行顺序：pre → error → post try { preRoute(); } catch (ZuulException e) { error(e); postRoute(); return; } // 第二种执行顺序：pre → route → error → post try { route(); } catch (ZuulException e) { error(e); postRoute(); return; } // 第三种执行顺序：pre → route → post → error try { postRoute(); } catch (ZuulException e) { error(e); return; } } catch (Throwable e) { error(new ZuulException(e, 500, \"UNHANDLED_EXCEPTION_\" + e.getClass().getName())); } finally { RequestContext.getCurrentContext().unset(); } } } 其实共有四种执行顺序\npre → error → post pre → route → error → post pre → route → post → error pre → route → post ","description":"","tags":["MSB","Spring Cloud","Zuul","Java"],"title":"Zuul","uri":"/posts/msb/spring-cloud/zuul/"},{"categories":null,"content":"Hystrix 相关概念 熔断 微服务相互调用时，如果某个服务依赖的服务失效（网络延时，服务异常，负载过大服务响应等问题），就会造成微服务级联异常。所以要隔离坏的服务，不让坏服务拖垮其他服务。\n简而言之就是 consumer 对某个 provider 服务重复调用几次都失败之后，就不再调用该服务了，下次再调用该 provider 的时候，consumer 就不再向该 provider 发送请求，直接通过降级等机制给客户返回结果。\n舱壁模式 舱壁模式（Bulkhead）隔离每个工作负载或服务的关键资源，如连接池，内存和 CPU，硬盘。每个工作单元都有独立的连接池，内存，CPU。\n使用舱壁避免了单个服务消耗掉所有资源，从而导致其他服务出现故障的场景。 这种模式主要是通过防止由一个服务引起的级联故障来增加系统的弹性。\n思路：可以对每个请求设置单独的连接池，配置线程数，超过线程数的根据拒绝策略进行处理，可以保证某个接口瘫痪后，不会影响别的接口\n雪崩效应 每个服务发出一个 HTTP 请求都会在服务中开启一个新线程。而下游服务挂了或者网络不可达，通常线程会阻塞住，直到 Timeout。如果并发量多一点，这些阻塞的线程就会占用大量的资源，很有可能把自己本身这个微服务所在的机器资源耗尽，导致自己也挂掉。\n如果服务提供者响应非常缓慢，那么服务消费者调用此提供者就会一直等待，直到提供者响应或超时。在高并发场景下，此种情况，如果不做任何处理，就会导致服务消费者的资源耗竭甚至整个系统的崩溃。一层一层的崩溃，导致所有的系统崩溃。\n雪崩：由基础服务故障导致级联故障的现象。\n描述的是：提供者不可用导致消费者不可用，并将不可用逐渐放大的过程。像滚雪球一样，不可用的服务越来越多。影响越来越恶劣。\n雪崩的三个流程\n服务提供者不可用 重试会导致网络流量加大，更影响服务提供者 导致服务消费者不可用。服务消费者一直等待返回，一直占用系统资源。（不可用的范围被逐渐放大） 服务不可用的原因\n服务器宕机 网络故障 程序异常 负载过大，导致服务提供者响应慢 缓存击穿导致服务超负荷运行 容错机制 为网络请求设置超时。\n必须为网络请求设置超时。一般的调用一般在几十毫秒内响应。如果服务不可用，或者网络有问题，那么响应时间会变很长。长到几十秒。\n每一次调用，对应一个线程或进程，如果响应时间长，那么线程就长时间得不到释放，而线程对应着系统资源，包括 CPU，内存，得不到释放的线程越多，资源被消耗的越多，最终导致系统崩溃。\n因此必须设置超时时间，让资源尽快释放。\n使用断路器模式。\n想一下家里的保险丝，跳闸。如果家里有短路或者大功率电器使用，超过电路负载时，就会跳闸，如果不跳闸，电路烧毁，波及到其他家庭，导致其他家庭也不可用。通过跳闸保护电路安全，当短路问题，或者大功率问题被解决，在合闸。\n自己家里电路，不影响整个小区每家每户的电路。\n断路器 如果对某个微服务请求有大量超时（说明该服务不可用），再让新的请求访问该服务就没有意义，只会无谓的消耗资源。例如设置了超时时间 1s，如果短时间内有大量的请求无法在 1s 内响应，就没有必要去请求依赖的服务了。\n断路器是对容易导致错误的操作的代理。这种代理能统计一段时间内的失败次数，并依据次数决定是正常请求依赖的服务还是直接返回。\n断路器可以实现快速失败，如果它在一段时间内检测到许多类似的错误（超时），就会在之后的一段时间，强迫对该服务的调用快速失败，即不再请求所调用的服务。这样对于消费者就无须再浪费 CPU 去等待长时间的超时。\n断路器也可自动诊断依赖的服务是否恢复正常。如果发现依赖的服务已经恢复正常，那么就会恢复请求该服务。通过重置时间来决定断路器的重新闭合。\n这样就实现了微服务的“自我修复”：当依赖的服务不可用时，打开断路器，让服务快速失败，从而防止雪崩。当依赖的服务恢复正常时，又恢复请求。\n断路器状态转换的逻辑\n关闭状态：正常情况下，断路器关闭，可以正常请求依赖的服务。\n打开状态：当一段时间内，请求失败率达到一定阈值，断路器就会打开。服务请求不会去请求依赖的服务。调用方直接返回。不发生真正的调用。重置时间过后，进入半开模式。\n半开状态：断路器打开一段时间后，会自动进入“半开模式”，此时，断路器允许一个服务请求访问依赖的服务。如果此请求成功（或者成功达到一定比例），则关闭断路器，恢复正常访问。否则，则继续保持打开状态。\n断路器的打开，能保证服务调用者在调用异常服务时，快速返回结果，避免大量的同步等待，减少服务调用者的资源消耗。并且断路器能在打开一段时间后继续侦测请求执行结果，判断断路器是否能关闭，恢复服务的正常调用。\n降级 在整体资源不够的时候，适当放弃部分服务，把主要的资源投放到核心服务中，待渡过难关后，再重启已关闭的服务，保证了系统核心服务的稳定。\n当服务停掉后，自动进入 fallback 替换主方法。用 fallback 方法代替主方法执行并返回结果，对失败的服务进行降级。当调用服务失败次数在一段时间内超过了断路器的阈值时，断路器将打开，不再进行真正的调用，而是快速失败，直接执行 fallback 逻辑。服务降级保护了服务调用者的逻辑。\n熔断和降级对比 共同点：\n为了防止系统崩溃，保证主要功能的可用性和可靠性。 用户体验到某些功能不能用。 不同点\n熔断由下级故障触发，主动惹祸。 降级由调用方从负荷角度触发，无辜被抛弃。 Hystrix 简介 Hystrix 是一个容错组件。实现了超时机制和断路器模式。用于隔离远程系统，服务或者第三方库，防止级联失败，从而提升系统的可用性与容错性。\n虽然 Ribbon 也有超时和重试机制，但是其该机制并不全面。\nHystrix 的主要功能\n为系统提供保护机制。在依赖的服务出现高延迟或失败时，为系统提供保护和控制。 防止雪崩。 包裹请求：使用 HystrixCommand（或 HystrixObservableCommand）包裹对依赖的调用逻辑，每个命令在独立线程中运行。 跳闸机制：当某服务失败率达到一定的阈值时，Hystrix 可以自动跳闸，停止请求该服务一段时间。 资源隔离：Hystrix 为每个请求都的依赖都维护了一个小型线程池，如果该线程池已满，发往该依赖的请求就被立即拒绝，而不是排队等候，从而加速失败判定。防止级联失败。 快速失败：Fail Fast。同时能快速恢复。侧重点是：不去真正的请求服务，而是直接失败。 监控：Hystrix 可以实时监控运行指标和配置的变化，提供近实时的监控、报警、运维控制。 回退机制：fallback，当请求失败、超时、被拒绝，或当断路器被打开时，执行回退逻辑。回退逻辑我们自定义，提供优雅的服务降级。 自我修复：断路器打开一段时间后，会自动进入“半开”状态，可以进行打开，关闭，半开状态的转换。前面有介绍。 Hystrix 独立使用 引入依赖\n1 2 3 4 5 \u003c!-- hystrix starter --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-netflix-hystrix\u003c/artifactId\u003e \u003c/dependency\u003e 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 import com.netflix.hystrix.HystrixCommand; import com.netflix.hystrix.HystrixCommandGroupKey; import java.util.concurrent.ExecutionException; import java.util.concurrent.Future; /** * Hystrix 独立使用，脱离 SpringCloud * \u003cp\u003e * 先执行 run 方法中的业务逻辑，如果业务逻辑出现异常，就会执行 getFallback 方法。 * * @author wangshuo * @date 2021/01/12 */ public class AloneHystrixTest extends HystrixCommand\u003cString\u003e { protected AloneHystrixTest(HystrixCommandGroupKey group) { super(group); } @Override protected String run() { System.out.println(\"执行逻辑\"); int i = 1 / 0; return \"run success\"; } @Override protected String getFallback() { return \"getFallback\"; } public static void main(String[] args) { // AloneHystrixTest aloneHystrixTest = new AloneHystrixTest(HystrixCommandGroupKey.Factory.asKey(\"ext\")); /* * execute()：以同步阻塞方式执行 run()。以 demo 为例，调用 execute() 后， * hystrix 先创建一个新线程运行 run()， * 接着调用程序要在 execute() 调用处一直阻塞着，直到 run() 运行完成 */ // System.out.println(\"result:\" + aloneHystrixTest.execute()); /* * queue()：以异步非阻塞方式执行 run()。以 demo 为例， * 一调用 queue() 就直接返回一个 Future 对象， * 同时 hystrix 创建一个新线程运行 run()， * 调用程序通过 Future.get() 拿到 run() 的返回结果， * 而 Future.get() 是阻塞执行的 */ Future\u003cString\u003e futureResult = new AloneHystrixTest(HystrixCommandGroupKey.Factory.asKey(\"ext\")).queue(); String result = \"\"; try { result = futureResult.get(); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } System.out.println(\"程序结果：\" + result); } } Hystrix 结合 RestTemplate 引入依赖\n1 2 3 4 5 \u003c!-- 引入 hystrix 依赖 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-hystrix\u003c/artifactId\u003e \u003c/dependency\u003e 启动类上添加 @EnableCircuitBreaker 或 @EnableHystrix 注解\n调用的方法上使用 @HystrixCommand 将方法纳入到 hystrix 监控中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package com.example.eurekaconsumer.service; import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import org.springframework.web.client.RestTemplate; /** * @author wangshuo * @date 2021/01/12 */ @Service public class RestTemplateService { @Autowired private RestTemplate restTemplate; /** * HystrixCommand 注解的 fallbackMethod 属性优先级高于 defaultFallback 属性 * fallbackMethod 指定方法的形参和返回值必须与原方法一致 * defaultFallback 指定方法不能包含行参，并且返回值必须与原方法一致 */ @HystrixCommand(fallbackMethod = \"fallback\") public String hystrixFallback(Integer millis) { String url = \"http://eureka-provider/provider/restTemplate/hystrix-fallback?millis={1}\"; return restTemplate.getForObject(url, String.class, millis); } /** * 可在形参出添加 Throwable 对象，用于接收 consumer/provider 抛出的异常，根据不同的异常类型，进行相应的降级处理 */ public String fallback(Integer millis, Throwable throwable) { return \"降级了……\"; } } 如果没有 @HystrixCommand 注解，添加如下依赖\n1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003ecom.netflix.hystrix\u003c/groupId\u003e \u003cartifactId\u003ehystrix-javanica\u003c/artifactId\u003e \u003c/dependency\u003e Hystrix 结合 Feign 方法级 添加依赖\n1 2 3 4 5 \u003c!-- 引入 hystrix 依赖 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-hystrix\u003c/artifactId\u003e \u003c/dependency\u003e Feign 自带 Hystrix，但是默认是关闭的。先打开 Hystrix\n1 2 3 feign: hystrix: enabled: true 新建一个类实现 UserService 接口，重写所有方法。当 Feign 调用这些方法出现异常后，就会执行该实现类的方法中的业务逻辑。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import com.example.eurekaconsumer.service.UserService; import org.springframework.stereotype.Component; import java.util.Map; /** * @author wangshuo * @date 2021/01/12 */ @Component public class UserServiceFallback implements UserService { @Override public String readTimeout(Integer seconds) { return \"降级了……\"; } // 省略其他方法…… } 在 @FeignClient 注解中使用 fallback 属性，指定该类\n1 @FeignClient(name = \"eureka-provider\", fallback = UserServiceFallback.class) 此时请求 readTimeout 接口，如果发生异常就会执行 UserServiceFallback 的 readTimeout 方法中的降级逻辑\n异常级 添加依赖\n打开 Hystrix\n新建一个实现 FallbackFactory 接口的类，泛型中填写标记 @FeignClient 注解的类，此处是 UserService\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package com.example.eurekaconsumer.fallback; import com.example.eurekaconsumer.service.UserService; import com.example.userapi.entity.Person; import feign.hystrix.FallbackFactory; import org.springframework.stereotype.Component; import java.util.Map; /** * @author wangshuo * @date 2021/01/12 */ @Component public class UserServiceFallbackFactory implements FallbackFactory\u003cUserService\u003e { /** * 重写 create 方法，在方法中新建对应接口的对象，并在实现方法中编写降级逻辑。 * 通过 throwable 对象可以获取到服务抛出的异常信息 * * @param throwable 该对象既可以捕捉 Consumer 抛出的异常，也可以捕捉 Provider 端抛出的异常 * @return */ @Override public UserService create(Throwable throwable) { return new UserService() { @Override public String readTimeout(Integer seconds) { // 可以根据不同的异常类型进行不同的降级处理 throwable.printStackTrace(); return \"降级了...\"; } // 省略...... }; } } 信号量隔离和线程池隔离 默认情况下 hystrix 使用线程池控制请求隔离\n线程池隔离 线程池隔离技术使用 Hystrix 自己的线程去执行调用。\n用户发送请求到 consumer 端，在 consumer 端使用一个 map（key 为服务 uri，val 是线程池）通过线程池的大小来限定单一 uri 的请求数量，并根据拒绝策略对超出的线程进行处理（排队，丢弃等），从而对 consumer 端不同的接口进行隔离，不会因为某个接口被大量请求而影响到其他接口的响应。\n该方式需要对每个 uri 初始化并维护一个线程池，向 provider 发送请求使用的是 hystrix 维护的线程池中的线程。\n信号量隔离 信号量隔离技术是直接用 tomcat 的线程去调用服务。\nHystrix 会维护一个 Semaphore（就是一个计数器），用户每向 consumer 发送一个请求，Semaphore 就减一，当其为 0 时，就不处理用户的请求了，向 provider 发送请求的时候，使用的就是 tomcat 的 worker 线程。所以此种方式 hystrix 并没有为每个 uri 都单独创建并维护线程池。\n线程池和信号量对比 信号量隔离不需要单独创建和维护线程池 线程池方式根据 uri 进行分组，可以根据不同的业务场景设置不同的拒绝策略 线程池方式，如果某个服务的线程池异常了，不会影响到其他服务 线程池方式可以把 tomcat 的 worker 线程和 hystrix 的线程池的线程做成异步（Servlet3.1）的，使得 tomcat 的 worker 线程可以快速被释放，执行其他的业务 代码健壮，不会出任何问题，业务执行计算速度很快的时候可以使用信号量。否则会一直占用 tomcat 的 worker 线程。\n配置信号量隔离 1 2 3 4 5 6 hystrix: command: default: execution: isolation: strategy: 'SEMAPHORE' Hystrix 的 Dashboard 添加 dashboard 依赖\n1 2 3 4 5 \u003c!-- hystrix dashboard starter --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-hystrix-dashboard\u003c/artifactId\u003e \u003c/dependency\u003e 在启动类上添加 @EnableHystrixDashboard 注解\n添加 actuator 依赖\n1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-actuator\u003c/artifactId\u003e \u003c/dependency\u003e 开放所有监控端点\n1 2 3 4 5 management: endpoints: web: exposure: include: '*' 访问 /actuator/hystrix.stream，然后调用被 hystrix 管理的接口，可以看到输出的监控信息\n访问 /hystrix，填入 http://hostname:port/actuator/hystrix.stream，即可访问图形化的监控页面\n修改 hystrix 使用信号量隔离后，可以看到 dashboard 上不显示线程池信息了\nHystrix 的配置 都在 HystrixCommandProperties 类中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 ## Execution 相关的属性的配置 ## # 隔离策略，默认是 Thread，可选 Thread｜Semaphore # thread 通过线程数量来限制并发请求数，可以提供额外的保护，但有一定的延迟。一般用于网络调用 # semaphore 通过 semaphore count 来限制并发请求数，适用于无网络的高并发请求 hystrix.command.default.execution.isolation.strategy # 命令执行超时时间，默认 1000ms hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds # 执行是否启用超时，默认启用 true hystrix.command.default.execution.timeout.enabled # 发生超时是是否中断，默认 true hystrix.command.default.execution.isolation.thread.interruptOnTimeout # 最大并发请求数，默认 10，该参数当使用 ExecutionIsolationStrategy.SEMAPHORE 策略时才有效。如果达到最大并发请求数，请求会被拒绝。理论上选择 semaphore size 的原则和选择 thread size 一致，但选用 semaphore 时每次执行的单元要比较小且执行速度快（ms 级别），否则的话应该用 thread。 # semaphore 应该占整个容器（tomcat）的线程池的一小部分。 hystrix.command.default.execution.isolation.semaphore.maxConcurrentRequests ## Fallback 相关的属性 ## # 这些参数可以应用于 Hystrix 的 THREAD 和 SEMAPHORE 策略 # 如果并发数达到该设置值，请求会被拒绝和抛出异常并且 fallback 不会被调用。默认 10 hystrix.command.default.fallback.isolation.semaphore.maxConcurrentRequests # 当执行失败或者请求被拒绝，是否会尝试调用 hystrixCommand.getFallback()。默认 true hystrix.command.default.fallback.enabled ## Circuit Breaker 相关的属性 ## # 用来跟踪 circuit 的健康性，如果未达标则让 request 短路。默认 true hystrix.command.default.circuitBreaker.enabled # 一个 rolling window 内最小的请求数。如果设为 20，那么当一个 rolling window 的时间内（比如说 1 个 rolling window 是 10 秒）收到 19 个请求，即使 19 个请求都失败，也不会触发 circuit break。默认 20 hystrix.command.default.circuitBreaker.requestVolumeThreshold # 触发短路的时间值，当该值设为 5000 时，则当触发 circuit break 后的 5000 毫秒内都会拒绝 request，也就是 5000 毫秒后才会关闭 circuit。默认 5000 hystrix.command.default.circuitBreaker.sleepWindowInMilliseconds # 错误比率阀值，如果错误率\u003e=该值，circuit 会被打开，并短路所有请求触发 fallback。默认 50，即为 50%。 hystrix.command.default.circuitBreaker.errorThresholdPercentage # 强制打开熔断器，如果打开这个开关，那么拒绝所有 request，默认 false hystrix.command.default.circuitBreaker.forceOpen # 强制关闭熔断器 如果这个开关打开，circuit 将一直关闭且忽略 circuitBreaker.errorThresholdPercentage hystrix.command.default.circuitBreaker.forceClosed ## Metrics 相关参数 ## # 设置统计的时间窗口值的，毫秒值，circuit break 的打开会根据 1 个 rolling window 的统计来计算。若 rolling window 被设为 10000 毫秒，则 rolling window 会被分成 n 个 buckets，每个 bucket 包含 success，failure，timeout，rejection 的次数的统计信息。默认 10000 hystrix.command.default.metrics.rollingStats.timeInMilliseconds # 设置一个 rolling window 被划分的数量，若 numBuckets＝10，rolling window＝10000，那么一个 bucket 的时间即 1 秒。必须符合 rolling window % numberBuckets == 0。默认 10 hystrix.command.default.metrics.rollingStats.numBuckets # 执行时是否 enable 指标的计算和跟踪，默认 true hystrix.command.default.metrics.rollingPercentile.enabled # 设置 rolling percentile window 的时间，默认 60000 hystrix.command.default.metrics.rollingPercentile.timeInMilliseconds # 设置 rolling percentile window 的 numberBuckets。逻辑同上。默认 6 hystrix.command.default.metrics.rollingPercentile.numBuckets # 如果 bucket size＝100，window＝10s，若这 10s 里有 500 次执行，只有最后 100 次执行会被统计到 bucket 里去。增加该值会增加内存开销以及排序的开销。默认 100 hystrix.command.default.metrics.rollingPercentile.bucketSize # 记录 health 快照（用来统计成功和错误绿）的间隔，默认 500ms hystrix.command.default.metrics.healthSnapshot.intervalInMilliseconds ","description":"","tags":["MSB","Spring Cloud","Hystrix","Java"],"title":"Hystrix","uri":"/posts/msb/spring-cloud/hystrix/"},{"categories":null,"content":"Feign Feign 简介 OpenFeign 是 Netflix 开发的声明式、模板化的 HTTP 请求客户端。可以更加便捷、优雅地调用 http api。\nOpenFeign 会根据带有注解的函数信息构建出网络请求的模板，在发送网络请求之前，OpenFeign 会将函数的参数值设置到这些请求模板中。\nfeign 主要是构建微服务消费端。只要使用 OpenFeign 提供的注解修饰定义网络请求的接口类，就可以使用该接口的实例发送 RESTful 的网络请求。还可以集成 Ribbon 和 Hystrix，提供负载均衡和断路器。\n英文表意为“假装，伪装，变形”，是一个 Http 请求调用的轻量级框架，可以以 Java 接口注解的方式调用 Http 请求，而不用像 Java 中通过封装 HTTP 请求报文的方式直接调用。通过处理注解，将请求模板化，当实际调用的时候，传入参数，根据参数再应用到请求上，进而转化成真正的请求，这种请求相对而言比较直观。Feign 封装 了 HTTP 调用流程，面向接口编程，回想第一节课的 SOP。\nFeign 和 OpenFeign 关系 Feign Feign 是 Spring Cloud 组件中的一个轻量级 RESTful 的 HTTP 服务客户端，Feign 内置了 Ribbon 用来做客户端负载均衡。Feign 的使用方式是：使用 Feign 的注解定义接口，调用这个接口，就可以调用服务注册中心的服务\n1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-feign\u003c/artifactId\u003e \u003c/dependency\u003e OpenFeign OpenFeign 是 Spring Cloud 在 Feign 的基础上支持了 SpringMVC 的注解，如 @RequestMapping 等。OpenFeign 的 @FeignClient 可以解析 SpringMVC 的 @RequestMapping 注解下的接口，并通过动态代理的方式产生实现类，实现类中做负载均衡并调用其他服务\n1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-openfeign\u003c/artifactId\u003e \u003c/dependency\u003e OpenFeign 和 RestTemplate 区别 RestTemplate 需要在编码的时候写死发送请求的 url，同时可以手动对请求头等信息进行修改。更自由，贴近 HttpClient，方便调用其他的第三方 http 服务。\nOpenFeign 使用注解 + 接口的方式发送请求，自动创建发送请求的代码，不需要手动编写，因此也就不能手动对请求进行相关的修改。更面向对象一些，更优雅\nOpenFeign 的使用 引入依赖 1 2 3 4 5 \u003c!-- openfeign starter --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-openfeign\u003c/artifactId\u003e \u003c/dependency\u003e 在启动类上启动 OpenFeign 1 @EnableFeignClients 创建一个接口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import org.springframework.cloud.openfeign.FeignClient; import org.springframework.stereotype.Component; import org.springframework.web.bind.annotation.GetMapping; /** * 单独使用 OpenFeign 时，在 FeignClient 注解的 url 中指定生产者的 url 前缀，name 自定义即可 * \u003cp\u003e * 结合 Eureka 使用 OpenFeign 时，在 FeignClient 中只需要指定 name 为服务生产者的服务名即可。 * \u003cp\u003e * 不需要写发送请求时的具体实现代码，当调用该接口的方法时，通过反射即可自动生成子类实现 * * @author wangshuo * @date 2021/01/09 */ @Component // @FeignClient(name = \"xxoo\", url = \"http://localhost:8080\") @FeignClient(name = \"eureka-provider\") public interface UserService { /** * 此处使用 RequestMapping 系列注解指定生产者的 EndPoint 即可， * OpenFeign 会向 FeignClient 中 url 和该 EndPoint 拼接后的 url 发送请求 * * @return 响应结果 */ @GetMapping(\"/getHi\") String getHi(); } 在 Controller 中直接调用上方接口的方法即可 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import com.example.eurekaconsumer.service.UserService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController @RequestMapping(\"/consumer/open-feign\") public class ConsumerOpenFeignController { @Autowired private UserService userService; @GetMapping(\"/hi\") public String getHi() { // 调用接口的方法即可发送请求 return userService.getHi(); } } Feign 默认集成了 Ribbon，所以会自动进行负载均衡\n原理简介 主程序入口添加 @EnableFeignClients 注解开启对 Feign Client 扫描加载处理。根据 Feign Client 的开发规范，定义接口并加@FeignClient注解。 当程序启动时，会进行包扫描，扫描所有 @FeignClient 注解的类，并将这些信息注入 Spring IoC 容器中。当定义的 Feign 接口中的方法被调用时，通过 JDK 的代理方式，来生成具体的 RequestTemplate。当生成代理时，Feign 会为每个接口方法创建一个 RequestTemplate 对象，该对象封装了 HTTP 请求需要的全部信息，如请求参数名、请求方法等信息都在这个过程中确定。 然后由 RequestTemplate 生成 Request，然后把这个 Request 交给 client 处理，这里指的 Client 可以是 JDK 原生的 URLConnection、Apache 的 Http Client ，也可以是 Okhttp。最后 Client 被封装到 LoadBalanceClient 类，这个类结合 Ribbon 负载均衡发起服务之间的调用。 优化硬编码问题 UserService 中的方法需要根据服务提供者提供的 API 文档写，是硬编码的，如何优化？\n如果服务提供者提供的接口，需要被其他语言进行调用，那么提供 API 文档是非常有必要的。\n如果提供的接口只需要被 Java 使用，那么就可以抽象出一个单独的工程，专门记录其提供的 api 接口信息，在消费方和提供方只需要引入该工程的 jar，既可以解决双方的硬编码问题，又可以规范双方的代码编写。\n新建 user-api 工程，包含 Spring Web 依赖即可\n1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e 新建一个接口类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package com.example.userapi.api; import org.springframework.web.bind.annotation.GetMapping; /** * @author wangshuo * @date 2021/01/09 */ public interface UserApi { /** * 调用服务提供者的接口 * * @return 响应结果 */ @GetMapping(\"/getHi\") String getHi(); } 将该 user-api 工程打包，并在 consumer 和 provider 中引用它\n1 2 3 4 5 6 \u003c!-- 引入自定义 API --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.example\u003c/groupId\u003e \u003cartifactId\u003euser-api\u003c/artifactId\u003e \u003cversion\u003e0.0.1-SNAPSHOT\u003c/version\u003e \u003c/dependency\u003e consumer 中的 Service 继承该接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package com.example.eurekaconsumer.service; import com.example.userapi.api.UserApi; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.stereotype.Component; /** * 继承抽象出来的 UserApi 接口即可 * * @author wangshuo * @date 2021/01/09 */ @Component @FeignClient(name = \"eureka-provider\") public interface UserService extends UserApi { } provider 中的 Controller 实现该接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package com.example.eurekaprovider.controller; import com.example.eurekaprovider.HealthStatusService; import com.example.userapi.api.UserApi; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RestController; /** * @author wangshuo * @date 2021/01/05 */ @RestController public class ProviderController implements UserApi { @Value(\"${server.port}\") private String port; @Override public String getHi() { return \"Hi! 我的 port 是 : \" + port; } } 通过该种方式将 provider 的 EndPoint 提取了出来，在 provider 工程中不需要硬编码写死 RequestMapping 中的 url。\n该方法还体现了面向接口编程的思想，在修改 user-api 后，会强制 consumer 和 provider 进行修改/重写，并包含提示信息。\n仅是 Java 工程进行调用时，只需要把依赖引入即可，不需要提供 API 文档。当需要其他语言进行调用的时候，可以再使用 swagger 等工具生成 API 文档，这两种方式并不冲突。\n**缺点：**Consumer 和 Provider 的耦合性提高了\nOpenFeign 多参数请求 在标记 @FeignClient 的接口方法中必须添加 @RequestParam 注解，否则 OpenFeign 不能正确解析参数\nGET 请求 普通参数 1 2 3 4 5 6 @Component @FeignClient(name = \"eureka-provider\") public interface UserService { @GetMapping(\"/string\") String getWithParam(@RequestParam(\"id\") String id); } Map 接收 1 2 3 4 5 6 @Component @FeignClient(name = \"eureka-provider\") public interface UserService { @GetMapping(\"/map\") Map\u003cString, Object\u003e getWithMapParam(@RequestParam Map\u003cString, Object\u003e map); } POST 请求 普通参数 1 2 3 4 5 6 @Component @FeignClient(name = \"eureka-provider\") public interface UserService { @PostMapping(\"/string\") String postWithParam(@RequestParam(\"id\") String id); } Map 接收 可以用 RequestParam 从 URL 中传参，也可以使用 RequestBody 中 Body 中传参\n1 2 3 4 5 6 @Component @FeignClient(name = \"eureka-provider\") public interface UserService { @PostMapping(\"/url-map\") Map\u003cString, Object\u003e postWithMapParam(@RequestBody Map\u003cString, Object\u003e map); } 或\n1 2 3 4 5 6 @Component @FeignClient(name = \"eureka-provider\") public interface UserService { @PostMapping(\"/body-map\") Map\u003cString, Object\u003e postWithMapParam(@RequestParam Map\u003cString, Object\u003e map); } 对象传参 1 2 3 4 5 6 @Component @FeignClient(name = \"eureka-provider\") public interface UserService { @PostMapping(\"/obj\") Person postWithObj(@RequestBody Person person); } @ReuqestParam 和 @RequestBody 在 Consumer 和 Provider 中单纯的按照 SpringMVC 的使用方式（在部分场景下可以省略），在标有 @FeignClient 的接口中，是给 FeignClient 用的，所以一定要按照 OpenFeign 的规则标记完整。\n自定义 Feign 配置 Feign 默认的配置类是 org.springframework.cloud.openfeign.FeignClientsConfiguration，定义了 Feign 默认的编码器，解码器等。\n可以使用 @FeignClient 的 configuration 属性自定义 Feign 配置。自定义的配置优先级高于默认的 FeignClientsConfiguration\n1 2 3 4 5 6 7 8 /** * 此处如果使用 @Configuration 被扫描到容器中，就会对所有的 FeignClient 生效 * 不使用 @Configuration，通过 FeignClient 注解的 configuration 属性单独指定，则仅对指定的 FeignClient 生效 */ // @Configuration public class FeignConfig { // 自定义的 Feign 配置 } Feign 压缩 开启压缩可以有效节约网络资源，但是会增加 CPU 压力，建议把最小压缩的文档大小适度调大一点，进行 gzip 压缩。一般不需要设置压缩，如果系统流量浪费比较多，可以考虑一下。\n1 2 3 4 5 6 feign: compression: request: enabled: true response: enabled: true 选择性的对指定类型进行压缩\n1 2 3 4 5 6 7 feign: compression: request: enabled: true mime-types: - text/xml min-request-size: 2048 Feign 日志 1 2 3 4 5 feign: client: config: service-valuation: logger-level: basic logger-level 有 4 种选项：\nnone：不记录任何日志，默认值 basic：仅记录请求方法，url，响应状态码，执行时间。 headers：在 basic 基础上，记录 header 信息 full：记录请求和响应的 header，body，元数据。 1 2 3 4 logging: level: # 指定某个类的日志级别。该初指定为 debug 后，上方 feign 的 logger-level 就只会对该类 debug 级别的日志做出响应 package.Class: debug Feign 超时和重试机制 Feign 默认支持 Ribbon，Ribbon 的重试机制和 Feign 的重试机制有冲突，所以源码中默认关闭 Feign 的重试机制，使用 Ribbon 的重试机制\n超时机制\n1 2 3 4 5 ribbon: # 连接超时时间（ms） ConnectTimeout: 1000 # 业务逻辑超时时间（ms） ReadTimeout: 2000 超时重试机制\n当服务请求超时后，Ribbon 会根据其重试机制进行重试调用。默认情况下，如果只有一个 provider 的实例，其会重试调用该 provider 一次；如果有多个 provider 的实例，会先重试调用该 provider 一次，如果还超时，就会调用 provider 的 1 个负载均衡实例一次，如果还超时，就会返回超时异常。\n1 2 3 4 5 6 7 ribbon: # 同一台实例最大重试次数，不包括首次调用 MaxAutoRetries: 1 # 重试负载均衡其他的实例最大重试次数，不包括首次调用 MaxAutoRetriesNextServer: 1 # 是否所有操作都重试，所有操作指 GET 和 POST 请求，建议配置为 false，仅对 GET 请求进行重试，因为 POST 是更新操作，重试可能会出问题 OkToRetryOnAllOperations: false 如果某次请求调用时，某个实例调用失败了，那么在 6 秒内如果又接收到了该请求，就不会去调用之前调用失败的实例了。6 秒后会恢复对该实例的调用\n","description":"","tags":["MSB","Feign","Java"],"title":"Feign","uri":"/posts/msb/spring-cloud/feign/"},{"categories":null,"content":"Ribbon 和 RestTemplate 服务间调用 微服务中，很多服务系统都在独立的进程中运行，通过各个服务系统之间的协作来实现一个大项目的所有业务功能。服务系统间 使用多种跨进程的方式进行通信协作，而基于 HTTP 的 RESTful 风格的网络请求是最为常见的交互方式之一。\n**思考：**如果让我们写服务调用如何写。\n硬编码。不好。ip 域名写在代码中。目的：找到服务。\n根据服务名，找相应的 ip。目的：这样 ip 切换或者随便变化，对调用方没有影响。\nMap\u003c服务名，服务列表\u003e map;\n加上负载均衡。目的：高可用。\nspring cloud 提供的方式：\nRestTemplate Feign 我个人习惯用 RestTemplate，因为自由，方便调用别的第三方的 http 服务。Feign 也可以，更面向对象一些，更优雅一些，就是需要配置。\n负载均衡 当系统面临大量用户访问，负载过高的时候，通常会增加服务器数量来进行横向扩展（集群），多个服务器的负载需要均衡，以免出现服务器负载不均衡，部分服务器负载较大，部分服务器负载较小的情况。使用负载均衡，使得集群中服务器的负载保持在稳定高效的状态，从而提高整个系统的处理能力。\n按软硬件分 软件负载均衡 nginx，lvs 等\n常见负载均衡策略\n第一层可以使用 DNS，配置多个 A 记录，让 DNS 做第一层分发。\n第二层比较流行的是反向代理。核心原理：代理根据一定规则，将 http 请求转发到服务器集群的单一服务器上。\n硬件负载均衡 F5\n按客户端/服务端分 客户端负载均衡和服务端负载均衡最大的区别在于 服务端地址列表的存储位置，以及负载算法在哪里。\n客户端的负载均衡 在客户端负载均衡中，所有的客户端节点都有一份自己要访问的服务端地址列表，这些列表统统都是从注册中心获取的。ribbon 就是客户端负载均衡。\n服务端的负载均衡 在服务端负载均衡中，客户端节点只知道单一服务代理的地址，服务代理则知道所有服务端的地址。nginx 就是服务端负载均衡。\nRibbon Ribbon 是 Netflix 开发的客户端负载均衡器，为 Ribbon 配置服务提供者地址列表后，Ribbon 就可以基于某种负载均衡策略算法，自动地帮助服务消费者去请求提供者。Ribbon 默认为我们提供了很多负载均衡算法，例如轮询，随机等。我们也可以实现自定义负载均衡算法。\n手写负载均衡 知道自己的请求目的地（虚拟主机名，默认是 spring.application.name） 获取所有服务端地址列表（也就是注册表） 选出一个地址，找到虚拟主机名对应的 ip，port（将虚拟主机名 对应到 ip 和 port 上） 发起实际请求（最朴素的请求） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @RestController public class ConsumerController { @Autowired DiscoveryClient discoveryClient; @GetMapping(\"/client5\") public Object client5() { // 1. 根据虚拟主机名获取所有 app Application app = eurekaClient.getApplication(\"eureka-provider\"); // 2. 获取 app 下的所有实例 List\u003cInstanceInfo\u003e instances = app.getInstances(); if (instances.size() \u003e 0) { // 3. 随机选择一个实例 InstanceInfo instance = instances.get((int) (Math.random() * instances.size())); InstanceInfo.InstanceStatus status = instance.getStatus(); if (status.equals(InstanceInfo.InstanceStatus.UP)) { String url = \"http://\" + instance.getIPAddr() + \":\" + instance.getPort() + \"/getHi\"; // 4. 发起请求 return new RestTemplate().getForObject(url, String.class); } } return null; } } Ribbon 的组成 官网首页：https://github.com/Netflix/ribbon\nribbon-core：核心的通用性代码。api 一些配置。\nribbon-eureka：基于 eureka 封装的模块，能快速集成 eureka。\nribbon-examples：学习示例。\nribbon-httpclient：基于 apache httpClient 封装的 rest 客户端，集成了负载均衡模块，可以直接在项目中使用。\nribbon-loadbalancer：负载均衡模块。\nribbon-transport：基于 netty 实现多协议的支持。比如 http，tcp，udp 等。\nSpring Cloud 中 Ribbon 的使用 Ribbon 可以单独使用，作为一个独立的负载均衡组件。只是需要我们手动配置 服务地址列表。 Ribbon 与 Eureka 配合使用时，Ribbon 可自动从 Eureka Server 获取服务提供者地址列表（DiscoveryClient），并基于负载均衡算法，请求其中一个服务提供者实例。 Ribbon 与 OpenFeign 和 RestTemplate 进行无缝对接，让二者具有负载均衡的能力。OpenFeign 默认集成了 ribbon。 在 Spring Cloud 中如果需要使用客户端负载均衡，只需要使用@LoadBalanced注解即可，这样客户端在发起请求的时候会根据负载均衡策略从服务端列表中选择一个服务端，向该服务端发起网络请求，从而实现负载均衡。\n负载均衡算法 默认实现\nZoneAvoidanceRule（区域权衡策略）：复合判断 Server 所在区域的性能和 Server 的可用性，轮询选择服务器。 其他规则：\nBestAvailableRule（最低并发策略）：会先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，然后选择一个并发量最小的服务。逐个找服务，如果断路器打开，则忽略。\nRoundRobinRule（轮询策略）：以简单轮询选择一个服务器。按顺序循环选择一个 server。\nRandomRule（随机策略）：随机选择一个服务器。\nAvailabilityFilteringRule（可用过滤策略）：会先过滤掉多次访问故障而处于断路器跳闸状态的服务和过滤并发的连接数量超过阀值得服务，然后对剩余的服务列表安装轮询策略进行访问。\nWeightedResponseTimeRule（响应时间加权策略）：据平均响应时间计算所有的服务的权重，响应时间越快服务权重越大，容易被选中的概率就越高。刚启动时，如果统计信息不中，则使用 RoundRobinRule（轮询）策略，等统计的信息足够了会自动的切换到 WeightedResponseTimeRule。响应时间长，权重低，被选择的概率低。反之，同样道理。此策略综合了各种因素（网络，磁盘，IO 等），这些因素直接影响响应时间。\nRetryRule（重试策略）：先按照 RoundRobinRule（轮询）的策略获取服务，如果获取的服务失败则在指定的时间会进行重试，进行获取可用的服务。如多次获取某个服务失败，就不会再次获取该服务。主要是在一个时间段内，如果选择一个服务不成功，就继续找可用的服务，直到超时。\n切换负载均衡策略 注解方式 给所有服务指定 ribbon 策略 第一种方式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 /** * 添加该配置类，并让其被 SpringBoot 主程序扫描到容器中 */ @Configuration public class IRuleConfig { /** * 修改 Ribbon 的负载均衡策略 */ @Bean public IRule iRule() { return new RandomRule(); } } 第二种方式 1 2 3 4 5 6 7 8 9 10 11 12 13 /** * 不让其被主程序扫描到容器中 */ // @Configuration public class IRuleConfig { /** * 修改 Ribbon 的负载均衡策略 */ @Bean public IRule iRule() { return new RandomRule(); } } 1 2 3 4 5 6 7 8 9 10 @SpringBootApplication // 在主程序类中使用该注解引用上方的配置类，使其生效 @RibbonClients(defaultConfiguration = IRuleConfig.class) public class EurekaConsumerApplication { public static void main(String[] args) { SpringApplication.run(EurekaConsumerApplication.class, args); } } 针对服务指定 ribbon 策略 添加该配置类，但是不能让其被主程序扫描到 1 2 3 4 5 6 7 8 9 10 11 12 13 /** * 不让其被主程序扫描到容器中 */ // @Configuration public class IRuleConfig { /** * 修改 Ribbon 的负载均衡策略 */ @Bean public IRule iRule() { return new RandomRule(); } } 新建一个配置类 1 2 3 4 5 @Configuration // 针对特定服务指定配置类 @RibbonClient(name = \"eureka-provider\", configuration = IRuleConfig.class) public class RibbonConfig { } 配置文件方式 配置文件方式优先级高于注解方式\n针对服务指定 ribbon 策略 ${spring.application.name}：替换为某个指定服务的服务名称\n1 2 3 ${spring.application.name}: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 示例：\n1 2 3 4 # 为 eureka-provider 服务指定负载均衡策略 eureka-provider: ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 自定义负载均衡策略 继承 AbstractLoadBalanceRule 类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 package com.example.eurekaconsumer.config; import com.netflix.client.config.IClientConfig; import com.netflix.loadbalancer.AbstractLoadBalancerRule; import com.netflix.loadbalancer.ILoadBalancer; import com.netflix.loadbalancer.Server; import java.util.List; /** * 自定义 Ribbon 负载均衡策略，需要继承 AbstractLoadBalancerRule * * @author wangshuo * @date 2021/01/07 */ public class MyRule extends AbstractLoadBalancerRule { public Server choose(ILoadBalancer lb) { // 获取所有存活的服务 List\u003cServer\u003e reachableServers = lb.getReachableServers(); // 获取所有服务 List\u003cServer\u003e allServers = lb.getAllServers(); if (reachableServers.size() \u003e 0) { // 随机返回一个服务 return reachableServers.get((int) (Math.random() * reachableServers.size())); } return null; } @Override public Server choose(Object key) { // getLoadBalancer() 返回的 ILoadBalancer 包含 appName 为 key 的服务 return choose(getLoadBalancer()); } @Override public void initWithNiwsConfig(IClientConfig iClientConfig) { } } Ribbon 独立使用 Ribbon 可以和服务注册中心 Eureka 一起工作，从服务注册中心获取服务端的地址信息，也可以在配置文件中使用 listOfServers 字段来设置服务端地址。\n1. 去掉 eureka-client 的依赖，只需要依赖 ribbon\n1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-ribbon\u003c/artifactId\u003e \u003c/dependency\u003e 2. 配置文件\n1 2 3 4 5 6 7 8 9 10 # 被负载均衡的服务端服务名 ${srping.application.name}: ribbon: # 指定负载均衡策略，默认是轮询，此处配置为随机 NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule eureka: # 关闭从 Eureka 注册中心获取注册表 enabled: false # 手动设置需要负载均衡的服务端地址 listOfServers: localhost:8080,localhost:8081 Ribbon 的超时和重试 超时机制\n1 2 3 4 5 ribbon: # 连接超时时间（ms） ConnectTimeout: 1000 # 业务逻辑超时时间（ms） ReadTimeout: 2000 超时重试机制\n当服务请求超时后，Ribbon 会根据其重试机制进行重试调用。默认情况下，如果只有一个 provider 的实例，其会重试调用该 provider 一次；如果有多个 provider 的实例，会先重试调用该 provider 一次，如果还超时，就会调用 provider 的 1 个负载均衡实例一次，如果还超时，就会返回超时异常。\n1 2 3 4 5 6 7 ribbon: # 同一台实例最大重试次数，不包括首次调用 MaxAutoRetries: 1 # 重试负载均衡其他的实例最大重试次数，不包括首次调用 MaxAutoRetriesNextServer: 1 # 是否所有操作都重试，所有操作指 GET 和 POST 请求，建议配置为 false，仅对 GET 请求进行重试，因为 POST 是更新操作，重试可能会出问题 OkToRetryOnAllOperations: false 如果某次请求调用时，某个实例调用失败了，那么在 6 秒内如果又接收到了该请求，就不会去调用之前调用失败的实例了。6 秒后会恢复对该实例的调用\n小技巧\n1 2 3 # ribbon 可以使用该方式针对某个服务进行修改配置，如果直接以 ribbon.xx，就是全局配置 ${srping.application.name}: ribbon: RESTful RESTful 网络请求是指 RESTful 风格的网络请求，其中 REST 是 Resource Representational State Transfer 的缩写，直接翻译即“资源表现层状态转移”。\nResource 代表互联网资源。所谓“资源”是网络上的一个实体，或者说网上的一个具体信息。它可以是一段文本，一首歌曲，一种服务，可以使用一个 URI 指向它，每种“资源”对应一个 URI。 Representational 是“表现层”意思。“资源”是一种消息实体，它可以有多种外在的表现形式，我们把“资源”具体呈现出来的形式叫作它的“表现层”。比如说文本可以用 TXT 格式进行表现，也可以使用 XML 格式，JSON 格式和二进制格式；视频可以用 MP4 格式表现，也可以用 AVI 格式表现。URI 只代表资源的实体，不代表它的形式。它的具体表现形式，应该由 HTTP 请求的头信息 Accept 和 Content-Type 字段指定，这两个字段是对“表现层”的描述。 State Transfer 是指“状态转移”。客户端访问服务的过程中必然涉及数据和状态的转化。如果客户端想要操作服务端资源，必须通过某种手段，让服务器端资源发生“状态转移”。而这种转化是建立在表现层之上的，所以被称为“表现层状态转移”。客户端通过使用 HTTP 协议中的四个动词来实现上述操作，它们分别是：获取资源的 GET，新建或更新资源的 POST，更新资源的 PUT 和删除资源的 DELETE。 RESTful 的使用层次\n第一个层次（Level 0）的 Web 服务只是使用 HTTP 作为传输方式，实际上只是远程方法调用（RPC）的一种具体形式。SOAP 和 XML-RPC 都属于此类。 第二个层次（Level 1）的 Web 服务引入了资源的概念。每个资源有对应的标识符和表达。 第三个层次（Level 2）的 Web 服务使用不同的 HTTP 方法来进行不同的操作，并且使用 HTTP 状态码来表示不同的结果。如 HTTP GET 方法来获取资源，HTTP DELETE 方法来删除资源。 第四个层次（Level 3）的 Web 服务使用 HATEOAS。在资源的表达中包含了链接信息。客户端可以根据链接来发现可以执行的动作。\nRestTemplate RestTemplate 是 Spring 提供的同步 HTTP 网络客户端接口，它可以简化客户端与 HTTP 服务器之间的交互，并且它强制使用 RESTful 风格。它会处理 HTTP 连接和关闭，只需要使用者提供服务器的地址（URL）和模板参数。\n依赖注入\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package com.example.eurekaconsumer.config; import org.springframework.cloud.client.loadbalancer.LoadBalanced; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.client.RestTemplate; /** * @author wangshuo * @date 2021/01/07 */ @Configuration public class RestTemplateConfig { /** * 必须添加 LoadBalanced 注解才能通过服务名进行调用，并进行负载均衡 */ @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); } } 服务调用\n1 2 String url =\"http://eureka-provider/getHi\"; String respStr = restTemplate.getForObject(url, String.class); 不同请求方式示例 GET 请求处理 getForEntity()：返回值是一个 ResponseEntity，ResponseEntity 是 Spring 对 HTTP 请求响应结果的封装，包含了几种重要的元素，如：responseCode，contentType，contentLength，responseBody 等 getForObject()：把响应结果的请求体映射为一个对象进行返回 如果需要请求头等信息使用 getForEntity，只需要将请求体封装成对象用 getForObject\n1. 返回字符串 生产者\n1 2 3 4 @GetMapping(\"/string\") public String getString() { return \"字符串\"; } 消费者\n1 2 3 4 5 @GetMapping(\"/string\") public String getString() { String url = \"http://eureka-provider/provider/restTemplate/string\"; return restTemplate.getForObject(url, String.class); } 2. 返回 Map 生产者\n1 2 3 4 @GetMapping(\"/map\") public Map\u003cString, String\u003e getMap() { return Collections.singletonMap(\"name\", \"zhangsan\"); } 消费者\n1 2 3 4 5 @GetMapping(\"/map\") public Map\u003cString, String\u003e getMap() { String url = \"http://eureka-provider/provider/restTemplate/map\"; return (Map\u003cString, String\u003e) restTemplate.getForObject(url, Map.class); } 3. 返回对象 生产者\n1 2 3 4 5 6 @GetMapping(\"/obj\") public Person getObj() { return new Person() .setName(\"zhangsan\") .setAge(18); } 消费者\n1 2 3 4 5 @GetMapping(\"/obj\") public Person getObj() { String url = \"http://eureka-provider/provider/restTemplate/obj\"; return restTemplate.getForObject(url, Person.class); } Person 类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class Person { private String name; private Integer age; public String getName() { return name; } public Person setName(String name) { this.name = name; return this; } public Integer getAge() { return age; } public Person setAge(Integer age) { this.age = age; return this; } } 4. 传参调用-使用占位符 生产者\n1 2 3 4 5 6 @GetMapping(\"/obj-with-param\") public Person getObjWithParam(@RequestParam String name, @RequestParam Integer age) { return new Person() .setName(name) .setAge(age); } 消费者\n1 2 3 4 5 6 7 @GetMapping(\"/obj-with-param\") public Person getObjWithParam(@RequestParam String name, @RequestParam Integer age) { // 参数使用占位符 String url = \"http://eureka-provider/provider/restTemplate/obj-with-param?name={1}\u0026age={2}\"; // 传入的值要与占位符顺序一致 return restTemplate.getForObject(url, Person.class, name, age); } 5. 传参调用-使用 map 生产者\n1 2 3 4 5 6 @GetMapping(\"/obj-with-param\") public Person getObjWithParam(@RequestParam String name, @RequestParam Integer age) { return new Person() .setName(name) .setAge(age); } 消费者\n1 2 3 4 5 6 7 @GetMapping(\"/obj-with-map-param\") public Person getObjWithParam(@RequestParam Map\u003cString, String\u003e map) { // 参数使用占位符，此处{name}与 map 中的 key 要一一对应，如果 map 中没有该 key 会报错 String url = \"http://eureka-provider/provider/restTemplate/obj-with-param?name={name}\u0026age={age}\"; // 把 map 作为参数传递 return restTemplate.getForObject(url, Person.class, map); } POST 请求处理 postForEntity()：返回值是一个 ResponseEntity，ResponseEntity 是 Spring 对 HTTP 请求响应结果的封装，包含了几种重要的元素，如：responseCode，contentType，contentLength，responseBody 等 postForObject()：把响应结果的请求体映射为一个对象进行返回 postForLocation()：用于资源重定向 postForEntity，postForObject 和 getForEntity，getForObject 用法大致一致\npostForObject 生产者\n1 2 3 4 @PostMapping(\"/obj\") public Person postObj(@RequestBody Person person) { return person; } 消费者\n1 2 3 4 5 @PostMapping(\"/obj\") public Person postForObject(@RequestBody Person person) { String url = \"http://eureka-provider/provider/restTemplate/obj\"; return restTemplate.postForObject(url, person, Person.class); } postForLocation 生产者\n1 2 3 4 5 6 7 @PostMapping(\"/location\") public URI postForLocation(@RequestBody Person person, HttpServletResponse response) throws URISyntaxException { URI uri = new URI(\"https://www.baidu.com/s?wd=\" + person.getName()); // 需要设置头信息，否则返回的是 null response.setHeader(\"Location\", uri.toString()); return uri; } 消费者\n1 2 3 4 5 6 7 @PostMapping(\"/location\") public URI postForLocation(@RequestBody Person person) { String url = \"http://eureka-provider/provider/restTemplate/location\"; URI uri = restTemplate.postForLocation(url, person); System.out.println(uri); return uri; } DELETE，PATCH，PUT，OPTIONS（略） exchange exchange 提供统一的方法模板进行四种请求：GET，POST，DELETE，PUT，可以自定义 http 请求的头信息\n1 2 3 4 5 6 7 8 9 10 @GetMapping(\"/exchange\") public Object exchange(Person person) { String url = \"http://eureka-provider/provider/restTemplate/obj\"; // 自定义 requestHeaders HttpHeaders httpHeaders = new HttpHeaders(); httpHeaders.setContentType(MediaType.APPLICATION_JSON); // 设置 requestBody，requestHeaders HttpEntity httpEntity = new HttpEntity(person, httpHeaders); return restTemplate.exchange(url, HttpMethod.POST, httpEntity, Person.class).getBody(); } 拦截器 会拦截 restTemplate 发出的所有请求，可以对 restTemplate 发出的请求和响应结果进行附加操作。\n需要实现ClientHttpRequestInterceptor接口\n添加拦截器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import org.springframework.http.HttpRequest; import org.springframework.http.client.ClientHttpRequestExecution; import org.springframework.http.client.ClientHttpRequestInterceptor; import org.springframework.http.client.ClientHttpResponse; import java.io.IOException; /** * @author wangshuo * @date 2021/01/09 */ public class com.example.eurekaconsumer.interceptor.MyClientHttpRequestInterceptor implements ClientHttpRequestInterceptor { @Override public ClientHttpResponse intercept(HttpRequest request, byte[] body, ClientHttpRequestExecution execution) throws IOException { System.out.println(\"拦截啦！！！\"); System.out.println(request.getURI()); ClientHttpResponse response = execution.execute(request, body); System.out.println(response.getHeaders()); return response; } } 添加到 restTemplate 中 1 2 3 4 5 6 7 8 9 @Bean @LoadBalanced public RestTemplate restTemplate() { RestTemplate restTemplate = new RestTemplate(); // 添加拦截器 restTemplate.getInterceptors() .add(new MyClientHttpRequestInterceptor()); return restTemplate; } ","description":"","tags":["MSB","Spring Cloud","Ribbon","RestTemplate","Java"],"title":"Ribbon 和 RestTemplate","uri":"/posts/msb/spring-cloud/ribbon-and-resttemplate/"},{"categories":null,"content":"微服务 服务进化概述 服务进化过程：单体应用 -\u003e SOA -\u003e 微服务\n单体应用 概念：所有功能全部打包在一起。应用大部分是一个 war 包或 jar 包。随着业务发展，功能增多，这个项目会越来越臃肿。\n好处：容易开发，测试，部署，适合项目初期试错\n坏处：随着项目越来越复杂，团队不断扩大，坏处就显现出来了。\n复杂性高：代码多，十万行，百万行级别。加一个小功能，会带来其他功能的隐患，因为它们在一起。\n技术债务：人员流动，不坏不修，因为不敢修。\n持续部署困难：由于是全量应用，改一个小功能，全部部署，会导致无关的功能暂停使用。编译部署上线耗时长，不敢随便部署，导致部署频率低，进而又导致两次部署之间 功能修改多，越不敢部署，恶性循环。\n可靠性差：某个小问题，比如小功能出现 OOM，会导致整个应用崩溃。\n扩展受限：只能整体扩展，无法按照需要进行扩展，不能根据计算密集型（派单系统）和 IO 密集型（文件服务）进行合适的区分。\n阻碍创新：单体应用是以一种技术解决所有问题，不容易引入新技术。但在高速的互联网发展过程中，适应的潮流是：用合适的语言做合适的事情。比如在单体应用中，一个项目用 spring MVC，想换成 spring boot，切换成本很高，因为有可能 10 万，百万行代码都要改，而微服务可以轻松切换，因为每个服务，功能简单，代码少。\nSOA 对单体应用的改进：引入 SOA（Service-Oriented Architecture）面向服务架构，拆分系统，用服务的流程化来实现业务的灵活性。服务间需要某些方法进行连接，面向接口等，它是一种设计方法，其中包含多个服务，服务之间通过相互依赖最终提供一系列的功能。一个服务 通常以独立的形式存在于操作系统进程中。各个服务之间 通过网络调用。但是还是需要用些方法来进行服务组合，有可能还是个单体应用。\n所以要引入微服务，是 SOA 思想的一种具体实践。\n微服务 微服务架构 = 80%的 SOA 服务架构思想 + 100%的组件化架构思想\n微服务概况 无严格定义。\n微服务是一种架构风格，将单体应用划分为小型的服务单元。\n微服务架构是一种使用一系列粒度较小的服务来开发单个应用的方式；每个服务运行在自己的进程中；服务间采用轻量级的方式进行通信（通常是 HTTP API）；这些服务是基于业务逻辑和范围，通过自动化部署的机制来独立部署的，并且服务的集中管理应该是最低限度的，即每个服务可以采用不同的编程语言编写，使用不同的数据存储技术。\n英文定义：http://www.martinfowler.com/articles/microservices.html\n微服务特性 独立运行在自己进程中。 一系列独立服务共同构建起整个系统。 一个服务只关注自己的独立业务。 轻量的通信机制 RESTful API 使用不同语言开发 全自动部署机制 微服务组件介绍 不局限与具体的微服务实现技术。\n服务注册与发现：服务提供方将己方调用地址注册到服务注册中心，让服务调用方能够方便地找到自己；服务调用方从服务注册中心找到自己需要调用的服务的地址。\n负载均衡：服务提供方一般以多实例的形式提供服务，负载均衡功能能够让服务调用方连接到合适的服务节点。并且，服务节点选择的过程对服务调用方来说是透明的。\n服务网关：服务网关是服务调用的唯一入口，可以在这个组件中实现用户鉴权、动态路由、灰度发布、A/B 测试、负载限流等功能。\n灰度发布（又名金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。在其上可以进行 A/B testing，即让一部分用户继续用产品特性 A，一部分用户开始用产品特性 B，如果用户对 B 没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到 B 上面来。灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。\n配置中心：将本地化的配置信息（Properties、XML、YAML 等形式）注册到配置中心，实现程序包在开发、测试、生产环境中的无差别性，方便程序包的迁移，也是无状态特性。\n集成框架：微服务组件都以职责单一的程序包对外提供服务，集成框架以配置的形式将所有微服务组件（特别是管理端组件）集成到统一的界面框架下，让用户能够在统一的界面中使用系统。Spring Cloud 就是一个集成框架。\n调用链监控：记录完成一次请求的先后衔接和调用关系，并将这种串行或并行的调用关系展示出来。在系统出错时，可以方便地找到出错点。\n支撑平台：系统微服务化后，各个业务模块经过拆分变得更加细化，系统的部署、运维、监控等都比单体应用架构更加复杂，这就需要将大部分的工作自动化。现在，Docker 等工具可以给微服务架构的部署带来较多的便利，例如持续集成、蓝绿发布、健康检查、性能监控等等。如果没有合适的支撑平台或工具，微服务架构就无法发挥它最大的功效。\n蓝绿部署是不停老版本，部署新版本然后进行测试，确认 OK，将流量切到新版本，然后老版本同时也升级到新版本。 灰度是选择部分部署新版本，将部分流量引入到新版本，新老版本同时提供服务。等待灰度的版本 OK，可全量覆盖老版本。 灰度是不同版本共存，蓝绿是新旧版本切换，2 种模式的出发点不一样。\n微服务优点 独立部署。不依赖其他服务，耦合性低，不用管其他服务的部署对自己的影响。 易于开发和维护：关注特定业务，所以业务清晰，代码量少，模块变的易开发、易理解、易维护。 启动块：功能少，代码少，所以启动快，有需要停机维护的服务，不会长时间暂停服务。 局部修改容易：只需要部署 相应的服务即可，适合敏捷开发。 技术栈不受限：java，node.js 等 按需伸缩：某个服务受限，可以按需增加内存，cpu 等。 职责专一。专门团队负责专门业务，有利于团队分工。 代码复用。不需要重复写。底层实现通过接口方式提供。 便于团队协作：每个团队只需要提供 API 就行，定义好 API 后，可以并行开发。 微服务缺点 分布式固有的复杂性：容错（某个服务宕机），网络延时，调用关系、分布式事务等，都会带来复杂。\n分布式事务的挑战：每个服务有自己的数据库，优点在于不同服务可以选择适合自身业务的数据库。订单用 MySQL，评论用 Mongodb 等。目前最理想解决方案是：柔性事务的最终一致性。\n刚性事务：遵循 ACID 原则，强一致性。 柔性事务：遵循 BASE 理论，最终一致性；与刚性事务不同，柔性事务允许一定时间内，不同节点的数据不一致，但要求最终一致。\nBASE 是 Basically Available（基本可用）、Soft state（软状态）和 Eventually consistent （最终一致性）三个短语的缩写。BASE 理论是对 CAP 中 AP 的一个扩展，通过牺牲强一致性来获得可用性，当出现故障允许部分不可用但要保证核心功能可用，允许数据在一段时间内是不一致的，但最终达到一致状态。满足 BASE 理论的事务，我们称之为“柔性事务”。\n接口调整成本高：改一个接口，调用方都要改。\n测试难度提升：一个接口改变，所有调用方都得测。自动化测试就变的重要了。API 文档的管理也尤为重要。推荐：yapi。\n运维要求高：需要维护 几十 上百个服务。监控变的复杂。并且还要关注多个集群，不像原来单体，一个应用正常运行即可。\n重复工作：比如 java 的工具类可以在共享 common.jar 中，但在多语言下行不通，C++无法直接用 java 的 jar 包。\n微服务设计原则 单一职责原则：关注整个系统功能中单独，有界限的一部分。\n服务自治原则：可以独立开发，测试，构建，部署，运行，与其他服务解耦。\n轻量级通信原则：轻，跨平台，跨语言。REST，AMQP 等。\n粒度把控：与自己实际相结合。不要追求完美，随业务进化而调整。《淘宝技术这 10 年》。\n技术选型 Spring Cloud 和 Dubbo 组件比较 Dubbo：Zookeeper + Dubbo + SpringMVC/SpringBoot\n通信方式：RPC 注册中心：Zookeeper，Nacos 配置中心：diamond（淘宝开发） Spring Cloud：Spring + Netflix\n通信方式：http RESTful 注册中心：Eureka，Consul，Nacos 配置中心：config 断路器：Hystrix 网关：Zuul，Gateway 分布式链路追踪系统：sleuth + zipkin 差别 dubbo spring cloud 背景 国内影响大 国外影响大 平手 社区活跃度 低（现在又好了） 高 cloud 胜出 架构完整度 不完善（dubbo 有些不提供，需要用第三方，它只关注服务治理） 比较完善，微服务组件应有尽有。 cloud 胜出 学习成本 dubbo 需要配套学习 无缝 spring cloud 胜出 性能 高。（基于 Netty） 低。（基于 http，每次都要创建）。此性能的损耗对大部分应用是可以接受的。而 HTTP 风格的 API，是很方便的。用小的性能损耗换来了方便。 dubbo 胜出 Spring Cloud 概念 Spring Cloud 是实现微服务架构的一系列框架的有机集合。\n是在 Spring Boot 基础上构建的，用于简化分布式系统构建的工具集。是拥有众多子项目的项目集合。利用 Spring Boot 的开发便利性，巧妙地简化了分布式系统基础设施（服务注册与发现、熔断机制、网关路由、配置中心、消息总线、负载均衡、链路追踪等）的开发。\n版本演进 版本过程：版本名。版本号。\n版本名：伦敦地铁字母顺序。\n版本号：M（milestone）：里程碑，\n​\tSR（Service Releases）：稳定版，\n​\tRC（Release Candidate）：稳定版的候选版，也就是稳定版的最后一个版本。\n看官网：查询每个 cloud 版本下面的子模块的版本。 https://spring.io/projects/spring-cloud 此网页的最下面，目前最新的 SpringCloud 最新版本是：Greenwich.SR2 版本记录 https://github.com/spring-cloud/spring-cloud-release/releases\n整体架构 组成：\n服务注册与发现组件：Eureka，Zookeeper，Consul，Nacos 等。Eureka 基于 REST 风格的。\n服务调用组件：Hystrix（熔断降级，在出现依赖服务失效的情况下，通过隔离 系统依赖服务 的方式，防止服务级联失败，同时提供失败回滚机制，使系统能够更快地从异常中恢复），Ribbon（客户端负载均衡，用于提供客户端的软件负载均衡算法，提供了一系列完善的配置项：连接超时、重试等），OpenFeign（优雅的封装 Ribbon，是一个声明式 RESTful 网络请求客户端，它使编写 Web 服务客户端变得更加方便和快捷）。\n网关：路由和过滤。Zuul，Gateway。\n配置中心：提供了配置集中管理，动态刷新配置的功能；配置通过 Git 或者其他方式来存储。\n消息组件：Spring Cloud Stream（对分布式消息进行抽象，包括发布订阅、分组消费等功能，实现了微服务之间的异步通信）和 Spring Cloud Bus（主要提供服务间的事件通信，如刷新配置）\n安全控制组件：Spring Cloud Security 基于 OAuth2.0 开放网络的安全标准，提供了单点登录、资源授权和令牌管理等功能。\n链路追踪组件：Spring Cloud Sleuth（收集调用链路上的数据），Zipkin（对 Sleuth 收集的信息，进行存储，统计，展示）。\n每个点中的内容，后面都会讲到。\n扩展 持续集成 持续集成，持续部署，持续交付。 集成：是指软件个人研发的部分向软件整体部分集成，以便尽早发现个人开发部分的问题； 部署：是代码尽快向可运行的开发/测试节交付，以便尽早测试； 交付：是指研发尽快向客户交付，以便尽早发现生产环境中存在的问题。 如果说等到所有东西都完成了才向下个环节交付，导致所有的问题只能在最后才爆发出来，解决成本巨大甚至无法解决。而所谓的持续，就是说每完成一个完整的部分，就向下个环节交付，发现问题可以马上调整。使问题不会放大到其他部分和后面的环节。 这种做法的核心思想在于：既然事实上难以做到事先完全了解完整的、正确的需求，那么就干脆一小块一小块的做，并且加快交付的速度和频率，使得交付物尽早在下个环节得到验证。早发现问题早返工。\n上面的 3 个持续，也都随着微服务的发展而发展，当架构师的同学，可以参考这种方式。\n持续集成的工具，向大家推荐：https://jenkins.io/doc/book/pipeline/\n中台段子 Q：大师大师，服务拆多了怎么办？ A：那就再合起来。 Q：那太没面子了。 A：那就说跨过了微服务初级阶段，在做中台（自助建站系统）。\n","description":"","tags":["MSB","Spring Cloud","Java"],"title":"微服务","uri":"/posts/msb/spring-cloud/microservice/"},{"categories":null,"content":"Eureka Eureka 介绍 背景：在传统应用中，组件之间的调用，通过有规范的约束的接口来实现，从而实现不同模块间良好的协作。但是被拆分成微服务后，每个微服务实例的网络地址都可能动态变化，数量也会变化，使得原来硬编码的地址失去了作用。需要一个中心化的组件来进行服务的登记和管理。\n概念：实现服务治理，即管理所有的服务信息和状态。\n注册中心好处：不用关心有多少提供方。\n注册中心有哪些：Eureka，Nacos，Consul，Zookeeper 等。\n服务注册与发现包括两部分，一个是服务器端，另一个是客户端。\nServer 是一个公共服务，为 Client 提供服务注册和发现的功能，维护注册到自身的 Client 的相关信息，同时提供接口给 Client 获取注册表中其他服务的信息，使得动态变化的 Client 能够进行服务间的相互调用。 Client 将自己的服务信息通过一定的方式登记到 Server 上，并在正常范围内维护自己信息一致性，方便其他服务发现自己，同时可以通过 Server 获取到自己依赖的其他服务信息，完成服务调用，还内置了负载均衡器，用来进行基本的负载均衡。 Eureka 是 Netflix 开源的组件，包含 Eureka Server（注册中心）和 Eureka Client（服务提供者/消费者）两部分。是一个 RESTful 风格的服务，是一个用于服务发现和注册的基础组件，是搭建 Spring Cloud 微服务的前提之一，它屏蔽了 Server 和 Client 的交互细节，使得开发者将精力放到业务上。\nEureka Server A 从 Eureka Server B 同步信息，则 Eureka Server B 是 Eureka Server A 的 peer。\nEureka Server 的功能 服务注册表：记录各个微服务信息，例如服务名称，IP，端口等\n提供查询 API（查询可用的服务实例）和管理 API（用于服务的注册和下线）\n服务注册与发现：\n注册：将服务注册到注册中心 发现：查询可用服务列表及其网络地址 服务检查：定时检测已注册服务，如果发现某实例长时间无法访问，就从注册表中移除\nEureka Client 的功能 注册：每个实例启动时，将自己的网络地址等信息注册到注册中心，注册中心会存储（在内存中）这些信息 拉取服务注册表：服务消费者从注册中心查询服务提供者的网络地址，并通过该地址调用服务提供者，为了避免每次都查询注册表信息，所以 Eureka Client 会定时去 Eureka Server 拉取注册表信息缓存到本地 心跳：各个服务会定期向注册中心发送心跳信息，如果注册中心长时间没有接受到服务的心跳信息，就会将该服务下线 调用：实际的服务调用，通过注册表，解析服务名和具体地址的对应关系，找到具体的服务地址，进行实际的调用。 Eureka 原理 Eureka Client 向 Eureka Server 进行注册并拉取 Eureka Server 中的注册表信息 consumer 根据拉取到本地的注册表信息调用 provider Eureka Client 定时向 Eureka Server 发送心跳 Eureka Client 定时从 Eureka Server 拉取新的注册表 Eureka Server 的 peer 间同步注册表 Eureka Client 可以主动下线，也可以通过 Eureka Server 对其进行下线 注册服务 Registry Eureka Client/Server 向 Eureka Server 注册自己，注册在第一次心跳发生时提交\n续约，心跳 Renew Eureka Client 默认每 30 秒向 Eureka Server 发送一次心跳来进行续租，告诉 Eureka Server 该 Eureka Client 是活动的。\n默认情况下，如果 90 秒内 Eureka Server 没有接收到某个 Eureka Client 的心跳，就会将其从服务注册表中删除\n拉取注册表 Fetch Registry Eureka Client 从 Eureka Server 拉取注册表并将其缓存到本地，之后客户端使用本地的缓存来查找其他服务。\n拉取注册表分为增量更新和全量更新，在服务注册时，会将该服务添加到 recentRegisteredQueue 和 registry 中，recentRegisteredQueue 中保存的服务信息默认 3 分钟会失效\n增量更新：Eureka Client 默认每 30 秒从 Eureka Server 的 recentRegisteredQueue 中获取更新，如果获取失败会进行增量更新 全量更新：Eureka Client 从 Eureka Server 的 registry 获取所有服务注册信息 增量更新时，由于每 30 秒拉取一次，而失效时间为 3 分钟，所以会拉取到重复的信息，Eureka Client 会自动处理重复的信息。\n在获得增量后，Eureka Client 通过比较数据库中返回的实例计数与服务器协调信息，如果由于某种原因信息不匹配，则再次获取整个注册表信息。\n服务下线 Cancel Eureka Client 在关闭时向 Eureka Server 发起下线请求，这将从服务器的实例注册表中删除该 Client，从而有效的将实例从通信量中取出。\n也可以通过 Eureka Server 提供的 RESTful 服务接口手动对 Eureka Client 进行下线\n同步延迟 Time Lag 来自 Eureka 客户端的所有操作可能需要一段时间才能反映到 Eureka 服务器上，然后反映到其他 Eureka 客户端上。这是因为 eureka 服务器上的有效负载缓存，它会定期刷新以反映新信息。Eureka 客户端还定期地获取增量。因此，更改传播到所有 Eureka 客户机可能需要 2 分钟。\n通讯机制 Communication mechanism 所有对 Eureka Server 的操作都是通过其提供的 RESTful 接口进行的\n默认情况下 Eureka 使用 Jersey 和 Jackson 以及 JSON 完成节点间的通讯\nEureka Server 注册中心搭建 Eureka Server 单节点搭建 pom.xml 引入依赖\n1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-server\u003c/artifactId\u003e \u003c/dependency\u003e application.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 server: port: 7900 eureka: client: # 是否将自己注册到 Eureka Server，默认为 true，由于当前就是 server，故而设置成 false，表明该服务不会向 eureka 注册自己的信息 register-with-eureka: false # 是否从 eureka server 获取注册信息，由于单节点，不需要同步其他节点数据，用 false fetch-registry: false # 设置服务注册中心的 URL，用于 client 和 server 端交流 service-url: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ instance: hostname: localhost 如果 service-url 为空，且 register-with-eureka，fetch-registry 为 true，则会报错：Cannot execute request on any known server，因为 eureka server 同时也是一个 eureka client，它会尝试注册自己，所以要有一个注册中心 url 去注册。\n代码\n1 2 // 在 SpringBoot 启动类上添加注解，标识该服务为服务注册中心 @EnableEurekaServer Eureka Server 高可用（集群）搭建 高可用：可以运行多个 Eureka Server 实例并进行相互注册。Eureka Server 节点之间会彼此增量的同步信息，从而保证节点中数据一致\nEureka Server 双节点 双节点 Eureka Server 相互注册，组成集群环境\n准备\n准备 2 个节点部署 eureka server，也可以单机部署\n修改本机 host 文件，绑定主机名。单机部署时使用 IP 地址会有问题，相同主机要使用不同的主机名进行配置\n配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 spring: application: name: eureka-server eureka: client: # 是否将自己注册到 Eureka Server，默认为 true，需要 register-with-eureka: true # 是否从 eureka server 获取注册信息，默认为 true，需要 fetch-registry: true --- # 节点 1 spring: profiles: 7901 server: port: 7901 eureka: client: # 设置服务注册中心的 URL，用于 client 和 server 端交流 service-url: # 此节点应向其他节点发起请求 defaultZone: http://ek2.com:7902/eureka/ instance: # 主机名，必填，需要和 peer 的 service-url 中配置的域名一致 hostname: ek1.com --- # 节点 2 spring: profiles: 7902 server: port: 7902 eureka: client: # 设置服务注册中心的 URL，用于 client 和 server 端交流 service-url: # 此节点应向其他节点发起请求 defaultZone: http://ek1.com:7901/eureka/ instance: # 主机名，必填，需要和 peer 的 service-url 中配置的域名一致 hostname: ek2.com 效果 Eureka Server 多节点（3 个以上） 配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 spring: application: name: eureka-server eureka: client: # 是否将自己注册到 Eureka Server，默认为 true，需要 register-with-eureka: true # 是否从 eureka server 获取注册信息，默认为 true，需要 fetch-registry: true # 设置服务注册中心的 URL，用于 client 和 server 端交流 service-url: # 3 个以上 Eureka Server 集群，需要把所有的 Eureka Server URL 都写上（注意逗号后不能有空格） defaultZone: http://ek1.com:7901/eureka/,http://ek2.com:7902/eureka/,http://ek3.com:7903/eureka/ --- # 节点 1 spring: profiles: 7901 server: port: 7901 eureka: instance: # 主机名，必填，需要和 peer 的 service-url 中配置的域名一致 hostname: ek1.com --- # 节点 2 spring: profiles: 7902 server: port: 7902 eureka: instance: # 主机名，必填，需要和 peer 的 service-url 中配置的域名一致 hostname: ek2.com --- # 节点 3 spring: profiles: 7903 server: port: 7903 eureka: instance: # 主机名，必填，需要和 peer 的 service-url 中配置的域名一致 hostname: ek3.com 效果图\nEureka Client 服务注册 pom.xml 中引入\n1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-client\u003c/artifactId\u003e \u003c/dependency\u003e 配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 spring: application: name: eureka-provider server: port: 9090 eureka: client: # 因为是 Eureka Client，所以需要向 Eureka Server 注册 register-with-eureka: true # 从 Eureka Server 拉取服务注册表 fetch-registry: true # Eureka Server 的 URL service-url: # 如果有多个 Eureka Server 使用逗号隔开 defaultZone: http://localhost:7900/eureka/ instance: hostname: localhost Eureka Client consumer 调用 provider Eureka Server RESTful 服务调用 依据官方提供的 RESTful 接口，向 Eureka Server 发送请求，可以对服务进行操作。默认返回 xml 格式，如果需要返回 json，可在请求头添加 Accept:application/json\n官方文档\n常用 RESTful 接口\nOperation HTTP action Description 服务状态 GET /eureka/status Output: JSON/XML 注册新实例 POST /eureka/v2/apps/appID Input: JSON/XML payload\nHTTP Code: 204 on success 服务下线 DELETE /eureka/v2/apps/appID/instanceID HTTP Code: 200 on success 发送心跳 PUT /eureka/v2/apps/appID/instanceID HTTP Code: * 200 on success * 404 if instanceID doesn’t exist 查询所有实例 GET /eureka/v2/apps HTTP Code: 200 on success Output: JSON/XML 查询指定appID的实例 GET /eureka/v2/apps/appID HTTP Code: 200 on success Output: JSON/XML 查询指定appID/instanceID的实例 GET /eureka/v2/apps/appID/instanceID HTTP Code: 200 on success Output: JSON/XML 指定instanceID查询 GET /eureka/v2/instances/instanceID HTTP Code: 200 on success Output: JSON/XML 更改服务状态 PUT /eureka/v2/apps/appID/instanceID/status?value={UP/DOWN} HTTP Code: * 200 on success * 500 on failure 更新 metadata PUT /eureka/v2/apps/appID/instanceID/metadata?key=value HTTP Code: * 200 on success * 500 on failure 元数据 Eureka 的元数据有两种：标准元数据和自定义元数据。\n标准元数据：主机名、IP 地址、端口号、状态页和健康检查等信息，这些信息都会被发布在服务注册表中，用于服务之间的调用。 自定义元数据：可以使用 eureka.instance.metadata-map 配置，这些元数据可以在远程客户端中访问，但是一般不改变客户端行为，除非客户端知道该元数据的含义。 可以在配置文件中对当前服务设置自定义元数据，可后期用户个性化使用（例如自定义负载均衡）\n元数据可以配置在 Eureka Server 和 Eureka Client 上\n1 2 3 4 5 eureka: instance: metadata-map: myKey1: myVal1 myKey2: myVal2 可通过 GET /eureka/status 查看到自己添加的元数据信息，也可在代码中获取到\nEureka 机制 自我保护机制 Eureka 在 CAP 理论当中属于 AP，也就是说当产生网络分区时，Eureka 保证系统可用性，但不保证数据的一致性\n默认情况下，Eureka Server 在 90s 内没有接收到某个微服务的心跳，就会将该微服务下线。但是当网络故障时，微服务与 Eureka Server 间无法正常通信，上述行为就非常危险，因为服务正常，不应该下线。\nEureka Server 的自我保护机制用来解决该问题，当 Eureka Server 在短时间内丢失过多客户端时，就会进入自我保护模式，会保护注册表中剩余的微服务不被注销掉。当网络故障恢复后，退出自我保护模式。\n思想：宁可保留健康的和不健康的，也不盲目注销任何健康的服务\n自我保护机制的触发 Eureka Server 通过一个定时剔除任务来对心跳数不满足条件的服务进行剔除。\n1 2 3 4 5 6 7 8 9 // AbstractInstanceRegistry.java public void evict(long additionalLeaseMs) { logger.debug(\"Running the evict task\"); // 如果 isLeaseExpirationEnabled 为 false 执行剔除逻辑，否则不进行剔除 if (!isLeaseExpirationEnabled()) { logger.debug(\"DS: lease expiration is currently disabled.\"); return; } // 服务剔除逻辑 1 2 3 4 5 6 7 8 9 10 11 // PeerAwareInstanceRegistryImpl.java @Override public boolean isLeaseExpirationEnabled() { // 如果关闭了自我保护，就返回 true，上方代码就执行自我保护逻辑 if (!isSelfPreservationModeEnabled()) { // The self preservation mode is disabled, hence allowing the instances to expire. return true; } // 如果开启了自我保护，判断最后一分钟续约数是否大于每分钟续约数阈值，大于就进行剔除，否则不进行剔除 return numberOfRenewsPerMinThreshold \u003e 0 \u0026\u0026 getNumOfRenewsInLastMin() \u003e numberOfRenewsPerMinThreshold; } 客户端每分钟续约数量小于客户端总数的 85%时会触发自我保护机制\n自我保护机制触发条件：开启了自我保护机制，并且每分钟心跳次数 \u003c numberOfRenewsPerMinThreshold 时，即触发自我保护机制，对之后没有续租的服务也不进行剔除。\nnumberOfRenewsPerMinThreshold = expectedNumberOfRenewsPerMin * renewalPercentThreshold\nexpectedNumberOfRenewsPerMin：期望的每分钟续约数，默认为某个微服务的实例数 x 2，乘 2 是因为 Client 默认每 30s 向 Server 发送一次心跳，一分钟就是 2 次\nrenewalPercentThreshold：续约百分比，默认是 0.85\n示例：假如某个微服务有 10 个实例，默认情况下，每分钟会向 Server 发送 10 * 2 = 20 个心跳，期望阈值为 0.85，则 20 * 0.85 = 17，即当 Server 每分钟接收该服务心跳数小于 17 时触发自我保护机制。\n配置调整 1 2 3 4 5 6 7 8 9 10 11 eureka: server: # 是否开启自我保护机制 enable-self-preservation: true # 续约阈值百分比 renewal-percent-threshold: 0.85 # 服务剔除时间间隔，默认 60s eviction-interval-timer-in-ms: 6000 instance: # 客户端向服务端发送心跳的时间间隔 lease-renewal-interval-in-seconds: 30 Eureka 健康检查 Eureka Server 默认根据 Eureka Client 定时发送的心跳来判断其是否是健康的，但是这种方式是不准确的，心跳包可能受网络因素的影响，没有发送到 Eureka Server 上，然而此时该服务是正常的；或者服务状态是 UP 的，但是 DB 出现问题，也无法提供正常服务。\n使用 Actuator 监控应用，可以更细粒度的来对服务进行健康检查。\n引入依赖，开启监控 1 2 3 4 5 \u003c!-- Eureka Server 的 starter 中已经包含了该依赖，所以不需要重复引入，Eureka Client 需要引入 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-actuator\u003c/artifactId\u003e \u003c/dependency\u003e EndPoint 介绍 通过 /actuator 可查看所有 EndPoint\n默认端点 Spring Boot2.x 的 Actuator 默认只暴露了 health 和 info 端点，提供的监控信息无法满足我们的需求\n开启所有端点 1 2 3 4 5 6 #开启所有端点 management: endpoints: web: exposure: include: '*' 所有端点开启后的 api 列表\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 { \"_links\":{ \"self\":{ \"href\":\"http://localhost:8080/actuator\", \"templated\":false }, \"archaius\":{ \"href\":\"http://localhost:8080/actuator/archaius\", \"templated\":false }, \"beans\":{ \"href\":\"http://localhost:8080/actuator/beans\", \"templated\":false }, \"caches-cache\":{ \"href\":\"http://localhost:8080/actuator/caches/{cache}\", \"templated\":true }, \"caches\":{ \"href\":\"http://localhost:8080/actuator/caches\", \"templated\":false }, \"health\":{ \"href\":\"http://localhost:8080/actuator/health\", \"templated\":false }, \"health-path\":{ \"href\":\"http://localhost:8080/actuator/health/{*path}\", \"templated\":true }, \"info\":{ \"href\":\"http://localhost:8080/actuator/info\", \"templated\":false }, \"conditions\":{ \"href\":\"http://localhost:8080/actuator/conditions\", \"templated\":false }, \"configprops\":{ \"href\":\"http://localhost:8080/actuator/configprops\", \"templated\":false }, \"env\":{ \"href\":\"http://localhost:8080/actuator/env\", \"templated\":false }, \"env-toMatch\":{ \"href\":\"http://localhost:8080/actuator/env/{toMatch}\", \"templated\":true }, \"loggers\":{ \"href\":\"http://localhost:8080/actuator/loggers\", \"templated\":false }, \"loggers-name\":{ \"href\":\"http://localhost:8080/actuator/loggers/{name}\", \"templated\":true }, \"heapdump\":{ \"href\":\"http://localhost:8080/actuator/heapdump\", \"templated\":false }, \"threaddump\":{ \"href\":\"http://localhost:8080/actuator/threaddump\", \"templated\":false }, \"metrics-requiredMetricName\":{ \"href\":\"http://localhost:8080/actuator/metrics/{requiredMetricName}\", \"templated\":true }, \"metrics\":{ \"href\":\"http://localhost:8080/actuator/metrics\", \"templated\":false }, \"scheduledtasks\":{ \"href\":\"http://localhost:8080/actuator/scheduledtasks\", \"templated\":false }, \"mappings\":{ \"href\":\"http://localhost:8080/actuator/mappings\", \"templated\":false }, \"refresh\":{ \"href\":\"http://localhost:8080/actuator/refresh\", \"templated\":false }, \"features\":{ \"href\":\"http://localhost:8080/actuator/features\", \"templated\":false }, \"service-registry\":{ \"href\":\"http://localhost:8080/actuator/service-registry\", \"templated\":false } } } 各端点介绍 Health 用于显示系统的状态\n1 {\"status\":\"UP\"} shutdown 用来关闭节点\n开启远程关闭功能\n1 2 3 4 management: endpoint: shutdown: enabled: true 使用 POST 请求调用返回\n1 2 3 { \"message\": \"Shutting down, bye...\" } beans 获取应用上下文中创建的所有 bean\nconfigprops 获取应用中配置的属性信息报告\nenv 获取应用所有可用的环境属性报告\nmappings 获取应用所有 Spring Web 控制器映射关系（Controller 层的 EndPoints）报告\ninfo 获取应用自定义的信息\nmetrics 返回应用的各类重要度量指标信息，例如 jvm 的相关信息\n该 EndPoint 并没有返回全量信息，可以通过不同的 key 去加载需要的值\n/metrics/{key}，例如 /metrics/jvm.memory.max\nthreaddump 返回应用程序运行中的线程信息\n开启手动控制 在 Eureka Client 端配置，将自己真正的健康状态传播给 Eureka Server\n1 2 3 4 5 eureka: client: healthcheck: # 可以上报服务的真实健康状态 enabled: true 修改健康状态的 Service 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import org.springframework.boot.actuate.health.Health; import org.springframework.boot.actuate.health.HealthIndicator; import org.springframework.stereotype.Service; /** * 可通过该 Service 的 setStatus() 方法对该服务进行上线/下线操作，可将其用在具体业务逻辑中，根据异常等信息，自定义服务上下线 * \u003cp\u003e * 对该服务进行状态修改后，通过调用 /actuator/health 可以实时的获取到该服务的状态， * 而 Eureka Server 需要等到该服务上传心跳后，才会更新该服务的状态 * * @author wangshuo * @date 2021/01/06 */ @Service public class HealthStatusService implements HealthIndicator { private Boolean status = true; @Override public Health health() { return status ? new Health.Builder().up().build() : new Health.Builder().down().build(); } public void setStatus(Boolean status) { this.status = status; } public Boolean getStatus() { return this.status; } } 测试用的 Controller\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RestController; /** * @author wangshuo * @date 2021/01/05 */ @RestController public class ProviderController { @Autowired HealthStatusService healthStatusService; @PostMapping(\"/health/{status}\") public String setHealth(@PathVariable(\"status\") Boolean status) { healthStatusService.setStatus(status); return healthStatusService.getStatus().toString(); } } 注意事项\n1 2 3 4 5 6 7 8 9 # 如果配置了 server: servlet: path: /path # 需要配置 eureka: instance: statusPageUrlPath: ${server.servlet.path}/actuator/info healthCheckUrlPath: ${server.servlet.path}/actuator/health Eureka 监听事件 EurekaInstanceCanceledEvent 服务下线事件 EurekaInstanceRegisteredEvent 服务注册事件 EurekaInstanceRenewedEvent 服务续约事件 EurekaRegistryAvailableEvent 注册中心可用事件 EurekaServerStartedEvent 注册中心启动 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import org.springframework.cloud.netflix.eureka.server.event.EurekaInstanceCanceledEvent; import org.springframework.context.event.EventListener; import org.springframework.stereotype.Component; // 声明为组件 @Component public class CustomEvent { // 声明为监听事件 @EventListener public void listen(EurekaInstanceCanceledEvent e) { System.out.println(e.getServerId() + \"下线事件\"); } } Eureka Server 安全配置 Eureka Server 引入 Spring Security 进行简单地安全验证\npom.xml 引入 Spring Security 依赖\n1 2 3 4 5 \u003c!-- spring security starter --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-security\u003c/artifactId\u003e \u003c/dependency\u003e application.yaml 中添加登录用户名和密码\n1 2 3 4 5 spring: security: user: name: admin password: 123456 修改 Eureka Client 中的 service-url\n1 2 3 4 5 eureka: client: service-url: # 添加上一步中设置的用户名和密码 defaultZone: http://admin:123456@localhost:7900/eureka/ 关闭 Spring Security 的 CSRF 防护\nSpring Security 默认开启了防止跨域攻击，如果不关闭，Eureka Client 会注册失败，并报如下错误\nRoot name 'timestamp' does not match expected ('instance') for type [simple type, class com.netflix.appinfo.InstanceInfo]\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; /** * @author wangshuo * @date 2021/01/06 */ @Configuration @EnableWebSecurity public class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { // 允许 CSRF http.csrf().disable(); super.configure(http); } } 多网卡选择 服务器有多个网卡，eth0 和 eth1，其中 eth0 是用于内网访问的网卡，eth1 是用于外网访问的网卡。如果 Eureka Client 使用 eth0 注册到了 Eureak Server 上，这样外网的其他服务就无法访问到该服务了。\n解决方案\n1 2 3 4 5 6 eureka: instance: # 表示将自己的 ip 注册到 Eureka Server 上。如果不配置或为 false，表示将操作系统的 hostname 注册到 Eureka Server 上 prefer-ip-address: true # 设置为外部服务能够访问到的 IP ip-address: 39.105.30.251 通过该方式设置了 ip-address 后，在元数据中查看到的就是此 ip，其他服务就可以通过该 ip 来进行调用了\n","description":"","tags":["MSB","Spring Cloud","Eureka","Java"],"title":"Eureka","uri":"/posts/msb/spring-cloud/eureka/"},{"categories":null,"content":"eureka github：https://github.com/Netflix/eureka/\n帮助文档：https://github.com/Netflix/eureka/wiki\n调试环境：\nSpring Boot version：2.3.0.RELEASE\nSpring Cloud version：Hoxton.SR4\neureka 简介：\neureka 是 Netflix 开发的服务发现框架，本身是一个基于 REST 的服务（即对服务的注册，续约，下线等操作都是基于 http/https 请求的方式）;\neureka 包含两个组件：eureka server 和 eureka client\neureka server 提供服务注册服务，也就是常说的注册中心; 常说的服务提供者和消费者都是 eureka 的 eureka client。 eureka 调用流程 Eureka-Server 启动原理 1. 引入 EurekaServerAutoConfiguration 类 1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-server\u003c/artifactId\u003e \u003c/dependency\u003e 在spring-cloud-netflix-eureka-server-2.2.2.RELEASE.jar的spring.factories中\n1 2 3 # 在 SpringBoot 启动时，会自动加载该文件中的 bean org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ org.springframework.cloud.netflix.eureka.server.EurekaServerAutoConfiguration 1 2 3 // 根据当前容器中是否包含 Marker 类，来决定自动配置是否生效 @ConditionalOnBean(EurekaServerMarkerConfiguration.Marker.class) public class EurekaServerAutoConfiguration implements WebMvcConfigurer { 2. 使用 @EnableEurekaServer 注解向容器中注入 Marker 对象 1 2 @Import(EurekaServerMarkerConfiguration.class) public @interface EnableEurekaServer { 1 2 3 4 5 6 7 8 9 public class EurekaServerMarkerConfiguration { // 向容器中注入 Marker 对象，使得 EurekaServerAutoConfiguration 自动配置类生效 @Bean public Marker eurekaServerMarkerBean() { return new Marker(); } class Marker { } } eureka-server 集群配置 三个以上集群配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 eureka: client: # 是否向服务注册还总新注册自己，默认为 true，因为当前就是注册中心，所以需要禁用其向注册中心注册 register-with-eureka: false # 是否需要去探索寻找服务，因为是注册中心，它的任务是维护服务实例，所以不需要去寻找服务 fetch-registry: false service-url: defaultZone: http://eureka-7900:7900/eureka/,http://eureka-7901:7901/eureka/,http://eureka-7902:7902/eureka/ --- spring: profiles: 7900 server: port: 7900 eureka: instance: hostname: eureka-7900 --- spring: profiles: 7901 server: port: 7901 eureka: instance: hostname: eureka-7901 --- spring: profiles: 7902 server: port: 7902 eureka: instance: hostname: eureka-7902 eureka 的 CAP 原则 Consistency（一致性）：在分布式系统中的所有数据备份，在同一时刻是否是同样的值。（等同于所有节点访问同一份最新的数据副本）\nAvailability（可用性）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具有高可用性）\nPartition Tolerance（分区容错性）：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在 C 和 A 之间作出选择。\nCAP 理论 在一个分布式系统中，Consistency（一致性），Availability（可用性），Partition Tolerance（分区容错性），这三个要素最多只能同时实现两点，不可能三者兼顾。由于 P 是分布式系统中比需要保证的，所以我们只能在 C 和 A 之间进行权衡。Zookeeper 保证的是 CP，而 Eureka 保证的是 AP。\neureka server 优化（源码） 服务剔除（优化点） eureka-server 定期检查 provider 服务是否存活，对长时间没有心跳的服务，可以进行下线操作等。\nEurekaServerAutoConfiguration\n@Import(EurekaServerInitializerConfiguration.class)\npublic void start()\n1 2 eurekaServerBootstrap.contextInitialized( EurekaServerInitializerConfiguration.this.servletContext); initEurekaServerContext();\nthis.registry.openForTraffic(this.applicationInfoManager, registryCount);\n1 2 super.openForTraffic(applicationInfoManager, count == 0 ? this.defaultOpenForTrafficCount :count); super.postInit();\n1 2 3 4 5 6 7 8 9 10 11 protected void postInit() { renewsLastMin.start(); if (evictionTaskRef.get() != null) { evictionTaskRef.get().cancel(); } evictionTaskRef.set(new EvictionTask()); evictionTimer.schedule(evictionTaskRef.get(), // 在 eureka-server 中定期将没有心跳的服务清除 serverConfig.getEvictionIntervalTimerInMs(), serverConfig.getEvictionIntervalTimerInMs()); } EvictionTask.run\nevict(compensationTimeMs);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 public void evict(long additionalLeaseMs) { // 没开自我保护，则 isLeaseExpirationEnabled() 为 true，此处取反为 false，即没开自我保护一定执行后面的服务剔除逻辑 // 开启了自我保护，最后一分钟续约的次数\u003e每分钟续订次数的阈值，isLeaseExpirationEnabled()为 true，此处取反为 false，即最后一分钟续约的次数\u003e每分钟续订次数的阈值进行剔除 if (!isLeaseExpirationEnabled()) { logger.debug(\"DS: lease expiration is currently disabled.\"); return; } // We collect first all expired items, to evict them in random order. For large eviction sets, // if we do not that, we might wipe out whole apps before self preservation kicks in. By randomizing it, // the impact should be evenly distributed across all applications. List\u003cLease\u003cInstanceInfo\u003e\u003e expiredLeases = new ArrayList\u003c\u003e(); for (Entry\u003cString, Map\u003cString, Lease\u003cInstanceInfo\u003e\u003e\u003e groupEntry : registry.entrySet()) { Map\u003cString, Lease\u003cInstanceInfo\u003e\u003e leaseMap = groupEntry.getValue(); if (leaseMap != null) { for (Entry\u003cString, Lease\u003cInstanceInfo\u003e\u003e leaseEntry : leaseMap.entrySet()) { Lease\u003cInstanceInfo\u003e lease = leaseEntry.getValue(); if (lease.isExpired(additionalLeaseMs) \u0026\u0026 lease.getHolder() != null) { expiredLeases.add(lease); } } } } // To compensate for GC pauses or drifting local time, we need to use current registry size as a base for // triggering self-preservation. Without that we would wipe out full registry. int registrySize = (int) getLocalRegistrySize(); int registrySizeThreshold = (int) (registrySize * serverConfig.getRenewalPercentThreshold()); int evictionLimit = registrySize - registrySizeThreshold; int toEvict = Math.min(expiredLeases.size(), evictionLimit); if (toEvict \u003e 0) { logger.info(\"Evicting {} items (expired={}, evictionLimit={})\", toEvict, expiredLeases.size(), evictionLimit); Random random = new Random(System.currentTimeMillis()); for (int i = 0; i \u003c toEvict; i++) { // Pick a random item (Knuth shuffle algorithm) int next = i + random.nextInt(expiredLeases.size() - i); Collections.swap(expiredLeases, i, next); Lease\u003cInstanceInfo\u003e lease = expiredLeases.get(i); String appName = lease.getHolder().getAppName(); String id = lease.getHolder().getId(); EXPIRED.increment(); logger.warn(\"DS: Registry: expired lease for {}/{}\", appName, id); // 服务下线，即服务剔除的本质就是服务下线 internalCancel(appName, id, false); } } } isLeaseExpirationEnabled()\n1 2 3 4 5 6 7 8 9 10 public boolean isLeaseExpirationEnabled() { // 没有开启自我保护直接返回 true if (!isSelfPreservationModeEnabled()) { // The self preservation mode is disabled, hence allowing the instances to expire. return true; } // 开启了自我保护 // 最后一分钟续约的次数\u003e每分钟续订次数的阈值，返回 true，否则返回 false return numberOfRenewsPerMinThreshold \u003e 0 \u0026\u0026 getNumOfRenewsInLastMin() \u003e numberOfRenewsPerMinThreshold; } internalCancel(appName, id, false);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 protected boolean internalCancel(String appName, String id, boolean isReplication) { try { read.lock(); CANCEL.increment(isReplication); // 从 registry 缓存中拿到该实例 Map\u003cString, Lease\u003cInstanceInfo\u003e\u003e gMap = registry.get(appName); Lease\u003cInstanceInfo\u003e leaseToCancel = null; if (gMap != null) { // 从缓存中移除该实例，并用 leaseToCancel 引用它 leaseToCancel = gMap.remove(id); } // 添加到下线队列 recentCanceledQueue.add(new Pair\u003cLong, String\u003e(System.currentTimeMillis(), appName + \"(\" + id + \")\")); InstanceStatus instanceStatus = overriddenInstanceStatusMap.remove(id); if (instanceStatus != null) { logger.debug(\"Removed instance id {} from the overridden map which has value {}\", id, instanceStatus.name()); } if (leaseToCancel == null) { CANCEL_NOT_FOUND.increment(isReplication); logger.warn(\"DS: Registry: cancel failed because Lease is not registered for: {}/{}\", appName, id); return false; } else { // 调用下线方法 leaseToCancel.cancel(); InstanceInfo instanceInfo = leaseToCancel.getHolder(); String vip = null; String svip = null; if (instanceInfo != null) { instanceInfo.setActionType(ActionType.DELETED); recentlyChangedQueue.add(new RecentlyChangedItem(leaseToCancel)); instanceInfo.setLastUpdatedTimestamp(); vip = instanceInfo.getVIPAddress(); svip = instanceInfo.getSecureVipAddress(); } // 从 readWriteCache 中清除该实例 invalidateCache(appName, vip, svip); logger.info(\"Cancelled instance {}/{} (replication={})\", appName, id, isReplication); } } finally { read.unlock(); } synchronized (lock) { if (this.expectedNumberOfClientsSendingRenews \u003e 0) { // Since the client wants to cancel it, reduce the number of clients to send renews. this.expectedNumberOfClientsSendingRenews = this.expectedNumberOfClientsSendingRenews - 1; updateRenewsPerMinThreshold(); } } return true; } 配置方式\n1 2 3 4 5 # 在 eureka server 中配置 eureka: server: # 剔除服务的检测时间间隔，默认 60s eviction-interval-timer-in-ms: 60000 面试题\npostInit() 方法中使用 evictionTimer（是个 Timer 类的对象）进行定时任务的调用，阿里巴巴 p3c 插件不推荐使用 Timer 进行定时任务调用，因为 Timer 运行多个 TimerTask 时，只要其中之一没有捕获抛出的异常，其他任务便会自动终止运行；建议使用 ScheduledExecutorService。\n自我保护（优化点） eureka server 会定期对 provider 服务进行心跳统计。如果开启自我保护，当最后一分钟有心跳服务个数/总服务数低于阈值（85%），就会触发自我保护，会将有心跳的服务保护起来，如果之后这些被保护的服务中又有服务故障了，eureka server 不会将这些服务进行剔除，此时客户端就可能会调用到这些故障服务。如果关闭自我保护，eureka-server 就总会将故障服务进行剔除，保证客户端不会调用到故障服务。\n当服务数量少的时候，请求到故障服务的概率高，服务大概率是真挂掉了，应该把故障服务尽快剔除，所以应该关闭自我保护。\n当服务数量多的时候，请求到故障服务的概率低，可能是由于网络原因出现的抖动，所以应该开启自我保护。\nPeerAwareInstanceRegistryImpl\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public void openForTraffic(ApplicationInfoManager applicationInfoManager, int count) { // 自我保护阈值的设置 // Renewals happen every 30 seconds and for a minute it should be a factor of 2. this.expectedNumberOfClientsSendingRenews = count; updateRenewsPerMinThreshold(); logger.info(\"Got {} instances from neighboring DS node\", count); logger.info(\"Renew threshold is: {}\", numberOfRenewsPerMinThreshold); this.startupTime = System.currentTimeMillis(); if (count \u003e 0) { this.peerInstancesTransferEmptyOnStartup = false; } DataCenterInfo.Name selfName = applicationInfoManager.getInfo().getDataCenterInfo().getName(); boolean isAws = Name.Amazon == selfName; if (isAws \u0026\u0026 serverConfig.shouldPrimeAwsReplicaConnections()) { logger.info(\"Priming AWS connections for all replicas..\"); primeAwsReplicas(applicationInfoManager); } logger.info(\"Changing status to UP\"); applicationInfoManager.setInstanceStatus(InstanceStatus.UP); super.postInit(); } updateRenewsPerMinThreshold();\n1 2 3 4 5 6 protected void updateRenewsPerMinThreshold() { this.numberOfRenewsPerMinThreshold = (int) (this.expectedNumberOfClientsSendingRenews * (60.0 / serverConfig.getExpectedClientRenewalIntervalSeconds()) // 对应配置中的 renewal-percent-threshold，设置触发自我保护的阈值 * serverConfig.getRenewalPercentThreshold()); } 配置方式\n1 2 3 4 5 6 7 # 在 eureka server 中配置 eureka: server: # 是否开启自我保护机制，默认是 true enable-self-preservation: false # 触发自我保护的阈值（有心跳服务/总服务），默认 0.85 renewal-percent-threshold: 0.85 三级缓存（优化点） eureka 使用了三级缓存：registry、readWriteCache、readOnlyCache，因此其没有保证 CAP 中的 C（一致性）。\n服务注册/取消注册等写操作，会直接写到 registry 中，并将该服务从 readWriteCache 中移除；当获取该服务时，会将 registry 中的服务与 readWriteCache 进行同步，因此 registry 和 readWriteCache 中同一服务是实时同步的。\n获取服务等读操作，先从 readOnlyCache 中读，如果读不到再从 readWriteCache 读，还读不到就从 registry 中读取\n写操作（服务注册） 读操作（服务拉取） 关闭 ReadOnlyCache 可以减少一次查询，从而提升访问速度，配置方式如下\n1 2 3 4 5 # 在 eureka server 中配置 eureka: server: # 关闭从 readOnlyCache 读注册表，默认 true use-read-only-response-cache: false readWriteCache 向 readOnlyCache 的同步 ResponseCacheImpl\n1 2 3 4 5 6 7 8 9 10 11 12 ResponseCacheImpl(EurekaServerConfig serverConfig, ServerCodecs serverCodecs, AbstractInstanceRegistry registry) { // ... // 如果开启 readOnlyCache，会定时将 readWriteCache 向 readOnlyCache 进行同步 if (shouldUseReadOnlyResponseCache) { timer.schedule(getCacheUpdateTask(), new Date(((System.currentTimeMillis() / responseCacheUpdateIntervalMs) * responseCacheUpdateIntervalMs) + responseCacheUpdateIntervalMs), // 通过该属性进行修改同步的时间间隔 responseCacheUpdateIntervalMs); } // ... } 如果开启了 ReadOnlyCache，可以通过如下配置调整同步的时间间隔\n1 2 3 4 5 # 在 eureka server 中配置 eureka: server: # readWriteCache 向 readOnlyCache 同步注册表的时间间隔，默认 30s response-cache-update-interval-ms: 1000 服务注册 此处启动两个 eureka server 搭建集群，分别标记为 7900 和 7901，然后发送请求让 eureka client 向 7900 进行注册。\n服务注册请求：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 POST http://localhost:7900/eureka/apps/my-service Accept: application/json Content-Type: application/xml \u003cinstance\u003e \u003cinstanceId\u003emy-instance-id\u003c/instanceId\u003e \u003chostName\u003elocalhost\u003c/hostName\u003e \u003capp\u003emy-service\u003c/app\u003e \u003cipAddr\u003e127.0.0.1\u003c/ipAddr\u003e \u003cstatus\u003eUP\u003c/status\u003e \u003coverridenstatus\u003eUNKNOWN\u003c/overridenstatus\u003e \u003cport enabled=\"true\"\u003e1900\u003c/port\u003e \u003csecurePort enabled=\"false\"\u003e443\u003c/securePort\u003e \u003ccountryId\u003e1\u003c/countryId\u003e \u003cdataCenterInfo class=\"com.netflix.appinfo.InstanceInfo$DefaultDataCenterInfo\"\u003e \u003cname\u003eMyOwn\u003c/name\u003e \u003c/dataCenterInfo\u003e \u003c/instance\u003e debug 源码：\n先执行 1️⃣，1️⃣执行结束后回过头从 addInstance()方法开始执行 2️⃣\n1 2 3 4 5 6 7 8 9 10 11 ApplicationResource.addInstance(InstanceInfo info, @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication){ /* * 服务注册分为两种情况 * 1️⃣. eureka client（包括 provider 和 consumer）向 eureka server 发起的服务注册，此时 isReplication 为 false * 2️⃣. eureka server 向 eureka server 的 peer 发起的服务注册请求，是将当前刚注册在 eureka server 上的该 eureka client 复制到 eureka server 的 peer 上，此时 isReplication 为 true */ // 1️⃣eureka client 向 7900 发起服务注册请求，此时 isReplication 为 false，当前服务为 7900 // 2️⃣7900 向 7901 发起服务注册请求，把刚注册在 7900 上的 eureka client 复制到 7901 上，此时 isReplication 为 true，当前服务已经变为 7901 registry.register(info, \"true\".equals(isReplication)); } 1 2 3 4 5 6 7 8 9 10 11 12 // PeerAwareInstanceRegistryImpl.java public void register(final InstanceInfo info, final boolean isReplication) { int leaseDuration = Lease.DEFAULT_DURATION_IN_SECS; if (info.getLeaseInfo() != null \u0026\u0026 info.getLeaseInfo().getDurationInSecs() \u003e 0) { leaseDuration = info.getLeaseInfo().getDurationInSecs(); } // 1️⃣2️⃣注册到当前 eureka server super.register(info, leaseDuration, isReplication); // 1️⃣向 7900 注册完成后，会将该服务同步注册到 peer(7901)上 // 2️⃣7900 向 7901 发起注册请求时，isReplication 为 true replicateToPeers(Action.Register, info.getAppName(), info.getId(), info, null, isReplication); } super.register(info, leaseDuration, isReplication);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 AbstractInstanceRegistry.register(InstanceInfo registrant, int leaseDuration, boolean isReplication) { try { read.lock(); // ConcurrentHashMap\u003cString, Map\u003cString, Lease\u003cInstanceInfo\u003e\u003e\u003e registry // Map\u003cAppName,Map\u003cid, 服务具体信息\u003e\u003e\u003e Map\u003cString, Lease\u003cInstanceInfo\u003e\u003e gMap = registry.get(registrant.getAppName()); REGISTER.increment(isReplication); // 1️⃣2️⃣如果 registry 中不包含该实例，就把它注册进去 if (gMap == null) { final ConcurrentHashMap\u003cString, Lease\u003cInstanceInfo\u003e\u003e gNewMap = new ConcurrentHashMap\u003cString, Lease\u003cInstanceInfo\u003e\u003e(); // 1️⃣2️⃣向 registry 中添加一个空的 Map，在后面会对其进行填充 gMap = registry.putIfAbsent(registrant.getAppName(), gNewMap); if (gMap == null) { gMap = gNewMap; } } Lease\u003cInstanceInfo\u003e existingLease = gMap.get(registrant.getId()); // Retain the last dirty timestamp without overwriting it, if there is already a lease if (existingLease != null \u0026\u0026 (existingLease.getHolder() != null)) { Long existingLastDirtyTimestamp = existingLease.getHolder().getLastDirtyTimestamp(); Long registrationLastDirtyTimestamp = registrant.getLastDirtyTimestamp(); logger.debug(\"Existing lease found (existing={}, provided={}\", existingLastDirtyTimestamp, registrationLastDirtyTimestamp); // this is a \u003e instead of a \u003e= because if the timestamps are equal, we still take the remote transmitted // InstanceInfo instead of the server local copy. if (existingLastDirtyTimestamp \u003e registrationLastDirtyTimestamp) { logger.warn(\"There is an existing lease and the existing lease's dirty timestamp {} is greater\" + \" than the one that is being registered {}\", existingLastDirtyTimestamp, registrationLastDirtyTimestamp); logger.warn(\"Using the existing instanceInfo instead of the new instanceInfo as the registrant\"); registrant = existingLease.getHolder(); } } else { // The lease does not exist and hence it is a new registration synchronized (lock) { if (this.expectedNumberOfClientsSendingRenews \u003e 0) { // Since the client wants to register it, increase the number of clients sending renews this.expectedNumberOfClientsSendingRenews = this.expectedNumberOfClientsSendingRenews + 1; updateRenewsPerMinThreshold(); } } logger.debug(\"No previous lease information found; it is new registration\"); } // 1️⃣2️⃣存放 registrant 信息 Lease\u003cInstanceInfo\u003e lease = new Lease\u003cInstanceInfo\u003e(registrant, leaseDuration); if (existingLease != null) { lease.setServiceUpTimestamp(existingLease.getServiceUpTimestamp()); } // 1️⃣2️⃣把 registrant 的信息填充到 gMap 中 gMap.put(registrant.getId(), lease); recentRegisteredQueue.add(new Pair\u003cLong, String\u003e( System.currentTimeMillis(), registrant.getAppName() + \"(\" + registrant.getId() + \")\")); // This is where the initial state transfer of overridden status happens if (!InstanceStatus.UNKNOWN.equals(registrant.getOverriddenStatus())) { logger.debug(\"Found overridden status {} for instance {}. Checking to see if needs to be add to the \" + \"overrides\", registrant.getOverriddenStatus(), registrant.getId()); if (!overriddenInstanceStatusMap.containsKey(registrant.getId())) { logger.info(\"Not found overridden id {} and hence adding it\", registrant.getId()); overriddenInstanceStatusMap.put(registrant.getId(), registrant.getOverriddenStatus()); } } InstanceStatus overriddenStatusFromMap = overriddenInstanceStatusMap.get(registrant.getId()); if (overriddenStatusFromMap != null) { logger.info(\"Storing overridden status {} from map\", overriddenStatusFromMap); registrant.setOverriddenStatus(overriddenStatusFromMap); } // Set the status based on the overridden status rules InstanceStatus overriddenInstanceStatus = getOverriddenInstanceStatus(registrant, existingLease, isReplication); registrant.setStatusWithoutDirty(overriddenInstanceStatus); // If the lease is registered with UP status, set lease service up timestamp if (InstanceStatus.UP.equals(registrant.getStatus())) { lease.serviceUp(); } registrant.setActionType(ActionType.ADDED); // 1️⃣2️⃣把新注册的 eureka client 添加到最近改变队列，可用来减少拉取注册表时的数据量 recentlyChangedQueue.add(new RecentlyChangedItem(lease)); registrant.setLastUpdatedTimestamp(); // 1️⃣2️⃣让 readWriteCache 中该 registrant 的注册信息失效 invalidateCache(registrant.getAppName(), registrant.getVIPAddress(), registrant.getSecureVipAddress()); logger.info(\"Registered instance {}/{} with status {} (replication={})\", registrant.getAppName(), registrant.getId(), registrant.getStatus(), isReplication); } finally { read.unlock(); } } invalidateCache(registrant.getAppName(), registrant.getVIPAddress(), registrant.getSecureVipAddress())\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public void invalidate(Key... keys) { for (Key key : keys) { logger.debug(\"Invalidating the response cache key : {} {} {} {}, {}\", key.getEntityType(), key.getName(), key.getVersion(), key.getType(), key.getEurekaAccept()); // 1️⃣2️⃣从 readWriteCacheMap 中把该服务删除 readWriteCacheMap.invalidate(key); Collection\u003cKey\u003e keysWithRegions = regionSpecificKeys.get(key); if (null != keysWithRegions \u0026\u0026 !keysWithRegions.isEmpty()) { for (Key keysWithRegion : keysWithRegions) { logger.debug(\"Invalidating the response cache key : {} {} {} {} {}\", key.getEntityType(), key.getName(), key.getVersion(), key.getType(), key.getEurekaAccept()); readWriteCacheMap.invalidate(keysWithRegion); } } } } replicateToPeers(Action.Register, info.getAppName(), info.getId(), info, null, isReplication);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // 1️⃣向 7900 注册完成后，会将该服务复制到 peer(7901)上，注意，此时 isReplication 为 false // 2️⃣7900 向 7901 发起服务注册请求时, isReplication 为 true private void replicateToPeers(Action action, String appName, String id, InstanceInfo info /* optional */, InstanceStatus newStatus /* optional */, boolean isReplication) { Stopwatch tracer = action.getTimer().start(); try { if (isReplication) { numberOfReplicationsLastMin.increment(); } /* * 如果 peerEurekaNodes 为 Empty，说明当前是单节点 eureka server，所以不需要进行同步注册，直接 return * 如果 isReplicaiton 为 true，说明当前注册请求是 peer 发过来的，不需要再向当前 eureka server 的 peer 进行注册，直接 return. * 如果 isReplication 为 false，说明当前请求是 eureka client 发出的服务注册请求，需要将当前服务同步到当前 eureka server 的 peer，所以执行下方服务同步代码。 */ // 1️⃣eureke client 向 7900 注册时，isReplicaiton=false，所以执行下方同步代码 // 2️⃣7900 向 7901 发起服务注册请求时，isReplication=true，不会再向 7901 的 peer 进行同步了，执行结束 // If it is a replication already, do not replicate again as this will create a poison replication if (peerEurekaNodes == Collections.EMPTY_LIST || isReplication) { return; } // 1️⃣eureka server 集群间服务复制代码 for (final PeerEurekaNode node : peerEurekaNodes.getPeerEurekaNodes()) { // If the url represents this host, do not replicate to yourself. if (peerEurekaNodes.isThisMyUrl(node.getServiceUrl())) { continue; } // 1️⃣将当前服务注册到 peer 节点 replicateInstanceActionsToPeers(action, appName, id, info, newStatus, node); } } finally { tracer.stop(); } } replicateInstanceActionsToPeers(action, appName, id, info, newStatus, node);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 private void replicateInstanceActionsToPeers(Action action, String appName, String id, InstanceInfo info, InstanceStatus newStatus, PeerEurekaNode node) { // ... switch (action) { // ... // 1️⃣eureka client 服务注册走该分支 case Register: node.register(info); break; // ... } // ... } node.register(info);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 1️⃣此时的服务注册是将已经注册在 7900 上的该服务注册到 peer（7901）上 public void register(final InstanceInfo info) throws Exception { long expiryTime = System.currentTimeMillis() + getLeaseRenewalOf(info); batchingDispatcher.process( taskId(\"register\", info), // 1️⃣此处 isReplication 写死为 true，标识当前注册请求是复制请求 new InstanceReplicationTask(targetHost, Action.Register, info, null, true) { public EurekaHttpResponse\u003cVoid\u003e execute() { // 1️⃣给 peer 发送服务注册请求，此时 isReplicaiton=false，告诉 peer 该注册请求是复制请求，不需要再次向 peer 的 peer 进行注册 return replicationClient.register(info); } }, expiryTime ); } replicationClient.register(info);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public EurekaHttpResponse\u003cVoid\u003e register(InstanceInfo info) { String urlPath = \"apps/\" + info.getAppName(); ClientResponse response = null; try { Builder resourceBuilder = jerseyClient.resource(serviceUrl).path(urlPath).getRequestBuilder(); addExtraHeaders(resourceBuilder); response = resourceBuilder .header(\"Accept-Encoding\", \"gzip\") .type(MediaType.APPLICATION_JSON_TYPE) .accept(MediaType.APPLICATION_JSON) .post(ClientResponse.class, info); // 1️⃣向 peer（7901）发送服务注册请求，此时会调用 7901 服务的 addInstance 方法（从头走 2️⃣） return anEurekaHttpResponse(response.getStatus()).headers(headersOf(response)).build(); } finally { if (logger.isDebugEnabled()) { logger.debug(\"Jersey HTTP POST {}/{} with instance {}; statusCode={}\", serviceUrl, urlPath, info.getId(), response == null ? \"N/A\" : response.getStatus()); } if (response != null) { response.close(); } } } 服务续约/心跳 续约请求：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 PUT http://localhost:7900/eureka/apps/my-service/my-instance-id Accept: application/json Content-Type: application/xml \u003cinstance\u003e \u003cinstanceId\u003emy-instance-id\u003c/instanceId\u003e \u003chostName\u003elocalhost\u003c/hostName\u003e \u003capp\u003emy-service\u003c/app\u003e \u003cipAddr\u003e127.0.0.1\u003c/ipAddr\u003e \u003cstatus\u003eUP\u003c/status\u003e \u003coverridenstatus\u003eUNKNOWN\u003c/overridenstatus\u003e \u003cport enabled=\"true\"\u003e1900\u003c/port\u003e \u003csecurePort enabled=\"false\"\u003e443\u003c/securePort\u003e \u003ccountryId\u003e1\u003c/countryId\u003e \u003cdataCenterInfo class=\"com.netflix.appinfo.InstanceInfo$DefaultDataCenterInfo\"\u003e \u003cname\u003eMyOwn\u003c/name\u003e \u003c/dataCenterInfo\u003e \u003c/instance\u003e debug 源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // InstanceResource.java @PUT public Response renewLease( @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication, @QueryParam(\"overriddenstatus\") String overriddenStatus, @QueryParam(\"status\") String status, @QueryParam(\"lastDirtyTimestamp\") String lastDirtyTimestamp) { // 续约时，isReplication=false，所以也需要向 peer 节点进行复制 boolean isFromReplicaNode = \"true\".equals(isReplication); // 进行续约 boolean isSuccess = registry.renew(app.getName(), id, isFromReplicaNode); // Not found in the registry, immediately ask for a register if (!isSuccess) { logger.warn(\"Not Found (Renew): {} - {}\", app.getName(), id); return Response.status(Status.NOT_FOUND).build(); } // Check if we need to sync based on dirty time stamp, the client // instance might have changed some value Response response; if (lastDirtyTimestamp != null \u0026\u0026 serverConfig.shouldSyncWhenTimestampDiffers()) { response = this.validateDirtyTimestamp(Long.valueOf(lastDirtyTimestamp), isFromReplicaNode); // Store the overridden status since the validation found out the node that replicates wins if (response.getStatus() == Response.Status.NOT_FOUND.getStatusCode() \u0026\u0026 (overriddenStatus != null) \u0026\u0026 !(InstanceStatus.UNKNOWN.name().equals(overriddenStatus)) \u0026\u0026 isFromReplicaNode) { registry.storeOverriddenStatusIfRequired(app.getAppName(), id, InstanceStatus.valueOf(overriddenStatus)); } } else { response = Response.ok().build(); } logger.debug(\"Found (Renew): {} - {}; reply status={}\", app.getName(), id, response.getStatus()); return response; } boolean isSuccess = registry.renew(app.getName(), id, isFromReplicaNode);\nsuper.renew(appName, serverId, isReplication)\nif(super.renew(appName, id, isReplication))\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 public boolean renew(String appName, String id, boolean isReplication) { RENEW.increment(isReplication); Map\u003cString, Lease\u003cInstanceInfo\u003e\u003e gMap = registry.get(appName); Lease\u003cInstanceInfo\u003e leaseToRenew = null; if (gMap != null) { leaseToRenew = gMap.get(id); } if (leaseToRenew == null) { RENEW_NOT_FOUND.increment(isReplication); logger.warn(\"DS: Registry: lease doesn't exist, registering resource: {} - {}\", appName, id); return false; } else { InstanceInfo instanceInfo = leaseToRenew.getHolder(); if (instanceInfo != null) { // touchASGCache(instanceInfo.getASGName()); InstanceStatus overriddenInstanceStatus = this.getOverriddenInstanceStatus( instanceInfo, leaseToRenew, isReplication); if (overriddenInstanceStatus == InstanceStatus.UNKNOWN) { logger.info(\"Instance status UNKNOWN possibly due to deleted override for instance {}\" + \"; re-register required\", instanceInfo.getId()); RENEW_NOT_FOUND.increment(isReplication); return false; } if (!instanceInfo.getStatus().equals(overriddenInstanceStatus)) { logger.info( \"The instance status {} is different from overridden instance status {} for instance {}. \" + \"Hence setting the status to overridden status\", instanceInfo.getStatus().name(), instanceInfo.getOverriddenStatus().name(), instanceInfo.getId()); instanceInfo.setStatusWithoutDirty(overriddenInstanceStatus); } } renewsLastMin.increment(); // 续约 leaseToRenew.renew(); return true; } } leaseToRenew.renew();\n1 2 3 4 public void renew() { // 续约就是只更新 lastUpdateTimestamp 的时间 lastUpdateTimestamp = System.currentTimeMillis() + duration; } replicateToPeers(Action.Heartbeat, appName, id, null, null, isReplication);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // 服务续约/心跳后也需要将其更新后的信息复制到 peer 节点 private void replicateToPeers(Action action, String appName, String id, InstanceInfo info /* optional */, InstanceStatus newStatus /* optional */, boolean isReplication) { Stopwatch tracer = action.getTimer().start(); try { if (isReplication) { numberOfReplicationsLastMin.increment(); } // 服务续约时，isReplicaiton 为 false // If it is a replication already, do not replicate again as this will create a poison replication if (peerEurekaNodes == Collections.EMPTY_LIST || isReplication) { return; } for (final PeerEurekaNode node : peerEurekaNodes.getPeerEurekaNodes()) { // If the url represents this host, do not replicate to yourself. if (peerEurekaNodes.isThisMyUrl(node.getServiceUrl())) { continue; } // 进行复制 replicateInstanceActionsToPeers(action, appName, id, info, newStatus, node); } } finally { tracer.stop(); } } replicateInstanceActionsToPeers(action, appName, id, info, newStatus, node);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 private void replicateInstanceActionsToPeers(Action action, String appName, String id, InstanceInfo info, InstanceStatus newStatus, PeerEurekaNode node) { // ... switch (action) { // ... // 服务续约/心跳走该分支 case Heartbeat: InstanceStatus overriddenStatus = overriddenInstanceStatusMap.get(id); infoFromRegistry = getInstanceByAppAndId(appName, id, false); node.heartbeat(appName, id, infoFromRegistry, overriddenStatus, false); break; // ... } // ... } node.heartbeat(appName, id, infoFromRegistry, overriddenStatus, false);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public void heartbeat(final String appName, final String id, final InstanceInfo info, final InstanceStatus overriddenStatus, boolean primeConnection) throws Throwable { if (primeConnection) { // We do not care about the result for priming request. replicationClient.sendHeartBeat(appName, id, info, overriddenStatus); return; } // 此处指定 isReplication=false，所以会把该续约后的服务复制到所有可达的 peer 上 // 此处与服务注册时有明显不同，服务注册时只会复制到相邻的 peer，此处会把该服务复制到所有可达的 peer 上 ReplicationTask replicationTask = new InstanceReplicationTask(targetHost, Action.Heartbeat, info, overriddenStatus, false) { @Override public EurekaHttpResponse\u003cInstanceInfo\u003e execute() throws Throwable { return replicationClient.sendHeartBeat(appName, id, info, overriddenStatus); } @Override public void handleFailure(int statusCode, Object responseEntity) throws Throwable { super.handleFailure(statusCode, responseEntity); if (statusCode == 404) { logger.warn(\"{}: missing entry.\", getTaskName()); if (info != null) { logger.warn(\"{}: cannot find instance id {} and hence replicating the instance with status {}\", getTaskName(), info.getId(), info.getStatus()); register(info); } } else if (config.shouldSyncWhenTimestampDiffers()) { InstanceInfo peerInstanceInfo = (InstanceInfo) responseEntity; if (peerInstanceInfo != null) { syncInstancesIfTimestampDiffers(appName, id, info, peerInstanceInfo); } } } }; long expiryTime = System.currentTimeMillis() + getLeaseRenewalOf(info); batchingDispatcher.process(taskId(\"heartbeat\", info), replicationTask, expiryTime); } 配置方式\n1 2 3 4 5 # 在 provider 服务中配置 eureka: instance: # 服务续约时间间隔，默认 30s lease-renewal-interval-in-seconds: 30 服务下线 下线请求：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 DELETE http://localhost:7900/eureka/apps/my-service/my-instance-id Accept: application/json Content-Type: application/xml \u003cinstance\u003e \u003cinstanceId\u003emy-instance-id\u003c/instanceId\u003e \u003chostName\u003elocalhost\u003c/hostName\u003e \u003capp\u003emy-service\u003c/app\u003e \u003cipAddr\u003e127.0.0.1\u003c/ipAddr\u003e \u003cstatus\u003eUP\u003c/status\u003e \u003coverridenstatus\u003eUNKNOWN\u003c/overridenstatus\u003e \u003cport enabled=\"true\"\u003e1900\u003c/port\u003e \u003csecurePort enabled=\"false\"\u003e443\u003c/securePort\u003e \u003ccountryId\u003e1\u003c/countryId\u003e \u003cdataCenterInfo class=\"com.netflix.appinfo.InstanceInfo$DefaultDataCenterInfo\"\u003e \u003cname\u003eMyOwn\u003c/name\u003e \u003c/dataCenterInfo\u003e \u003c/instance\u003e debug 源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // InstanceResource.java @DELETE public Response cancelLease( @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication) { try { // 服务下线时, isReplication=false boolean isSuccess = registry.cancel(app.getName(), id, \"true\".equals(isReplication)); if (isSuccess) { logger.debug(\"Found (Cancel): {} - {}\", app.getName(), id); return Response.ok().build(); } else { logger.info(\"Not Found (Cancel): {} - {}\", app.getName(), id); return Response.status(Status.NOT_FOUND).build(); } } catch (Throwable e) { logger.error(\"Error (cancel): {} - {}\", app.getName(), id, e); return Response.serverError().build(); } } boolean isSuccess = registry.cancel(app.getName(), id, \"true\".equals(isReplication));\nhandleCancelation(appName, serverId, isReplication);\n1 2 3 4 5 6 private void handleCancelation(String appName, String id, boolean isReplication) { log(\"cancel \" + appName + \", serverId \" + id + \", isReplication \" + isReplication); // 发布下线事件 publishEvent(new EurekaInstanceCanceledEvent(this, appName, id, isReplication)); } super.cancel(appName, serverId, isReplication);\nif (super.cancel(appName, id, isReplication))\ninternalCancel(appName, id, isReplication);\nsuper.internalCancel(appName, id, isReplication);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 protected boolean internalCancel(String appName, String id, boolean isReplication) { try { read.lock(); CANCEL.increment(isReplication); // 从 registry 缓存中拿到该实例 Map\u003cString, Lease\u003cInstanceInfo\u003e\u003e gMap = registry.get(appName); Lease\u003cInstanceInfo\u003e leaseToCancel = null; if (gMap != null) { // 从缓存中移除该实例，并用 leaseToCancel 引用它 leaseToCancel = gMap.remove(id); } // 添加到下线队列 recentCanceledQueue.add(new Pair\u003cLong, String\u003e(System.currentTimeMillis(), appName + \"(\" + id + \")\")); InstanceStatus instanceStatus = overriddenInstanceStatusMap.remove(id); if (instanceStatus != null) { logger.debug(\"Removed instance id {} from the overridden map which has value {}\", id, instanceStatus.name()); } if (leaseToCancel == null) { CANCEL_NOT_FOUND.increment(isReplication); logger.warn(\"DS: Registry: cancel failed because Lease is not registered for: {}/{}\", appName, id); return false; } else { // 调用下线方法 leaseToCancel.cancel(); InstanceInfo instanceInfo = leaseToCancel.getHolder(); String vip = null; String svip = null; if (instanceInfo != null) { instanceInfo.setActionType(ActionType.DELETED); recentlyChangedQueue.add(new RecentlyChangedItem(leaseToCancel)); instanceInfo.setLastUpdatedTimestamp(); vip = instanceInfo.getVIPAddress(); svip = instanceInfo.getSecureVipAddress(); } // 从 readWriteCache 中清除该实例 invalidateCache(appName, vip, svip); logger.info(\"Cancelled instance {}/{} (replication={})\", appName, id, isReplication); } } finally { read.unlock(); } synchronized (lock) { if (this.expectedNumberOfClientsSendingRenews \u003e 0) { // Since the client wants to cancel it, reduce the number of clients to send renews. this.expectedNumberOfClientsSendingRenews = this.expectedNumberOfClientsSendingRenews - 1; updateRenewsPerMinThreshold(); } } return true; } leaseToCancel.cancel();\n1 2 3 4 5 6 7 public void cancel() { if (evictionTimestamp \u003c= 0) { // 将该实例的 evictionTimestamp 时间修改为当前时间 // 服务剔除的本质其实也是服务下线 evictionTimestamp = System.currentTimeMillis(); } } replicateToPeers(Action.Cancel, appName, id, null, null, isReplication);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // 服务下线后也需要将其复制到 peer 节点 private void replicateToPeers(Action action, String appName, String id, InstanceInfo info /* optional */, InstanceStatus newStatus /* optional */, boolean isReplication) { Stopwatch tracer = action.getTimer().start(); try { if (isReplication) { numberOfReplicationsLastMin.increment(); } // 服务下线时, isReplicaiton 也为 false // If it is a replication already, do not replicate again as this will create a poison replication if (peerEurekaNodes == Collections.EMPTY_LIST || isReplication) { return; } for (final PeerEurekaNode node : peerEurekaNodes.getPeerEurekaNodes()) { // If the url represents this host, do not replicate to yourself. if (peerEurekaNodes.isThisMyUrl(node.getServiceUrl())) { continue; } // 进行复制 replicateInstanceActionsToPeers(action, appName, id, info, newStatus, node); } } finally { tracer.stop(); } } replicateInstanceActionsToPeers(action, appName, id, info, newStatus, node);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 private void replicateInstanceActionsToPeers(Action action, String appName, String id, InstanceInfo info, InstanceStatus newStatus, PeerEurekaNode node) { // ... switch (action) { // ... // 服务下线走该分支 case Cancel: node.cancel(appName, id); break; // ... } // ... } node.cancel(appName, id);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public void cancel(final String appName, final String id) throws Exception { long expiryTime = System.currentTimeMillis() + maxProcessingDelayMs; batchingDispatcher.process( taskId(\"cancel\", appName, id), // 服务下线这没有指定 isReplication 的值，默认为 false，所以会将所有可达的 peer 上的该服务全部都下线 // 此处与服务续约相同，与服务注册不同 new InstanceReplicationTask(targetHost, Action.Cancel, appName, id) { @Override public EurekaHttpResponse\u003cVoid\u003e execute() { return replicationClient.cancel(appName, id); } @Override public void handleFailure(int statusCode, Object responseEntity) throws Throwable { super.handleFailure(statusCode, responseEntity); if (statusCode == 404) { logger.warn(\"{}: missing entry.\", getTaskName()); } } }, expiryTime ); } 服务拉取 服务拉取分为全量拉取和增量拉取，增量拉取是从\n全量拉取 GET http://localhost:7900/eureka/apps 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 // ApplicationsResource.java @GET public Response getContainers(@PathParam(\"version\") String version, @HeaderParam(HEADER_ACCEPT) String acceptHeader, @HeaderParam(HEADER_ACCEPT_ENCODING) String acceptEncoding, @HeaderParam(EurekaAccept.HTTP_X_EUREKA_ACCEPT) String eurekaAccept, @Context UriInfo uriInfo, @Nullable @QueryParam(\"regions\") String regionsStr) { boolean isRemoteRegionRequested = null != regionsStr \u0026\u0026 !regionsStr.isEmpty(); String[] regions = null; if (!isRemoteRegionRequested) { EurekaMonitors.GET_ALL.increment(); } else { regions = regionsStr.toLowerCase().split(\",\"); Arrays.sort(regions); // So we don't have different caches for same regions queried in different order. EurekaMonitors.GET_ALL_WITH_REMOTE_REGIONS.increment(); } // Check if the server allows the access to the registry. The server can // restrict access if it is not // ready to serve traffic depending on various reasons. if (!registry.shouldAllowAccess(isRemoteRegionRequested)) { return Response.status(Status.FORBIDDEN).build(); } CurrentRequestVersion.set(Version.toEnum(version)); KeyType keyType = Key.KeyType.JSON; String returnMediaType = MediaType.APPLICATION_JSON; if (acceptHeader == null || !acceptHeader.contains(HEADER_JSON_VALUE)) { keyType = Key.KeyType.XML; returnMediaType = MediaType.APPLICATION_XML; } Key cacheKey = new Key(Key.EntityType.Application, ResponseCacheImpl.ALL_APPS, keyType, CurrentRequestVersion.get(), EurekaAccept.fromString(eurekaAccept), regions ); Response response; if (acceptEncoding != null \u0026\u0026 acceptEncoding.contains(HEADER_GZIP_VALUE)) { // 全量拉取的 cacheKey 为 ALL_APPS response = Response.ok(responseCache.getGZIP(cacheKey)) .header(HEADER_CONTENT_ENCODING, HEADER_GZIP_VALUE) .header(HEADER_CONTENT_TYPE, returnMediaType) .build(); } else { response = Response.ok(responseCache.get(cacheKey)) .build(); } CurrentRequestVersion.remove(); return response; } responseCache.getGZIP(cacheKey)\n1 2 3 4 5 6 7 public byte[] getGZIP(Key key) { Value payload = getValue(key, shouldUseReadOnlyResponseCache); if (payload == null) { return null; } return payload.getGzipped(); } getValue(key, shouldUseReadOnlyResponseCache);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 Value getValue(final Key key, boolean useReadOnlyCache) { Value payload = null; try { // 判读是否开启了 ReadOnlyCache if (useReadOnlyCache) { // 先从 ReadOnlyCache 中获取 final Value currentPayload = readOnlyCacheMap.get(key); if (currentPayload != null) { payload = currentPayload; } else { // ReadOnlyCache 中没有就从 ReadWriteCache 中获取 payload = readWriteCacheMap.get(key); // 并将该值从 ReadWriteCache 中复制到 ReadOnlyCache 中 readOnlyCacheMap.put(key, payload); } } else { // 如果没开启 ReadOnlyCache，直接从 ReadWriteCache 中获取 payload = readWriteCacheMap.get(key); } } catch (Throwable t) { logger.error(\"Cannot get value for key : {}\", key, t); } return payload; } readWriteCacheMap.get(key)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // readWriteCacheMap 使用了 LoadingCache，在 ResponseCacheImpl 中对其的 get 进行了设置 ResponseCacheImpl(EurekaServerConfig serverConfig, ServerCodecs serverCodecs, AbstractInstanceRegistry registry) { // ... this.readWriteCacheMap = // 初始化容量，从配置中获取 CacheBuilder.newBuilder().initialCapacity(serverConfig.getInitialCapacityOfResponseCache()) // 设置缓存的失效时间，从配置中获取 .expireAfterWrite(serverConfig.getResponseCacheAutoExpirationInSeconds(), TimeUnit.SECONDS) .removalListener(new RemovalListener\u003cKey, Value\u003e() { @Override public void onRemoval(RemovalNotification\u003cKey, Value\u003e notification) { Key removedKey = notification.getKey(); if (removedKey.hasRegions()) { Key cloneWithNoRegions = removedKey.cloneWithoutRegions(); regionSpecificKeys.remove(cloneWithNoRegions, removedKey); } } }) .build(new CacheLoader\u003cKey, Value\u003e() { // 当 readWriteCacheMap 调用 get 方法获取不到值的时候，会调用该方法获取返回值。 @Override public Value load(Key key) throws Exception { if (key.hasRegions()) { Key cloneWithNoRegions = key.cloneWithoutRegions(); regionSpecificKeys.put(cloneWithNoRegions, key); } // 该方法是从 registry 中获取值 // 所以说 readWriteCache 和 registry 是相同的，因为如果从 readWriteCache 中获取不到值，会直接从 registry 中获取 Value value = generatePayload(key); return value; } }); // ... } Value value = generatePayload(key);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 private Value generatePayload(Key key) { Stopwatch tracer = null; try { String payload; switch (key.getEntityType()) { case Application: boolean isRemoteRegionRequested = key.hasRegions(); // 全量拉取的 key 为 ALL_APPS if (ALL_APPS.equals(key.getName())) { if (isRemoteRegionRequested) { tracer = serializeAllAppsWithRemoteRegionTimer.start(); payload = getPayLoad(key, registry.getApplicationsFromMultipleRegions(key.getRegions())); } else { tracer = serializeAllAppsTimer.start(); // 从 registry 中获取数据并进行包装后返回 payload = getPayLoad(key, registry.getApplications()); } } else if (ALL_APPS_DELTA.equals(key.getName())) { // 增量拉取的 key 为 ALL_APPS_DELTA if (isRemoteRegionRequested) { tracer = serializeDeltaAppsWithRemoteRegionTimer.start(); versionDeltaWithRegions.incrementAndGet(); versionDeltaWithRegionsLegacy.incrementAndGet(); payload = getPayLoad(key, registry.getApplicationDeltasFromMultipleRegions(key.getRegions())); } else { tracer = serializeDeltaAppsTimer.start(); versionDelta.incrementAndGet(); versionDeltaLegacy.incrementAndGet(); // 从 registry 的最近更新队列中获取数据并包装后返回 payload = getPayLoad(key, registry.getApplicationDeltas()); } } else { tracer = serializeOneApptimer.start(); payload = getPayLoad(key, registry.getApplication(key.getName())); } break; case VIP: case SVIP: tracer = serializeViptimer.start(); payload = getPayLoad(key, getApplicationsForVip(key, registry)); break; default: logger.error(\"Unidentified entity type: {} found in the cache key.\", key.getEntityType()); payload = \"\"; break; } return new Value(payload); } finally { if (tracer != null) { tracer.stop(); } } } 增量拉取 增量拉取是从 recentlyChangedQueue 中进行拉取，可以减少拉取注册表的数据量\nGET http://localhost:7900/eureka/apps/delta 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 @Path(\"delta\") @GET public Response getContainerDifferential( @PathParam(\"version\") String version, @HeaderParam(HEADER_ACCEPT) String acceptHeader, @HeaderParam(HEADER_ACCEPT_ENCODING) String acceptEncoding, @HeaderParam(EurekaAccept.HTTP_X_EUREKA_ACCEPT) String eurekaAccept, @Context UriInfo uriInfo, @Nullable @QueryParam(\"regions\") String regionsStr) { boolean isRemoteRegionRequested = null != regionsStr \u0026\u0026 !regionsStr.isEmpty(); // If the delta flag is disabled in discovery or if the lease expiration // has been disabled, redirect clients to get all instances if ((serverConfig.shouldDisableDelta()) || (!registry.shouldAllowAccess(isRemoteRegionRequested))) { return Response.status(Status.FORBIDDEN).build(); } String[] regions = null; if (!isRemoteRegionRequested) { EurekaMonitors.GET_ALL_DELTA.increment(); } else { regions = regionsStr.toLowerCase().split(\",\"); Arrays.sort(regions); // So we don't have different caches for same regions queried in different order. EurekaMonitors.GET_ALL_DELTA_WITH_REMOTE_REGIONS.increment(); } CurrentRequestVersion.set(Version.toEnum(version)); KeyType keyType = Key.KeyType.JSON; String returnMediaType = MediaType.APPLICATION_JSON; if (acceptHeader == null || !acceptHeader.contains(HEADER_JSON_VALUE)) { keyType = Key.KeyType.XML; returnMediaType = MediaType.APPLICATION_XML; } Key cacheKey = new Key(Key.EntityType.Application, ResponseCacheImpl.ALL_APPS_DELTA, keyType, CurrentRequestVersion.get(), EurekaAccept.fromString(eurekaAccept), regions ); final Response response; if (acceptEncoding != null \u0026\u0026 acceptEncoding.contains(HEADER_GZIP_VALUE)) { // 增量拉取时，cacheKey 为 ALL_APPS_DELTA response = Response.ok(responseCache.getGZIP(cacheKey)) .header(HEADER_CONTENT_ENCODING, HEADER_GZIP_VALUE) .header(HEADER_CONTENT_TYPE, returnMediaType) .build(); } else { response = Response.ok(responseCache.get(cacheKey)).build(); } CurrentRequestVersion.remove(); return response; } responseCache.getGZIP(cacheKey)\n1 2 3 4 5 6 7 public byte[] getGZIP(Key key) { Value payload = getValue(key, shouldUseReadOnlyResponseCache); if (payload == null) { return null; } return payload.getGzipped(); } getValue(key, shouldUseReadOnlyResponseCache);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 Value getValue(final Key key, boolean useReadOnlyCache) { Value payload = null; try { // 判读是否开启了 ReadOnlyCache if (useReadOnlyCache) { // 先从 ReadOnlyCache 中获取 final Value currentPayload = readOnlyCacheMap.get(key); if (currentPayload != null) { payload = currentPayload; } else { // ReadOnlyCache 中没有就从 ReadWriteCache 中获取 payload = readWriteCacheMap.get(key); // 并将该值从 ReadWriteCache 中复制到 ReadOnlyCache 中 readOnlyCacheMap.put(key, payload); } } else { // 如果没开启 ReadOnlyCache，直接从 ReadWriteCache 中获取 // 后续流程可见全量拉取 payload = readWriteCacheMap.get(key); } } catch (Throwable t) { logger.error(\"Cannot get value for key : {}\", key, t); } return payload; } 集群同步 集群同步的代码主要再 PeerAwareInstanceRegistryImpl 类中\n[eureka server 启动](#eureka server 启动时的集群同步)：如果 registry-sync-retries 大于 0，则会在 eureka server 启动时从 peer 节点拉取注册表信息\n服务注册：eureka client 向某个 eureka server 发起注册，注册成功后，该 eureka server 会将该 eureka client 同步注册到它的相邻 peer 节点\n服务续约：每个服务续约时都会所有可达的 peer 进行同步\n服务下线：每个服务下线时都会所有可达的 peer 进行同步\n服务剔除：不会同步，因为每个 eureka server 有自己的剔除逻辑\n注意\n服务注册和服务续约/下线在同步时是有区别的，服务注册只会向相邻的 peer 进行复制，服务续约/下线会向所有可达的 peer 都进行复制\neureka server 启动时的集群同步 EurekaServerAutoConfiguration\n@Import(EurekaServerInitializerConfiguration.class)\nEurekaServerInitializerConfiguration.start()\neurekaServerBootstrap.contextInitialized(EurekaServerInitializerConfiguration.this.servletContext);\ninitEurekaServerContext();\n1 2 // 在启动的时候从其他 peer 拉取注册表，之后注册到 peer 的服务需要通过后续集群同步服务进行同步，不同 peer 间可能存在不同步的情况，所以此处也没有保证一致性 int registryCount = this.registry.syncUp(); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public int syncUp() { // Copy entire entry from neighboring DS node int count = 0; // 注册表同步尝试次数，默认值为 0，如果要再 server 启动时就从 peer 进行拉取注册表，需要将其设置为大于 0 for (int i = 0; ((i \u003c serverConfig.getRegistrySyncRetries()) \u0026\u0026 (count == 0)); i++) { if (i \u003e 0) { try { // 拉取注册表服务的等待时间，默认为 0 Thread.sleep(serverConfig.getRegistrySyncRetryWaitMs()); } catch (InterruptedException e) { logger.warn(\"Interrupted during registry transfer..\"); break; } } Applications apps = eurekaClient.getApplications(); for (Application app : apps.getRegisteredApplications()) { for (InstanceInfo instance : app.getInstances()) { try { if (isRegisterable(instance)) { // 调用服务注册方法进行注册 register(instance, instance.getLeaseInfo().getDurationInSecs(), true); count++; } } catch (Throwable t) { logger.error(\"During DS init copy\", t); } } } } return count; } register(instance, instance.getLeaseInfo().getDurationInSecs(), true);\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 public void register(InstanceInfo registrant, int leaseDuration, boolean isReplication) { try { read.lock(); Map\u003cString, Lease\u003cInstanceInfo\u003e\u003e gMap = registry.get(registrant.getAppName()); REGISTER.increment(isReplication); if (gMap == null) { final ConcurrentHashMap\u003cString, Lease\u003cInstanceInfo\u003e\u003e gNewMap = new ConcurrentHashMap\u003cString, Lease\u003cInstanceInfo\u003e\u003e(); gMap = registry.putIfAbsent(registrant.getAppName(), gNewMap); if (gMap == null) { gMap = gNewMap; } } Lease\u003cInstanceInfo\u003e existingLease = gMap.get(registrant.getId()); // Retain the last dirty timestamp without overwriting it, if there is already a lease if (existingLease != null \u0026\u0026 (existingLease.getHolder() != null)) { Long existingLastDirtyTimestamp = existingLease.getHolder().getLastDirtyTimestamp(); Long registrationLastDirtyTimestamp = registrant.getLastDirtyTimestamp(); logger.debug(\"Existing lease found (existing={}, provided={}\", existingLastDirtyTimestamp, registrationLastDirtyTimestamp); // this is a \u003e instead of a \u003e= because if the timestamps are equal, we still take the remote transmitted // InstanceInfo instead of the server local copy. if (existingLastDirtyTimestamp \u003e registrationLastDirtyTimestamp) { logger.warn(\"There is an existing lease and the existing lease's dirty timestamp {} is greater\" + \" than the one that is being registered {}\", existingLastDirtyTimestamp, registrationLastDirtyTimestamp); logger.warn(\"Using the existing instanceInfo instead of the new instanceInfo as the registrant\"); registrant = existingLease.getHolder(); } } else { // The lease does not exist and hence it is a new registration synchronized (lock) { if (this.expectedNumberOfClientsSendingRenews \u003e 0) { // Since the client wants to register it, increase the number of clients sending renews this.expectedNumberOfClientsSendingRenews = this.expectedNumberOfClientsSendingRenews + 1; updateRenewsPerMinThreshold(); } } logger.debug(\"No previous lease information found; it is new registration\"); } Lease\u003cInstanceInfo\u003e lease = new Lease\u003cInstanceInfo\u003e(registrant, leaseDuration); if (existingLease != null) { lease.setServiceUpTimestamp(existingLease.getServiceUpTimestamp()); } gMap.put(registrant.getId(), lease); recentRegisteredQueue.add(new Pair\u003cLong, String\u003e( System.currentTimeMillis(), registrant.getAppName() + \"(\" + registrant.getId() + \")\")); // This is where the initial state transfer of overridden status happens if (!InstanceStatus.UNKNOWN.equals(registrant.getOverriddenStatus())) { logger.debug(\"Found overridden status {} for instance {}. Checking to see if needs to be add to the \" + \"overrides\", registrant.getOverriddenStatus(), registrant.getId()); if (!overriddenInstanceStatusMap.containsKey(registrant.getId())) { logger.info(\"Not found overridden id {} and hence adding it\", registrant.getId()); overriddenInstanceStatusMap.put(registrant.getId(), registrant.getOverriddenStatus()); } } InstanceStatus overriddenStatusFromMap = overriddenInstanceStatusMap.get(registrant.getId()); if (overriddenStatusFromMap != null) { logger.info(\"Storing overridden status {} from map\", overriddenStatusFromMap); registrant.setOverriddenStatus(overriddenStatusFromMap); } // Set the status based on the overridden status rules InstanceStatus overriddenInstanceStatus = getOverriddenInstanceStatus(registrant, existingLease, isReplication); registrant.setStatusWithoutDirty(overriddenInstanceStatus); // If the lease is registered with UP status, set lease service up timestamp if (InstanceStatus.UP.equals(registrant.getStatus())) { lease.serviceUp(); } registrant.setActionType(ActionType.ADDED); recentlyChangedQueue.add(new RecentlyChangedItem(lease)); registrant.setLastUpdatedTimestamp(); invalidateCache(registrant.getAppName(), registrant.getVIPAddress(), registrant.getSecureVipAddress()); logger.info(\"Registered instance {}/{} with status {} (replication={})\", registrant.getAppName(), registrant.getId(), registrant.getStatus(), isReplication); } finally { read.unlock(); } } 1 2 3 4 5 6 eureka: server: # 拉取注册表尝试次数 registry-sync-retries: 1 # 拉取注册表的等待时间间隔 registry-sync-retry-wait-ms: 0 DashBoard Eureka DashBoard 相关接口都存放再 EurekaController 中，就是基于 SpringMVC 的接口。\neureka server 总结 eureka server 提供的功能\n接受注册 接受心跳 下线 获取注册列表 集群同步 优化点\n服务剔除 自我保护 三级缓存 其他点 服务测算 服务续约的时间间隔默认是 30s，再续约的时候，会向所有 peer 发送服务注册请求。所以单个 eureka server 每 30 秒会接收 2 个请求。\n当前工程一共有 18 个服务，假设有 20 个，然后每个服务部署 5 个实例，一共就是 100 个 eureka client;\n此时的 eureka server 每 30s 一共会接收 2 * 100=200 个请求，1 分钟就是 400 请求。\n模拟服务注册所用时间，大约是每次 100ms，1 分钟单个 eureka server 就可以接收 60 * 1000 / 100 = 600 次请求。\nrecentlyChangedQueue 用于保存最近被更改过的注册表信息，可见 服务注册，服务续约/心跳，服务下线，再进行 服务拉取 时，增量拉取 就是从 recentlyChangedQueue 中进行获取注册表信息，实际使用时，可以选择先进行增量拉取，如果获取不到再进行 全量拉取。\n1 2 3 4 5 6 7 protected AbstractInstanceRegistry(EurekaServerConfig serverConfig, EurekaClientConfig clientConfig, ServerCodecs serverCodecs) { // ... // 定时触发对 recentlyChangedQueue 中注册信息的失效任务 this.deltaRetentionTimer.schedule(getDeltaRetentionTask(), serverConfig.getDeltaRetentionTimerIntervalInMs(), serverConfig.getDeltaRetentionTimerIntervalInMs()); } getDeltaRetentionTask()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 private TimerTask getDeltaRetentionTask() { return new TimerTask() { @Override public void run() { Iterator\u003cRecentlyChangedItem\u003e it = recentlyChangedQueue.iterator(); while (it.hasNext()) { // 把超过 RetentionTimeInMSInDeltaQueue 时间的注册表失效 if (it.next().getLastUpdateTime() \u003c System.currentTimeMillis() - serverConfig.getRetentionTimeInMSInDeltaQueue()) { it.remove(); } else { break; } } } }; } 1 2 3 4 5 6 eureka: server: # recentlyChangedQueue 失效任务的时间间隔，默认 30s delta-retention-timer-interval-in-ms: 30000 # recentlyChangedQueue 中信息的失效时间，默认 3min retention-time-in-m-s-in-delta-queue: 180000 unavailable-replicas 在 eureka 的 dashboard 中可能看到 General Info 下 available-replicas 是空的，我们的注册中心地址都在 unavailable-replicas 里，这是不对的，如果是内外网环境，会造成服务调用不通的问题。\nEurekaController\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @RequestMapping(method = RequestMethod.GET) public String status(HttpServletRequest request, Map\u003cString, Object\u003e model) { populateBase(request, model); populateApps(model); StatusInfo statusInfo; try { statusInfo = new StatusResource().getStatusInfo(); } catch (Exception e) { statusInfo = StatusInfo.Builder.newBuilder().isHealthy(false).build(); } model.put(\"statusInfo\", statusInfo); populateInstanceInfo(model, statusInfo); filterReplicas(model, statusInfo); return \"eureka/status\"; } statusInfo = new StatusResource().getStatusInfo();\nstatusUtil.getStatusInfo()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 public StatusInfo getStatusInfo() { StatusInfo.Builder builder = StatusInfo.Builder.newBuilder(); // Add application level status int upReplicasCount = 0; StringBuilder upReplicas = new StringBuilder(); StringBuilder downReplicas = new StringBuilder(); StringBuilder replicaHostNames = new StringBuilder(); // 获取到当前 EurekaServer 的所有 peer 节点并进行遍历，这里获取到的是配置文件中配置的信息，并且不包含当前服务，要与后续从 registry 中获取到的区分开 for (PeerEurekaNode node : peerEurekaNodes.getPeerEurekaNodes()) { if (replicaHostNames.length() \u003e 0) { replicaHostNames.append(\", \"); } replicaHostNames.append(node.getServiceUrl()); // 需要该方法返回 true，才会给 upReplicas 赋值 if (isReplicaAvailable(node.getServiceUrl())) { upReplicas.append(node.getServiceUrl()).append(','); upReplicasCount++; } else { downReplicas.append(node.getServiceUrl()).append(','); } } builder.add(\"registered-replicas\", replicaHostNames.toString()); // 前端显示的 available-replicas 是 upReplicas 的结果 builder.add(\"available-replicas\", upReplicas.toString()); builder.add(\"unavailable-replicas\", downReplicas.toString()); // Only set the healthy flag if a threshold has been configured. if (peerEurekaNodes.getMinNumberOfAvailablePeers() \u003e -1) { builder.isHealthy(upReplicasCount \u003e= peerEurekaNodes.getMinNumberOfAvailablePeers()); } builder.withInstanceInfo(this.instanceInfo); return builder.build(); } isReplicaAvailable(node.getServiceUrl()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 private boolean isReplicaAvailable(String url) { try { // 从 registry 中获取名称为 myAppName 的对象，myAppName 对应 spring.application.name 属性的值 Application app = registry.getApplication(myAppName, false); // 如果拿不到当前 EurekaServer 对象，直接返回 false if (app == null) { return false; } // 遍历每个实例信息 for (InstanceInfo info : app.getInstances()) { // 把从 registry 中获取到的所有实例信息和当前 url 做对比 if (peerEurekaNodes.isInstanceURL(url, info)) { return true; } } } catch (Throwable e) { logger.error(\"Could not determine if the replica is available \", e); } return false; } peerEurekaNodes.isInstanceURL(url, info)\n1 2 3 4 5 6 7 8 9 10 public boolean isInstanceURL(String url, InstanceInfo instance) { // 从 url 中获取到 hostName String hostName = hostFromUrl(url); // 从配置中获取到实例的 hostName，对应的配置为 eureka.instance.hostname String myInfoComparator = instance.getHostName(); if (clientConfig.getTransportConfig().applicationsResolverUseIp()) { myInfoComparator = instance.getIPAddr(); } return hostName != null \u0026\u0026 hostName.equals(myInfoComparator); } 解决方案：\n1 2 3 4 5 6 7 8 9 10 11 12 13 spring: application: # 相同的服务，myAppName 相同 name: myAppName eureka: client: # 设置为 true，保证将当前 EurekaServer 注册到注册中心 register-with-eureka: true service-url: # 此处的 myHostname 需要与 eureka.instance.hostname 一致 defaultZone: http://myHostname:port/eureka instance: hostname: myHostname ","description":"","tags":["MSB","Project","网约车三期","Eureka","Java"],"title":"Eureka","uri":"/posts/msb/%E7%BD%91%E7%BA%A6%E8%BD%A6%E4%B8%89%E6%9C%9F/eureka/"},{"categories":null,"content":"Bean 创建源码 参考下方的流程 debug 代码 源码中常见的几个 BeanFactory\nDefaultListableBeanFactory\nListableBeanFactory\nHierarchicalBeanFactory\nConfigurableBeanFactory\nGenericBeanDefinition 和 RootBeanDefinition\n解析 xml 得到的 BeanDefinition 是 GenericBeanDefinition 类型，在执行完 BeanFactoryPostProcessor 后其依旧是 GenericBeanDefinition 类型，在进行对象创建时，将其与父类和父容器进行了合并，此时的 BeanDefinition 变为了 RootBeanDefinition 类型，用于实例化和初始化 Bean 对象。\n反射的优缺点？\n反射效率比 new 慢，但是是大量使用反射的时候才会明显感觉到慢。反射比 new 更灵活。\n参考：Java 反射到底慢在哪？\n","description":"","tags":["MSB","源码","Spring","Java"],"title":"Bean 创建源码","uri":"/posts/msb/spring-framework/source-code-for-bean-creation/"},{"categories":null,"content":"Spring 容器 Spring 介绍 Spring 是什么？\n框架 生态。\n为什么阅读源码？\n要学习它的扩展性。\nSpring 包含两大特性，IOC 和 AOP，需要搞清楚 IOC，才能学习 AOP。\nDI 是实现 IOC 的手段\nIOC 容器：用于存放 Bean 对象\n基础回顾 配置文件创建 Bean 的方式 1. 通过无参构造器创建，set 方法赋值 1 2 3 4 5 6 \u003cbeans\u003e \u003cbean id=\"xx\" class=\"xx\" abstract init-method scope dependon...\u003e \u003cpropertie name=\"xx\", value=\"xx\" /\u003e \u003cpropertie name=\"xx\", value=\"xx\" /\u003e \u003c/bean\u003e \u003c/beans\u003e 2. 通过有参构造器创建 1 2 3 4 5 6 \u003cbeans\u003e \u003cbean id=\"xx\" class=\"xxx\" abstract init-method scope dependon...\u003e \u003cconstructor name=\"xx\" value=\"xx\" /\u003e \u003cconstructor name=\"xx\" value=\"xx\" /\u003e \u003c/bean\u003e \u003c/beans\u003e 获取 Bean 的方式 1 2 3 4 // 使用指定配置文件加载 ApplicationContext，ApplicaitonContext 中一定包含配置文件中配置的 Bean 对象 ApplicationContext ac = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); Xxx xxx = ac.getBean(Xxx.class); xxx.method(); 分析 xml 转化为 Bean 的过程 我们需要将 xml 中定义的信息加载到 IOC 容器中，然后通过 IOC 容器获取相应的 Bean。\nxml 中使用 bean 标签配置的其实是 Bean 的 BeanDefinition 信息，通过 BeanDefinition 将相应的 Bean 进行实例化\n容器 Spring 中的 IOC 容器，其实就是多个 Map，因为使用 Map 可以更灵活快速的获取到对应的 Bean 对象。其中 Map 的 Key 和 Value 可以有以下类型\n// getBean 方法可以根据 Bean 的名称和类型获取 Bean Key: String\tVal: Object Key: class Val: Object // 三级缓存时用到的 Key: String Val: ObjectFactory // 用于获取对象的定义信息 Key: String Val: BeanDefinition 配置文件向 Bean 转化的详细流程（Bean 的生命周期） 1. xml -\u003e BeanDefinition xml/properties/yaml 中存储的是 bean 的定义信息，为了便于统一使用，我们需要把它解析成 BeanDefinition 类型的对象，这样在后续使用 Bean 的时候统一处理 BeanDefinition 类型的对象就可以了。\n而为了便于扩展，比如说要支持 json 格式的配置文件，抽象出一个 BeanDefinitionReader 类型的接口，用于定义配置文件的转换规则。\n转换后的 BeanDefinition 对象还可以通过 BeanFactoryPostProcessor 接口的实现类对其进行增强处理，例如设置是否懒加载等。\n1 2 3 4 5 6 7 public class MyBeanFactoryPostProcessor implements BeanFactoryPostProcessor { @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException { BeanDefinition a = beanFactory.getBeanDefinition(\"A\"); System.out.println(\"增强 BeanDefinition...\"); } } 2. BeanDefinition → 实例化 Bean 对象 通过 BeanDefinition 对象，使用反射来对相应的 Bean 对象进行实例化操作。\n思考问题\n为什么使用反射而不使用 new？\n因为反射更加灵活，可以获取到对象上的属性，方法，注解等信息。\n3. 实例化 Bean 对象 → 初始化 Bean 对象 首先通过对象的 set 方法给对象的属性赋值 如果实现了 Aware 接口，则调用 Aware 接口中定义的方法 调用 BeanPostProcessor 类的 before 方法，对 Bean 对象前置增强 调用 init-method 调用 BeanPostProcessor 类的 after 方法，对 Bean 对象进行后置增强 最终创建出完整的 Bean 对象，此时就可通过 ApplicationContext 的 getBean 方法获取相应对象了 思考问题\n在容器运行过程中，需要动态改变 Bean 的定义信息，怎么办？\n例如在创建数据库连接对象时，需要替换 SPEL 表达式代表的值\n1 \u003cproperty name=\"url\" value=\"${jdbc.url}\" /\u003e 此处就是通过使用 BeanFactoryPostProcessor 来进行处理的，同时 AOP 的动态代理，使用的 AbstractAutoProxyCreator 类也是实现了 BeanPostProcessor 接口\nBeanFactoryPostProcessor 和 BeanPostProcessor 区别\n都是后置处理器/增强器，BeanFactoryPostProcessor 用来增强 BeanDefinition 信息，BeanPostProcessor 用来增强 Bean 的信息\n实例化和初始化的区别\n实例化：在堆中开辟一片空间，给属性赋默认值（例如 int 为 0，String 为 null）\n初始化：给实例化后的对象设置属性值，然后执行构造方法，然后执行初始化方法（init-method）\n容器对象和普通对象的理解\n容器对象相当于内置对象，是容器自己需要的对象；普通对象是我们自定义的对象，写在 xml 中的。\nAware 接口的作用\n当 Spring 容器创建自定义对象时，如果需要使用到容器对象，此时可通过让自定义对象实现相应 Aware 接口的方法，来进行注入，从而满足需求。\n例如：ApplicationContextAware，EnvironmentAware，BeanNameAware。\n在初始化的不同的阶段要处理不同的工作，应该怎么办？\n观察者模式：监听器，监听事件，多播器（广播器）\n常用接口 BeanFactory：IOC 容器的入口\nDefaultListableBeanFactory AutowireCapableBeanFactory BeanDefinitionReader：定义配置文件的解析规则\nBeanDefinition：配置文件中的 bean 标签会被封装为该类型的对象\nBeanFactoryPostProcessor：对 BeanDefinition 进行增强\nBeanDefinitionRegistry：用来对容器中的 BeanDefinition 进行增删改查操作\nAware：用于向普通对象中注入容器对象\nBeanPostProcessor：在执行普通对象的 init-method 前后进行增强处理\nEnvironment：包含系统的环境和配置信息\nStandardEnvironment System.getenv(); System.getProperties(); FactoryBean：自定义普通对象的创建流程\nFactoryBean 和 BeanFactory 的区别？\n都是用来创建对象的。当使用 BeanFactory 的时候，必须要遵循完整的创建过程，该过程是由 Spring 来管理控制的；而使用 FactoryBean 只需要调用 getObject 就可以返回具体的对象，整个对象的创建过程是由用户自己来控制的，更加灵活。实现 FactoryBean 的类，在容器已经创建结束后，首次调用 getBean 方法是才会创建出来。\n","description":"","tags":["MSB","源码","Spring","Java"],"title":"Spring 容器","uri":"/posts/msb/spring-framework/spring-container-introduction/"},{"categories":null,"content":"项目介绍 项目过程 第一阶段：启动阶段 可行性分析，立项。\n面试问题\n为什么做这个项目？\n从技术人员角度考虑，该项目有什么长远的好处。\n残障人士（后备箱有轮椅），孕妇（开车比较稳的司机），小孩（儿童座椅）\n第二阶段：计划阶段 进度安排，资源计划，成本估计，质量保证计划，风险，实施。\n面试问题\n如果项目做不完了怎么办？\n加班；2) 加人；3)功能排优先级，重要的先做保证能用，后面再迭代 第三阶段：实施控制阶段 开发，测试，部署，运维\n第四阶段：收尾阶段 验收。产品验收。\n项目和产品 项目管理方式：矩阵式，开发组分为 1 组，2 组；项目经理组也分 1 组，2 组，有项目需要做的时候，从开发组和产品组各选出几人组合成一组进行开发。\n项目开发流程：\ngraph TD A[需求分析] --\u003e B[KickOff] B --\u003e C[需求评审] B --\u003e D[里程碑] C --\u003e E[需求确认] D --\u003e E E --\u003e F[测试 TestCase 编写] E --\u003e G[开发设计] F --\u003e H[评审] G --\u003e I[设计评审] H --\u003e J[开发] I --\u003e J J --\u003e K[测试] K --\u003e L[上线] 面试题\n项目开发过程中是严格按照上面的开发流程进行的吗？\n不是\n如果和同事之间发生矛盾，怎么处理\n人员安排 项目管理：3 人（1 个高级项目经理，2 个助理）\n技术总监：1 人\n运维：2 人（1 个普通，1 个做容器化）\n能力层：10 人\n业务层：12 人\n产品：10 人（乘客，司机，BOSS，h5）\n安卓：4 人\nios：4 人\nh5：4 人\n测试：20 人（功能测试，自动化测试，接口测试，安全测试）\n运营，市场，大客户关系：未知\n面试题\n你在项目中的职责\n组长：接口定义，工程结构设计，代码 review，各方沟通（产品，测试），核心功能开发。\n组员：具体开发实现。核心功能开发。\nKick Off：各方（项目经理，产品，开发，测试，运营等），动员大会。14:00-22:00\n实现需求 乘客端 发送验证码 三档验证。技术人员从技术上防止恶意发短信。 登录/注册 查看开通区域 高德围栏 预估价格。 下单（呼叫司机） （司机流程） 支付（分布式事务：订单，支付，积分） 评价 司机端 发送验证码 登录/注册 查看/改变司机状态 抢单（分布式锁） 订单状态变更 发起收款 BOSS 端 运营端\n","description":"","tags":["MSB","Project","网约车三期","Java"],"title":"项目介绍","uri":"/posts/msb/%E7%BD%91%E7%BA%A6%E8%BD%A6%E4%B8%89%E6%9C%9F/project-introduction/"},{"categories":null,"content":"项目设计 微服务设计原则 设计架构/模式/拆分/隔离等的目标：隔离系统的变化点\n具体原则 高内聚，低耦合：一个服务中只做一件事 高度自治：每个服务都可以独立的开发，测试，构建，部署，运行，发布。（无状态） 以业务为中心：每个服务有特定的业务逻辑 弹性设计：容错，隔离，降级等 自动化：持续集成，持续交付 粒度把控：微服务微到什么地步没有标准。遵循任何一个服务的开发和维护不能影响其他服务 AKF 原则 x 轴：复制备份。集群，负载均衡。\ngraph TD A[请求] --\u003e B[Nginx] B --\u003e C[Service] B --\u003e D[Service] B --\u003e E[Service] B --\u003e F[Service] B --\u003e G[......] y 轴：业务拆分。将一个业务中的某些步骤拆分出来，作为新服务。\nz 轴：数据分区。例如按照地区存储数据\n整体架构图 所用 SpringCloud 组件图 服务拆分 业务层 模块 项目名 描述 乘客端 api-passenger 乘客端 司机端 api-driver 司机端 司机听单 api-listen-order 司机听单 能力层 模块 项目名 描述 app 升级 service-app-update 订单 service-order 派单 service-order-dispatch 乘客用户管理 service-passenger-user 短信 service-sms 计价 service-valuation 验证码 service-verification-code 钱包 service-wallet 支付 service-payment Spring Cloud 基础服务层 模块 项目名 描述 注册中心 cloud-eureka 配置中心 cloud-config-server 网关 cloud-zuul 熔断监控 cloud-hystrix-dashboard 健康检查 cloud-admin 链路追踪 cloud-zipkin-ui 基础 common 模块 项目名 描述 通用 internal-common 通用类，工具类，统一异常，校验 用到的技术 boot，cloud，maven，git，mysql，redis，active-mq\n第三方服务\n短信服务：腾讯，阿里云，华信 语音服务：隐私号（乘客和司机订单匹配后互相拨打的不是真实号码），录音。 文件服务：阿里 OSS 地图服务：高德 消息推送：极光。透传，通知。 支付：微信，支付宝 航路纵横：查航班 发票服务：百望云 前端：vue，android，ios 面试包装 商务都来公司，跟我们技术做个交流，我们也了解他们的技术情况等，和我们业务结合是否匹配，开发是否易用，稳定等\n能力层：预估 1500 的并发量，压测 QPS：2000（4G 8core），有些服务 300\n了解到 QPS（Query Per Second）如果还要增大，应该如何做。\nQPS 和 TPS（Transaction Per Second）是通过压测测试出来的。\n关键词\n复盘，赋能，抓手，对标，沉淀，对齐，拉通，倒逼，课粒度，落地，中台，方法论，漏斗，组合全，闭环，生命周期，打法，履约，引爆点，串联，价值转化，纽带，矩阵，协同，反哺，点线面，认知，强化认知，强化心智，交互，兼容，包装，响应，刺激，规模，重组，量化，宽松，资源倾斜，完善逻辑，抽离透传，抽象，复用打法，发力，精细化，布局，商业模式，联动，场景，聚焦，快速响应，影响力，价值，细分，垂直领域，维度，定性定量，去中心化，关键路径，接地气，梳理，输出，格局，生态，结果导向，话术，体系，认知，分享，流程，感知度，加速，用户画像，摸索，提炼，玩法，共建，分发，支撑，抓手，体感，感知，融合，调性，心智，解耦，拆解，集成，对焦，拉通，打透，吃透，课粒度，迁移，分层，漏斗，战役，组合拳，合力，体系，心力，赛道。\n接口设计 接口定义了之后，app，后端同时开发。\n后端定接口。\nRESTful 风格 Representational State Transfer，表述性状态转移)，基于 http。重在资源\n考虑的点 协议：http/https。IOS 只能用 https（否则应用商店审核不过）\n域名：api.domain.com\n版本：v1\n路径：/xxoo/ooxx?param1=xx\u0026param2=xx，URL 路径中只能是名词\n动作：\npost：新建\nput：修改（修改后的全量数据）\npatch：修改（修改哪个传哪个）\ndelete：删除\nget：查询\n接口安全 等保三级\nCIA：保密性，完整性，可用性。\n保密性：数据传输和存储需要加密（手机号，身份证号，脱敏）\n完整性：数据不丢失。\n可用性：防止服务被恶意占用\n数据层面：SQL 注入。可通过 jsoup 框架对接口的输入参数进行过滤，jsoup 里的 xss whitelist（白名单）有 6 中方法，一个构造方法和 5 种静态方法。\nXSS：跨站脚本攻击。黑客通过将一段脚本上传到服务器，使得其他用户在访问包含该脚本页面时，自动执行了脚本中包含的恶意代码。可使用 spring-htmlUtils 进行转义。也可使用 OWASP HTML Sanitizer，参考：Java 对 html 标签的过滤和清洗\nCSRF：跨站请求伪造。可通过人机交互； token 解决\nReferer：HTTP 请求头中的信息。跨站请求访问\n数据权限控制：用户对其没有权限的数据进行了操作。例如：A 用户请求，删除 order/a1；B 用户请求，删除 order/a1\n面试题\nXSS 和 CSRF 的区别?\nXSS 是由于没有对用户数据没有过滤，转义，在正常用户请求中执行了黑客提供的恶意代码。\nCSRF 是冒充别人的登录信息，没有防范不信任的调用。\n微服务项目结构 项目在独立仓库中。\n整体\n1 2 3 | -- online-taxi-three | -- 项目 A | -- 项目 B 单独项目\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 | -- pom | -- src | -- controller | -- service | -- impl | -- dao | -- entity | -- mapper | -- manager | -- constant | -- request | -- response | -- resource | -- mapper | -- xxxMapper.xml | -- yml 异常的处理 DAO 层的异常：catch 到，然后抛出，不用打日志\nService 层的异常：打日志，详细信息，时间，参数等。\nController 层的异常：捕获所有的异常，把异常包装成状态码\n","description":"","tags":["MSB","Project","网约车三期","Java"],"title":"项目设计","uri":"/posts/msb/%E7%BD%91%E7%BA%A6%E8%BD%A6%E4%B8%89%E6%9C%9F/project-design/"},{"categories":null,"content":"Spring Boot 自动序列化/反序列化 JDK8 的时间 API Jdk8TimeConfig.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 import com.fasterxml.jackson.datatype.jsr310.deser.LocalDateDeserializer; import com.fasterxml.jackson.datatype.jsr310.deser.LocalDateTimeDeserializer; import com.fasterxml.jackson.datatype.jsr310.deser.LocalTimeDeserializer; import com.fasterxml.jackson.datatype.jsr310.ser.LocalDateSerializer; import com.fasterxml.jackson.datatype.jsr310.ser.LocalDateTimeSerializer; import com.fasterxml.jackson.datatype.jsr310.ser.LocalTimeSerializer; import org.springframework.beans.factory.annotation.Value; import org.springframework.boot.autoconfigure.jackson.Jackson2ObjectMapperBuilderCustomizer; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import java.time.LocalDate; import java.time.LocalDateTime; import java.time.LocalTime; import java.time.ZoneId; import java.time.format.DateTimeFormatter; /** * JDK8 时间序列化/反序列化支持，仅对 Controller 层序列化返回以及 @RequestBody 反序列化生效, * 对 GET 请求不生效，参照{@link converter.jdk8time.Jdk8TimeConverter} * * @author wangshuo * @date 2020/10/27 */ @Configuration public class Jdk8TimeConfig { @Value(\"${spring.jackson.jdk8-date-time-format:yyyy-MM-dd HH:mm:ss}\") private String dateTimeFormat; @Value(\"${spring.jackson.jdk8-date-format:yyyy-MM-dd}\") private String dateFormat; @Value(\"${spring.jackson.jdk8-time-format:HH:mm:ss}\") private String timeFormat; @Value(\"${spring.jackson.jdk8-time-zone:UTC}\") private String timeZone; @Bean public Jackson2ObjectMapperBuilderCustomizer jackson2ObjectMapperBuilderCustomizer() { return builder -\u003e builder .serializerByType(LocalDateTime.class, new LocalDateTimeSerializer(DateTimeFormatter.ofPattern(dateTimeFormat).withZone(ZoneId.of(timeZone)))) .serializerByType(LocalDate.class, new LocalDateSerializer(DateTimeFormatter.ofPattern(dateFormat).withZone(ZoneId.of(timeZone)))) .serializerByType(LocalTime.class, new LocalTimeSerializer(DateTimeFormatter.ofPattern(timeFormat).withZone(ZoneId.of(timeZone)))) .deserializerByType(LocalDateTime.class, new LocalDateTimeDeserializer(DateTimeFormatter.ofPattern(dateTimeFormat).withZone(ZoneId.of(timeZone)))) .deserializerByType(LocalDate.class, new LocalDateDeserializer(DateTimeFormatter.ofPattern(dateFormat).withZone(ZoneId.of(timeZone)))) .deserializerByType(LocalTime.class, new LocalTimeDeserializer(DateTimeFormatter.ofPattern(timeFormat).withZone(ZoneId.of(timeZone)))); } } Jdk8TimeConverter.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.Bean; import org.springframework.core.convert.converter.Converter; import org.springframework.stereotype.Component; import java.time.LocalDate; import java.time.LocalDateTime; import java.time.LocalTime; import java.time.ZoneId; import java.time.format.DateTimeFormatter; /** * JDK8 时间格式转换器，用于 GET 请求时，将 URL 中的时间字符串反序列化为时间对象 * * @author wangshuo * @date 2020/10/28 */ @Component public class Jdk8TimeConverter { private static final Logger logger = LoggerFactory.getLogger(Jdk8TimeConverter.class); @Value(\"${spring.jackson.jdk8-date-time-format:yyyy-MM-dd HH:mm:ss}\") private String dateTimeFormat; @Value(\"${spring.jackson.jdk8-date-format:yyyy-MM-dd}\") private String dateFormat; @Value(\"${spring.jackson.jdk8-time-format:HH:mm:ss}\") private String timeFormat; @Value(\"${spring.jackson.jdk8-time-zone:UTC}\") private String timeZone; @Bean public Converter\u003cString, LocalDateTime\u003e localDateTimeConverter() { DateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofPattern(dateTimeFormat).withZone(ZoneId.of(timeZone)); return new Converter\u003cString, LocalDateTime\u003e() { @Override public LocalDateTime convert(String source) { LocalDateTime target = null; try { target = LocalDateTime.parse(source, dateTimeFormatter); } catch (Exception e) { logger.error(\"source [{}] can not converted to java.time.LocalDateTime, please use [{}] format.\", source, dateTimeFormat, e); } return target; } }; } @Bean public Converter\u003cString, LocalDate\u003e localDateConverter() { DateTimeFormatter dateFormatter = DateTimeFormatter.ofPattern(dateFormat).withZone(ZoneId.of(timeZone)); return new Converter\u003cString, LocalDate\u003e() { @Override public LocalDate convert(String source) { LocalDate target = null; try { target = LocalDate.parse(source, dateFormatter); } catch (Exception e) { logger.error(\"source [{}] can not converted to java.time.LocalDate, please use [{}] format.\", source, dateFormat, e); } return target; } }; } @Bean public Converter\u003cString, LocalTime\u003e localTimeConverter() { DateTimeFormatter timeFormatter = DateTimeFormatter.ofPattern(timeFormat).withZone(ZoneId.of(timeZone)); return new Converter\u003cString, LocalTime\u003e() { @Override public LocalTime convert(String source) { LocalTime target = null; try { target = LocalTime.parse(source, timeFormatter); } catch (Exception e) { logger.error(\"source [{}] can not converted to java.time.LocalTime, please use [{}] format.\", source, timeFormat, e); } return target; } }; } } ","description":"","tags":["Spring Boot","Java"],"title":"Spring Boot 自动序列化/反序列化 JDK8 的时间 API","uri":"/posts/java/spring-boot-use-jdk8-time-api/"},{"categories":null,"content":"xrandr 设置显示比例 1 xrandr --output HDMI-1 --scale 1x1 ","description":"","tags":["Linux"],"title":"xrandr 设置显示比例","uri":"/posts/linux/xrandr-set-scale/"},{"categories":null,"content":"umount.nfs device is busy 问题 问题描述 使用 ls 或者 df -h 命令，系统卡死。\n使用 umount /path/to/mount/point 提示 umount.nfs: /path/to/mount/point: device is busy\n解决方法 尝试使用 umount -f /path/to/mount/poing，强制卸载挂载点。\n尝试使用 fuser -mv /path/to/mount/point，查看正在使用该挂载点的进程，使用 kill 命令杀死该进程，再进行 umount。或者使用 fuser -mvk /path/to/mount/point 直接杀死使用该挂载点的进程。\n尝试使用 umount -l /path/to/mount/point，等待挂载点空闲时，自动卸载挂载点。\n","description":"","tags":["Linux"],"title":"umount.nfs device is busy 问题","uri":"/posts/linux/umount-nfs-device-is-busy/"},{"categories":null,"content":"Google 软件离线安装版下载 Chrome 平台 链接 Windows 32 位 https://www.google.cn/chrome/?standalone=1\u0026platform=win Windows 64 位 https://www.google.cn/chrome/?standalone=1\u0026platform=win64 Mac https://www.google.cn/chrome/?standalone=1\u0026platform=mac Linux https://www.google.cn/chrome/?standalone=1\u0026platform=linux Google Earth 更新 Google 地球专业版 - Google 地球帮助\n平台 链接 Windows 32 位 https://dl.google.com/dl/earth/client/advanced/current/googleearthprowin-7.3.4.exe Windows 64 位 https://dl.google.com/dl/earth/client/advanced/current/googleearthprowin-7.3.4-x64.exe Mac https://dl.google.com/dl/earth/client/advanced/current/googleearthpromac-intel-7.3.4.dmg DEB 64 位 https://dl.google.com/dl/linux/direct/google-earth-pro-stable_7.3.4_amd64.deb RPM 64 位 https://dl.google.com/dl/linux/direct/google-earth-pro-stable-7.3.4.x86_64.rpm ","description":"","tags":["Google"],"title":"Google 软件离线安装版下载","uri":"/posts/google/google-offline-version-download/"},{"categories":null,"content":"ThinkStation P520c Win7 驱动 安装 Win7 及驱动\n联想 ThinkStation Win10 改 Win7 系统及 bios 设置\n联想 ThinkStation P520, P520c 工作站 Windows7, 10 驱动\n","description":"","tags":["Computer"],"title":"ThinkStation P520c Win7 驱动","uri":"/posts/computer/thinkstation-p520c-win7-drivers/"},{"categories":null,"content":"Windows 挂载 nfs 控制面板 → 程序和功能 → 打开 NFS\nmoumt \\\\ip\\floder X:\n自动挂载\n我的电脑 → 右键 → 映射网络驱动器\n","description":"","tags":["Windows"],"title":"Windows 挂载 nfs","uri":"/posts/windows/windows10-mount-nfs/"},{"categories":null,"content":"Spring Boot 添加 swagger maven 导包\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u003cproperties\u003e \u003cswagger.version\u003e2.9.2\u003c/swagger.version\u003e \u003c/properties\u003e \u003cdependencies\u003e \u003c!-- swagger2--\u003e \u003cdependency\u003e \u003cgroupId\u003eio.springfox\u003c/groupId\u003e \u003cartifactId\u003espringfox-swagger2\u003c/artifactId\u003e \u003cversion\u003e${swagger.version}\u003c/version\u003e \u003c/dependency\u003e \u003c!-- swagger2-UI--\u003e \u003cdependency\u003e \u003cgroupId\u003eio.springfox\u003c/groupId\u003e \u003cartifactId\u003espringfox-swagger-ui\u003c/artifactId\u003e \u003cversion\u003e${swagger.version}\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e 配置类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 import io.swagger.annotations.ApiOperation; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import springfox.documentation.builders.ApiInfoBuilder; import springfox.documentation.builders.PathSelectors; import springfox.documentation.builders.RequestHandlerSelectors; import springfox.documentation.service.ApiInfo; import springfox.documentation.service.Contact; import springfox.documentation.spi.DocumentationType; import springfox.documentation.spring.web.plugins.Docket; import springfox.documentation.swagger2.annotations.EnableSwagger2; /** * Swagger2 的接口配置 * * @author wangshuo */ @Configuration @EnableSwagger2 public class SwaggerConfig { /** * 系统基础配置 */ @Autowired private ProjectMetaConfig projectMetaConfig; /** * 是否开启 swagger */ @Value(\"${swagger.enabled}\") private boolean enabled; /** * 设置请求的统一前缀 */ @Value(\"${swagger.pathMapping}\") private String pathMapping; /** * 创建 API */ @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) // 是否启用 Swagger .enable(enabled) // 用来创建该 API 的基本信息，展示在文档的页面中（自定义展示的信息） .apiInfo(apiInfo()) // 设置哪些接口暴露给 Swagger 展示 .select() // 扫描所有有注解的 api，用这种方式更灵活 .apis(RequestHandlerSelectors.withMethodAnnotation(ApiOperation.class)) // 扫描指定包中的 swagger 注解 // .apis(RequestHandlerSelectors.basePackage(\"cn.piesat.controller\")) // 扫描所有 .apis(RequestHandlerSelectors.any()) .paths(PathSelectors.any()) .build() /* 设置安全模式，swagger 可以设置访问 token */ // .securitySchemes(securitySchemes()) // .securityContexts(securityContexts()) .pathMapping(pathMapping); } // // /** // * 安全模式，这里指定 token 通过 Authorization 头请求头传递 // */ // private List\u003cApiKey\u003e securitySchemes() { // List\u003cApiKey\u003e apiKeyList = new ArrayList\u003c\u003e(); // apiKeyList.add(new ApiKey(\"Authorization\", \"Authorization\", \"header\")); // return apiKeyList; // } // // /** // * 安全上下文 // */ // private List\u003cSecurityContext\u003e securityContexts() { // List\u003cSecurityContext\u003e securityContexts = new ArrayList\u003c\u003e(); // securityContexts.add( // SecurityContext.builder() // .securityReferences(defaultAuth()) // .forPaths(PathSelectors.regex(\"^(?!auth).*$\")) // .build()); // return securityContexts; // } // // /** // * 默认的安全上引用 // */ // private List\u003cSecurityReference\u003e defaultAuth() { // AuthorizationScope authorizationScope = new AuthorizationScope(\"global\", \"accessEverything\"); // AuthorizationScope[] authorizationScopes = new AuthorizationScope[1]; // authorizationScopes[0] = authorizationScope; // List\u003cSecurityReference\u003e securityReferences = new ArrayList\u003c\u003e(); // securityReferences.add(new SecurityReference(\"Authorization\", authorizationScopes)); // return securityReferences; // } /** * 添加摘要信息 */ private ApiInfo apiInfo() { // 用 ApiInfoBuilder 进行定制 return new ApiInfoBuilder() // 设置标题 .title(\"标题: \" + projectMetaConfig.getTitle()) // 描述 .description(\"描述:\" + projectMetaConfig.getDescription()) // 作者信息 .contact(new Contact(projectMetaConfig.getContactName(), projectMetaConfig.getContactUrl(), projectMetaConfig.getContactEmail())) // 版本 .version(\"版本号:\" + projectMetaConfig.getVersion()) .build(); } } 配置文件对应的类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 package cn.piesat.config; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Configuration; /** * 项目源信息 * * @author wangshuo * @date 2020/09/10 */ @Configuration @ConfigurationProperties(prefix = \"proj.meta\") public class ProjectMetaConfig { /** * 标题 */ private String title; /** * 作者姓名 */ private String contactName; /** * 作者主页 */ private String contactUrl; /** * 作者邮箱 */ private String contactEmail; /** * 项目版本 */ private String version; /** * 项目描述信息 */ private String description; /** * 版权年限 */ private String copyrightYear; public String getTitle() { return title; } public void setTitle(String title) { this.title = title; } public String getContactName() { return contactName; } public void setContactName(String contactName) { this.contactName = contactName; } public String getContactUrl() { return contactUrl; } public void setContactUrl(String contactUrl) { this.contactUrl = contactUrl; } public String getContactEmail() { return contactEmail; } public void setContactEmail(String contactEmail) { this.contactEmail = contactEmail; } public String getVersion() { return version; } public void setVersion(String version) { this.version = version; } public String getDescription() { return description; } public void setDescription(String description) { this.description = description; } public String getCopyrightYear() { return copyrightYear; } public void setCopyrightYear(String copyrightYear) { this.copyrightYear = copyrightYear; } } ","description":"","tags":["Swagger","Spring Boot","Java"],"title":"Spring Boot 添加 swagger","uri":"/posts/java/spring-boot-swagger/"},{"categories":null,"content":"swagger 使用 GET 请求接收 query 参数 GET 请求使用对象接收 query 的参数，paramType 使用 query，参数上不用加任何注解。\n1 2 @ApiImplicitParam(name = \"user\", value = \"查询条件\", dataType = \"SysUser\", paramType = \"query\") public AjaxResult getList(SysUser user) { ","description":"","tags":["Swagger","Java"],"title":"swagger 使用 GET 请求接收 query 参数","uri":"/posts/java/swagger-get-by-object/"},{"categories":null,"content":"PostgreSQL 设置开机自启动 PG11 server-start\n官网的可能要在编译时指定了 --with-systemd 才能用，具体原因未知\n整个野的\n添加 /etc/systemd/system/postgresql.service\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [Unit] Description=PostgreSQL database server Documentation=man:postgres(1) [Service] Type=forking User=postgres Group=postgres ExecStart=/usr/local/pgsql/bin/pg_ctl start -D /usr/local/pgsql/data ExecReload=/usr/local/pgsql/bin/pg_ctl restart -D /usr/local/pgsql/data ExecStop=/usr/local/pgsql/bin/pg_ctl stop -D /usr/local/pgsql/data TimeoutSec=0 [Install] WantedBy=multi-user.target ","description":"","tags":["PostgreSQL"],"title":"Linux 设置 PostgreSQL 开机自启","uri":"/posts/database/postgresql-auto-startup/"},{"categories":null,"content":"systemd 启动配置文件说明 配置文件包含三个区块 [Unit] [Install] [Service] [Unit] 通常是配置文件的第一个区块，用来定义 Unit 的元数据，以及配置与其他 Unit 的关系。它的主要字段如下:\nDescription：简短描述 Documentation：文档地址 Requires：当前 Unit 依赖的其他 Unit，如果它们没有运行，当前 Unit 会启动失败 Wants：与当前 Unit 配合的其他 Unit，如果它们没有运行，当前 Unit 不会启动失败 BindsTo：与Requires类似，它指定的 Unit 如果退出，会导致当前 Unit 停止运行 Before：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之后启动 After：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之前启动 Conflicts：这里指定的 Unit 不能与当前 Unit 同时运行 Condition...：当前 Unit 运行必须满足的条件，否则不会运行 Assert...：当前 Unit 运行必须满足的条件，否则会报启动失败 [Install] 是配置文件的最后一个区块，用来定义如何启动，以及是否开机启动。它的主要字段如下。\nWantedBy：它的值是一个或多个 Target，当前 Unit 激活时（enable）符号链接会放入/etc/systemd/system目录下面以 Target 名 + .wants后缀构成的子目录中 RequiredBy：它的值是一个或多个 Target，当前 Unit 激活时，符号链接会放入/etc/systemd/system目录下面以 Target 名 + .required后缀构成的子目录中 Alias：当前 Unit 可用于启动的别名 Also：当前 Unit 激活（enable）时，会被同时激活的其他 Unit [Service] 用来 Service 的配置，只有 Service 类型的 Unit 才有这个区块。它的主要字段如下。\nType：定义启动时的进程行为。它有以下几种值。 Type=simple：默认值，执行ExecStart指定的命令，启动主进程 Type=forking：以 fork 方式从父进程创建子进程，创建后父进程会立即退出 Type=oneshot：一次性进程，Systemd 会等当前服务退出，再继续往下执行 Type=dbus：当前服务通过 D-Bus 启动 Type=notify：当前服务启动完毕，会通知Systemd，再继续往下执行 Type=idle：若有其他任务执行完毕，当前服务才会运行 ExecStart：启动当前服务的命令 ExecStartPre：启动当前服务之前执行的命令 ExecStartPost：启动当前服务之后执行的命令 ExecReload：重启当前服务时执行的命令 ExecStop：停止当前服务时执行的命令 ExecStopPost：停止当其服务之后执行的命令 RestartSec：自动重启当前服务间隔的秒数 Restart：定义何种情况 Systemd 会自动重启当前服务，可能的值包括always（总是重启）、on-success、on-failure、on-abnormal、on-abort、on-watchdog TimeoutSec：定义 Systemd 停止当前服务之前等待的秒数 Environment：指定环境变量 阮一峰 Systemd 入门教程：命令篇 作者：阮一峰\n日期：2016 年 3 月 7 日\nSystemd 是 Linux 系统工具，用来启动守护进程，已成为大多数发行版的标准配置。\n本文介绍它的基本用法，分为上下两篇。今天介绍它的主要命令，下一篇介绍如何用于实战。\n由来 历史上，Linux 的启动一直采用init进程。\n下面的命令用来启动服务。\n1 2 3 $ sudo /etc/init.d/apache2 start # 或者 $ service apache2 start 这种方法有两个缺点。\n一是启动时间长。init进程是串行启动，只有前一个进程启动完，才会启动下一个进程。\n二是启动脚本复杂。init进程只是执行启动脚本，不管其他事情。脚本需要自己处理各种情况，这往往使得脚本变得很长。\nSystemd 概述 Systemd 就是为了解决这些问题而诞生的。它的设计目标是，为系统的启动和管理提供一套完整的解决方案。\n根据 Linux 惯例，字母d是守护进程（daemon）的缩写。Systemd 这个名字的含义，就是它要守护整个系统。\n（上图为 Systemd 作者 Lennart Poettering）\n使用了 Systemd，就不需要再用init了。Systemd 取代了initd，成为系统的第一个进程（PID 等于 1），其他进程都是它的子进程。\n1 $ systemctl --version 上面的命令查看 Systemd 的版本。\nSystemd 的优点是功能强大，使用方便，缺点是体系庞大，非常复杂。事实上，现在还有很多人反对使用 Systemd，理由就是它过于复杂，与操作系统的其他部分强耦合，违反\"keep simple, keep stupid\"的Unix 哲学。\n（上图为 Systemd 架构图）\n系统管理 Systemd 并不是一个命令，而是一组命令，涉及到系统管理的方方面面。\nsystemctl systemctl是 Systemd 的主命令，用于管理系统。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 重启系统 $ sudo systemctl reboot # 关闭系统，切断电源 $ sudo systemctl poweroff # CPU 停止工作 $ sudo systemctl halt # 暂停系统 $ sudo systemctl suspend # 让系统进入冬眠状态 $ sudo systemctl hibernate # 让系统进入交互式休眠状态 $ sudo systemctl hybrid-sleep # 启动进入救援状态（单用户状态） $ sudo systemctl rescue systemd-analyze systemd-analyze命令用于查看启动耗时。\n1 2 3 4 5 6 7 8 9 10 11 # 查看启动耗时 $ systemd-analyze # 查看每个服务的启动耗时 $ systemd-analyze blame # 显示瀑布状的启动过程流 $ systemd-analyze critical-chain # 显示指定服务的启动流 $ systemd-analyze critical-chain atd.service hostnamectl hostnamectl命令用于查看当前主机的信息。\n1 2 3 4 5 # 显示当前主机的信息 $ hostnamectl # 设置主机名。 $ sudo hostnamectl set-hostname rhel7 localectl localectl命令用于查看本地化设置。\n1 2 3 4 5 6 # 查看本地化设置 $ localectl # 设置本地化参数。 $ sudo localectl set-locale LANG=en_GB.utf8 $ sudo localectl set-keymap en_GB timedatectl timedatectl命令用于查看当前时区设置。\n1 2 3 4 5 6 7 8 9 10 # 查看当前时区设置 $ timedatectl # 显示所有可用的时区 $ timedatectl list-timezones # 设置当前时区 $ sudo timedatectl set-timezone America/New_York $ sudo timedatectl set-time YYYY-MM-DD $ sudo timedatectl set-time HH:MM:SS loginctl loginctl命令用于查看当前登录的用户。\n1 2 3 4 5 6 7 8 # 列出当前 session $ loginctl list-sessions # 列出当前登录用户 $ loginctl list-users # 列出显示指定用户的信息 $ loginctl show-user ruanyf Unit 含义 Systemd 可以管理所有系统资源。不同的资源统称为 Unit（单位）。\nUnit 一共分成 12 种。\nService unit：系统服务 Target unit：多个 Unit 构成的一个组 Device Unit：硬件设备 Mount Unit：文件系统的挂载点 Automount Unit：自动挂载点 Path Unit：文件或路径 Scope Unit：不是由 Systemd 启动的外部进程 Slice Unit：进程组 Snapshot Unit：Systemd 快照，可以切回某个快照 Socket Unit：进程间通信的 socket Swap Unit：swap 文件 Timer Unit：定时器 systemctl list-units命令可以查看当前系统的所有 Unit。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 列出正在运行的 Unit $ systemctl list-units # 列出所有 Unit，包括没有找到配置文件的或者启动失败的 $ systemctl list-units --all # 列出所有没有运行的 Unit $ systemctl list-units --all --state=inactive # 列出所有加载失败的 Unit $ systemctl list-units --failed # 列出所有正在运行的、类型为 service 的 Unit $ systemctl list-units --type=service Unit 的状态 systemctl status命令用于查看系统状态和单个 Unit 的状态。\n1 2 3 4 5 6 7 8 # 显示系统状态 $ systemctl status # 显示单个 Unit 的状态 $ sysystemctl status bluetooth.service # 显示远程主机的某个 Unit 的状态 $ systemctl -H root@rhel7.example.com status httpd.service 除了status命令，systemctl还提供了三个查询状态的简单方法，主要供脚本内部的判断语句使用。\n1 2 3 4 5 6 7 8 # 显示某个 Unit 是否正在运行 $ systemctl is-active application.service # 显示某个 Unit 是否处于启动失败状态 $ systemctl is-failed application.service # 显示某个 Unit 服务是否建立了启动链接 $ systemctl is-enabled application.service Unit 管理 对于用户来说，最常用的是下面这些命令，用于启动和停止 Unit（主要是 service）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 立即启动一个服务 $ sudo systemctl start apache.service # 立即停止一个服务 $ sudo systemctl stop apache.service # 重启一个服务 $ sudo systemctl restart apache.service # 杀死一个服务的所有子进程 $ sudo systemctl kill apache.service # 重新加载一个服务的配置文件 $ sudo systemctl reload apache.service # 重载所有修改过的配置文件 $ sudo systemctl daemon-reload # 显示某个 Unit 的所有底层参数 $ systemctl show httpd.service # 显示某个 Unit 的指定属性的值 $ systemctl show -p CPUShares httpd.service # 设置某个 Unit 的指定属性 $ sudo systemctl set-property httpd.service CPUShares=500 依赖关系 Unit 之间存在依赖关系：A 依赖于 B，就意味着 Systemd 在启动 A 的时候，同时会去启动 B。\nsystemctl list-dependencies命令列出一个 Unit 的所有依赖。\n1 $ systemctl list-dependencies nginx.service 上面命令的输出结果之中，有些依赖是 Target 类型（详见下文），默认不会展开显示。如果要展开 Target，就需要使用--all参数。\n1 $ systemctl list-dependencies --all nginx.service Unit 的配置文件 概述 每一个 Unit 都有一个配置文件，告诉 Systemd 怎么启动这个 Unit。\nSystemd 默认从目录/etc/systemd/system/读取配置文件。但是，里面存放的大部分文件都是符号链接，指向目录/usr/lib/systemd/system/，真正的配置文件存放在那个目录。\nsystemctl enable命令用于在上面两个目录之间，建立符号链接关系。\n1 2 3 $ sudo systemctl enable clamd@scan.service # 等同于 $ sudo ln -s '/usr/lib/systemd/system/clamd@scan.service' '/etc/systemd/system/multi-user.target.wants/clamd@scan.service' 如果配置文件里面设置了开机启动，systemctl enable命令相当于激活开机启动。\n与之对应的，systemctl disable命令用于在两个目录之间，撤销符号链接关系，相当于撤销开机启动。\n1 $ sudo systemctl disable clamd@scan.service 配置文件的后缀名，就是该 Unit 的种类，比如sshd.socket。如果省略，Systemd 默认后缀名为.service，所以sshd会被理解成sshd.service。\n配置文件的状态 systemctl list-unit-files命令用于列出所有配置文件。\n1 2 3 4 5 # 列出所有配置文件 $ systemctl list-unit-files # 列出指定类型的配置文件 $ systemctl list-unit-files --type=service 这个命令会输出一个列表。\n1 2 3 4 5 6 $ systemctl list-unit-files UNIT FILE STATE chronyd.service enabled clamd@.service static clamd@scan.service disabled 这个列表显示每个配置文件的状态，一共有四种。\nenabled：已建立启动链接 disabled：没建立启动链接 static：该配置文件没有[Install]部分（无法执行），只能作为其他配置文件的依赖 masked：该配置文件被禁止建立启动链接 注意，从配置文件的状态无法看出，该 Unit 是否正在运行。这必须执行前面提到的systemctl status命令。\n1 $ systemctl status bluetooth.service 一旦修改配置文件，就要让 SystemD 重新加载配置文件，然后重新启动，否则修改不会生效。\n1 2 $ sudo systemctl daemon-reload $ sudo systemctl restart httpd.service 配置文件的格式 配置文件就是普通的文本文件，可以用文本编辑器打开。\nsystemctl cat命令可以查看配置文件的内容。\n1 2 3 4 5 6 7 8 9 10 11 $ systemctl cat atd.service [Unit] Description=ATD daemon [Service] Type=forking ExecStart=/usr/bin/atd [Install] WantedBy=multi-user.target 从上面的输出可以看到，配置文件分成几个区块。每个区块的第一行，是用方括号表示的区别名，比如[Unit]。注意，配置文件的区块名和字段名，都是大小写敏感的。\n每个区块内部是一些等号连接的键值对。\n1 2 3 4 5 [Section] Directive1=value Directive2=value . . . 注意，键值对的等号两侧不能有空格。\n配置文件的区块 [Unit]区块通常是配置文件的第一个区块，用来定义 Unit 的元数据，以及配置与其他 Unit 的关系。它的主要字段如下。\nDescription：简短描述 Documentation：文档地址 Requires：当前 Unit 依赖的其他 Unit，如果它们没有运行，当前 Unit 会启动失败 Wants：与当前 Unit 配合的其他 Unit，如果它们没有运行，当前 Unit 不会启动失败 BindsTo：与Requires类似，它指定的 Unit 如果退出，会导致当前 Unit 停止运行 Before：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之后启动 After：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之前启动 Conflicts：这里指定的 Unit 不能与当前 Unit 同时运行 Condition...：当前 Unit 运行必须满足的条件，否则不会运行 Assert...：当前 Unit 运行必须满足的条件，否则会报启动失败 [Install]通常是配置文件的最后一个区块，用来定义如何启动，以及是否开机启动。它的主要字段如下。\nWantedBy：它的值是一个或多个 Target，当前 Unit 激活时（enable）符号链接会放入/etc/systemd/system目录下面以 Target 名 + .wants后缀构成的子目录中 RequiredBy：它的值是一个或多个 Target，当前 Unit 激活时，符号链接会放入/etc/systemd/system目录下面以 Target 名 + .required后缀构成的子目录中 Alias：当前 Unit 可用于启动的别名 Also：当前 Unit 激活（enable）时，会被同时激活的其他 Unit [Service]区块用来 Service 的配置，只有 Service 类型的 Unit 才有这个区块。它的主要字段如下。\nType：定义启动时的进程行为。它有以下几种值。 Type=simple：默认值，执行ExecStart指定的命令，启动主进程 Type=forking：以 fork 方式从父进程创建子进程，创建后父进程会立即退出 Type=oneshot：一次性进程，Systemd 会等当前服务退出，再继续往下执行 Type=dbus：当前服务通过 D-Bus 启动 Type=notify：当前服务启动完毕，会通知Systemd，再继续往下执行 Type=idle：若有其他任务执行完毕，当前服务才会运行 ExecStart：启动当前服务的命令 ExecStartPre：启动当前服务之前执行的命令 ExecStartPost：启动当前服务之后执行的命令 ExecReload：重启当前服务时执行的命令 ExecStop：停止当前服务时执行的命令 ExecStopPost：停止当其服务之后执行的命令 RestartSec：自动重启当前服务间隔的秒数 Restart：定义何种情况 Systemd 会自动重启当前服务，可能的值包括always（总是重启）、on-success、on-failure、on-abnormal、on-abort、on-watchdog TimeoutSec：定义 Systemd 停止当前服务之前等待的秒数 Environment：指定环境变量 Unit 配置文件的完整字段清单，请参考官方文档。\nTarget 启动计算机的时候，需要启动大量的 Unit。如果每一次启动，都要一一写明本次启动需要哪些 Unit，显然非常不方便。Systemd 的解决方案就是 Target。\n简单说，Target 就是一个 Unit 组，包含许多相关的 Unit。启动某个 Target 的时候，Systemd 就会启动里面所有的 Unit。从这个意义上说，Target 这个概念类似于\"状态点\"，启动某个 Target 就好比启动到某种状态。\n传统的init启动模式里面，有 RunLevel 的概念，跟 Target 的作用很类似。不同的是，RunLevel 是互斥的，不可能多个 RunLevel 同时启动，但是多个 Target 可以同时启动。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 查看当前系统的所有 Target $ systemctl list-unit-files --type=target # 查看一个 Target 包含的所有 Unit $ systemctl list-dependencies multi-user.target # 查看启动时的默认 Target $ systemctl get-default # 设置启动时的默认 Target $ sudo systemctl set-default multi-user.target # 切换 Target 时，默认不关闭前一个 Target 启动的进程， # systemctl isolate 命令改变这种行为， # 关闭前一个 Target 里面所有不属于后一个 Target 的进程 $ sudo systemctl isolate multi-user.target Target 与 传统 RunLevel 的对应关系如下。\n1 2 3 4 5 6 7 8 9 Traditional runlevel New target name Symbolically linked to... Runlevel 0 | runlevel0.target -\u003e poweroff.target Runlevel 1 | runlevel1.target -\u003e rescue.target Runlevel 2 | runlevel2.target -\u003e multi-user.target Runlevel 3 | runlevel3.target -\u003e multi-user.target Runlevel 4 | runlevel4.target -\u003e multi-user.target Runlevel 5 | runlevel5.target -\u003e graphical.target Runlevel 6 | runlevel6.target -\u003e reboot.target 它与init进程的主要差别如下。\n（1）默认的 RunLevel（在/etc/inittab文件设置）现在被默认的 Target 取代，位置是/etc/systemd/system/default.target，通常符号链接到graphical.target（图形界面）或者multi-user.target（多用户命令行）。\n（2）启动脚本的位置，以前是/etc/init.d目录，符号链接到不同的 RunLevel 目录（比如/etc/rc3.d、/etc/rc5.d等），现在则存放在/lib/systemd/system和/etc/systemd/system目录。\n（3）配置文件的位置，以前init进程的配置文件是/etc/inittab，各种服务的配置文件存放在/etc/sysconfig目录。现在的配置文件主要存放在/lib/systemd目录，在/etc/systemd目录里面的修改可以覆盖原始设置。\n日志管理 Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用journalctl一个命令，查看所有日志（内核日志和应用日志）。日志的配置文件是/etc/systemd/journald.conf。\njournalctl功能强大，用法非常多。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 # 查看所有日志（默认情况下，只保存本次启动的日志） $ sudo journalctl # 查看内核日志（不显示应用日志） $ sudo journalctl -k # 查看系统本次启动的日志 $ sudo journalctl -b $ sudo journalctl -b -0 # 查看上一次启动的日志（需更改设置） $ sudo journalctl -b -1 # 查看指定时间的日志 $ sudo journalctl --since=\"2012-10-30 18:17:16\" $ sudo journalctl --since \"20 min ago\" $ sudo journalctl --since yesterday $ sudo journalctl --since \"2015-01-10\" --until \"2015-01-11 03:00\" $ sudo journalctl --since 09:00 --until \"1 hour ago\" # 显示尾部的最新 10 行日志 $ sudo journalctl -n # 显示尾部指定行数的日志 $ sudo journalctl -n 20 # 实时滚动显示最新日志 $ sudo journalctl -f # 查看指定服务的日志 $ sudo journalctl /usr/lib/systemd/systemd # 查看指定进程的日志 $ sudo journalctl _PID=1 # 查看某个路径的脚本的日志 $ sudo journalctl /usr/bin/bash # 查看指定用户的日志 $ sudo journalctl _UID=33 --since today # 查看某个 Unit 的日志 $ sudo journalctl -u nginx.service $ sudo journalctl -u nginx.service --since today # 实时滚动显示某个 Unit 的最新日志 $ sudo journalctl -u nginx.service -f # 合并显示多个 Unit 的日志 $ journalctl -u nginx.service -u php-fpm.service --since today # 查看指定优先级（及其以上级别）的日志，共有 8 级 # 0: emerg # 1: alert # 2: crit # 3: err # 4: warning # 5: notice # 6: info # 7: debug $ sudo journalctl -p err -b # 日志默认分页输出，--no-pager 改为正常的标准输出 $ sudo journalctl --no-pager # 以 JSON 格式（单行）输出 $ sudo journalctl -b -u nginx.service -o json # 以 JSON 格式（多行）输出，可读性更好 $ sudo journalctl -b -u nginx.serviceqq -o json-pretty # 显示日志占据的硬盘空间 $ sudo journalctl --disk-usage # 指定日志文件占据的最大空间 $ sudo journalctl --vacuum-size=1G # 指定日志文件保存多久 $ sudo journalctl --vacuum-time=1years （完）\n文档信息 版权声明：自由转载-非商用-非衍生-保持署名（创意共享 3.0 许可证） 发表日期：2016 年 3 月 7 日 ","description":"","tags":["Linux"],"title":"systemd 启动配置文件说明","uri":"/posts/linux/linux-systemd-config/"},{"categories":null,"content":"RStudio 打开项目文件夹 File → New Project... → Existing Directory\n","description":"","tags":["RStudio","R"],"title":"RStudio 打开项目文件夹","uri":"/posts/r/rstudio/rstudio-open-project-folder/"},{"categories":null,"content":"将已有的 R 项目打包 目录介绍 R：存放源码（.R 文件）的文件夹 man：存放方法说明文档 .Rd 文件（类似于 JavaDoc），每个 .Rd 文件对应一个方法的文档注释 DESCRIPTION：描述信息，主要包含 Package：包名，Author：作者，Description：描述信息，Imports：依赖包，Suggests：不是必须依赖的包，License：协议等 NAMESPACE：命名空间 xx.Rproj：当前项目的配置信息 打包 首先安装 devtools 1 install.packages(\"devtools\", dependencies = TRUE) 使用 devtools 生成 .Rd 文档 1 devtools::document() 使用 RStadio 重新将项目打包 Build → Clean and Rebuild 等\n","description":"","tags":["R"],"title":"将已有的 R 项目打包","uri":"/posts/r/r-packing/"},{"categories":null,"content":"批量安装 R 包 1 2 3 4 5 6 words \u003c- c(\"dplyr\",\"purrr\",\"rlang\",\"readr\",\"mlegp\",\"tibble\",\"magrittr\",\"solartime\",\"bigleaf\",\"Rcpp\") for(var in words){ cat(\"start install \" , var) install.packages(var) cat(\"installed \",var) } ","description":"","tags":["R"],"title":"批量安装 R 包","uri":"/posts/r/r-bash-install-package/"},{"categories":null,"content":"新建 R 包 创建 R 包 首先必须安装 RStudio。\n然后点击 File → New Project，然后选择 New Directory，接着选择 R Package，最后给你 R 包取个名字即可，如下图所示：\nrpackage_creat\nRStudio 会在当前目录（默认是个人目录下）创建一个 R 包文件夹，主要文件（夹）包括：man，R，DESCRIPTION，NAMESPACE 以及 xx.Rproj\n如果你 R 包使用的比较多的话，一般就能看明白 man 文件夹主要放的是一些 .Rd 文件，R 文件夹则是这个 R 包的 R code，DESCRIPTION 文件写了这个 R 的描述信息，NAMESPACE 则是命名空间（比较重要，但不是必须的）\n先对 DESCRIPTION 文件进行修改（在 RStudio 右边 Files 里打开），这个文件主要为了告诉别人（或者自己）这个 R 包的一些重要的元数据（官方说法），我将模板修改为如下所示\nrpackage_description\n这里主要有几个点，Package 包名，Author 作者，Description 描述信息，Imports 依赖包等；Suggests 是指那些不是必须的包，License 则是协议，最后保存下\n接着需要准备好一个写好的 R 自定义函数，比如我先在 R 文件夹创建一个 uniprot.R 文件，然后将函数写入该文件；其实 R 包粗略的理解就是多个函数的集合，我们使用 R 包就是将输入参数导入函数中，然后函数给我们一个结果。比如我的函数如下：\nidmapping \u003c- function(query, inputid, outputid, fmt){ query \u003c- paste(query, collapse = \",\") r \u003c- httr::POST('http://www.uniprot.org/uploadlists/', body = list(from= inputid, to = outputid, format = fmt, query = query), encode = \"form\") cont \u003c- httr::content(r, type = \"text\") result \u003c- readr::read_tsv(cont) } 我们需要给上述idmapping函数写个文档，告诉使用者这个函数是做什么用的（也可以方便自己记忆）；其实我们再使用 R 包的时候，为了查看一个函数的使用，都会?函数名来阅读使用说明，其实这个使用说明就是接下来要说的对象文档\n首先给函数加上注释信息，这里的注释信息不是我们常见的代码注释，而是对函数整体的 roxygen 注释，主要为了方便后续文档的生成（前人已经帮我们简化了最繁琐的步骤！！！），我比较喜欢用 RStudio 的快捷键来实现：Ctrl+Shift+Alt+R（光标放在函数名上, Code-\u003eInsert Roxygen Skeleton），然后其会生成一个最基础的模板，我们按照自己的函数的具体情况做些修改，如下：\nrpackage_wendang\n接着输入devtools::document()，自动会在 man 文件夹下生成该函数的 Rd 文档\n如果修改函数注释后，再重新执行第二步即可\n最后安装下自己的这个 R 包，这里还是用 RStudio 的功能：点击 Build -\u003e Build \u0026 Reload，其会重新编译这个 R 包，更新文档等操作，并重新加载 R 包；我用?idmapping看下自己写的文档（我写的有点粗糙了。。。）\nrpackage_help\n最后我们需要考虑的是将这个 R 包放在哪，传 CRAN 就暂时别想了，身为野包就要有野包的觉悟，当然也不能放在自己电脑里（不方便别人安装使用），那么 Github 则是最佳的选择的了，比如我存放的路径是：https://github.com/kaigu1990/rpackage，那么安装方式如下：\ndevtools::install_github(\"kaigu1990/rpackage\") library(rmytools) 这样我随时随地都可以安装并使用自己的 R 包咯，也方便别人使用\n参考文档 https://www.bioinfo-scrounger.com/archives/546/\n","description":"","tags":["R"],"title":"新建 R 包","uri":"/posts/r/r-create-package/"},{"categories":null,"content":"修改 R 语言包下载镜像源 全局配置文件：/etc/R/Rprofile.site 用户配置文件：~/.Rprofile 如果 ~ 目录下没有，将全局配置文件复制到 ~ 目录，并重命名为 .Rprofile 即可\n修改 ~/.Rprofile 文件中镜像地址为国内源即可\n1 2 3 4 5 local({ r \u003c- getOption(\"repos\") r[\"CRAN\"] \u003c- \"http://mirrors.tuna.tsinghua.edu.cn/CRAN/\" options(repos = r) }) ","description":"","tags":["R"],"title":"修改 R 语言包下载镜像源","uri":"/posts/r/r-change-mirror/"},{"categories":null,"content":"Spring Data JPA 操作空间数据 引入如下依赖\n1 2 3 4 5 6 7 8 \u003cdependency\u003e \u003cgroupId\u003eorg.postgresql\u003c/groupId\u003e \u003cartifactId\u003epostgresql\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.hibernate\u003c/groupId\u003e \u003cartifactId\u003ehibernate-spatial\u003c/artifactId\u003e \u003c/dependency\u003e https://docs.jboss.org/hibernate/orm/5.4/userguide/html_single/Hibernate_User_Guide.html#spatial-configuration-dialect\n","description":"","tags":["Spring Data JPA","PostGIS"],"title":"hibernate-spatial 文档","uri":"/posts/spring-data/hibernate-spatial/"},{"categories":null,"content":"将 Nginx 设置为开机启动 源码方式安装的默认会去使用 sbin 同级的 conf 下的 nginx.conf 配置文件，nginx.service 中 PIDFile 的路径需要与 nginx.conf 中的 pid 一致，否则会出现 timeout，找不到 pidfile 等错误。\nhttps://www.nginx.com/resources/wiki/start/topics/examples/systemd/\n","description":"","tags":["Nginx"],"title":"将 Nginx 设置为开机启动","uri":"/posts/nginx/nginx-startup/"},{"categories":null,"content":"多线程入门 进程，线程，纤程 进程和线程的区别\n区别 进程 线程 纤程/协程 根本区别 资源分配的最小单位 调度和执行的最小单位 - 开销 每个进程都有独立的代码和数据空间（进程上下文），进程间切换会有较大的开销（需要 CPU 保留和恢复线程） 线程可以看成是轻量级进程，同一进程内的线程共享代码和数据空间（进程上下文），每个线程有自己独立的运行栈和程序计数器()，线程切换开销小 - 所处环境 在操作系统中能同试运行多个程序 在同一应用程序中多个顺序流同时执行 - 分配内存 系统在运行的时候会为每个进程分配不同的内存区域 除了 CPU 之外，不会为线程分配内存（线程使用的资源是其所属进程的资源），线程组只能共享资源 - 包含关系 一个进程可以包含多个线程，没有线程的进程可以看作单线程，进程退出了线程一定会退出 线程是进程的一部分，线程退出进程不一定退出 - Java 中的多线程 Java 中负责线程功能的是 java.lang.Thread 类 每个线程都通过 Thread 对象的 run() 方法完成其操作，run() 方法称为线程体 通过调用 Thread 的 start() 方法，启动线程 创建线程的方式 继承 Thread 类，重写 run() 方法，启动的时候调用 start() 方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Thread1 extends Thread { @Override public void run() { for (int i = 0; i \u003c 10; i++) { System.out.println(Thread.currentThread().getName()); } } } public class T01_WhatIsThread { public static void main(String[] args){ // 创建线程 Thread thread = new Thread1(); // 启动线程 thread.start(); for (int i = 0; i \u003c 10; i++) { System.out.println(Thread.currentThread().getName()); } } } 实现 Runnable 接口，实现 run() 方法，启动的时候调用 start() 方法。（与法 1 相比，推荐使用该方式，因为 Java 是单继承的。同时该方式使用了代理模式）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Thread2 implements Runnable { @Override public void run() { for (int i = 0; i \u003c 10; i++) { System.out.println(Thread.currentThread().getName() + \" ---- \" + i); } } } public class T01_WhatIsThread { public static void main(String[] args){ // 创建线程 Thread thread = new Thread(new Thread2()); // 启动线程 thread.start(); for (int i = 0; i \u003c 10; i++) { System.out.println(Thread.currentThread().getName() + \" ---- \" + i); } } } 线程池的方式（底层依旧是 Thread，后续再说）\n线程的状态 新生（New）状态 用 new 关键字创建一个线程后，该线程对象就处于新生状态 处于该状态的线程有自己的内存空间，通过调用 start() 方法进入就绪状态 就绪（Runnable）状态 处于就绪状态的线程具备了运行条件，但还没有分配到 CPU，处于就绪队列中，等待系统为其分配 CPU 执行 当系统选定一个等待执行的线程后，它就会从就绪状态进入执行状态，该动作称为“CPU 调度” 执行（Running）状态 在运行状态的线程执行自己 run() 方法中的代码，直到等待某资源或调用 wait() 方法而进入阻塞状态或执行结束进入死亡状态 如果在给定的时间片内没有执行结束或者调用了 yield() 方法，就会被系统给换下来回到等待队列，进入就绪状态 阻塞（Blocked）状态 处于运行状态的线程在某些情况下（如执行了 sleep()/wait() 方法，或等待 I/O 设备等），将让出 CPU 并暂时停止自己运行，进行阻塞状态 在阻塞状态的线程不能进入就绪队列，只有当引起阻塞的原因消除时（如 sleep/wait 时间已到，或 wait 状态被 notify()/notifyAll()，或等待的 I/O 设备空闲），线程便转入就绪状态，重新回到就绪队列，等待被系统选中后从之前停止的位置继续执行。 死亡（Terminated）状态 线程死亡的原因有三种：1 是征程运行的线程完成了它的全部工作，2 是线程被强制性终止（如 stop() 方法，不推荐使用），3 是线程抛出未捕获的异常 注：在多线程的时候，可以实现唤醒和等待的过程，但是唤醒（notify/notifyAll）和等待（wait）的操作对应不是 thread 对象，而是我们设置的共享对象或者共享变量。 notify() 和 wait() 方法是 Object 类的方法。\n线程的生命周期 Thread 类基本 API 序号 方法名称 描述 1 public static native Thread currentThread() 返回当前正在执行的线程 2 public final String getName() 返回线程的名称 3 public final int getPriority() 返回线程的优先级 4 public final synchronized void setName(String name) 设置线程名称 5 public final void setPriority(int newPriority) 设置线程优先级 6 public final native boolean isAlive() 判断线程是否在活动 7 public final void join() 调用该方法的线程强制执行，其他线程变为阻塞状态，该线程执行完毕后，其他线程再执行 8 public static native void sleep(long millis) 使当前线程休眠 millis 秒，期间处于阻塞状态 9 public static native void yield() 将当前正在执行的线程暂停一次，允许其他线程执行，不阻塞，线程进入就绪状态，当前线程就会马上恢复执行 示例\ncurrentThread、getName、getPriority、isAlive、setPriority\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 public class D02_ThreadAPI { public static void main(String[] args) { Thread mainThread = Thread.currentThread(); String name = mainThread.getName(); System.out.println(\"name = \" + name); /* 默认值为 5, 范围为 0-10, 也有的操作系统是 0-100 priority 值高不一定优先执行, 只是优先执行的概率比低的高 */ int priority = mainThread.getPriority(); System.out.println(\"priority = \" + priority); boolean alive = mainThread.isAlive(); System.out.println(\"alive = \" + alive); mainThread.setPriority(6); System.out.println(\"newPriority = \" + mainThread.getPriority()); System.out.println(\"--------------------------------\"); new Thread(new Thread01()).start(); for (int i = 0; i \u003c 10; i++) { System.out.println(Thread.currentThread().getName() + \" --- \" + i); } } } class Thread01 implements Runnable { @Override public void run() { for (int i = 0; i \u003c 10; i++) { System.out.println(Thread.currentThread().getName() + \" --- \" + i); } } } join\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /** * 在 mainThread 中调用 Thread-0.join() 后, 会在 Thread-0 完全执行结束后再继续执行mainThread */ public class D03_ThreadJoin implements Runnable { @Override public void run() { for (int i = 0; i \u003c 10; i++) { System.out.println(Thread.currentThread().getName() + \" --- \" + i); } } public static void main(String[] args) { D03_ThreadJoin tt = new D03_ThreadJoin(); Thread t = new Thread(tt); t.start(); for (int i = 0; i \u003c 10; i++) { if (i == 5) { try { // 将t线程join到当前main线程, 等到t线程执行结束后, main线程才会继续执行 t.join(); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(Thread.currentThread().getName() + \" --- \" + i); } } } sleep\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /** * 线程会进入阻塞状态指定毫秒, 超时后进入就绪状态 */ public class D04_ThreadSleep implements Runnable { @Override public void run() { for (int i = 0; i \u003c 10; i++) { System.out.println(Thread.currentThread().getName() + \" --- \" + i); } } public static void main(String[] args) { D04_ThreadSleep tt = new D04_ThreadSleep(); Thread t = new Thread(tt); t.start(); for (int i = 0; i \u003c 10; i++) { if (i == 5) { try { // 让当前主线程 sleep 5 秒, 主线程会阻塞 Thread.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(Thread.currentThread().getName() + \" --- \" + i); } } } yield\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 /** * 将运行状态的线程变为就绪状态, 至于cpu下一次是执行其他线程还是执行该线程是不确定的 */ public class D05_ThreadYield implements Runnable { @Override public void run() { for (int i = 0; i \u003c 5; i++) { System.out.println(Thread.currentThread().getName() + \" --- \" + i); } } public static void main(String[] args) { D05_ThreadYield tt = new D05_ThreadYield(); Thread t = new Thread(tt); t.start(); for (int i = 0; i \u003c 5; i++) { if (i == 2) { System.out.println(\"礼让1次\"); Thread.yield(); } System.out.println(Thread.currentThread().getName() + \" --- \" + i); } } } state\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 public class D06_ThreadState implements Runnable { @Override public synchronized void run() { // 线程正在运行, RUNNABLE 状态 System.out.println(\"run 1: \" + Thread.currentThread().getState()); try { // sleep 3 秒, 进入阻塞状态 Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } try { // 注意: 调用 wait() 和 notify() 方法的对象, 必须已被锁定 this.wait(); System.out.println(\"run 2: \" + Thread.currentThread().getState()); } catch (InterruptedException e) { e.printStackTrace(); } } public static void main(String[] args) throws InterruptedException { D06_ThreadState ts = new D06_ThreadState(); Thread thread = new Thread(ts); // 创建完 Thread 对象, 是 NEW 状态 System.out.println(\"main 1: \" + thread.getState()); thread.start(); // 调用 start() 启动之后, 是 RUNNABLE 状态 System.out.println(\"main 2: \" + thread.getState()); Thread.sleep(2000); // 2 秒时, thread 正在 sleep, 所以是 TIMED_WAITING状态 System.out.println(\"main 3: \" + thread.getState()); Thread.sleep(2000); System.out.println(\"main 4: \" + thread.getState()); synchronized (ts) { ts.notify(); } System.out.println(\"main 5: \" + thread.getState()); thread.join(); // join 到主线程, 等 thread 结束, 主线程才会执行, 此时 thread 已经变为 TERMINATED 状态 System.out.println(\"main 6: \" + thread.getState()); } } 练习\n继承 Thread，模拟抢票\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 /** * 继承 Thread，模拟抢票 */ public class T01_TicketThread extends Thread { /* * 共有 5 张票 * 由于是继承 Thread, 所以每次 new 创建的线程都具有自己独立的属性, 只会对自己的属性（tickets）进行操作 * 解决方式：将属性设置为 static，达到线程间共享数据 * 但仍会出现乱序出票的问题 */ private static int tickets = 5; @Override public void run() { while (true) { if (tickets \u003e 0) { System.out.println(Thread.currentThread().getName() + \" 抢到了第 \" + (tickets--) + \" 张票。\"); } else { break; } } } public static void main(String[] args) { T01_TicketThread t1 = new T01_TicketThread(); T01_TicketThread t2 = new T01_TicketThread(); T01_TicketThread t3 = new T01_TicketThread(); T01_TicketThread t4 = new T01_TicketThread(); T01_TicketThread t5 = new T01_TicketThread(); t1.start(); t2.start(); t3.start(); t4.start(); t5.start(); } } 实现 Runnable 接口，模拟抢票\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 /** * 实现 Runnable 接口，模拟抢票 */ public class T02_TicketRunnable implements Runnable { /* 使用实现Runnable接口, 每次只创建了一个共享对象, 所有线程能够实现资源共享, 但仍会出现出票乱序/重复出票的情况 解决方法: 线程同步(加锁) */ private int tickets = 5; @Override public void run() { while (true) { if (tickets \u003e 0) { System.out.println(Thread.currentThread().getName() + \" 抢到了第 \" + (tickets--) + \" 张票.\"); } else { break; } } } public static void main(String[] args) { T02_TicketRunnable tt = new T02_TicketRunnable(); Thread t1 = new Thread(tt); Thread t2 = new Thread(tt); Thread t3 = new Thread(tt); Thread t4 = new Thread(tt); Thread t5 = new Thread(tt); t1.start(); t2.start(); t3.start(); t4.start(); t5.start(); } } 启动两个线程,，一个正序输出 1-10，一个倒序，并且交替输出\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 /** * 启动两个线程,，一个正序输出 1-10，一个倒序，并且交替输出 */ public class T01_Sleep implements Runnable { @Override public void run() { for (int i = 1; i \u003c= 10; i++) { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \" --- \" + i); } } public static void main(String[] args) { new Thread(new T01_Sleep()).start(); for (int i = 1; i \u003c= 10; i++) { try { Thread.sleep(1001); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName() + \" --- \" + i); } } } 线程安全问题 线程同步 多个线程执行时，会出现共享数据不一致问题，需要使用线程同步来解决。\n同步的前提\n必须有两个或两个以上的线程 必须是多线程使用同一资源 必须保证同步中只能有一个线程在运行 同步监视器\nsynchronized(obj){} 中的 obj 称为同步监视器 同步代码块中同步监视器可以是任何对象，但是推荐使用共享资源作为同步监视器 同步方法中无需指定同步监视器，因为同步方法的监视器是 this，静态同步方法的监视器是当前类的 Class 对象（在同一个 ClassLoader 中是唯一的） 同步监视器的执行过程\n第一个线程访问，锁定同步监视器，执行其中代码 第二线程访问，发现同步监视器被锁定，无法访问 第一个线程访问完毕，解锁同步监视器 第二个线程访问，发现同步监视器未锁，锁定并访问 示例\n同步代码块\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 /** * 同步代码块 * \u003cpre\u003e{@code * synchronized(o) { * 业务代码 * } * }\u003c/pre\u003e * 其中 o 为线程共享的对象，必须为 Object 的子类，并且不能为 String（因为 String 使用了字符串池，相同的字符串在内存中只有一个对象） */ public class D01_TicketSyncBlock implements Runnable { private int tickets = 5; // Object o = new Object(); @Override public void run() { while (true) { try { // 使当前线程阻塞，让出 CPU 执行权，来让其他线程执行 Thread.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } /* 因为会出现乱序，所以将业务代码放到同步代码块中进行加锁，这样在一个线程执行该代码块中的代码时，其他线程就不会执行该内容了. 同步代码块可以使用线程间共享的 Object 类的子类或 this 作为锁，通常使用 this */ synchronized (this) { // synchronized (o) { if (tickets \u003e 0) { System.out.println(Thread.currentThread().getName() + \" 抢到了第 \" + (tickets--) + \" 张票。\"); } else { break; } } } } public static void main(String[] args) { D01_TicketSyncBlock tt = new D01_TicketSyncBlock(); Thread t1 = new Thread(tt,\"A\"); Thread t2 = new Thread(tt,\"B\"); Thread t3 = new Thread(tt,\"C\"); Thread t4 = new Thread(tt,\"D\"); Thread t5 = new Thread(tt,\"E\"); t1.start(); t2.start(); t3.start(); t4.start(); t5.start(); } } 同步方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 /** * 同步方法，在方法中添加 synchronized 关键字，将核心逻辑放到 * \u003cp\u003e * 普通方法锁定的是 this，静态方法锁定的是当前类的 class 对象 */ public class D02_TicketSyncMethod implements Runnable { private int tickets = 5; // Object o = new Object(); @Override public void run() { while (true) { try { // 使当前线程阻塞，让出CPU执行权，来让其他线程执行 Thread.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } this.sale(); } } /** * 同步方法，锁的是this */ private synchronized void sale() { if (tickets \u003e 0) { System.out.println(Thread.currentThread().getName() + \" 抢到了第 \" + (tickets--) + \" 张票。\"); } } public static void main(String[] args) { D02_TicketSyncMethod tt = new D02_TicketSyncMethod(); Thread t1 = new Thread(tt, \"A\"); Thread t2 = new Thread(tt, \"B\"); Thread t3 = new Thread(tt, \"C\"); Thread t4 = new Thread(tt, \"D\"); Thread t5 = new Thread(tt, \"E\"); t1.start(); t2.start(); t3.start(); t4.start(); t5.start(); } } 练习\n张三和妻子各拥有一张银行卡和存折，可以同时对一个银行账户进行存取款的操作，请使用多线程及同步方法模拟张三和妻子同时取款的过程，要求使用同步方法和同步代码块两种方式实现\n同步方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 public class T01_SaleSyncMethod { private static class Account implements Runnable { int balance = 10; @Override public void run() { while (true) { try { // 等价于Thread.sleep() TimeUnit.MICROSECONDS.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } withdrawal(); } } private synchronized void withdrawal() { System.out.println(Thread.currentThread().getName() + \" 准备取款\"); if (balance \u003e 0) { balance--; System.out.println(Thread.currentThread().getName() + \" 完成取款, 余额为 \" + balance); } else { System.out.println(\"余额不足以支付 \" + Thread.currentThread().getName() + \" 的取款.余额为 \" + balance); } } } public static void main(String[] args) { Account account = new Account(); Thread zhangsan = new Thread(account, \"张三\"); Thread wife = new Thread(account, \"张三妻子\"); zhangsan.start(); wife.start(); } } 同步代码块\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 public class T02_SaleSyncBlock { private static class Account implements Runnable { int balance = 10; @Override public void run() { while (true) { try { // 等价于Thread.sleep() TimeUnit.MICROSECONDS.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (this) { System.out.println(Thread.currentThread().getName() + \" 准备取款\"); if (balance \u003e 0) { balance--; System.out.println(Thread.currentThread().getName() + \" 完成取款, 余额为 \" + balance); } else { System.out.println(\"余额不足以支付 \" + Thread.currentThread().getName() + \" 的取款.余额为 \" + balance); break; } } } } } public static void main(String[] args) { Account account = new Account(); Thread zhangsan = new Thread(account, \"张三\"); Thread wife = new Thread(account, \"张三妻子\"); zhangsan.start(); wife.start(); } } 线程死锁 同步可以保证资源共享操作的正确性，但是过多同步也会产生死锁。 死锁一般情况下表示互相等待，是程序运行时出现的一种问题 练习\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 /** * 线程间死锁，Thread01 和 Thread02 有两个公共属性，Thread01 先锁定 o1 再锁定 o2，Thread02 先锁定 o2 再锁定 o1, * 在 Thread01 锁定 o1，Thread02 锁定 o2 后，Thread01 接下来将获取不到 o2 所以无法向下执行，Thread02 接下来将获取不到 o1 也无法向下执行，出现死锁。 * * @author wangshuo * @date 2020/08/23 */ public class T01_DeadLock { static class Thread01 implements Runnable { private Object o1; private Object o2; public Thread01(Object o1, Object o2) { this.o1 = o1; this.o2 = o2; } @Override public void run() { synchronized (o1) { System.out.println(Thread.currentThread().getName() + \" locked o1......\"); synchronized (o2) { System.out.println(Thread.currentThread().getName() + \" locked o2......\"); } } } } static class Thread02 implements Runnable { private Object o1; private Object o2; public Thread02(Object o1, Object o2) { this.o1 = o1; this.o2 = o2; } @Override public void run() { synchronized (o2) { System.out.println(Thread.currentThread().getName() + \" locked o2......\"); synchronized (o1) { System.out.println(Thread.currentThread().getName() + \" locked o1......\"); } } } } public static void main(String[] args) { Object o1 = new Object(); Object o2 = new Object(); Thread01 t1 = new Thread01(o1, o2); Thread02 t2 = new Thread02(o1, o2); new Thread(t1).start(); new Thread(t2).start(); } } 线程的生产者与消费者 生产者不断生产，消费者不断取走生产者生产的产品 生产者生产产品放到一个区域（共享资源）中，之后消费者从此区域里取出产品 多线程访问的时候出现了数据安全的问题\n生产者没有生产商品，消费者就可以获取 商品的品牌和名称对应不上 练习\n版本 1：没有同步机制\n商品类\n1 2 3 4 5 6 7 @Data public class Goods { /** 品牌 */ private String brand; /** 名称 */ private String name; } 生产者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 public class Producer implements Runnable { private Goods goods; public Producer(Goods goods) { this.goods = goods; } @Override public void run() { for (int i = 0; i \u003c 10; i++) { if (i % 2 == 0) { goods.setBrand(\"娃哈哈\"); try { // 让消费者可以更容易在商品未完全生产时，拿到错误的商品信息 Thread.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } goods.setName(\"矿泉水\"); } else { goods.setBrand(\"旺仔\"); try { // 让消费者可以更容易在商品未完全生产时，拿到错误的商品信息 Thread.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } goods.setName(\"馒头\"); } System.out.println(\"生产了 \" + goods.getBrand() + \" --- \" + goods.getName()); } } } 消费者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class Consumer implements Runnable { private Goods goods; public Consumer(Goods goods) { this.goods = goods; } @Override public void run() { for (int i = 0; i \u003c 10; i++) { System.out.println(\"消费了 \" + goods.getBrand() + \" --- \" + goods.getName()); } } } 启动类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * 生产者消费者问题第一版本，未进行同步机制，会出现如下不正确的情况 * \u003cli\u003e1. 生产者还未生产，消费者先消费了 * \u003cli\u003e2. 生产者生产和消费者消费的商品品牌和名称不对应 */ public class TestMain { public static void main(String[] args) { Goods goods = new Goods(); Producer producer = new Producer(goods); Consumer consumer = new Consumer(goods); Thread t1 = new Thread(producer); Thread t2 = new Thread(consumer); t1.start(); t2.start(); } } 版本 2：\n商品类\n1 2 3 4 5 6 7 @Data public class Goods { /** 品牌 */ private String brand; /** 名称 */ private String name; } 生产者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public class Producer implements Runnable { private Goods goods; public Producer(Goods goods) { this.goods = goods; } @Override public void run() { for (int i = 0; i \u003c 10; i++) { synchronized (goods) { if (i % 2 == 0) { goods.setBrand(\"娃哈哈\"); // 此处是否添加 sleep 均可, 因为生产者和消费者均已上锁, 并使用的是同一把锁（goods），即使生产者 sleep，消费者也拿不到锁。 // Thread.sleep(100); goods.setName(\"矿泉水\"); } else { goods.setBrand(\"旺仔\"); try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } goods.setName(\"小馒头\"); } System.out.println(\"生产了 \" + goods.getBrand() + \" --- \" + goods.getName()); } } } } 消费者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class Consumer implements Runnable { private Goods goods; public Consumer(Goods goods) { this.goods = goods; } @Override public void run() { for (int i = 0; i \u003c 10; i++) { synchronized (goods) { System.out.println(\"消费了 \" + goods.getBrand() + \" --- \" + goods.getName()); } } } } 启动类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /** * 生产者消费者问题第二版本，将生产者生产代码和消费者消费代码均放到同步代码块中（必要条件 1），并均使用goods对象作为锁（必要条件 2）, * 保证了同一时刻只有一个线程可以对 goods 对象进行修改（需要同时满足必要条件 1 和 2 才可） * \u003cp\u003e解决了：商品商标和名称不对应的问题 * \u003cp\u003e仍存在：生产者还未生产，消费者先消费了 * * @author wangshuo * @date 2020/08/20 */ public class TestMain { public static void main(String[] args) { Goods goods = new Goods(); Producer producer = new Producer(goods); Consumer consumer = new Consumer(goods); Thread t1 = new Thread(producer); Thread t2 = new Thread(consumer); t1.start(); t2.start(); } } 版本 3\n商品类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @Data public class Goods { /** 品牌 */ private String brand; /** 名称 */ private String name; /** * 产品已生产为true, 产品已消费为false */ private boolean flag; public synchronized void set(String brand, String name) { if (!flag) { this.brand = brand; this.name = name; System.out.println(\"生产了 \" + this.brand + \" --- \" + this.name); flag = !flag; } } public synchronized void get() { if (flag) { System.out.println(\"消费了 \" + this.brand + \" --- \" + this.name); flag = !flag; } } } 生产者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class Producer implements Runnable { private Goods goods; public Producer(Goods goods) { this.goods = goods; } @Override public void run() { for (int i = 0; ; i++) { try { /* 减慢每次循环的速度，防止执行速度过快，不能从头看到输出。对程序执行结果没有影响。 */ Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } if (i % 2 == 0) { goods.set(\"娃哈哈\", \"矿泉水\"); } else { goods.set(\"旺仔\", \"小馒头\"); } } } } 消费者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class Consumer implements Runnable { private Goods goods; public Consumer(Goods goods) { this.goods = goods; } @Override public void run() { for (int i = 0; ; i++) { goods.get(); } } } 启动类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 /** * 生产者消费者问题第三版本，添加生产（set）和消费（get）同步方法（锁定的是 this，还是同一个 Goods 对象，解决品牌和名称不对应问题）， * 并通过 flag 判断商品已生产/已消费状态，解决生产和消费的顺序问题. * \u003cp\u003e解决了: * \u003cli\u003e1. 商品商标和名称不对应的问题 * \u003cli\u003e2. 仍存在: 生产者还未生产，消费者先消费了 * * @author wangshuo * @date 2020/08/20 */ public class TestMain { public static void main(String[] args) { Goods goods = new Goods(); Producer producer = new Producer(goods); Consumer consumer = new Consumer(goods); Thread t1 = new Thread(producer); Thread t2 = new Thread(consumer); t1.start(); t2.start(); } } 版本 4\n商品类\n1 2 3 4 5 6 7 @Data public class Goods { /** 品牌 */ private String brand; /** 名称 */ private String name; } 生产者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public class Producer implements Runnable { private BlockingQueue\u003cGoods\u003e bq; public Producer(BlockingQueue\u003cGoods\u003e bq) { this.bq = bq; } @Override public void run() { for (int i = 0; ; i++) { Goods goods; if (i % 2 == 0) { goods = new Goods(\"娃哈哈\", \"矿泉水\"); } else { goods = new Goods(\"旺仔\", \"小馒头\"); } System.out.println(\"生产了 \" + goods.getBrand() + \" --- \" + goods.getName()); try { bq.put(goods); // 给消费者的输出一些时间，防止消费者还未输出 sout，生产者已经输出下一次的商品 Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } } } 消费者\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class Consumer implements Runnable { private BlockingQueue\u003cGoods\u003e bq; public Consumer(BlockingQueue\u003cGoods\u003e bq) { this.bq = bq; } @Override public void run() { while (true) { try { Goods goods = bq.take(); System.out.println(\"消费了 \" + goods.getBrand() + \" --- \" + goods.getName()); } catch (InterruptedException e) { e.printStackTrace(); } } } } 启动类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /** * 生产者消费者问题第四版本，使用同步代码块（锁定 lbq，解决商标和名称不对应问题）和 BlockingQueue（解决生产和消费的顺序问题） * \u003cp\u003e解决了： * \u003cli\u003e1. 商品商标和名称不对应的问题 * \u003cli\u003e2. 仍存在：生产者还未生产，消费者先消费了 * * @author wangshuo * @date 2020/08/22 */ public class TestMain { public static void main(String[] args) { ArrayBlockingQueue\u003cGoods\u003e bq = new ArrayBlockingQueue\u003c\u003e(1); Producer producer = new Producer(bq); Consumer consumer = new Consumer(bq); Thread t1 = new Thread(producer); Thread t2 = new Thread(consumer); t1.start(); t2.start(); } } 线程池 为什么使用线程池？ 在实际使用中，线程是很占用系统资源的，如果对线程管理不善，很容易导致系统问题。 因此，在大多数并发框架中，都会使用线程池来管理线程，使用线程池管理线程主要有如下好处\n使用线程池可以重复利用已有的线程继续执行任务，避免线程在创建和销毁时造成的消耗 由于没有线程创建和销毁的消耗，可以提高系统响应速度 通过线程可以对线程进行合理的管理，根据系统的承受能力调整可运行线程数量等 线程池执行过程 概念\n核心线程池：线程池中最少线程数，线程池启动及运行时，至少包含该数量的线程 阻塞队列：存放暂时无法执行的线程的队列（BlockingQueue） 线程池：线程池中最大线程数。 执行过程\n先判断核心线程池所有的线程是否都在执行任务。如果不是则新创建一个线程执行刚提交的任务；否则，进入第 2 步 判断当前阻塞队列是否已满，如果未满，则将提交的任务放置在阻塞队列中；否则，进入第 3 步 判断线程池中所有的线程是否都在执行任务，如果没有，则创建一个新的线程来执行任务；否则，交给饱和策略进行处理 饱和策略（拒绝策略）\nThreadPoolExecutor.AbortPolicy：丢弃任务并抛出 RejectedExecutionException 异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）。 ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务。 线程池的分类 ThreadPoolExecutor\nnewCacheThreadPool\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; /** * 创建一个可根据需要创建新线程的线程池，并可在已构造的线程可用时重用他们。 * 这些线程池通常可以提高许多执行时间短的异步任务的效率。 * 调用 execute 方法将会重用之前已构造的并且可用的线程。如果没有可用的线程，将创建一个新的线程并添加到线程池中。 * 如果线程在 60 秒都没有被用到，将会把它终止并从缓存中移除。 * 因此，该线程池空闲时间很长将不会消耗任何资源。 * 请注意可以使用 ThreadPoolExecutor 构造函数创建具有相似属性但细节不同（例如，超时参数）的池。 * 并在需要时使用提供的 ThreadFactory 创建新线程。 * \u003cp\u003e特征： * \u003cli\u003e1.线程池中线程数量没有固定，可达到最大值（Integer.MAX_VALUE） * \u003cli\u003e2.线程池中的线程可进行缓存重复利用和回收（回收默认时间为 1 分钟） * \u003cli\u003e3.当线程池中没有可用线程，会重新创建一个线程 */ public class D01_CacheTheadPool { public static void main(String[] args) { ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i \u003c 200; i++) { executorService.execute(() -\u003e { System.out.println(Thread.currentThread().getName() + \" running.....\"); }); } executorService.shutdown(); } } newFixedThreadPool\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 /** * 创建一个可重用固定线程数的线程池，以共享的无界队列来运行这些线程。 * 在任何时候，至多有 nThreads 个被激活的线程处理任务。 * 当在所有线程都被激活时提交了新的任务，将会把它放到队列中等待，直到有一个线程变为可用状态。 * 如果任意一个线程在终止之前，由于执行过程中发生错误而被强行关闭，将会创建一个新的线程代替它执行随后的任务。 * 线程池中的线程将一直存在，直到它被明确的关闭。 * \u003cp\u003e特征: * \u003cli\u003e1.线程池中线程数是固定的，可达很好的控制线程的并发量 * \u003cli\u003e2.线程可以被重复使用，在显式关闭之前，都将一直存在 * \u003cli\u003e3.超出一定量的线程被提交时需要在队列中等待 * * @author wangshuo * @date 2020/08/22 */ public class D02_FixedThreadPool { public static void main(String[] args) { ExecutorService executorService = Executors.newFixedThreadPool(1); for (int i = 0; i \u003c 100; i++) { executorService.execute(() -\u003e { System.out.println(Thread.currentThread().getName() + \" running......\"); }); } executorService.shutdown(); } } newSingleThreadExecutor\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /** * 创建一个只使用单个 worker 线程操作无界队列的 Executor。 * （注意，无论怎样，只要该线程在正常终止之前，因为执行过程中发生错误而关闭，就会创建一个新的线程代替它执行随后的任务。） * 保证任务按照顺序执行，并且在同一时刻仅会有执行一个任务。 * 与其他等效的 newFixedThreadPool(1) 不同，可保证无需重新配置此方法所返回的 Executor 即可使用其他的线程。 * \u003cp\u003e特征： * \u003cli\u003e1.线程池中至多执行 1 个线程，之后提交的线程将会排在队列中依次执行 * * @author wangshuo * @date 2020/08/22 */ public class D03_SingleThreadPoolExecutor { public static void main(String[] args) { ExecutorService executorService = Executors.newSingleThreadExecutor(); for (int i = 0; i \u003c 100; i++) { executorService.execute(() -\u003e { System.out.println(Thread.currentThread().getName() + \" running......\"); }); } executorService.shutdown(); } } ScheduledThreadPoolExecutor\nnewScheduledThreadPool\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 /** * 创建一个线程池，可以延迟或定期执行。 * \u003cp\u003e特征： * \u003cli\u003e1.线程池中具有指定数量的线程，即便是空线程也将保留 * \u003cli\u003e2.可延迟或定期执行 * * @author wangshuo * @date 2020/08/23 */ public class D01_ScheduledThreadPool { public static void main(String[] args) { ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(3); long start = System.currentTimeMillis(); for (int i = 0; i \u003c 100; i++) { // 前一个任务结束 3 秒后执行下一个任务 scheduledExecutorService.schedule(() -\u003e { System.out.println(Thread.currentThread().getName() + \" 在\" + (System.currentTimeMillis() - start) + \"后 running.....\"); }, 3, TimeUnit.SECONDS); } /* for (int i = 0; i \u003c 100; i++) { // 在 1 秒后开始执行, 然后每 3 秒执行一次 scheduledExecutorService.scheduleAtFixedRate(() -\u003e { System.out.println(Thread.currentThread().getName() + \" 在\" + (System.currentTimeMillis() - start) + \"后 running.....\"); }, 1, 3, TimeUnit.SECONDS); }*/ /* for (int i = 0; i \u003c 100; i++) { // 在 3 秒后执行, 然后在前一个任务结束后 2 秒执行下一个任务 scheduledExecutorService.scheduleWithFixedDelay(() -\u003e { System.out.println(Thread.currentThread().getName() + \" 在\" + (System.currentTimeMillis() - start) + \"后 running.....\"); }, 3, 2, TimeUnit.SECONDS); }*/ /* 会在该方法中执行已提交的命令, 同时调用后不会再接收新的提交 cheduleAtFixedRate和scheduleWithFixedDelay 需要注释到 shutdown */ scheduledExecutorService.shutdown(); } } newSingleThreadScheduledExecutor\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 /** * 创建一个单线程的 Executor，可以在指定延迟或定期执行命令。 * （注意，无论怎样，只要该线程在正常终止之前，因为执行过程中发生错误而关闭，就会创建一个新的线程代替它执行随后的任务。） * 保证任务按照顺序执行，并且在同一时刻仅会有执行一个任务。 * 与其他等效的 newScheduledThreadPool(1) 不同，可保证无需重新配置此方法所返回的 Executor 即可使用其他的线程。 * \u003cp\u003e特征 * \u003cli\u003e1.线程池中至多执行 1 个线程，之后提交的线程将会排在队列中依次执行 * * @author wangshuo * @date 2020/08/23 */ public class D02_SingleThreadScheduledExecutor { public static void main(String[] args) { ScheduledExecutorService scheduledExecutorService = Executors.newSingleThreadScheduledExecutor(); long start = System.currentTimeMillis(); for (int i = 0; i \u003c 100; i++) { int finalI = i; scheduledExecutorService.schedule(() -\u003e { System.out.println(Thread.currentThread().getName() + \" 在\" + (System.currentTimeMillis() - start) + \"后 running..... i = \" + finalI); }, 2, TimeUnit.SECONDS); } scheduledExecutorService.shutdown(); } } ForkJoinPool\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 /** * 简单的打印, 每个任务最多打印 THREAD_HOLD 个数, 如果超过该数量, 就对其进行拆分（分治） */ public class D01_PrintTask extends RecursiveAction { // 最多打印 30 个数 private final static int THREAD_HOLD = 30; private int start; private int end; public D01_PrintTask(int start, int end) { this.start = start; this.end = end; } @Override protected void compute() { if (end - start \u003c THREAD_HOLD) { for (int i = start; i \u003c end; i++) { System.out.println(Thread.currentThread().getName() + \" 的i值: \" + i); } } else { int middle = (start + end) / 2; D01_PrintTask left = new D01_PrintTask(start, middle); D01_PrintTask right = new D01_PrintTask(middle, end); // 并行执行两个小任务 left.fork(); right.fork(); } } public static void main(String[] args) throws InterruptedException { D01_PrintTask task = new D01_PrintTask(0, 100); // 创建实例并执行分割任务 ForkJoinPool pool = new ForkJoinPool(); pool.submit(task); //线程阻塞，等待所有任务完成 pool.awaitTermination(2, TimeUnit.SECONDS); pool.shutdown(); } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 /** * 对数组中的数进行求和。每个任务最多可对数组中 THREAD_HOLD 个数求和, * 如果超过该数量，就对其进行拆分，最后将每个线程累加的结果再累加到一起（分治） */ public class D02_SumTask extends RecursiveTask\u003cInteger\u003e { // 每个任务最多只允许有20个数进行累加 private static final int THREAD_HOLD = 20; // 需要累加的数放在数组中 private int array[]; private int start; private int end; public D02_SumTask(int start, int end, int[] array) { this.start = start; this.end = end; this.array = array; } @Override protected Integer compute() { if (end - start \u003c THREAD_HOLD) { int sum = 0; for (int i = start; i \u003c end; i++) { sum += array[i]; } return sum; } else { int middle = (start + end) / 2; D02_SumTask left = new D02_SumTask(start, middle, array); D02_SumTask right = new D02_SumTask(middle, end, array); // 并行执行两个小任务 left.fork(); right.fork(); // 把两个小任务的结果累加起来 return left.join() + right.join(); } } public static void main(String[] args) throws ExecutionException, InterruptedException { int[] array = new int[100]; Random r = new Random(); int sum = 0; // 初始化 100 个元素数组 for (int i = 0; i \u003c array.length; i++) { int temp = r.nextInt(20); // 对数组元素赋值，并将数组元素的值累加 sum += (array[i] = temp); } System.out.println(\"初始化数组总和: sum = \" + sum); D02_SumTask task = new D02_SumTask(0, array.length, array); // 创建一个通用池，这个是 jdk8 提供的功能 ForkJoinPool pool = ForkJoinPool.commonPool(); // 提交分解的SumTask任务 Future\u003cInteger\u003e future = pool.submit(task); System.out.println(\"多线程执行结果: \" + future.get()); } } newWorkStealingPool\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /** * 创建一个带并行级别的线程池，并行级别决定了同一时刻最多有多少个线程在执行，如不传入并行级别参数，将默认为当前系统 CPU 核数 */ public class D03_WorkStealingPool { public static void main(String[] args) throws InterruptedException { // 设置并行级别为 2，即默认每时刻只有两个线程同时执行 ExecutorService executorService = Executors.newWorkStealingPool(2); for (int i = 0; i \u003c 10; i++) { int finalI = i; executorService.submit(() -\u003e { try { // 模拟该任务耗时 1s Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"线程: \" + Thread.currentThread().getName() + \" 完成任务: \" + finalI + \" 时间为: \" + LocalDateTime.now().getSecond()); }); } executorService.awaitTermination(10, TimeUnit.SECONDS); executorService.shutdown(); } } 线程池的生命周期 RUNNING：能接受新提交的任务，并且也能处理阻塞队列中的任务。 SHUTDOWN：关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务。 STOP：不能接受新任务，也不处理队列中的任务，会中断正在处理任务的线程。 TIDYING：如果所有的任务都已终止了，workerCount（有效线程数）为 0，线程池进入该状态后会调用 terminated() 方法进入 TERMINATED 状态。 TERMINATED：在 terminated() 方法执行完后进入该状态，默认 terminated() 方法中什么也没有做。 线程池参数说明 ThreadPoolExecutor\nnewCacheThreadPool，newFixedThreadPool，newSingleThreadExecutor，ScheduledThreadPool，SingleThreadScheduledExecutor 其实都是通过创建 ThreadPoolExecutor 类的对象实现的 的。\nThreadPoolExecutor 的全参构造方法如下\npublic ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u003cRunnable\u003e workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 参数 含义 int corePoolSize 核心线程池的大小 int maximumPoolSize 线程池能创建线程的最大个数 long keepAliveTime 空闲线程存活时间 TimeUnit unit keepAliveTime 的时间单位 BlockingQueue\u003cRunnable\u003e workQueue 用于保存任务的阻塞队列 ThreadFactory threadFactory 创建线程的工厂类 RejectedExecutionHandler handler 拒绝（饱和）策略 ForkJoinPool\nWorkStealingPool 和 ForkJoinPool 是通过创建 ForkJoinPool 类的对象实现的。\nForkJoinPool的全参构造方法如下\npublic ForkJoinPool(int parallelism, ForkJoinWorkerThreadFactory factory, UncaughtExceptionHandler handler, boolean asyncMode, int corePoolSize, int maximumPoolSize, int minimumRunnable, Predicate\u003c? super ForkJoinPool\u003e saturate, long keepAliveTime, TimeUnit unit) 参数 含义 int parallelism 并行级别，默认是 CPU 核数 ForkJoinWorkerThreadFactory factory 创建线程的工厂 UncaughtExceptionHandler handler 任务在执行过程发生不可恢复错误后的处理器，默认值为 null boolean asyncMode 异步模式，默认 false int corePoolSize 核心线程池的大小 int maximumPoolSize 线程池能创建线程的最大个数 int minimumRunnable 核心线程池中最小活跃线程数。当阻塞队列中线程较少时，直接在核心线程池中创建线程来执行新任务。 Predicate\\\u003c? super ForkJoinPool\\\u003e saturate 拒绝（饱和）策略 long keepAliveTime 空闲线程存活时间 TimeUnit unit keepAliveTime 的时间单位 阻塞队列 ArrayBlockingQueue\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 /** * 基于数组的阻塞队列，在其内部维护了一个定长数组，用来缓存队列中的数据对象。 * \u003cp\u003e这是一个常用的阻塞队列，除了一个定长数组外，其内部还保存着两个整型变量，分别标识着队列队列的头部和尾部。 * \u003cp\u003e在生产者放入数据和消费者获取数据时共用同一个锁对象，由此意味着两者无法实现真正的并行，这点尤其不同于 LinkedBlockingQueue； * \u003cp\u003e按照实现原理来分析，其完全可以采用分离锁，从而实现生产者和消费者操作的完全并行。Doug Lea 之所以没有这样去做，也许是因为该队列对于数据的写入和获取操作已经足够轻巧，以至于引入独立的锁机制，除了给代码带来额外的复杂性外，其在性能上完全占不到任何便宜。ArrayBlockingQueue 与 LinkedBlockingQueue 还有一个明显的不同之处在于，前者在插入或删除元素时不会产生或销毁任何额外的对象实例，而后者则会生成额外的 Node 对象，这在长时间需要高效并发地处理大批量数据的系统中，其对于 GC 的影响还是存在一定的区别。同时，在创建 ArrayBlockingQueue 时，我们还可以控制对象内部锁是否采用公平锁，默认使用非公平锁。 * * @author wangshuo * @date 2020/08/23 */ public class D01_ArrayBlockingQueue { static class Producer implements Runnable { private BlockingQueue\u003cInteger\u003e blockingQueue; public Producer(BlockingQueue\u003cInteger\u003e blockingQueue) { this.blockingQueue = blockingQueue; } @Override public void run() { try { for (int i = 0; ; i++) { Thread.sleep(1000); blockingQueue.put(i); System.out.println(\"生产者放入了 \" + i); } } catch (InterruptedException e) { e.printStackTrace(); } } } static class Consumer implements Runnable { private BlockingQueue\u003cInteger\u003e blockingQueue; public Consumer(BlockingQueue\u003cInteger\u003e blockingQueue) { this.blockingQueue = blockingQueue; } @Override public void run() { try { while (true) { System.out.println(\"消费者取出了 \" + blockingQueue.take()); } } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) { BlockingQueue\u003cInteger\u003e blockingQueue = new ArrayBlockingQueue\u003c\u003e(3); Producer producer = new Producer(blockingQueue); Consumer consumer = new Consumer(blockingQueue); new Thread(producer).start(); new Thread(consumer).start(); } } LinkedBlockingQueue\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 /** * \u003cp\u003e基于链表的阻塞队列，在其内部维护了一个链表，用来缓存队列中的数据对象。 * \u003cp\u003e可以选择是否和自定队列的大小，如不指定，默认是 Integer.MAX_VALUE。 * \u003cp\u003e当生产者往队列中放入一个数据时，队列会从生产者手中获取数据，并缓存到队列内部，而生产者立即返回；只有当队列缓冲区达到最大缓冲容量时（可通过构造函数指定该值，默认值为 Integer.MAX_VALUE），才会阻塞生产者队列，直到消费者从队列中消费掉一份数据，生产者线程会被唤醒，反之对于消费者这端的处理也基于同样地原理。而其之所以能够高效的处理并发数据，还因为其对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发情况下，生产者和消费者可以并行的操作队列中的数据，以此来提高整个队列的并发性能。 * * @author wangshuo * @date 2020/08/23 */ public class D02_LinkedBlockingQueue { static class Producer implements Runnable { private BlockingQueue\u003cInteger\u003e blockingQueue; public Producer(BlockingQueue\u003cInteger\u003e blockingQueue) { this.blockingQueue = blockingQueue; } @Override public void run() { try { for (int i = 0; ; i++) { Thread.sleep(1000); blockingQueue.put(i); System.out.println(\"生产者放入了 \" + i); } } catch (InterruptedException e) { e.printStackTrace(); } } } static class Consumer implements Runnable { private BlockingQueue\u003cInteger\u003e blockingQueue; public Consumer(BlockingQueue\u003cInteger\u003e blockingQueue) { this.blockingQueue = blockingQueue; } @Override public void run() { try { while (true) { System.out.println(\"消费者取出了 \" + blockingQueue.take()); } } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) { BlockingQueue\u003cInteger\u003e blockingQueue = new LinkedBlockingDeque\u003c\u003e(); Producer producer = new Producer(blockingQueue); Consumer consumer = new Consumer(blockingQueue); new Thread(producer).start(); new Thread(consumer).start(); } } DelayQueue\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 /** * 延迟队列中的元素只有当其指定的延迟时间到了，才能从队列中获取该元素。DelayQueue 是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。 * \u003cp\u003e使用场景较少，但都相当巧妙，常见的例子比如使用一个 DelayQueue 来管理一个超时未响应的连接队列。 */ public class D03_DelayQueue { static class DelayTask implements Delayed { /** 线程名称 */ private String name; /** 延迟执行时间 */ private long delayTime; /** 延迟执行时间单位 */ private TimeUnit delayTimeUnit; /** 执行时间 */ private Long executeTime; public DelayTask(String name, long delayTime, TimeUnit delayTimeUnit) { this.name = name; this.delayTime = delayTime; this.delayTimeUnit = delayTimeUnit; this.executeTime = System.currentTimeMillis() + this.delayTimeUnit.toMillis(delayTime); } @Override public long getDelay(TimeUnit unit) { return unit.convert(this.executeTime - System.currentTimeMillis(), unit); } @Override public int compareTo(Delayed o) { if (this.getDelay(TimeUnit.MILLISECONDS) \u003e o.getDelay(TimeUnit.MILLISECONDS)) { return 1; } else if (this.getDelay(TimeUnit.MILLISECONDS) \u003c o.getDelay(TimeUnit.MILLISECONDS)) { return -1; } return 0; } } public static void main(String[] args) { DelayQueue\u003cDelayTask\u003e queue = new DelayQueue\u003c\u003e(); DelayTask t1 = new DelayTask(\"Task1\", 1000L, TimeUnit.MILLISECONDS); DelayTask t2 = new DelayTask(\"Task2\", 2000L, TimeUnit.MILLISECONDS); DelayTask t3 = new DelayTask(\"Task3\", 3000L, TimeUnit.MILLISECONDS); queue.put(t1); queue.put(t2); queue.put(t3); System.out.println(\"queue put done......\"); while (!queue.isEmpty()) { try { DelayTask take = queue.take(); System.out.println(take.name + \" : \" + System.currentTimeMillis()); } catch (InterruptedException e) { e.printStackTrace(); } } } } PriorityBlockingQueue\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 /** * 基于优先级的阻塞队列（优先级的判断基于构造函数传入的 Comparator 对象来决定）。需要注意的是，该队列并不会阻塞生产者，而只会在没有可消费数据时阻塞消费者。因此使用的时候要特别注意，生产者生产数据的速度绝对不能比消费者消费数据的速度快，否则时间一长，会最终耗尽所有的可用堆内存空间。在实现该队列时，内部控制线程同步的锁采用的是公平锁。 * * @author wangshuo * @date 2020/08/24 */ public class D04_PriorityBlockingQueue { static class Task implements Comparable\u003cTask\u003e { private int id; private String name; public Task(int id, String name) { this.id = id; this.name = name; } public int getId() { return id; } public void setId(int id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public int compareTo(Task o) { return this.id - o.id; } @Override public String toString() { return name; } } public static void main(String[] args) throws InterruptedException { PriorityBlockingQueue\u003cTask\u003e queue = new PriorityBlockingQueue(); queue.put(new Task(5, \"TaskID=5\")); queue.put(new Task(1, \"TaskID=1\")); queue.put(new Task(2, \"TaskID=2\")); System.out.println(\"Queue: \" + queue); Task take = queue.take(); System.out.println(take.name); System.out.println(\"Queue: \" + queue); } } SynchronousQueue\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 /** * 一种无缓冲的等待队列，类似于无中介的直接交易，有点像原始社会中的生产者和消费者，生产者拿着商品去集市销售给产品的最终消费者，而消费者必须亲自去集市找到所要商品的直接生产者，如果一方没有找到合适的目标，那么大家都在集市等待。相对于有缓冲的 BlockingQueue 来说，少了一个中间经销商环节（缓冲区），如果有经销商，生产者直接把产品批发给经销商，而无需在意经销商最终会将这些产品卖给哪些消费者，由于经销商可以库存一部分商品，因此相对于直接交易模式，总体来说采用经销商的模式吞吐量会高一些（可以批量售卖）；但另一方面，有因为经销商的引入，使得产品从生产者到消费者中间增加了额外的交易环节，单个产品的及时相应性能可能会降低。 * \u003cp\u003e声明一个 SynchronousQueue 有两种不同的方式，它们之间有着不太一样的行为。公平模式和非公平模式（默认使用）的区别： * \u003cli\u003e如果采用公平模式，会使用公平锁，并配合一个 FIFO 队列来阻塞所欲的生产者和消费者，从而实现整体的公平策略 * \u003cli\u003e如果是非公平模式，会使用非公平锁，同时配合一个 LIFO 队列来管理多余的生产者和消费者，而后一种模式，如果生产者和消费者的处理速度有差距，则很容易出现饥渴的情况，即可能有某些生产者或者是消费者的数据永远得不到处理。 * * @author wangshuo * @date 2020/08/24 */ public class D05_SynchronousQueue { static class Producer implements Runnable { private BlockingQueue\u003cString\u003e blockingQueue; public Producer(BlockingQueue\u003cString\u003e blockingQueue) { this.blockingQueue = blockingQueue; } @Override public void run() { try { while (true) { String data = UUID.randomUUID().toString(); blockingQueue.put(data); System.out.println(Thread.currentThread().getName() + \", Put: \" + data); Thread.sleep(1000); } } catch (InterruptedException e) { e.printStackTrace(); } } } static class Consumer implements Runnable { private BlockingQueue\u003cString\u003e blockingQueue; public Consumer(BlockingQueue\u003cString\u003e blockingQueue) { this.blockingQueue = blockingQueue; } @Override public void run() { try { while (true) { Thread.sleep(2000); String data = blockingQueue.take(); System.out.println(Thread.currentThread().getName() + \", Take: \" + data); } } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) { BlockingQueue\u003cString\u003e blockingQueue = new SynchronousQueue\u003c\u003e(); new Thread(new Producer(blockingQueue)).start(); new Thread(new Consumer(blockingQueue)).start(); new Thread(new Consumer(blockingQueue)).start(); } } ArrayBlockingQueue 和 LinkedBlockingQueue 区别\n队列中锁的实现不同\nArrayBlockingQueue 中的锁是没有分离的，即生产者和消费者共用同一个锁\nLinkedBlockingQueue 中锁是分离的，即生产者用的是 putLock，消费者是 takeLock\n队列大小初始化方式不通\nArrayBlockingQueue 必须指定队列大小 LinkedBlockingQueue 可以不指定队列的大小，默认是 Integer.MAX_VALUE 线程池的 execute 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 public class ThreadPoolExecutor extends AbstractExecutorService { public void execute(Runnable command) { if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn't, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) \u003c corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } if (isRunning(c) \u0026\u0026 workQueue.offer(command)) { int recheck = ctl.get(); if (! isRunning(recheck) \u0026\u0026 remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); } else if (!addWorker(command, false)) reject(command); } } 如果当前运行的线程少于 corePoolSize，则会创建新线程来执行新任务，否则下一步 如果阻塞队列未满，则将提交的任务存放到阻塞队列 workQueue 中，否则下一步 如果线程个数未超过 maximumPoolSize，则会创建新线程来执行任务，否则下一步 根据拒绝（饱和）策略 RejectedExecutionHandler 进行处理 线程池的 execute 和 submit 对比 submit 是基方法 Executor.execute(Runnable) 的延伸，通过创建并返回一个 Future 类对象，可用于取消执行和/或等待完成。\nexecute 只能执行 Runnable 接口的实现类，submit 可以执行 Runnable 或 Callable 接口的实现类 execute 没有返回值，submit 返回 Future，通过 Future 的 get() 方法可以获取 call() 方法的返回值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /** * Callable 接口和线程池的 submit 方法 */ public class D01_Callable { static class CallableTask implements Callable\u003cString\u003e { @Override public String call() throws Exception { Thread.sleep(1000); return Thread.currentThread().getName(); } } public static void main(String[] args) throws Exception { ExecutorService executorService = Executors.newFixedThreadPool(5); while (true) { Future\u003cString\u003e submit = executorService.submit(new CallableTask()); System.out.println(submit.get()); } } } 线程池的关闭 关闭线程池，可以通过 shutdown 或 shutdownNow 方法。\n原理：遍历线程池中的所有线程，然后依次中断。\nshutdownNow 首先将线程池状态设置为 STOP，然后尝试停止所有正在执行和未执行的线程，并返回等待执行任务的列表 shutdown 只是将线程池的状态设置为 SHUTDOWN 状态，然后中断所有没有正在执行任务的线程 ","description":"","tags":["MSB","JUC","Java"],"title":"多线程入门","uri":"/posts/msb/juc/thread-introduction/"},{"categories":null,"content":"SpringBoot 项目打 war 包 步骤\n其实就是将 SpringBoot 工程修改为了 Maven Web 工程，然后添加了一个 SpringBootServletInitializer 的子类，在外置 tomcat 启动后，自动启动 SpringBoot 工程。\n必须创建一个 war 项目：jar 项目可以修改 pom.xml 中的 \u003cpackaging\u003ewar\u003c/packaging\u003e\n1 2 3 4 \u003cgroupId\u003ecc.ccue\u003c/groupId\u003e \u003cartifactId\u003espring-boot-jpa-demo\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003cpackaging\u003ewar\u003c/packaging\u003e 创建好目录结构：\nIDEA 可通过 Project Structure 快速创建，手动创建的也需要进入 Project Structure 将 web 根目录和 web.xml 设置好\n将嵌入式的 tomcat 指定为 provided\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-tomcat\u003c/artifactId\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e 必须编写一个 SpringBootServletInitializer 的子类，并调用 configure 方法\n1 2 3 4 5 6 7 8 9 public class ServletInitializer extends SpringBootServletInitializer { @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) { // 需要传入 SpingBoot 应用的主程序 return application.sources(Application.class); } } IDEA 通过 Edit Configurations... 添加 tomcat 容器，并将当前项目设置进去\n启动外置 tomcat 就可以使用（此处直接运行 Application.java 使用的还是嵌入式的 tomcat）\n","description":"","tags":["JAVA","Spring Boot"],"title":"SpringBoot 项目打 war 包","uri":"/posts/spring-boot/springboot-package-to-war/"},{"categories":null,"content":"Kafka 安装 安装 jdk 并配置环变量 修改 /etc/hostname 修改 /etc/hosts\n单机安装 应用下载\nzookeeper 下载\nkafka 下载\n安装 zk\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 $ tar -zxvf apache-zookeeper-3.6.1-bin.tar.gz $ cd apache-zookeeper-3.6.1-bin/ $ cp conf/zoo_sample.cfg conf/zoo.cfg $ mkdir data $ vi conf/zoo.cfg dataDir=/home/normal/software/apache-zookeeper-3.6.1-bin/data $ ./bin/zkServer.sh start conf/zoo.cfg $ ./bin/zkServer.sh status conf/zoo.cfg ZooKeeper JMX enabled by default Using config: conf/zoo.cfg Client port found: 2181. Client address: localhost. Mode: standalone $ jps 879 QuorumPeerMain $ ./bin/zkServer.sh stop conf/zoo.cfg 安装 kafka\n1 2 3 4 5 6 7 8 9 10 $ tar -zxvf ../mnt/kafka_2.12-2.5.0.tgz $ cd kafka_2.12-2.5.0/ $ vi config/server.properties listeners=PLAINTEXT://k8s-master:9092 log.dirs=/home/normal/software/kafka_2.12-2.5.0/kafka-logs zookeeper.connect=k8s-master:2181 $ ./bin/kafka-server-start.sh -daemon config/server.properties $ jps 13548 Kafka $ ./bin/kafka-server-stop.sh config/server.properties 创建 topic，因为是单机模式，所以 1 个 topic 可以创建多个 partitions，但是 replication-factor（副本数）只能有 1 个\n1 $ ./bin/kafka-topics.sh --create --bootstrap-server=k8s-master:9092 --topic topic01 --partitions 3 --replication-factor 1 启动一个 consumer，订阅 topic01，并且属于 group01，如果不指定组，系统会随机给指定一个组\n1 $ ./bin/kafka-console-consumer.sh --bootstrap-server=k8s-master:9092 --topic topic01 --group group01 启动一个 producer，向 topic02 中发送消息\n1 $ ./bin/kafka-console-producer.sh --broker-list k8s-master:9092 --topic topic01 此时 topic01 中有 3 个 partitions，而 group01 组中只有一个 consumer，所以该 consumer 可以接收到所有 partitions 中的消息。\n再次启动两个 consumer，订阅 topic01，并且属于 group01\n1 $ ./bin/kafka-console-consumer.sh --bootstrap-server=k8s-master:9092 --topic topic01 --group group01 此时再次发送消息，可见同一个消息只会被同一组中的一个 consume 消费，证明了消息的组内均分，且是按照轮询机制来消费的（partitions 与 consumer 数量相同均为 3）。\n关闭一个 consume，再次发送消息，发现消息被负载均衡的消费掉（partitions 数 \u003e consume 数）\n启动一个 consumer，订阅 topic01，并且属于 group02 组\n1 $ ./bin/kafka-console-consumer.sh --bootstrap-server=k8s-master:9092 --topic topic01 --group group02 此时再次发送消息，可见同一消息会被不同组的两个 consumer 同时消费，证明了消息是组间广播的\n集群安装 时钟同步\nzk 集群安装\n1 2 3 4 5 6 7 8 9 10 $ tar -zxvf apache-zookeeper-3.6.1-bin.tar.gz $ cd apache-zookeeper-3.6.1-bin/ $ cp conf/zoo_sample.cfg conf/zoo.cfg $ mkdir data $ vi conf/zoo.cfg dataDir=/home/normal/software/apache-zookeeper-3.6.1-bin/data server.1=k8s-master:2888:3888 server.2=k8s-node1:2888:3888 server.3=k8s-node2:2888:3888 在每台机器的 data 目录创建一个名称为 myid 的文件，内容与上方配置的 server.后面的数字对应，比如在 k8s-master 中，使用如下命令创建内容为 1 的 myid 文件\n1 2 3 $ echo 1 \u003e data/myid $ ./bin/zkServer.sh start conf/zoo.cfg $ ./bin/zkServer.sh status conf/zoo.cfg 将所有 zk 均启动后查看状态，可见 1leader，多 follower 的现象\n1 2 3 4 5 6 7 8 9 10 ZooKeeper JMX enabled by default Using config: conf/zoo.cfg Client port found: 2181. Client address: localhost. Mode: leader ZooKeeper JMX enabled by default Using config: conf/zoo.cfg Client port found: 2181. Client address: localhost. Mode: follower $ ./bin/zkServer.sh stop conf/zoo.cfg kafka 集群安装\n1 2 3 $ tar -zxvf ../mnt/kafka_2.12-2.5.0.tgz $ cd kafka_2.12-2.5.0/ $　vi config/server.properties 多台机器的 broker.id 的值不能相同\n1 2 3 4 5 broker.id=0 listeners=PLAINTEXT://k8s-master:9092 log.dirs=/home/normal/software/kafka_2.12-2.5.0/kafka-logs zookeeper.connect=k8s-master:2181,k8s-node1:2181,k8s-node2:2181 $ bin/kafka-server-start.sh -daemon config/server.properties topic 创建 topic\n1 $ ./bin/kafka-topics.sh --bootstrap-server k8s-master:9092,k8s-node1:9092,k8s-node2:9092 --create --topic topic01 --partitions 3 --replication-factor 2 查看每个 kafka 节点的 kafka-logs 目录，可见 topic0 共包含 3 个分区，且每个分区有有两台备份\n查看所有 topic\n1 $ ./bin/kafka-topics.sh --bootstrap-server k8s-master:9092,k8s-node1:9092,k8s-node2:9092 --list 查看 topic 详细信息\n1 2 3 4 5 $ ./bin/kafka-topics.sh --bootstrap-server k8s-master:9092,k8s-node1:9092,k8s-node2:9092 --describe --topic topic01 Topic: topic01\tPartitionCount: 3\tReplicationFactor: 2\tConfigs: segment.bytes=1073741824 Topic: topic01\tPartition: 0\tLeader: 0\tReplicas: 0,3\tIsr: 0,3 Topic: topic01\tPartition: 1\tLeader: 3\tReplicas: 3,1\tIsr: 3,1 Topic: topic01\tPartition: 2\tLeader: 1\tReplicas: 1,0\tIsr: 1,0 修改 topic\npartitions 数量只能增加，不能减少。\n1 $ ./bin/kafka-topics.sh --bootstrap-server k8s-master:9092,k8s-node1:9092,k8s-node2:9092 --alter --topic topic02 --partitions 2 删除 topic\n1 2 $ ./bin/kafka-topics.sh --bootstrap-server k8s-master:9092,k8s-node1:9092,k8s-node2:9092 --delete --topic topic02 $ ./bin/kafka-server-stop.sh config/server.properties ","description":"","tags":["MSB","Kafka","Java"],"title":"Kafka 安装","uri":"/posts/java/msb-kafka-install/"},{"categories":null,"content":"系统 I/O 常用工具安装 1 yum install -y strace lsof pmap tcpdump pcstat 安装\n下载 golang：https://studygolang.com/dl 设置 GO 环境变量和代理 1 2 3 4 5 6 GOROOT=/home/normal/software/go GOPATH=$GOROOT/gopath GO111MODULE=on GOPROXY=https://goproxy.io,direct PATH=$GOROOT/bin:$PATH export GOROOT GOPATH GO111MODULE GOPROXY PATH 编译 pcstat，并将其移动到 /usr/local/bin 目录 1 2 3 go get golang.org/x/sys/unix go get github.com/tobert/pcstat/pcstat sudo cp -a $GOPATH/bin/pcstat /usr/local/bin 对文件描述符的理解 0：std_in，标准输入 1：std_out，标准输出 2：err_out，错误输出 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 创建一个文件描述符（fd, file descriptor），用于读取 xxoo.txt 中的内容 $ exec 8\u003c xxoo.txt # 查看当前 bash 下的 fd，可以看到包含上一步中创建的 fd，$$ 代表当前 bash 的进程号 $ ll /etc/$$/fd lr-x------. 1 wangshuo wangshuo 64 Jul 14 01:18 8 -\u003e /home/wangshuo/Public/xxoo.txt # 使用 lsof 命令进行查看，可见 8 号 fd 是可读的（r 读，w 写，u 读写），类型为普通文件（REG，regular），偏移量（OFFSET）为 0 $ lsof -op $$ COMMAND PID USER FD TYPE DEVICE OFFSET NODE NAME bash 13229 wangshuo 8r REG 253,3 0t0 3162420 /home/wangshuo/Public/xxoo.txt # 读取 fd 为 8 的文件，将其内容赋值给变量（此处的 read 方法读到换行符\\n 后，就不会继续向后读取了） $ read a 0\u003c\u0026 8 # 打印变量 a，此时 a 的值为 xxoo.txt 的第一行的值 $ echo $a abc # 可以看到 OFFSET 变为了 4，表示文件被读了 4 个字节（abc\\n） $ lsof -op $$ COMMAND PID USER FD TYPE DEVICE OFFSET NODE NAME bash 13925 wangshuo 8r REG 253,3 0t4 3162420 /home/wangshuo/Public/xxoo.txt # 启动另一个 bash 窗口，查看其 fd 列表，发现并没有 8r 文件描述符 $ lsof -op $$ # 在该新 bash 窗口中执行下方命令，会发现不会对第一个 bash 线程中的 fd 造成影响 $ exec 8\u003c xxoo.txt $ read a 0\u003c\u0026 8 $ echo $a $ read a 0\u003c\u0026 8 $ echo $a 系统为每个线程维护了一套自己的文件描述符，不同线程内的 FD 是互不影响的。\nlinux 中一些名词的理解 swap：交换分区，将一部分的硬盘空间当作内存来用，当内存快被占满的时候，kernel 会根据 LRU（Least Recently Used）算法将内存中长期没有使用到的 PageCache 刷进 swap 中。 PageCache：在 linux 的内存中，由 kernel 进行维护，默认大小为 1 页 4KB，作为应用程序和物理磁盘之间读写数据的缓存。 当调用 read()方法时，先从 PageCache 中查找是否包含需要的数据块，如果包含直接返回，否则，从磁盘中找到相应的数据块缓存到 PageCache 中，再返回 当调用 write() 方法时，先将数据写入到 PageCache 中，然后 DMA（协处理器）定时将 PageCache 中的数据刷新到物理硬盘。内容未被保存到硬盘的 PageCache，称为脏页（Dirty Page）。 DMA（Direct Memory Access，直接存储器访问，协处理器）：如果使用 CPU 操控内存与 IO 设备间的数据传输，会大量占用 CPU 的时间，使得 CPU 无法处理其它应用的指令，严重影响机器性能。而使用 DMA 能使 IO 设备直接和内存之间进行成批数据的快速传送。 由于程序是先将数据写入到 PageCache，而 PageCache 是在内存中，所以，如果在程序写入数据时强制断电，会造成数据的丢失 MMU（Memory Management Unit，内存管理单元）：它的功能包括虚拟地址到物理地址的转换（即虚拟内存管理）、内存保护、中央处理器高速缓存的控制。 应用程序（比如一个 Java 程序）在运行时，它看到的内存是一个线性的，完全属于它自己的虚拟内存，而在真实的物理内存上，它使用的并不一定是连续的。 MMU 将应用程序中的虚拟内存地址与真实的物理内存之间进行了地址的映射，从而规避了由于应用程序可以直接访问物理内存而造成的一系列不安全的问题。 mmap（Memory Mapped Files）：内存映射文件，将物理磁盘上的文件映射到内核的多个 PageCache 中，此时向 PageCache 中写入数据，就相当于写入到了文件中，而真实情况是，写入的内容是在 PageCache 中，需要依赖 kernel 对赃页的处理方式，由 kernel 将 PageCache 中的数据刷入到磁盘。 ZoreCopy：零拷贝。传统 web 程序执行流程：内核将数据从磁盘（内核空间）拷贝到内存（内核空间），再从内存（内核空间）拷贝到应用程序（用户空间），应用程序对数据进行处理后，将处理后的数据（用户空间）写入到内存（内核空间），内核再将内存中的数据通过网络发送出去，此种方式包含两次用户态与内核态的切换。 而零拷贝，是借助与 mmap，将应用程序获取到的数据以及处理后的数据均是放在内核管理的内存中的，就不会再有两次用户态与内核态的切换，因此称其为零拷贝，极大的提高了程序的效率。 文件 IO 最基本文件 IO 编写运行脚本，简化测试\n1 2 3 4 rm -rf out* javac OsFileIo.java # 追踪程序的系统调用，将信息输出到 out 开头的文件中 strace -ff -o out java OsFileIo $1 修改脚本权限，并运行脚本\n1 2 chmod 755 run.sh sh run.sh 0 此时，在另一窗口使用 ll -h 查看 jout.txt，可以看到其占用空间持续增长\n1 2 3 4 5 6 7 [normal@localhost testfileio]$ ll -h jout.txt -rw-rw-r--. 1 normal normal 316K Jul 14 23:30 jout.txt [normal@localhost testfileio]$ ll -h jout.txt -rw-rw-r--. 1 normal normal 837K Jul 14 23:30 jout.txt ... [normal@localhost testfileio]$ ll -h jout.txt -rw-rw-r--. 1 normal normal 2.2M Jul 14 23:30 jout.txt 使用 tail -f 命令也可以看到向文件中写了内容\n123456789 ... 123456789 对虚拟机进行强制关机，重新登录，查看 jout.txt，发现其文件大小为 0，可见，数据并没有直接写入磁盘，证明了 PageCache 的存在\n1 2 [normal@localhost testfileio]$ ll -h jout.txt -rw-rw-r--. 1 normal normal 0 Jul 14 23:33 jout.txt 再次运行，一段时间关闭程序，查看输出的系统调用文件，可见每一次调用系统的 write()方法，写入了 10Byte 的数据。注意：每次 wirite 方法都是一次系统调用\n1 2 3 write(4, \"123456789\\n\", 10) = 10 write(4, \"123456789\\n\", 10) = 10 ... Buffered 文件 IO 使用同样的脚本，修改传入的变量为 1\n1 sh run.sh 1 在另一窗口使用 ll -h 命令查看 jout.txt 的大小，可见其大小一直增多，且增长的速度明显比基本 IO 方式快的多\n1 2 3 4 5 6 7 [normal@localhost testfileio]$ ll -h jout.txt -rw-rw-r--. 1 normal normal 38M Jul 14 23:34 jout.txt [normal@localhost testfileio]$ ll -h jout.txt -rw-rw-r--. 1 normal normal 99M Jul 14 23:34 jout.txt ... [normal@localhost testfileio]$ ll -h jout.txt -rw-rw-r--. 1 normal normal 2.0G Jul 14 23:39 jout.txt 使用 tail -f 命令也可以看到向文件中写了内容\n123456789 ... 123456789 对虚拟机进行强制关机，重新登录，查看 jout.txt，发现其文件大小为 0（或小于最后一次 ll -h 看到的大小），可见，数据并没有直接写入磁盘，证明了 PageCache 的存在\n1 2 [normal@localhost testfileio]$ ll -h jout.txt -rw-rw-r--. 1 normal normal 0 Jul 14 23:41 jout.txt 再次运行，一段时间关闭程序，查看输出的系统调用文件，可见每一次调用系统的 write()方法，写入了 8190Byte 的数据。注意：每次 wirite 方法都是一次系统调用\n1 2 3 write(5, \"123456789\\n123456789\\n123456789\\n12\"..., 8190) = 8190 write(5, \"123456789\\n123456789\\n123456789\\n12\"..., 8190) = 8190 ... 此处一次系统调用写入了 8190B 的数据，数据相同时，减少了系统调用的次数，显著提高了 IO 的速度\n使用 pcstat 命令查看 PageCache 的脏页信息\n重新运行脚本 1 sh run.sh 1 使用 pcstat 命令查看 jout.txt 文件的信息，可见随着文件的变大，系统会将内存中的 PageCache 刷到物理磁盘中，从而空出内存空间 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 [normal@192-168-99-100 testfileio]$ pcstat jout.txt +----------+----------------+------------+-----------+---------+ | Name | Size (bytes) | Pages | Cached | Percent | |----------+----------------+------------+-----------+---------| | jout.txt | 93963870 | 22941 | 22941 | 100.000 | +----------+----------------+------------+-----------+---------+ ... [normal@192-168-99-100 testfileio]$ pcstat jout.txt +----------+----------------+------------+-----------+---------+ | Name | Size (bytes) | Pages | Cached | Percent | |----------+----------------+------------+-----------+---------| | jout.txt | 525434880 | 128280 | 124503 | 097.056 | +----------+----------------+------------+-----------+---------+ ... [normal@192-168-99-100 testfileio]$ pcstat jout.txt +----------+----------------+------------+-----------+---------+ | Name | Size (bytes) | Pages | Cached | Percent | |----------+----------------+------------+-----------+---------| | jout.txt | 822444032 | 200792 | 123068 | 061.291 | +----------+----------------+------------+-----------+---------+ ... [normal@192-168-99-100 testfileio]$ pcstat jout.txt +----------+----------------+------------+-----------+---------+ | Name | Size (bytes) | Pages | Cached | Percent | |----------+----------------+------------+-----------+---------| | jout.txt | 2127646720 | 519445 | 127132 | 024.475 | +----------+----------------+------------+-----------+---------+ ... 使用如下命令可以查看到与脏页相关的系统配置信息，该配置文件为 /etc/sysctl.conf\n1 2 3 4 5 6 7 8 9 10 $ sudo sysctl -a | grep dirty vm.dirty_background_bytes = 0 # 如果脏页占了内存的 10%，将脏页向磁盘写入 vm.dirty_background_ratio = 10 vm.dirty_bytes = 0 vm.dirty_expire_centisecs = 3000 # 如果脏页占了内存的 30%，阻塞该进程 vm.dirty_ratio = 30 vm.dirty_writeback_centisecs = 500 vm.dirtytime_expire_seconds = 43200 ByteBuffer 的使用说明 使用同样的脚本，修改传入的变量为 2 shell sh run.sh 2 程序输出结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 position = 0 limit = 1024 capacity = 1024 mark = java.nio.DirectByteBuffer[pos=0 lim=1024 cap=1024] ------------ put(abc) ------------ mark = java.nio.DirectByteBuffer[pos=3 lim=1024 cap=1024] ------------ flip ------------ mark = java.nio.DirectByteBuffer[pos=0 lim=3 cap=1024] ------------ get ------------ mark = java.nio.DirectByteBuffer[pos=1 lim=3 cap=1024] ------------ compace ------------ mark = java.nio.DirectByteBuffer[pos=2 lim=1024 cap=1024] ------------ clear ------------ mark = java.nio.DirectByteBuffer[pos=0 lim=1024 cap=1024] 相应图示：\nRandomAccessFile 以及 FileChannel 随机读写 NIO 使用同样的脚本，修改传入的变量为 3，同时再开启两个窗口，一个使用 tail -f 追踪主程序的系统调用信息，一个负责查看文件内容及大小信息 1 sh run.sh 3 当输出 write 之后，程序阻塞，主程序的内存调用信息包含如下的输出，说明 raf.write 执行了系统调用 1 2 write(4, \"hello world\", 11) = 11 write(4, \"hello java\", 10) = 10 查看文件内容，为 1 hello worldhello java 输入回车，程序输出 seek(4)，此时使用 cat 命令查看 jout.txt，可见 123 是从 hello worldhello java 角标为 4 的位置开始写入的 1 hell123orldhello java 使用 jps 命令，查看 OsFileIo 的进程 id，使用 lsof -p 进程号 查看文件描述符信息，jout.txt 仅包含 FD 为 5u 的文件描述符，大小为 21Byte 1 2 COMMAND PID USER FD TYPE DEVICE OFFSET NODE NAME java 2531 normal 5u REG 253,0 21 34601606 /home/normal/testfileio/jout.txt 继续回车，程序输出 map.put(@@@)，会发现 map.put() 并没有执行系统调用，查看 jout.txt，内容也已经写入文件 1 @@@l123orldhello java 使用 lsof -p 进程号 再次查看文件描述符信息，此时 jout.txt 多了一个 FD 为 mem 的文件描述符，表明已经进行了 mmap 内存映射，同时文件大小也变为了设置的 4096Byte 1 2 3 COMMAND PID USER FD TYPE DEVICE OFFSET NODE NAME java 2531 normal mem REG 253,0 4096 34601606 /home/normal/testfileio/jout.txt java 2531 normal 5u REG 253,0 4096 34601606 /home/normal/testfileio/jout.txt 继续回车，程序输出如下，读取 FileChannel 中的字节数据存放到给定的 buffer 中，翻转该 buffer，将其中的数据进行读出 1 2 3 fileChannel.read(buffer); buffer = java.nio.HeapByteBuffer[pos=4096 lim=8192 cap=8192] buffer.flip(); buffer = java.nio.HeapByteBuffer[pos=0 lim=4096 cap=8192] @@@l123orldhello java 网络 IO TCP 参数 使用 sudo tcpdump -nn -i enp0s3 port 9999 抓取 enp0s3 网卡，9999 端口的 tcp 包\n启动 SocketIoProperties 服务端，程序输出信息后阻塞，等待客户端连接，此时 tcp 抓包没有任何信息，因为只是启动了监听，没有发送/接受数据包\n使用 netstat -anp 查看 9999 端口信息，可见 PID 为 14870 的应用正在监听 9999 端口\n1 2 Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp6 0 0 :::9999 :::* LISTEN 14870/java 使用 lsof -p 14870 查看文件描述符信息，可见其已有一个文件描述符显示为监听状态\n1 2 Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name java 14870 normal 5u IPv6 5127216 0t0 TCP *:distinct (LISTEN) 启动 SocketClient 客户端，可见 tcpdump 抓取到了客户端与服务端的 3 次握手\n1 2 3 09:14:40.082915 IP 192.168.99.1.45554 \u003e 192.168.99.101.9999: Flags [S], seq 2802904548, win 64240, options [mss 1460,sackOK,TS val 844799154 ecr 0,nop,wscale 7], length 0 09:14:40.083055 IP 192.168.99.101.9999 \u003e 192.168.99.1.45554: Flags [S.], seq 361953027, ack 2802904549, win 1152, options [mss 1460,sackOK,TS val 252766455 ecr 844799154,nop,wscale 0], length 0 09:14:40.083378 IP 192.168.99.1.45554 \u003e 192.168.99.101.9999: Flags [.], ack 1, win 502, options [nop,nop,TS val 844799155 ecr 252766455], length 0 使用 netstat -anp | grep 9999 查看 9999 端口状态，在客户端与服务端还未建立连接时（因为服务端此时还在阻塞）可见系统内核中已经有了一个状态为ESTABLISHED的连接，同时还没有分配给应用程序，此时，该 socket 是在内核态的。 Recv-Q 与 Send-Q 均为 0，说明没有收发信息\n1 2 3 Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp6 0 0 :::9999 :::* LISTEN 14870/java tcp6 0 0 192.168.99.101:9999 192.168.99.1:45554 ESTABLISHED - 在客户端还在阻塞时，使用客户端发送一些消息，tcpdump 抓取到如下信息，表明客户端与服务端可以正常正常交互\n1 2 3 4 5 6 7 8 9 10 11 12 13 09:21:59.451685 IP 192.168.99.1.45554 \u003e 192.168.99.101.9999: Flags [P.], seq 1:2, ack 1, win 502, options [nop,nop,TS val 845237076 ecr 252766455], length 1 09:21:59.451793 IP 192.168.99.101.9999 \u003e 192.168.99.1.45554: Flags [.], ack 2, win 1151, options [nop,nop,TS val 253205823 ecr 845237076], length 0 09:21:59.451837 IP 192.168.99.1.45554 \u003e 192.168.99.101.9999: Flags [P.], seq 2:3, ack 1, win 502, options [nop,nop,TS val 845237076 ecr 252766455], length 1 09:21:59.451852 IP 192.168.99.1.45554 \u003e 192.168.99.101.9999: Flags [P.], seq 3:4, ack 1, win 502, options [nop,nop,TS val 845237076 ecr 252766455], length 1 09:21:59.451859 IP 192.168.99.1.45554 \u003e 192.168.99.101.9999: Flags [P.], seq 4:5, ack 1, win 502, options [nop,nop,TS val 845237076 ecr 252766455], length 1 09:21:59.467476 IP 192.168.99.1.45554 \u003e 192.168.99.101.9999: Flags [P.], seq 4:5, ack 1, win 502, options [nop,nop,TS val 845237092 ecr 253205823], length 1 09:21:59.467531 IP 192.168.99.101.9999 \u003e 192.168.99.1.45554: Flags [.], ack 5, win 1148, options [nop,nop,TS val 253205839 ecr 845237076,nop,nop,sack 1 {4:5}], length 0 09:21:59.467654 IP 192.168.99.1.45554 \u003e 192.168.99.101.9999: Flags [P.], seq 5:6, ack 1, win 502, options [nop,nop,TS val 845237092 ecr 253205839], length 1 09:21:59.467721 IP 192.168.99.1.45554 \u003e 192.168.99.101.9999: Flags [P.], seq 6:7, ack 1, win 502, options [nop,nop,TS val 845237092 ecr 253205839], length 1 09:21:59.467728 IP 192.168.99.1.45554 \u003e 192.168.99.101.9999: Flags [P.], seq 7:8, ack 1, win 502, options [nop,nop,TS val 845237093 ecr 253205839], length 1 09:21:59.467731 IP 192.168.99.1.45554 \u003e 192.168.99.101.9999: Flags [P.], seq 8:9, ack 1, win 502, options [nop,nop,TS val 845237093 ecr 253205839], length 1 09:21:59.487421 IP 192.168.99.1.45554 \u003e 192.168.99.101.9999: Flags [P.], seq 8:9, ack 1, win 502, options [nop,nop,TS val 845237112 ecr 253205839], length 1 09:21:59.487459 IP 192.168.99.101.9999 \u003e 192.168.99.1.45554: Flags [.], ack 9, win 1144, options [nop,nop,TS val 253205859 ecr 845237092,nop,nop,sack 1 {8:9}], length 0 使用 netstat -anp | grep 9999 查看端口信息，Recv-Q 变为了 8，表明该 socket 还未分配给应用程序使用，但此时就已经可以接收信息了\n1 2 Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp6 8 0 192.168.99.101:9999 192.168.99.1:45554 ESTABLISHED - tcp 三次握手是内核完成的，当完成握手之后，连接就建立了，就可以收发消息了，只不过此时是内核与客户端进行交互，还未将该 socket（文件描述符）分配给应用程序\n使用 lsof -p 14870 查看文件描述符信息，没有任何变化。\n在服务端窗口输入回车，使其不再阻塞，程序输出如下，客户端正常接受到了客户端发来的数据\n1 client read some data is: 8 val: 11111111 再次查看 9999 端口情况，Recv-Q 变为了 0，也将该连接分配给了 14870 这个客户端程序\n1 2 Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp6 0 0 192.168.99.101:9999 192.168.99.1:45554 ESTABLISHED 14870/java 查看文件描述符信息，多了如下 6u 描述符号，四元组 k8s-master:distinct-\u003ehost:45554 已经为建立连接状态\n1 2 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME java 14870 normal 6u IPv6 5144029 0t0 TCP k8s-master:distinct-\u003ehost:45554 (ESTABLISHED) 小总结\nTCP 是面向连接的，三次握手之后，客户端与服务端都会开辟资源（文件描述符），双方通过这两个 FD 来传输信息。 即使服务端没有 accept()，客户端依旧可以向服务端发送数据，该数据会被保存在服务端网卡的缓冲区中，当服务端 accept() 后，kernel 会将缓冲区的数据发送给服务端。 如果客户端发送了超出服务端缓冲区大小的数据，并且服务端一直没有 accept()，那么内核只会在缓冲区中保留最新接收的数据。\nsocket 是一个四元组：服务端 IP+服务端 Port+客户端 IP+客户端 Port，保证了连接的唯一性。\n验证 BACK_LOG\n将 SocketIoProperties 服务端中的 BACK_LOG 设置为 2\n启动 SocketIoProperties，并使用 tcpdump 进行抓包\n启动一个客户端，可见抓包窗口输出如下信息，客户端与服务端成功完成了三次握手\n1 2 3 17:41:26.572940 IP 192.168.99.1.42050 \u003e 192.168.99.101.9999: Flags [S], seq 1079717590, win 64240, options [mss 1460,sackOK,TS val 875204207 ecr 0,nop,wscale 7], length 0 17:41:26.573018 IP 192.168.99.101.9999 \u003e 192.168.99.1.42050: Flags [S.], seq 1918656041, ack 1079717591, win 1152, options [mss 1460,sackOK,TS val 283172944 ecr 875204207,nop,wscale 0], length 0 17:41:26.573113 IP 192.168.99.1.42050 \u003e 192.168.99.101.9999: Flags [.], ack 1, win 502, options [nop,nop,TS val 875204207 ecr 283172944], length 0 netstat 可见已经建立了一个 tcp 连接（第一个）\n1 2 tcp6 1 0 :::9999 :::* LISTEN 21753/java tcp6 0 0 192.168.99.101:9999 192.168.99.1:42050 ESTABLISHED - 再次启动一个客户端，可见抓包窗口输出如下信息，客户端与服务端成功完成了三次握手\n1 2 3 17:44:02.074472 IP 192.168.99.1.42152 \u003e 192.168.99.101.9999: Flags [S], seq 2993811130, win 64240, options [mss 1460,sackOK,TS val 875359709 ecr 0,nop,wscale 7], length 0 17:44:02.074529 IP 192.168.99.101.9999 \u003e 192.168.99.1.42152: Flags [S.], seq 1945101284, ack 2993811131, win 1152, options [mss 1460,sackOK,TS val 283328446 ecr 875359709,nop,wscale 0], length 0 17:44:02.074660 IP 192.168.99.1.42152 \u003e 192.168.99.101.9999: Flags [.], ack 1, win 502, options [nop,nop,TS val 875359709 ecr 283328446], length 0 netstat 可见又建立了一个 tcp 连接（第二个）\n1 2 3 tcp6 2 0 :::9999 :::* LISTEN 21753/java tcp6 0 0 192.168.99.101:9999 192.168.99.1:42050 ESTABLISHED - tcp6 0 0 192.168.99.101:9999 192.168.99.1:42152 ESTABLISHED - 再次启动一个客户端，可见抓包窗口输出如下信息，客户端与服务端成功完成了三次握手\n1 2 3 17:46:54.537908 IP 192.168.99.1.42324 \u003e 192.168.99.101.9999: Flags [S], seq 4026614965, win 64240, options [mss 1460,sackOK,TS val 875532172 ecr 0,nop,wscale 7], length 0 17:46:54.538019 IP 192.168.99.101.9999 \u003e 192.168.99.1.42324: Flags [S.], seq 4197451679, ack 4026614966, win 1152, options [mss 1460,sackOK,TS val 283500909 ecr 875532172,nop,wscale 0], length 0 17:46:54.538131 IP 192.168.99.1.42324 \u003e 192.168.99.101.9999: Flags [.], ack 1, win 502, options [nop,nop,TS val 875532173 ecr 283500909], length 0 netstat 可见又建立了一个 tcp 连接（第三个）\n1 2 3 4 tcp6 3 0 :::9999 :::* LISTEN 21753/java tcp6 0 0 192.168.99.101:9999 192.168.99.1:42050 ESTABLISHED - tcp6 0 0 192.168.99.101:9999 192.168.99.1:42324 ESTABLISHED - tcp6 0 0 192.168.99.101:9999 192.168.99.1:42152 ESTABLISHED - 再次启动一个客户端，可见抓包窗口输出如下信息，客户端与服务端已经不能成功三次握手了\n1 2 17:49:13.752171 IP 192.168.99.101.9999 \u003e 192.168.99.1.42408: Flags [S.], seq 2105096148, ack 2133474618, win 1152, options [mss 1460,sackOK,TS val 283640124 ecr 875666977,nop,wscale 0], length 0 17:49:13.752315 IP 192.168.99.1.42408 \u003e 192.168.99.101.9999: Flags [.], ack 1, win 502, options [nop,nop,TS val 875671387 ecr 283632194], length 0 netstat 可见生成的 FD 状态为 SYN_RECV，表示服务端接收到了客户端的 SYN，但是服务端没有收到客户端的第二次请求（因为服务端没有给客户端回复消息），因此没有连接没有建立成功。过一段时间后，该连接会自动断开。\n1 2 3 4 5 tcp 0 0 192.168.99.101:9999 192.168.99.1:42408 SYN_RECV - tcp6 3 0 :::9999 :::* LISTEN 21753/java tcp6 0 0 192.168.99.101:9999 192.168.99.1:42050 ESTABLISHED - tcp6 0 0 192.168.99.101:9999 192.168.99.1:42324 ESTABLISHED - tcp6 0 0 192.168.99.101:9999 192.168.99.1:42152 ESTABLISHED - 此时 BACK_LOG 为 2，服务端一共可以建立 3 个连接（包含两个备用连接）\n验证 TIME_OUT\n客户端和服务端均可以设置 TIMEOUT 的值，服务端的 accept 方法，默认是永久阻塞的（只要收不到客户端的消息，就一直阻塞），设置了 TIMEOUT 后，如果超过 TIMEOUT 后还没有客户端连接，就会抛出异常，进行下一次循环。 客户端的 read 方法默认是永久阻塞的（只要收不到服务端的消息，就一直阻塞），设置了 TIMEOU 后，在超过 TIMEOUT 还没有接受到客户端的消息，就会抛出异常，并继续下一次循环。\ntcpdump 中的 win\nwin 代表窗口大小，双方用来协商每次发送数据包的最大大小，如果其中一方 win 满了，就会给另一方发送个消息通知对方，此时对方会拥塞，不会再发送数据包，直到接受到表明可以继续发送消息的数据包后才会解除阻塞，继续发送数据包。\n可以使用 ifconfig 查看 MTU（Maximum Transmission Unit，最大传输单元），表明当前网络接口一次最多可发送多少字节的数据包\n演示向服务发送数据，当拥塞后，再次发送的数据会被丢弃的现象：\n启动 SocketIoProperteis 服务端，使用nc命令启动一个客户端，并一直向服务端发送数据\n1 nc 192.168.99.101 9999 随着发送数据使用 netstat 查看服务端的 Recv-Q 信息，会发现其一直会增长，到达某一数值后便不再增加\n1 tcp6 1152 0 192.168.99.100:9999 192.168.99.1:52202 ESTABLISHED - 向服务端发送一个与之前数据有明显区别的数据，在服务端窗口输入回车，解除阻塞，可见服务端并没有接受到最后发送的数据，说明当 Recv-Q 存满后，会丢弃之后再发送过来的数据包\n验证客户端 TcpNoDelay 和 SendBufferSize\nTcpNoDelay 是否延迟发送，SocketClient 类中从 Terminal 读取数据是一批一批读的，但是向服务端写是 1 个字节 1 个字节写的，并且没有手动调用 flush 方，当客户端一个字节一个字节的发送数据时，每个包中有用的数据只有 1 字节，同时会有 40 多个字节的标题数据等，会极大增加网络传输的消耗，因此可以将这些数据攒一些后，按批发送。\nSocketClient 客户端中将 TcpNoDelay 设置为 false（延迟），SendBufferSize 设置为 20 client.setSendBufferSize(20); client.setTcpNoDelay(false); 启动 SocketIoProperties 并回车，开始接收客户端的连接 启动 SocketClient，并向服务端发送数据 1 2 3 1 123 1234567890123456789012345678901234 服务端窗口打印出如下信息，可见当 TcpNoDelay 为 false 时，发出的一个包的大小是可以超过设置的缓冲区 20 的限制的。 1 2 3 4 5 6 client IP: /192.168.99.1 Port: 49026 client read some data is: 1 val: 1 client read some data is: 1 val: 1 client read some data is: 2 val: 23 client read some data is: 1 val: 1 client read some data is: 33 val: 234567890123456789012345678901234 将 TcpNoDelay 设置为 true（不延迟），重新启动 SocketClient，向服务端发送一些数据 1 2 123 1234567890123456789012345678901234 客户端窗口打印如下信息，可见当发送数据量较大时，会尽快发送（客户端是 1 个字节 1 个字节发送的），不会积攒数据。 1 2 3 4 5 6 7 8 9 10 client IP: /192.168.99.1 Port: 49550 client read some data is: 3 val: 123 client read some data is: 4 val: 1234 client read some data is: 4 val: 5678 client read some data is: 4 val: 9012 client read some data is: 4 val: 3456 client read some data is: 4 val: 7890 client read some data is: 4 val: 1234 client read some data is: 8 val: 56789012 client read some data is: 2 val: 34 验证 OOBInline（Out-Of-Band data，带外数据）\n没啥用默认 false 就行。具体不理解。\n验证 KeepAlive\n再服务端为 client 开启 KEEPALIVE 后，如果客户端与服务端一直不互相发送数据，服务端就会定时向客户端发送一个数据包，来判断客户端是否还存活。\nKEEPALIVE 受 Linux 系统参数 net.ipv4.tcp_keepalive_time，net.ipv4.tcp_keepalive_intvl，net.ipv4.tcp_keepalive_probes，的影响\nnet.ipv4.tcp_keepalive_time：客户端与服务端多久不发送数据包，开始进行 KEEPALIVE 检测，默认是 7200 秒 net.ipv4.tcp_keepalive_intvl：两次 KEEPALIVED 间的时间间隔，默认 75 秒 net.ipv4.tcp_keepalive_probes：发送多少次探测包后，对方仍没有反应，就关闭与对方的连接，默认 9 次 修改 SocketIoProperties 中 CLI_KEEPALIVE 值为 true 为了让服务端尽快发送探测包，将 net.ipv4.tcp_keepalive_time 设置为 1 秒 1 sudo echo 1 \u003e /proc/sys/net/ipv4/tcp_keepalive_time 启动服务端，并回车，在另一窗口使用 tcpdump 抓包。 启动客户端，服务端显示客户端已连接，此时双方均不发送消息，可见 tcpdump 依旧会抓取到如下信息 1 2 21:16:27.908536 IP 192.168.99.101.9999 \u003e 192.168.99.1.45698: Flags [.], ack 1, win 1152, options [nop,nop,TS val 1506131435 ecr 3043275146], length 0 21:16:27.908869 IP 192.168.99.1.45698 \u003e 192.168.99.101.9999: Flags [.], ack 1, win 502, options [nop,nop,TS val 3043352011 ecr 1506053503], length 0 网络 IO 变化 模型 同步：发出一个功能调用时，再没有得到结果之前，该调用就不返回或继续执行后续操作。即同步只能一件一件事做，要等前一件做完了才能做下一件事。 异步：发出一个功能调用后，还没有得到结果，就去做其他的事情了，该调用的结果可以通过轮询状态或通知或回调的方式来返回给调用放。即异步可以同时做多个不同的事。\n阻塞：调用一个功能后，在没有得到结果之前，该线程就一直等待返回结果 非阻塞：调用一个功能后，在不能立即得到结果之前，该函数不会阻塞当前线程\n同步阻塞 同步非阻塞 异步非阻塞\n异步（Async） 阻塞 IO（BIO） 需要使用 j2se1.4 的 jdk 来操作，才能看到如下效果，因为老版本 JDK 使用的是纯 BIO 的方式，新版本的 JDK 对源码编译后会使用单连接单 poll 的方式，在效果上与阻塞 IO 相同。\n使用下方命令编译并运行 AsyncBlockSocketIo，同时追踪系统调用信息 1 javac AsyncBlockSocketIo.java \u0026\u0026 strace -ff -o out java AsyncBlockSocketIo 使用 nc 192.168.99.101 9999 启动一个客户端，查看服务器系统调用信息，可以看到发生如下系统调用 Java 系统调用 生成 ServerSocket server = new ServerSocket(); socket 服务端生成文件描述符 fd3 server.bind(new InetSocketAddress(9999)); bind(fd3, 9999) - getImpl().listen(backlog); listen(fd3) 在 bind() 方法内部包含对 listen 方法的调用 server.accept(); accept(fd3 此处是第一处阻塞 new Thread().start() clone( 服务端为每个客户端都抛一个线程 reader.readLine(); recv(fd5 此处是第二次阻塞 BIO 弊端\n阻塞：由于阻塞所以需要为每个客户端抛出一个线程来解决阻塞的问题，进而造成低效。\nC10K 压力测试\nThe C10K problem 如果宿主机的网卡与虚拟机网卡有不连通的，需要下方命令为宿主机/虚拟机添加路由跳转\n1 sudo route add -host 192.168.1.102 gw 192.168.99.1 使用下方命令编译并运行 AsyncBlockSocketIo 1 javac AsyncBlockSocketIo.java \u0026\u0026 java AsyncBlockSocketIo 启动 C10kClient，观察客户端输出及速度，连接端口号均是成对出现的 1 2 3 4 5 6 step1：server start, bind port 9999... step2：client connected, IP：/192.168.99.1, port：10000, 当前已连接客户端总数：1 step2：client connected, IP：/192.168.1.102, port：10000, 当前已连接客户端总数：2 ... step2：client connected, IP：/192.168.99.1, port：11935, 当前已连接客户端总数：3857 step2：client connected, IP：/192.168.1.102, port：11935, 当前已连接客户端总数：3858 在达到共 4000 个左右连接后，会报如下异常（root 用户可能不会报错） 1 2 3 4 5 [65.753s][warning][os,thread] Failed to start thread - pthread_create failed (EAGAIN) for attributes: stacksize: 1024k, guardsize: 0k, detached. Exception in thread \"main\" java.lang.OutOfMemoryError: unable to create native thread: possibly out of memory or process/resource limits reached at java.base/java.lang.Thread.start0(Native Method) at java.base/java.lang.Thread.start(Thread.java:803) at AsyncBlockSocketIo.main(AsyncBlockSocketIo.java:57) 上述问题是由于 Linux 对普通用户使用系统资源的数量进行了限制，可以使用如下命令查看 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 $ ulimit -a core file size (blocks, -c) 0 data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 3871 max locked memory (kbytes, -l) 64 max memory size (kbytes, -m) unlimited open files (-n) 1024 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) 8192 cpu time (seconds, -t) unlimited max user processes (-u) 3871 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited 上方 max user processes (-u) 3871 限制了当前用户最多可以启动 3871 个进程，当前程序已经启动了 3858 个进程，再加上其他系统进程超过限制后就会发生该异常。 root 用户虽然会显示限制信息，但一般限制不生效。 同步（Sync）非阻塞 IO（NIO） 编译并运行 NonBlockSocketIo，并追踪系统调用信息\n1 javac NonBlockSocketIo.java \u0026\u0026 strace -ff -o out java NonBlockSocketIo 当没有客户端连接时，终端窗口会一直输出 client is null ......\n查看系统调用信息可见如下信息，调用系统的 accept 方法后不会阻塞，返回值为 -1，代表没有客户端连接\n1 2 3 accept(4, 0x7fbf482817c0, [28]) = -1 EAGAIN (Resource temporarily unavailable) ... accept(4, 0x7fbf482817c0, [28]) = -1 EAGAIN (Resource temporarily unavailable) 使用 nc 命令创建几个客户端，并发送一些消息，服务端可以在单线程中即处理客户端的连接，又接收客户端发送来的数据\n1 2 3 4 5 6 client IP：/192.168.99.101, port：39524 当前已连接客户端总数：1 received：dfasdfsaf send by client IP：/192.168.99.101, port：39524 client IP：/192.168.99.101, port：39586 当前已连接客户端总数：2 received：1234 send by client IP：/192.168.99.101, port：39586 C10K 压力测试\n注释掉 NonBlockSocketIo 中的如下两行代码，重新编译运行服务端\n1 2 // Thread.sleep(1000); // System.out.println(\"client is null ......\"); 使用 C10kClient 测试，会发现建立连接速度比 AsyncBlockSocketIo 快很多。 同时，随着客户端连接数的增长，连接速度会变慢，是由于将已连接的客户端保存在了集合中，随着连接客户端的增多，每次遍历已连接的客户端都会调用 client 的 read 方法，用户态和内核态切换次数变多。\n超过 4000 多个连接后，会报如下异常\n1 2 3 4 5 6 client IP：/192.168.99.101, port：12045 当前已连接客户端总数：4090 java.io.IOException: Too many open files at java.base/sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method) at java.base/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:533) at java.base/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:285) at NonBlockSocketIo.main(NonBlockSocketIo.java:40) 使用 ps 命令查看当前服务端的进程号，在使用 cat 命令查看当前进程的限制信息，可见当前 Max open files 限制了该进程最多可以打开 4096 个 FD\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 $ ps -ef | grep NonBlockSocketIo normal 16704 2423 42 15:54 pts/0 00:00:13 java NonBlockSocketIo $ cat /proc/16704/limits Limit Soft Limit Hard Limit Units Max cpu time unlimited unlimited seconds Max file size unlimited unlimited bytes Max data size unlimited unlimited bytes Max stack size 8388608 unlimited bytes Max core file size 0 unlimited bytes Max resident set unlimited unlimited bytes Max processes 3871 3871 processes Max open files 4096 4096 files Max locked memory 65536 65536 bytes Max address space unlimited unlimited bytes Max file locks unlimited unlimited locks Max pending signals 3871 3871 signals Max msgqueue size 819200 819200 bytes Max nice priority 0 0 Max realtime priority 0 0 Max realtime timeout unlimited unlimited us NIO 对比 BIO 的优点\n可以设置服务端和客户端为非阻塞，使用单线程即可处理所有客户端的连接和接收数据\nNIO 弊端\n将已经连接的客户端存放在了集合中，每次遍历已连接的客户端尝试接收客户端数据时，都会调用 client 的 read 方法（是系统调用），当客户端连接数很多时，导致大量用户态和内核态的切换，并且很多调用是无用的。\n多路复用器 多路复用器（SELECT/POLL，EPOLL）对比 NIO\n多路复用器与 NIO 都是同步非阻塞模型。 无论 NIO 还是多路复用器（SELECT/POLL），都需要遍历所有的 FD 询问状态。NIO 是应用程序自己维护了一个 FD 列表，在程序中自己询问 FD 状态，每询问一个 FD 都会有一次系统调用； SELECT/POLL 也是应用程序自己维护了一个 FD 列表，不同的是只需要将 FD 列表传给 select()/poll()进行一次系统调用，即可获取所有 FD 的状态 应用程序使用 SELECT/POLL 将 FD 列表从用户空间传递到内核空间并调用内核函数 select()/poll()，在内核方法中对传入的 FD 列表进行了遍历，将有状态的 FD 进行返回， 此处存在了两个问题，第一：如果 FD 列表过大，从用户空间向内核空间拷贝该 FD 列表的开销会很大；第二：内核方法中依旧对所有的 FD 进行了全量遍历，时间复杂度是 O(n)。 而 EPOLL 可以理解为 event poll，其在内核层面维护了一个红黑树用来存放需要监视的 FD 和一个双向链表用来存放有状态的 FD，并提供了三个系统函数 epoll_create，epoll_ctl 和 epoll_wait 对 FD 进行修改等操作。 当创建 ServerSocket 或者有 Socket 进行连接时，就会调用 epoll_create 方法，为其创建 FD，然后调用 epoll_ctl 将该 FD 存入到红黑树中，如果该 Socket 发送了数据，则在红黑树中会标记其是有状态的，并将其插入到双向链表中，此时如果调用 epoll_wait，则会将双向链表中的所有 FD（均是有状态的）返回。 多路复用器分类\nSELECT：POSIX 标准，synchronous I/O multiplexing，受 FD_SETSIZE 大小的限制，一个 SELECT 只能接收 1024 个 fd\nint select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select() and pselect() allow a program to monitor multiple file descriptors, waiting until one or more of the file descriptors become \"ready\" for some class of I/O operation (e.g., input possible). A file descriptor is considered ready if it is possible to perform a corresponding I/O operation (e.g., read(2) without blocking, or a sufficiently small write(2)).\nPOLL：与 SELECT 一置，唯一区别就是没有 FD_SETSIZE 大小的限制\nint poll(struct pollfd *fds, nfds_t nfds, int timeout);\npoll() performs a similar task to select(2): it waits for one of a set of file descriptors to become ready to perform I/O.\nEPOLL：event poll, I/O event notification facility\nint epoll_create(int size); - open an epoll file descriptor\nint epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); - control interface for an epoll file descriptor\nint epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); - wait for an I/O event on an epoll file descriptor\n无论是 SELECT，POLL 还是 EPOLL，在 Java 中均被抽象为了 Selector，可通过在启动时指定 -Djava.nio.channels.spi.SelectorProvider=sun.nio.ch.PollSelectorProvider 来选择使用哪种多路复用器，默认会选择系统支持的较好的\nTCP 四次挥手及 POLL 与 EPOLL 追踪系统调用对比 服务端在客户端断开连接后，不调用 client.close()\n注释掉 MultiplexingSocketIoSingleThread 中的 client.close()，使用如下命令指定使用 POLL 多路复用器进行启动并追踪系统调用（为了对比 POLL 和 EPOLL）\n1 javac MultiplexingSocketIoSingleThread.java \u0026\u0026 strace -ff -o poll java -Djava.nio.channels.spi.SelectorProvider=sun.nio.ch.PollSelectorProvider MultiplexingSocketIoSingleThread 启动后使用 netstat -antp 查看系统端口情况，并使用 lsof -op 10371 查看当前应用开辟的 FD，可见当前 Java 程序已经监听了 9999 端口，并且生成了一个文件描述符 4u\n1 2 Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp6 0 0 :::9999 :::* LISTEN 10371/java 1 java 10371 normal 4u IPv6 365461 0t0 TCP *:distinct (LISTEN) 使用 nc 127.0.0.1 9999 创建一个客户端连接到服务端，服务端输出如下信息，说明端口号为 55598 的客户端已经连接\n1 新客户端连接，IP：/127.0.0.1，port：55598 再次使用 netstat -antp 和 lsof -op 10371 进行查看，可见内核中存在了两个 ESTABLISHED 状态的连接，并且生成了新的文件描述符 7u\n1 2 3 Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:55598 127.0.0.1:9999 ESTABLISHED 11600/nc tcp6 0 0 127.0.0.1:9999 127.0.0.1:55598 ESTABLISHED 10371/java 1 2 COMMAND PID USER FD TYPE DEVICE OFFSET NODE NAME java 10371 normal 7u IPv6 365466 0t0 TCP localhost:distinct-\u003elocalhost:55598 (ESTABLISHED) 在客户端窗口使用 Ctrl+c 关闭，使用 netstat -antp 和 lsof -op 10371 进行查看，可见客户端的连接状态变为了 FIN_WAIT2，服务端的连接状态变为 CLOSE_WAIT，同时代表连接的文件描述符 7u 立即消失了。 过一会后内核中代表客户端的连接也会消失，而代表服务端的连接，会一直存在，并且状态一直为 CLOSE_WAIT\n1 2 3 Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:55598 127.0.0.1:9999 FIN_WAIT2 - tcp6 0 0 127.0.0.1:9999 127.0.0.1:55598 CLOSE_WAIT 10371/java 关闭服务端，代表服务端的，状态为 CLOSE_WAIT 的连接立即消失\nCtrl+C 后，客户端向服务端发送了 FIN，然后接收到服务端返回的 ACK，但是由于服务端并调用client.close（)，所以客户端接收不到第二个 FIN，因此客户端状态变为 FIN_WAIT2(会在 2MSL 后断开），而服务端也接收不到客户端的 ACK，因此会一直为 CLOSE_WAIT 状态。\n服务端在客户端断开连接后，调用 client.close()\n取消 MultiplexingSocketIoSingleThread 中的 client.close()注释，使用如下命令指定使用 POLL 多路复用器进行启动并追踪系统调用（Java 在 Linux 系统中一般默认选择 EPOLL）\n1 javac MultiplexingSocketIoSingleThread.java \u0026\u0026 strace -ff -o epoll java MultiplexingSocketIoSingleThread 启动后使用 netstat -antp 查看系统端口情况，并使用 lsof -op 11814 查看当前应用开辟的 FD，可见当前 Java 程序已经监听了 9999 端口，并且生成了一个文件描述符 4u 和 7u(eventpoll fd, epfd)\n1 2 Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp6 0 0 :::9999 :::* LISTEN 11814/java 1 2 3 COMMAND PID USER FD TYPE DEVICE OFFSET NODE NAME java 11814 normal 4u IPv6 364652 0t0 TCP *:distinct (LISTEN) java 11814 normal 7u a_inode 0,10 0t0 5366 [eventpoll] 使用 nc 127.0.0.1 9999 创建一个客户端连接到服务端，服务端输出如下信息，说明端口号为 55602 的客户端已经连接\n1 新客户端连接，IP：/127.0.0.1，port：55602 再次使用 netstat -antp 和 lsof -op 11814 进行查看，可见内核中存在了两个 ESTABLISHED 状态的连接，并且生成了新的文件描述符 8u\n1 2 3 Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:55602 127.0.0.1:9999 ESTABLISHED 11850/nc tcp6 0 0 127.0.0.1:9999 127.0.0.1:55602 ESTABLISHED 11814/java 1 2 COMMAND PID USER FD TYPE DEVICE OFFSET NODE NAME java 11814 normal 8u IPv6 365060 0t0 TCP localhost:distinct-\u003elocalhost:55602 (ESTABLISHED) 在客户端窗口使用 Ctrl+c 关闭，使用 netstat -antp 和 lsof -op 11814 进行查看，可见内核中客户端的连接变为了 TIME_WAIT 状态，服务端变为 LISTEN 状态，而代表客户端和连接的描述符已经消失了。 过一会后，代表客户端的连接也会消失。\n1 2 3 Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 127.0.0.1:55602 127.0.0.1:9999 TIME_WAIT - tcp6 0 0 127.0.0.1:9999 127.0.0.1:55602 LISTEN 11814/java 关闭服务端，代表服务端的，状态为 LISTEN 的连接立即消失\nCtrl+c 后，客户端会向服务端发送 FIN，然后接收到服务端的 ACK，因为服务端调用了 client.close()，所以服务端会向客户端发送 FIN，然后客户端会返回 ACK，并且会在 2MSL 后断开连接，在此期间会一直为 TIME_WAIT 状态。\nPOLL，EPOLL 系统调用查看\nPOLL\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # server = ServerSocketChannel.open(); 创建 ServerSocket，生成一个文件描述符 4 socket(AF_INET6, SOCK_STREAM, IPPROTO_IP) = 4 # server.bind(new InetSocketAddress(9999)); 绑定并监听 9999 端口 bind(4, {sa_family=AF_INET6, sin6_port=htons(9999), inet_pton(AF_INET6, \"::\", \u0026sin6_addr), sin6_flowinfo=htonl(0), s in6_scope_id=0}, 28) = 0 listen(4, 50) # server.configureBlocking(Boolean.FALSE); 设置 server 非阻塞 fcntl(4, F_SETFL, O_RDWR|O_NONBLOCK) = 0 # selector = Selector.open(); 创建 POLL，生成监视数组（没有系统调用，没有系统调用，在程序中创建的数组） # System.out.println(\"server start......\"); write(1, \"server start......\", 18) = 18 # server.register(selector, SelectionKey.OP_ACCEPT); 将 server 的 FD4 放入监视数组中（无系统调用） # while (selector.select(50) \u003e 0) 将监视数组中的 FD 作为参数调用内核函数 poll poll([{fd=5, events=POLLIN}, {fd=4, events=POLLIN}], 2, 50) = 0 (Timeout) # SocketChannel client = ssc.accept(); 有客户端进行连接，生成 socket 四元组，对应 FD7 accept(4, {sa_family=AF_INET6, sin6_port=htons(55598), inet_pton(AF_INET6, \"::ffff:127.0.0.1\", \u0026sin6_addr), sin6_flo winfo=htonl(0), sin6_scope_id=0}, [28]) = 7 # client.configureBlocking(Boolean.FALSE); 设置客户端非阻塞 fcntl(7, F_SETFL, O_RDWR|O_NONBLOCK) # client.register(selector, SelectionKey.OP_READ, ByteBuffer.allocateDirect(4096)); 将客户端也添加到监视数组中（无系统调用） # while (selector.select(50) \u003e 0) 循环对数组中的 FD 进行状态查询，返回有状态的 FD poll([{fd=5, events=POLLIN}, {fd=4, events=POLLIN}, {fd=7, events=POLLIN}], 3, 50) = 0 (Timeout) # read = client.read(buffer); 客户端发送了一些数据 read(7, \"12345\\n\", 4096) = 6 # client.write(buffer); 写回给客户端 write(7, \"12345\\n\", 6) = 6 # while (selector.select(50) \u003e 0) 循环对数组中的 FD 进行状态查询，返回有状态的 FD poll([{fd=5, events=POLLIN}, {fd=4, events=POLLIN}, {fd=7, events=POLLIN}], 3, 50) = 0 (Timeout) EPOLL\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # server = ServerSocketChannel.open(); 创建 ServerSocket，生成一个文件描述符 4 socket(AF_INET6, SOCK_STREAM, IPPROTO_IP) = 4 # server.bind(new InetSocketAddress(9999)); 绑定并监听 9999 端口 bind(4, {sa_family=AF_INET6, sin6_port=htons(9999), inet_pton(AF_INET6, \"::\", \u0026sin6_addr), sin6_flowinfo=htonl(0), sin 6_scope_id=0}, 28) = 0 listen(4, 50) # server.configureBlocking(Boolean.FALSE); 设置 server 非阻塞 fcntl(4, F_SETFL, O_RDWR|O_NONBLOCK) = 0 # selector = Selector.open(); 创建 EPOLL，生成 EPFD7，生成监视红黑树以及存放有状态 FD 的双向链表 epoll_create(256) = 7 # System.out.println(\"server start......\"); write(1, \"server start......\", 18) = 18 # server.register(selector, SelectionKey.OP_ACCEPT); 将 ServerSocket 的 FD4 添加到 EPOLL 的 EPFD7 中 # 💡 注意输出 server start 和该语句的顺序，Java 代码中输出 server start 在 server.register()之后，而 write()系统调用在此处系统调用在之前，是因为此处有懒加载机制，在调用 select()之前才会将该 FD 添加到监视红黑树中 epoll_ctl(7, EPOLL_CTL_ADD, 4, {EPOLLIN, {u32=4, u64=140381006069764}}) = 0 # while (selector.select(50) \u003e 0) 获取所有有状态的 FD epoll_wait(7, [], 4096, 50) = 0 # SocketChannel client = ssc.accept(); 有客户端进行连接 accept(4, {sa_family=AF_INET6, sin6_port=htons(55602), inet_pton(AF_INET6, \"::ffff:127.0.0.1\", \u0026sin6_addr), sin6_flowi nfo=htonl(0), sin6_scope_id=0}, [28]) = 8 # client.configureBlocking(Boolean.FALSE); 设置客户端非阻塞 fcntl(8, F_SETFL, O_RDWR|O_NONBLOCK) = 0 # client.register(selector, SelectionKey.OP_READ, ByteBuffer.allocateDirect(4096)); 将客户端添加到监视红黑树中 epoll_ctl(7, EPOLL_CTL_ADD, 8, {EPOLLIN, {u32=8, u64=8}}) = 0 # while (selector.select(50) \u003e 0) 获取有状态的 FD epoll_wait(7, [], 4096, 50) = 0 # client.read(buffer); 客户端发送了一些数据 read(8, \"123\\n\", 4096) = 4 # client.write(buffer); 将客户端发送的数据返回 write(8, \"123\\n\", 4) = 4 # while (selector.select(50) \u003e 0) 获取有状态的 FD epoll_wait(7, [], 4096, 50) = 0 多路复用器代码的演变 MultiplexingSocketIoSingleThread：仅包含对 server 的 OP_ACCEPT 和 client 的 OP_READ 事件的监听 MultiplexingSocketIoSingleThreadPlus：对比 MultiplexingSocketIoSingleThread，添加了对 client 的 OP_WRITE 事件的监听 MultiplexingSocketIoMultiThread：对比 MultiplexingSocketIoSingleThreadPlus，为了解决单线程处理 client 的 read 和 write 会阻塞问题，分别开辟新线程处理 client 的 read 和 write 对比 MultiplexingSocketIoMultiThread，为了解决多线程需要频繁调用 cancel() 方法（是系统调用），考虑到使用多线程，在每个线程中均包含一个 Selector，单个线程的内部使用单线程的方式进行处理（参考 MultiplexingSocketIoSingleThreadPlus），而多个单线程构成多线程的处理方式（分治的思想）。 Netty ","description":"","tags":["MSB","I/O","Java"],"title":"系统 I/O","uri":"/posts/msb/%E7%B3%BB%E7%BB%9F-io/system-io/"},{"categories":null,"content":"普通用户安装 MySQL 官方文档\n将 mysql 安装到 /home/normal/software/mysql 目录下\n解压二进制包，移动文件\n1 2 tar -zxvf mysql-5.7.30-el7-x86_64.tar.gz mv ./mysql-5.7.30-el7-x86_64 /home/normal/softwore/mysql 创建 data，conf，log 目录\n1 mkdir data conf log 初始化\n1 bin/mysqld --defaults-file=/home/normal/software/mysql/conf/my.cnf --initialize 配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 [mysqld] port=3306 basedir=/home/normal/software/mysql datadir=/home/normal/software/mysql/data pid-file=/home/normal/software/mysql/mysql.pid socket=/home/normal/software/mysql/mysql.sock log_error=/home/normal/software/mysql/error.log character_set_server=utf8mb4 lower_case_table_names=1 [mysql] default-character-set=utf8mb4 后台启动 mysqld 服务\n1 nohup ./bin/mysqld_safe --defaults-file=./conf/my.cnf 2\u003e\u00261 1\u003e\u003elog/mysql.log \u0026 查看随机生成的密码，文件对应配置文件中的 log_error\n1 cat /home/normal/software/mysql/error.log 使用 mysql 客户端登录，需要使用 -S 指定 sock 文件位置，对应在配置文件中 socket 的配置\n1 ./bin/mysql -uroot -p -S /home/normal/software/mysql/mysql.sock 修改 root 用户密码，开启 root 用户远程访问\n1 2 3 ALTER USER 'root'@'localhost' IDENTIFIED BY 'root'; CREATE USER 'root'@'%' IDENTIFIED BY 'root'; GRANT ALL ON *.* TO 'root'@'%' WITH GRANT OPTION; 配置环境变量\n1 2 3 vi ~/.bash_profile # 添加 export PATH=/home/normal/software/mysql/bin:$PATH 使环境变量生效\n1 source ~/.bash_profile ","description":"","tags":["MySQL","Linux"],"title":"普通用户安装 MySQL","uri":"/posts/database/mysql-install-by-normal-user/"},{"categories":null,"content":"解决 k8s 无法通过 svc 访问其他节点 pod 的问题 转载自 https://www.jianshu.com/p/ed1ae8443fff\n问题描述 有两个（或多个）运行在不同节点上的 pod，通过一个 svc 提供服务，如下\n1 2 3 4 5 6 7 8 root@master1:~# kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE kubia-nwjcc 1/1 Running 0 33m 10.244.1.27 worker1 kubia-zcpbb 1/1 Running 0 33m 10.244.2.11 worker2 root@master1:~# kubectl get svc kubia NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubia ClusterIP 10.98.41.49 \u003cnone\u003e 80/TCP 34m 当透过其他 pod 访问该 svc 时（使用命令k exec kubia-nwjcc -- curl http://10.98.41.49），出现了只能访问到和自己同处于一个节点的pod的问题，访问到其他节点上的pod时会出现command terminated with exit code 7的问题，如下：\n正常访问到相同节点的pod\n1 2 3 4 5 root@master1:~# kubectl exec kubia-nwjcc -- curl http://10.98.41.49 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 23 0 23 0 0 8543 0 --:--:-- --:--:-- --:--:-- 11500 You've hit kubia-nwjcc 无法访问其他节点的pod\n1 2 3 4 5 6 root@master1:~# kubectl exec kubia-nwjcc -- curl http://10.98.41.49 % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0 curl: (7) Failed to connect to 10.98.41.49 port 80: No route to host command terminated with exit code 7 本问题随机发生，如下：\n1 2 3 4 5 6 7 8 root@master1:~# kubectl exec kubia-nwjcc -- curl http://10.98.41.49 You've hit kubia-nwjcc root@master1:~# kubectl exec kubia-nwjcc -- curl http://10.98.41.49 command terminated with exit code 7 root@master1:~# kubectl exec kubia-nwjcc -- curl http://10.98.41.49 command terminated with exit code 7 root@master1:~# kubectl exec kubia-nwjcc -- curl http://10.98.41.49 You've hit kubia-nwjcc 问题原因 原因是因为，我是用的VirtualBox虚拟化出了两台 ubuntu 主机搭建的 k8s，详见 virtualbox 虚拟机组网。在组网的过程中，我采用了双网卡方案，网卡 1 使用 NAT 地址转换用来访问互联网，网卡 2 使用Host-only来实现虚拟机互相访问。flannel默认使用了网卡 1 的 ip 地址，而网卡 1 的 NAT 地址转换是无法访问其他虚拟机的，从而导致的问题的产生。\n解决方案 因为是flannel使用的默认网卡 1 导致了这个问题的产生，所以我们需要使用--iface参数手动指定它使用网卡 2 来进行通信，这就需要修改flannel的配置文件，执行如下命令即可进行修改：\nsudo kubectl edit daemonset kube-flannel-ds-amd64 -n kube-system 如果你执行后出现了Error from server (NotFound): daemonsets.extensions \"kube-flannel-ds-amd64\" not found的问题，按照下列步骤找到其配置文件名称：\n查找flannel配置文件名\n首先输入kubectl get po -n kube-system，然后找到正在运行的flannelpod。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 root@master1:~# k get po -n kube-system NAME READY STATUS RESTARTS AGE coredns-bccdc95cf-69zrw 1/1 Running 1 2d1h coredns-bccdc95cf-77bg4 1/1 Running 1 2d1h etcd-master1 1/1 Running 6 2d1h kube-apiserver-master1 1/1 Running 6 2d1h kube-controller-manager-master1 1/1 Running 2 2d1h # 下面这四个都可以 kube-flannel-ds-amd64-8c2lc 1/1 Running 4 2d1h kube-flannel-ds-amd64-dflsl 1/1 Running 9 23h kube-flannel-ds-amd64-hgp55 1/1 Running 1 2d1h kube-flannel-ds-amd64-jb79v 1/1 Running 33 26h kube-proxy-2lz7f 1/1 Running 0 23h kube-proxy-hqsdn 1/1 Running 4 2d1h kube-proxy-rh92r 1/1 Running 1 2d1h kube-proxy-tv4mt 1/1 Running 0 26h kube-scheduler-master1 1/1 Running 2 2d1h 然后使用flannel的 pod 名来查看其配置yaml。使用命令kubectl get po -n kube-system kube-flannel-ds-amd64-8c2lc -o yaml，注意修改其中的 pod 名称。在输出的内容开头可以找到ownerReferences字段，其下的name属性就是要找的配置文件名。如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 root@master1:~# kubectl get po -n kube-system kube-flannel-ds-amd64-8c2lc -o yaml apiVersion: v1 kind: Pod metadata: creationTimestamp: \"2019-07-01T07:53:25Z\" generateName: kube-flannel-ds-amd64- labels: app: flannel controller-revision-hash: 7c75959b75 pod-template-generation: \"1\" tier: node name: kube-flannel-ds-amd64-8c2lc namespace: kube-system ownerReferences: - apiVersion: apps/v1 blockOwnerDeletion: true controller: true kind: DaemonSet name: kube-flannel-ds-amd64 uid: df09fb4c-5390-4498-b539-74cb5d90f66d resourceVersion: \"126940\" selfLink: /api/v1/namespaces/kube-system/pods/kube-flannel-ds-amd64-8c2lc uid: 31d11bc6-b8f3-492a-9f92-abac1d330663 将找到的配置文件名填入sudo kubectl edit daemonset \u003c配置文件名\u003e -n kube-system并执行即可打开配置文件。\n修改配置文件，指定目标网卡\n在打开的配置文件中找到spec.template.spec.containers[0].args字段，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ... spec: revisionHistoryLimit: 10 selector: matchLabels: app: flannel tier: node template: metadata: creationTimestamp: null labels: app: flannel tier: node spec: containers: # 看这里 - args: - --ip-masq - --kube-subnet-mgr command: - /opt/bin/flanneld env: ... 这个字段表示了flannel启动时都要附加那些参数，我们要手动添加参数--iface=网卡名来进行指定，如下：\n- args: - --ip-masq - --kube-subnet-mgr - --iface=enp0s8 这里的enp0s8是我的网卡名，你可以通过ifconfig来找到自己的网卡名。\n修改完成之后输入:wq保存退出。命令行会提示:\ndaemonset.extensions/kube-flannel-ds-amd64 edited 这就说明保存成功了。然后就要重启所有已经存在的flannel。使用kubectl delete pod -n kube-system \u003cpod 名 1\u003e \u003cpod 名 2\u003e ...把所有的flannel删除即可。k8s 会自动按照你修改好的yaml配置重建flannel。\n1 2 3 4 5 6 7 8 9 10 root@master1:~# kubectl delete pod -n kube-system \\ kube-flannel-ds-amd64-8c2lc \\ kube-flannel-ds-amd64-dflsl \\ kube-flannel-ds-amd64-hgp55 \\ kube-flannel-ds-amd64-jb79v pod \"kube-flannel-ds-amd64-8c2lc\" deleted pod \"kube-flannel-ds-amd64-dflsl\" deleted pod \"kube-flannel-ds-amd64-hgp55\" deleted pod \"kube-flannel-ds-amd64-jb79v\" deleted 然后再次kubectl get pod -n kube-system | grep flannel就发现所有flannel都已经重启成功了：\n1 2 3 4 5 root@master1:~# kubectl get pod -n kube-system | grep flannel kube-flannel-ds-amd64-2d6tb 1/1 Running 0 89s kube-flannel-ds-amd64-kp5xs 1/1 Running 0 86s kube-flannel-ds-amd64-l9728 1/1 Running 0 92s kube-flannel-ds-amd64-r87qc 1/1 Running 0 91s 然后再随便找个pod试一下就可以看到问题解决了：\n1 2 3 4 5 6 7 8 root@master1:~# k exec kubia-d7kjl -- curl -s http://10.103.214.110 You've hit kubia-d7kjl root@master1:~# k exec kubia-d7kjl -- curl -s http://10.103.214.110 You've hit kubia-d7kjl root@master1:~# k exec kubia-d7kjl -- curl -s http://10.103.214.110 You've hit kubia-kdjgf root@master1:~# k exec kubia-d7kjl -- curl -s http://10.103.214.110 You've hit kubia-d7kjl 问题发现 这里记录一下问题的发现经过，希望对大家有所帮助。当我一开始遇到这个问题的时候还以为是svc的问题，但是在查看了对应svc的endpoint之后，并没有发现有什么显式的问题出现，如下，可以看到svc正确的识别到了已存在的两个pod：\n1 2 3 root@master1:~# kubectl get ep kubia NAME ENDPOINTS AGE kubia 10.244.1.5:8080,10.244.3.4:8080 8h 什么是endpoint?\nendpoint可以简单理解成路由导向的终点，因为 svc 是将许多个动态的 ip 映射成一个静态的 ip。那么就可以把这些动态的 pod ip 称为 svc 的endpoint。\n继续说，因为在测试过程中向 svc 发了很多请求，也可以察觉到其实 svc 已经随机的将你的请求分发到了不同的 pod，只是目标 pod 不在当前节点的时候就会返回exit code 7。然后尝试一下绕过 svc 直接请求 pod，首先新建出来一个 pod，然后使用kubectl get po -o wide查看 pod ip。\n1 2 3 4 5 root@master1:~# kubectl get po -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kubia-d7kjl 1/1 Running 0 8h 10.244.1.5 worker1 \u003cnone\u003e \u003cnone\u003e kubia-kdjgf 1/1 Running 0 9h 10.244.3.4 worker2 \u003cnone\u003e \u003cnone\u003e kubia-kn45c 1/1 Running 0 13s 10.244.1.6 worker1 \u003cnone\u003e \u003cnone\u003e 可以看到 k8s 把新的 pod 放在了worker1上，所以我们就拿这个新的 pod 去直接访问其他两个 pod。这里不能在主机上直接 ping pod ip，因为 pod 都是开放在虚拟网络10.244.x.x上的，在主机上访问不到：\n访问相同节点上的 pod\n1 2 3 4 5 root@master1:~# k exec -it kubia-d7kjl -- ping 10.244.1.6 PING 10.244.1.6 (10.244.1.6): 56 data bytes 64 bytes from 10.244.1.6: icmp_seq=0 ttl=64 time=0.377 ms 64 bytes from 10.244.1.6: icmp_seq=1 ttl=64 time=0.114 ms ... 访问不同节点上的 pod\n1 2 3 4 root@master1:~# k exec -it kubia-d7kjl -- ping 10.244.3.4 PING 10.244.3.4 (10.244.3.4): 56 data bytes # 没反应了 # 死一般寂静 这么看的话其实问题不在svc上，而是两个节点之间的网络联通出现了问题。而10.244.x.x虚拟网段是通过flannel搭建的，所以问题自然就是出在它上。在翻阅了官方文档后可以发现，官方明确指出了在vagrant类型的虚拟机上运行时要注意默认网卡的问题，再结合自己的网络情况，问题就已经很明确了了。\n参考 flannel - Troubleshooting Kubernetes with Flannel — Understanding the Networking — Part 1 (Setup the demo). k8s svc can not find pod in other worker node ","description":"","tags":["Kubernetes"],"title":"解决 k8s 无法通过 svc 访问其他节点 pod 的问题","uri":"/posts/kubernetes/kubernetes-svc-pod-error/"},{"categories":null,"content":"Ubuntu 连接不上蓝牙耳机 Kali-Linux 安装驱动并使用 Blueman 连接蓝牙耳机\n安装蓝牙驱动 我使用的是台式机 + 蓝牙控制器，首先需要安装蓝牙驱动，否则开机会报错(最后一行)\nbluetooth hci0: firmware: failed to load brcm/BCM20702A1-0a5c-21ec.hcd (-2)\n根据错误信息，上网搜索对应的蓝牙驱动，我在 GitHub 上找到了这个BCM20702A1-0a5c-21ec.hcd驱动，下载后放到 /lib/firmware/brcm 目录下，重启即可加载。\n安装 Blueman 启动 dbus 和蓝牙服务(使用 service 或/etc/init.d/均可)：\n1 2 service dbus start /etc/init.d/bluetooth start Blueman 是个非常方便的图形化蓝牙管理软件，使用 apt-get 可以直接安装它：\n1 apt-get install blueman 完成后左下角会出现蓝牙图标（也可使用 blueman-applet 手动启动）。\n1 apt-get install pulseaudio pulseaudio-module-bluetooth pavucontrol bluez-firmware 安装音频相关模块，如果缺少这些模块的话，连接耳机将会出现 blueman.bluez.errors.DBusFailedError: Resource temporarily unavailable 的错误信息。\n1 2 service bluetooth restart killall pulseaudio 重启完蓝牙服务，这时候就可以与蓝牙耳机配对了，不过音质很差，需要在音频配置里选择高保真回放（A2DP 信宿），如果报错的话，则还需要对配置文件进行一些修改。\nA2DP 出错解决方案 如果安装了模块，但是 pactl load-module module-bluetooth-discover 加载不了模块的话，需要手动修改一下配置。 参考A2DP Bluetooth headset issues with PulseAudio 6.0 帖子中 17 楼的做法：\n1.编辑 /etc/pulse/default.pa 文件。\n1 vim /etc/pulse/default.pa 2.找到 load-module module-bluetooth-discover 并在前面加#将它注释掉：\n1 # load-module module-bluetooth-discover 3.编辑 /usr/bin/start-pulseaudio-x11 文件\n1 vim /usr/bin/start-pulseaudio-x11 找到下面的代码，并在它下面另其一行\n1 2 3 if [ x”$SESSION_MANAGER”!= x ] ; then /usr/bin/pactl load-module module-x11-xsmp“display=$DISPLAY session_manager=$SESSION_MANAGER”\u003e /dev/null fi 在它下面写入(两个 fi 中间) /usr/bin/pactl load-module module-bluetooth-discover，完整如下：\n1 2 3 4 5 if [ x”$SESSION_MANAGER”!= x ] ; then /usr/bin/pactl load-module module-x11-xsmp“display=$DISPLAY session_manager=$SESSION_MANAGER”\u003e /dev/null fi /usr/bin/pactl load-module module-bluetooth-discover fi 重启服务：\n1 2 service bluetooth restart sudo pkill pulseaudio 这时候就可以在音频配置里选择 A2DP 了，音质瞬间变好了很多。\nProtocol not available 错误解决方案 输入命令加载 module-bluetooth-discover 模块即可\n1 # pactl load-module module-bluetooth-discover ","description":"","tags":["Linux","Ubuntu"],"title":"Ubuntu 连接不上蓝牙耳机","uri":"/posts/linux/ubuntu/ubuntu-bluetooth-earphone/"},{"categories":null,"content":"马士兵 JUC 目录 多线程入门 synchronized 简介 volatile 简介 CAS 和 Atomic MarkWord 和 Synchronized 细节 JUC 中新的锁 ","description":"","tags":["MSB","JUC","Java"],"title":"马士兵 JUC 目录","uri":"/posts/msb/juc/msb-juc-table/"},{"categories":null,"content":"马士兵 Spring Cloud 目录 微服务 Eureka Ribbon 和 RestTemplate Feign Hystrix Zuul Sleuth Spring Cloud Admin Spring Cloud Config ","description":"","tags":["MSB","Spring Cloud","Java"],"title":"马士兵 Spring Cloud 目录","uri":"/posts/msb/spring-cloud/msb-spring-cloud-table/"},{"categories":null,"content":"马士兵 Spring Framework 源码目录 Spring 容器 Bean 创建源码 ","description":"","tags":["MSB","源码","Spring","Java"],"title":"马士兵 Spring Framework 源码目录","uri":"/posts/msb/spring-framework/spring-framework-table/"},{"categories":null,"content":"Java 程序员需要掌握的计算机底层知识v1.01 微机原理，计算机组成原理，操作系统\n主要内容 硬件基础知识：Java 相关硬件知识 汇编语言的执行过程：时钟发生器，寄存器，程序计数器 计算机启动过程 操作系统基本知识 进程线程纤程的基本概念（面试高频）：纤程的实现 内存管理 进程管理与线程管理（进程与纤程在 Linux 中的实现） 中断与系统调用（软中断） 内核同步基础知识 关于键盘的 I/O 以及 DMA 相关书籍推荐 读书的原则：不求甚解，观其大略\n《编码：隐匿在计算机软硬件背后的语言》：比较浅显 《深入理解计算机系统》：比较难 编程语言 C：K\u0026R《C 程序设计语言》，《C Primer Plus》 Java 数据结构与算法：毕生的学习，LeetCode 《Java 数据结构与算法》，《算法》 《算法导论》，《计算机程序设计艺术》：难 操作系统：《Linux 内核源码解析》，《Linux 内核设计与实现》，《30 天自制操作系统》 网络：《TCP/IP 详解 卷一》（翻译一般） 编译原理：《编译原理》，《编程语言实现模式》 数据库：SQLite 源码（C 语言中的），Derby（JDK 自带数据库） 硬件基础知识 CPU 的制作过程 Intel CPU 的制作过程：https://haokan.baidu.com/v?vid=11928468945249380709\u0026pd=bjh\u0026fr=bjhauthor\u0026type=video\nCPU 是如何制作的（文字描述）：https://www.sohu.com/a/255397866_468626\nCPU 的原理 计算机需要解决的最根本问题：如何代表数字\n晶体管是如何工作的：https://haokan.baidu.com/v?vid=16026741635006191272\u0026pd=bjh\u0026fr=bjhauthor\u0026type=video\n晶体管的工作原理：https://www.bilibili.com/video/av47388949?p=2\n汇编语言（机器语言）的执行过程 汇编语言的本质：机器语言的助记符，其实它就是机器语言\n计算机通电 → CPU 读取内存中的指令（电信号输入）→ 时钟发生器不断震荡通断电，推动 CPU 内部一步一步执行（执行多少步取决于指令需要的时钟周期）→ 计算完成 → 写回到内存（电信号）- - \u003e 写给显卡输出（sout，或者图形）\n量子计算机 量子比特，1 位可以同时表示 1 0\nJava 相关硬件知识 计算机的基本组成 CPU 和 IO Bridge 间的总线称为“系统总线”；内存和 IO Bridge 间的总线称为“内存总线”；所有外设和 IO Bridge 间的总线称为 IO 总线。\n程序的加载过程：磁盘上的程序 -\u003e 加载到内存 -\u003e CPU 从内存读取数据进行处理 -\u003e CPU 处理结束后，将结果写回内存\nCPU 的基本组成 PC（Program Counter，程序计数器）：记录当前正在执行指令在内存中的地址\nRegisters（寄存器）：暂时存储 CPU 计算需要用到的数据\nALU（Arithmetic \u0026 Logic Unit，逻辑运算单元）：用于计算。\n例如计算 2+3，从内存读取指令\nmove 2 将 2 移动到寄存器 A move 3 将 3 移动到寄存器 B add ALU 从 寄存器 A 和 寄存器 B 中取出两个数，进行加运算后，将结果写到寄存器 C 将寄存器 C 中的结果，写回到内存的指定区域 CU（Control Unit，控制单元）\nMMU（Memory Management Unit，内存管理单元）\ncache（缓存）\n超线程 单核单线程：CPU 的 1 个核心中，包含 1 个 ALU，1 组 Registers 和 PC。例如 ALU 执行了 Thread-1 读文件的指令，此时 ALU 可以不等待 Thread-1 读取完成，就去执行 Thread-2 的指令，但是此时需要先将 Thread-1 的指令从 Registers 和 PC 中移动出去，然后将 Thread-2 的指令读取到 Registers 和 PC 中，这个过程就叫“上下文切换“，“上下文切换”会降低性能。\n单核双线程（超线程）：CPU 的 1 个核心中，包含 1 个 ALU，2 组 Registers 和 PC，1 个线程使用 1 组 Registers 和 PC。例如 ALU 执行了 Thread-1 读文件的指令，此时 ALU 不需要等待 Thread-1 完成读取，即可直接使用另一组 Registers 和 PC 执行 Thread-2 的指令（不需要将 Thread-1 的指令从它的 Registers 和 PC 中移走，减少了“上下文切换”），当 Thread-1 完成读取后，ALU 可以直接通过 Thread-1 的 Registers 和 PC，继续执行 Thread-1 后续的指令。\n超线程主要是减少了上下文切换，从而提高了效率。\n缓存 寄存器，L1 缓存，L2 缓存在每个 CPU 的核心中都有一份，L3 以后的缓存在 CPU 核心的外面，是 CPU 共享的。\n从 CPU 到不同缓存间的读写速度 device time Registers \u003c 1ns L1 cache 约 1ns L2 cache 约 3ns L3 cache 约 15ns main memory 约 80ns 多核 CPU 的缓存 程序局部性原理 程序局部性原理，可以提高效率，充分发挥总线，CPU 针脚等一次性读取更多数据的能力。\n程序局部性原理又表现为：时间局部性和空间局部性。时间局部性是指如果程序中的某条指令一旦执行，则不久之后该指令可能再次被执行；如果某数据被访问，则不久之后该数据可能再次被访问。空间局部性是指一旦程序访问了某个存储单元，则不久之后，其附近的存储单元也将被访问。\n按块读取：假如某个指令需要读取 1 个字节的数据，根据程序局部性原理，会将该数据附近的数据都读取进来（目前多用 64 字节）。\n缓存行（Cache Line） x，y 两个数据在同一个“缓存行”中，当 CPU 读取 x（或者 y）的时候，会将 x，y 所在的缓存行都读取到缓存，ALU 会按照 L1 Cache -\u003e L2 Cache -\u003e L3 Cache -\u003e main memory 的顺序去读取数据。\n缓存一致性协议：如果两颗 CPU 的核心都读取了同一缓存行内的数据，其中一个 CPU 对缓存行中的某个数据进行了修改后写回内存，如果修改后的数据对另一个 CPU 正在处理的指令有影响，需要通知另一个 CPU 重新读取该缓存行数据。\n缓存行：\n缓存行越大，局部性空间效率越高，但读取时间慢\n缓存行越小，局部性空间效率越低，但读取时间快\n取一个折中值，目前多用：64 字节\n验证缓存行的代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 package com.mashibing.juc.c_028_FalseSharing; public class T03_CacheLinePadding { volatile long x; volatile long y; public static void main(String[] args) throws Exception { T03_CacheLinePadding t = new T03_CacheLinePadding(); Thread t1 = new Thread(() -\u003e { for (int i = 0; i \u003c 1_0000_0000L; i++) { t.x = i; } }); Thread t2 = new Thread(() -\u003e { for (int i = 0; i \u003c 1_0000_0000L; i++) { t.y = i; } }); final long start = System.nanoTime(); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println((System.nanoTime() - start) / 100_0000); } } package com.mashibing.juc.c_028_FalseSharing; public class T04_CacheLinePadding { volatile long x; public long p1, p2, p3, p4, p5, p6, p7; volatile long y; public static void main(String[] args) throws Exception { T04_CacheLinePadding t = new T04_CacheLinePadding(); Thread t1 = new Thread(() -\u003e { for (int i = 0; i \u003c 1_0000_0000L; i++) { t.x = i; } }); Thread t2 = new Thread(() -\u003e { for (int i = 0; i \u003c 1_0000_0000L; i++) { t.y = i; } }); final long start = System.nanoTime(); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println((System.nanoTime() - start) / 100_0000); } } 缓存行对齐：对于有些特别敏感的数字，会存在线程高竞争的访问，为了保证不发生伪共享，可以使用缓存行对齐的编程方式\nJDK7 中，很多采用 long padding 提高效率\n1 2 3 public long p1, p2, p3, p4, p5, p6, p7; // cache line padding private volatile long cursor = INITIAL_CURSOR_VALUE; public long p8, p9, p10, p11, p12, p13, p14; // cache line padding JDK8，加入了 @Contended 注解（实验）需要加上：JVM -XX:-RestrictContended\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import sun.misc.Contended; public class T05_Contended { /** * @Contended：强制 x，y 不在同一缓存行 */ @Contended volatile long x; @Contended volatile long y; public static void main(String[] args) throws Exception { T05_Contended t = new T05_Contended(); Thread t1 = new Thread(() -\u003e { for (int i = 0; i \u003c 1_0000_0000L; i++) { t.x = i; } }); Thread t2 = new Thread(() -\u003e { for (int i = 0; i \u003c 1_0000_0000L; i++) { t.y = i; } }); final long start = System.nanoTime(); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println((System.nanoTime() - start) / 100_0000); } } CPU 指令的乱序执行 https://preshing.com/20120515/memory-reordering-caught-in-the-act/\njvm/jmm/Disorder.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 package com.mashibing.jvm.c3_jmm; public class T04_Disorder { private static int x = 0, y = 0; private static int a = 0, b =0; public static void main(String[] args) throws InterruptedException { int i = 0; for(;;) { i++; x = 0; y = 0; a = 0; b = 0; Thread one = new Thread(new Runnable() { public void run() { // 由于线程 one 先启动，下面这句话让它等一等线程 two。读着可根据自己电脑的实际性能适当调整等待时间。 //shortWait(100000); a = 1; x = b; } }); Thread other = new Thread(new Runnable() { public void run() { b = 1; y = a; } }); one.start();other.start(); one.join();other.join(); String result = \"第\" + i + \"次 (\" + x + \",\" + y + \"）\"; if(x == 0 \u0026\u0026 y == 0) { System.err.println(result); break; } else { //System.out.println(result); } } } public static void shortWait(long interval){ long start = System.nanoTime(); long end; do{ end = System.nanoTime(); }while(start + interval \u003e= end); } } 如果 CPU 不存在乱序执行，则结果只有三种情况 0, 0、0, 1、1, 0 执行程序后发现会出现 0, 0 的情况，说明 CPU 存在乱序执行。\n面试题：DCL（Double Check Lock）单例为什么要加 volatile\nJava 对象创建过程\n源码\n1 2 3 4 class T { int m = 8; } T t = new T(); 汇编码\n0 new #2 \u003cT\u003e // new 了一块内存，并给 m 赋初始值 0 3 dup // duplicate，复制，在栈中再添加一个该对象的引用，执行下方语句时，消耗该引用，最后栈中只剩一个引用 4 invokespecial #3 \u003cT.\u003cinit\u003e\u003e // 执行构造方法对对象进行初始化，m 变为 8 7 astore_1 // 将对象地址保存在局部变量表的第一个位置，将引用 t 指向对象 8 return 当 thread1 执行完第 0 条指令后，4 和 7 发生了指令重排，并执行了 7，此时引用 t 指向了一个半初始化状态的对象，如果此时 thread2 执行 if(t != null)，此时使用了半初始化状态的对象，因此必须加 volatile。\nCPU 层面如何禁止重排序 CPU 层面：Intel → 原语（mfence lfence sfence）或者锁总线\nJVM 层级：8 个 hanppens-before 原则规定哪些指令不能重排序。4 个内存屏障（LL LS SL SS）保证 volitale 修饰的指令不被重排序\nas-if-serial：不管硬件什么顺序，单线程执行的结果不变，看上去像是 serial，实际可能是乱序的\n合并写（不重要） Write Combining Buffer\n一般是 4 个字节\n由于 ALU 速度太快，所以在写入 L1 的同时，写入一个 WC Buffer，满了之后，直接更新到 L2\nNUMA Non Uniform Memory Access\nZGC - NUMA aware\n分配内存会优先分配该线程所在 CPU 的最近内存\nOS 内核分类 微内核 - 弹性部署 5G loT\n宏内核 - PC phone\n外核 - 科研 实验室中 为应用定制操作系统（多租户 requestbashed GC JVM）\n启动过程（不重要） 通电 → bios uefi 工作 → 自检 → 到硬盘固定位置加载 bootloader → 读取可配置信息 → CMOS\n用户态与内核态 cpu 分不同的指令级别\nlinux 内核跑在 ring 0 级，用户程序跑在 ring 3，对于系统的关键访问，需要经过 kernel 的同意，保证系统健壮性\n内核执行的操作 - \u003e 200 多个系统调用 sendfile read write pthread fork\nJVM → 站在 OS 老大的角度，就是个普通程序\n进程 线程 纤程 中断 面试高频：进程和线程有什么区别？\n答案：进程是 OS 分配资源的基本单位，线程是执行调度的基本单位。分配资源最重要的是：独立的内存空间，线程调度执行（线程共享进程的内存空间，没有自己独立的内存空间）\n纤程/协程：用户态的线程，线程中的线程，切换和调度不需要经过 OS\n优势：1：占有资源很少 OS 启动线程占 1M 空间，Fiber 启动占用 4K 2：切换比较简单 3：启动很多个 10W+\n目前 2020 3 22 支持内置纤程的语言：Kotlin Scala Go Python(lib)... Java？（open jdk : loom）\nJava 中对于纤程的支持：没有内置，盼望内置 利用 Quaser 库（不成熟）\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003eco.paralleluniverse\u003c/groupId\u003e \u003cartifactId\u003equasar-core\u003c/artifactId\u003e \u003cversion\u003e0.8.0\u003c/version\u003e \u003c/dependency\u003e 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 import co.paralleluniverse.fibers.Fiber; import co.paralleluniverse.fibers.SuspendExecution; import co.paralleluniverse.strands.SuspendableRunnable; public class HelloFiber { public static void main(String[] args) throws Exception { long start = System.currentTimeMillis(); Runnable r = new Runnable() { @Override public void run() { calc(); } }; int size = 10000; Thread[] threads = new Thread[size]; for (int i = 0; i \u003c threads.length; i++) { threads[i] = new Thread(r); } for (int i = 0; i \u003c threads.length; i++) { threads[i].start(); } for (int i = 0; i \u003c threads.length; i++) { threads[i].join(); } long end = System.currentTimeMillis(); System.out.println(end - start); } static void calc() { int result = 0; for (int m = 0; m \u003c 10000; m++) { for (int i = 0; i \u003c 200; i++) result += i; } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 import co.paralleluniverse.fibers.Fiber; import co.paralleluniverse.fibers.SuspendExecution; import co.paralleluniverse.strands.SuspendableRunnable; public class HelloFiber2 { public static void main(String[] args) throws Exception { long start = System.currentTimeMillis(); int size = 10000; Fiber\u003cVoid\u003e[] fibers = new Fiber[size]; for (int i = 0; i \u003c fibers.length; i++) { fibers[i] = new Fiber\u003cVoid\u003e(new SuspendableRunnable() { public void run() throws SuspendExecution, InterruptedException { calc(); } }); } for (int i = 0; i \u003c fibers.length; i++) { fibers[i].start(); } for (int i = 0; i \u003c fibers.length; i++) { fibers[i].join(); } long end = System.currentTimeMillis(); System.out.println(end - start); } static void calc() { int result = 0; for (int m = 0; m \u003c 10000; m++) { for (int i = 0; i \u003c 200; i++) result += i; } } } 作业：目前是 10000 个 Fiber → 1 个 JVM 线程，想办法提高效率，10000Fiber → 10 份 → 10Threads\n纤程的应用场景 纤程 vs 线程池：很短的计算任务，不需要和内核打交道，并发量高！\nLinux 中的进程 在 Linux 中线程就是普通的进程，只不过共享主进程的资源\nLinux 中进程也称为 task，通过 PCB（Process Control Block，进程描述符）对进程进行管理\n僵尸进程 ps -ef | grep defuct\n父进程产生子进程后，会维护子进程的 PCB 结构，子进程退出，由父进程释放，如果父进程没有释放，那么子进程称为一个僵尸进程\nzombie.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e #include \u003cstring.h\u003e #include \u003cassert.h\u003e #include \u003csys/types.h\u003e int main() { pid_t pid = fork(); if (0 == pid) { printf(\"child id is %d\\n\", getpid()); printf(\"parent id is %d\\n\", getppid()); } else { while(1) {} } } 孤儿进程 子进程结束之前，父进程已经退出。\n孤儿进程会成为 init 进程的孩子，由 1 号进程维护\norphan.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e #include \u003cstring.h\u003e #include \u003cassert.h\u003e #include \u003csys/types.h\u003e int main() { pid_t pid = fork(); if (0 == pid) { printf(\"child ppid is %d\\n\", getppid()); sleep(10); printf(\"parent ppid is %d\\n\", getppid()); } else { printf(\"parent id is %d\\n\", getpid()); sleep(5); exit(0); } } 进程调度 linux kernel 2.6 采用 CFS 调度策略：Completely Fair Scheduler\n按优先级分配时间片的比例，记录每个进程的执行时间，如果有一个进程执行时间不到他应该分配的比例，优先执行\n默认调度策略：\n实时进程，永远比普通进程先执行。优先级分高低 - FIFO（First In First Out），优先级一样 - RR（Round Robin）普通进程：CFS\n中断 硬中断：硬件跟操作系统内核打交道的一种机制\n软中断（80 中断）== 系统调用\n系统调用：int 0x80 或者 sysenter 原语\n通过 ax 寄存器填入调用号\n参数通过 bx cx dx si di 传入内核\n返回值通过 ax 返回\njava 读网络 – jvm read() – c 库 read() →\n内核空间 → system_call()（系统调用处理程序）\n→ sys_read()\n从汇编角度理解软中断 搭建汇编环境\nyum install nasm\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ;hello.asm ;write(int fd, const void *buffer, size_t nbytes) ;fd 文件描述符 file descriptor - linux 下一切皆文件 section data msg db \"Hello\", 0xA len equ $ - msg section .text global _start _start: mov edx, len mov ecx, msg mov ebx, 1 ;文件描述符 1 std_out mov eax, 4 ;write 函数系统调用号 4 int 0x80 mov ebx, 0 mov eax, 1 ;exit 函数系统调用号 int 0x80 编译：nasm -f elf hello.asm -o hello.o\n链接：ld -m elf_i386 -o hello hello.o\n一个程序的执行过程，要么处于用户态，要么处于内核态\n内存管理 内存管理的发展历程 DOS 时代 - 同一时间只能有一个进程在运行（也有一些特殊算法可以支持多进程）\nwindows9x - 多个进程装入内存 1：内存不够用 2：互相打扰\n为了解决这两个问题，诞生了现在的内存管理系统：虚拟地址 分页装入 软硬件结合寻址\n分页（内存不够用），内存中分成固定大小的页框（4K），把程序（硬盘上）分成 4K 大小的块，用到哪一块，加载那一块，加载的过程中，如果内存已经满了，会把最不常用的一块放到 swap 分区，把最新的一块加载进来，这个就是著名的 LRU 算法 LRU 算法 LeetCode146 题，头条要求手撕，阿里去年也要求手撕 Least Recently Used 最不常用 哈希表（保证 查找操作 O(1)）+ 链表（保证 排序操作和新增操作 O(1)）） 双向链表（保证 左边指针 指向右边块） 虚拟内存（解决相互打扰问题） DOS Win31 ... 互相干掉 为了保证互不影响 - 让进程工作在虚拟空间，程序中用到的空间地址不再是直接的物理地址，而是虚拟的地址，这样，A 进程永远不可能访问到 B 进程的空间 虚拟空间多大呢？寻址空间 - 64 位系统 2 ^ 64，比物理空间大很多，单位是 byte 站在虚拟的角度，进程是独享整个系统 + CPU 内存映射：偏移量 + 段的基地址 = 线性地址（虚拟空间） 线性地址通过 OS + MMU（硬件 Memory Management Unit） 缺页中断（不是很重要）： 需要用到页面内存中没有，产生缺页异常（中断），由内核处理并加载 ZGC 算法叫做：Colored Pointer\nGC 信息记录在指针上，不是记录在头部，immediate memory use\n42 位指针 寻址空间 4T JDK13 → 16T 目前为止最大 16T 2^44\nCPU 如何区分一个立即数 和 一条指令 总线内部分为：数据总线 地址总线 控制总线\n地址总线目前：48 位\n颜色指针本质上包含了地址映射的概念\n内核同步机制 关于同步理论的一些基本概念 临界区（critical area）：访问或操作共享数据的代码段 简单理解：synchronized 大括号中部分（原子性） 竞争条件（race conditions）两个线程同时拥有临界区的执行权 数据不一致：data unconsistency 由竞争条件引起的数据破坏 同步（synchronization）避免 race conditions 锁：完成同步的手段（门锁，门后是临界区，只允许一个线程存在）上锁解锁必须具备原子性 原子性（象原子一样不可分割的操作） 有序性（禁止指令重排） 可见性（一个线程内的修改，另一个线程可见） 互斥锁 排他锁 共享锁 分段锁\n内核同步常用方法 原子操作 – 内核中类似于 AtomicXXX，位于\u003clinux/types.h\u003e\n自旋锁 – 内核中通过汇编支持的 cas，位于\u003casm/spinlock.h\u003e\n读-写自旋 – 类似于 ReadWriteLock，可同时读，只能一个写 读的时候是共享锁，写的时候是排他锁\n信号量 – 类似于 Semaphore(PV 操作 down up 操作 占有和释放）重量级锁，线程会进入 wait，适合长时间持有的锁情况\n读-写信号量 – downread upread downwrite upwrite（多个写，可以分段写，比较少用）(分段锁）\n互斥体（mutex）– 特殊的信号量（二值信号量）\n完成变量 – 特殊的信号量（A 发出信号给 B，B 等待在完成变量上）vfork() 在子进程结束时通过完成变量叫醒父进程 类似于(Latch)\nBKL：大内核锁（早期，现在已经不用）\n顺序锁（2.6）：– 线程可以挂起的读写自旋锁 序列计数器（从 0 开始，写时增加(+1)，写完释放(+1)，读前发现单数，说明有写线程，等待，读前读后序列一样，说明没有写线程打断）\n禁止抢占 – preempt_disable()\n内存屏障 – 见 volatile\n汇编实现引导程序 编写汇编码 ; 文件名 boot.asm org 7c00h ; BIOS 读入 MBR 后，从 0x7c00h 处开始执行 ; 下面部分和 10h 有关中断，10h 中断用来显示字符 mov ax, cs mov es, ax mov ax, msg mov bp, ax ; ES:BP 表示显示字符串的地址 mov cx, msgLen ; CX 存字符长度 mov ax, 1301h ; AH=13h 表示向 TTY 显示字符，AL=01h 表示显示方式（字符串是否包含显示属性，01h 表示不包含） mov bx, 000fh ; BH=00h 表示页号，BL=0fh 表示颜色 mov dl, 0 ; 列 int 10h msg: db \"hello world, welcome to OS!\" msgLen: equ $ - msg ; 字符串长度 times 510 - ($ - $$) db 0 ; 填充剩余部分 dw 0aa55h ; 魔数，必须有这两个字节 BIOS 才确认是 MBR 编译 nasm boot.asm -o boot.bin\n制作启动软盘 dd if=/dev/zero of=floppy.img bs=1474560 count=1 生成空白软盘镜像 dd if=boot.bin of=myos.img bs=512 count=1 制作包含主引导记录 boot.bin 的启动镜像文件 dd if=floppy.img of=myos.img skip=1 seek=1 bs=512 count=2879 在 bin 生成的镜像文件后补上空白，成为合适大小的软盘镜像，一共 2880 个扇区，略过第一个 用软盘启动系统 将 myos.img 下载到 windows VMWare 创建空的虚拟机 文件 - 创建新的虚拟机 - 典型 稍后安装操作系统 其他 一路 next 完成 虚拟机设置，去掉 CD/DVD 选项中“启动时连接” 网络，选择“仅主机模式”，勾选“启动时连接”（好像无所谓） 添加软盘驱动器 使用软盘映像 找到 myos.img 启动虚拟机 为什么是 0x7C00？ 参考：https://www.glamenv-septzen.net/en/view/6\nhttps://ke.qq.com/webcourse/index.html#cid=398381\u0026term_id=100475149\u0026taid=4067441403892781\u0026type=1024\u0026vid=5285890799733685067 ↩︎\n","description":"","tags":["MSB","Computer","Java"],"title":"Java 程序员需要掌握的计算机底层知识","uri":"/posts/msb/java-%E7%A8%8B%E5%BA%8F%E5%91%98%E9%9C%80%E8%A6%81%E4%BA%86%E8%A7%A3%E7%9A%84%E5%BA%95%E5%B1%82%E7%9F%A5%E8%AF%86/msb-computer/"},{"categories":null,"content":"源码方式安装 PostGIS3.0.1 PostGIS 是以插件的形式安装到 PostgreSQL 中的，因此需要首先安装 PostgreSQL，参考CentOS 安装 PostgreSQL12.2\n包管理器安装 略\n源码方式安装 解压 Postgis 源码包\n1 2 3 tar -zxvf postgis-3.0.1.tar.gz cd postgis-3.0.1 ./configure --prefix=/path/to/postgresql --with-pgconfig=/path/to/postgresql/bin/pg_config --prefix=PREFIX: PostGIS 安装的位置 --with-pgconfig=FILE1: PostgreSQL 提供了一个名为 pg_config 的文件，用于使 PostGIS 这样的插件能够定位到 PostgreSQL 的安装目录。 1 2 make all make install 登录 postgres，使用如下命令安装 postgis 插件\n1 2 3 create extension postgis; select postgis_full_version(); 官方安装文档\n","description":"","tags":["PostGIS","PostgreSQL"],"title":"Linux 安装 PostGIS3","uri":"/posts/database/postgis-install-in-linux/"},{"categories":null,"content":"Docker 安装 MySQL 官方文档\n在主机上新建一个目录用来存放 mysql 的配置文件和数据 1 2 3 4 $ mkdir -p /path-on-host-machine/data $ mkdir -p /path-on-host-machine/log $ mkdir -p /path-on-host-machine/conf $ touch /path-on-host-machine/conf/my.cnf 其中 data 目录必须为空，my.cnf 的内容如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## 必须包含的配置 [mysqld] user=mysql # 常用配置 # 设置服务端字符集 character_set_server=utf8mb4 # 不区分表名大小写 lower_case_table_names=1 [mysql] # 设置客户端字符集 default-character-set=utf8mb4 运行容器 docker 运行 mysql 的说明\n1 2 3 4 5 6 $ docker run --name some-mysql \\ -p 3306:3306 \\ -v /path-on-host-machine/conf:/etc/mysql/conf.d \\ -v /path-on-host-machine/datadi:/var/lib/mysql \\ -v /path-on-host-machine/logdir:/var/log/mysql \\ -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag 说明:\ndocker 中 /etc/mysql/my.cnf 内容如下\n1 2 !includedir /etc/mysql/conf.d/ !includedir /etc/mysql/mysql.conf.d/ 引入了 /etc/mysql/conf.d/ 和 /etc/mysql/mysql.conf.d/ 目录下的配置文件信息，所以将宿主机上存放自定义配置文件的目录映射到 docker 中的 /etc/mysql/conf.d/, mysql 就会读取其中的配置文件。\n","description":"","tags":["MySQL","Docker"],"title":"Docker 安装 MySQL","uri":"/posts/database/mysql-install-by-docker/"},{"categories":null,"content":"VrtualBox 网络相关及设置网络互通 networkingdetails\nVirtualBox 网络模式简介 Mode VM → Host Host → VM VM1 → VM2 VM → Net/LAN Net/LAN → VM Host-only + + + - - Internal - - + - - Bridged + + + + + NAT + Port forward - + Port forward NAT Network + Port forward + + Port forward 每个网络适配器都可以单独配置为以以下方式之一运行：\nNot attached：Oracle VM VirtualBox 向 Guest 报告存在网卡，但没有连接。就像没有插入以太网电缆一样。使用此模式相当于拔除了虚拟机的以太网电缆并中断连接，可用来通知 Guest 操作系统没有可用的网络连接并强制进行重新配置。\nNAT（Network Address Translation，网络地址转换）：如果您只需要浏览 Web，下载文件和查看 Guest 内部的电子邮件，则此默认模式就足够了。\nGuest 访问网络的所有数据都是由宿主机提供的，Guest 可以访问宿主机能访问到的所有网络，Guest 并不真实存在于网络中，宿主机与网络中的任何机器都不能直接查看和访问到 Guest。\n关系 说明 Guest 与 Host 默认只能 Guest 单向访问 Host。宿主机设置端口转发后 Host 可以通过转发的端口访问 Guest 上的服务（例如数据库服务） Guest 与 Net/LAN 只能 Guest 单向访问网络中的其他主机。宿主机设置端口转发后其他主机可以通过宿主机转发的端口访问 Guest 上的服务（例如数据库服务） Guest1 与 Guest2 虚拟机间完全相互独立，不能相互访问 设置方式： ​\t选中虚拟机 → Settings → Network → Attached to，选中 NAT 即可\nIP，Gateway，DNS：\n​\t默认 IP: 10.0.2.15，默认 Gateway：10.0.2.2，默认 DNS：10.0.2.3。同一 Guest 设置多块 NAT 网卡，网段按 10.0.2.0，10.0.3.0，...递增。\nNAT Network：NAT 网络是允许出站连接的一种内部网络\n该模式的工作方式类似于家用路由器，将使用该服务的系统分组到一个网络中，并防止该网络外部的系统直接访问其内部的系统，但允许内部的系统相互通信并与之通信。外部系统在 IPv4 和 IPv6 上使用 TCP 和 UDP。\n与 NAT 模式相比，该模式增加了 DHCP 功能，使得在同一网络内的 Guest 可以相互访问\n关系 说明 Guest 与 Host 默认只能 Guest 单向访问 Host. 设置端口转发后 Host 可以访问 Guest 上的服务（例如数据库服务） Guest 与 Net/LAN 只能 Guest 单向访问网络中的其他主机。设置端口转发后其他主机可以访问 Guest 上的服务（例如数据库服务） Guest1 与 Guest2 虚拟机之间可以相互访问 设置方式： 首先创建一个 NAT Network：选中 Tools → Preferences → Network → NAT Networks → Adds New NAT networks（图标） → Edits selected NAT networks → 设置好 CIDR 等信息即可\n为 Guest 选择使用 NAT Network：选中需要设置的 Guest → Settings → Network → Attached to: → 选择 NAT Network → Name 选择上一步设置的 NAT network 的名称即可\nIP，Gateway，DNS\n按照上方创建 NAT Network 时配置的 CIDR 及 DHCP 自动配置\nBridged networking（桥接网络）：这是为了满足更高级的网络需求。例如网络仿真和在 Guest 中运行服务。启用后，Oracle VM VirtualBox 将连接到宿主机上已安装的网卡之一并直接交换网络数据包，从而规避了主机操作系统的网络栈。\n该模式通过宿主机的网卡，架设了一条桥，直接接入到了宿主机所在的网络中，所有功能与网络中的真实主机一样。\nGuest 与 Host 在同一网络中，具有相同的网段等信息\n关系 说明 Guest 与 Host 可以互相访问，Guest 与 Host 在同一网段中 Guest 与 Net/LAN 可以互相访问，Guest，Host，以及 Host 所在网段中的其他机器均在同一网段 Guest1 与 Guest2 虚拟机之间可以相互访问，原因同上 设置方法： 选中 Guest → Settings → Network → Attached to: → 选中 Bridged Adapter → Name 选中宿主机中的网卡（通常选择正连接到网络中的网卡）\nIP，Gateway，DNS：\n一般是宿主机所在网络的 DHCP 分配，与宿主机在同一网段\nInternal networking（内部网络）：可用于创建另一种基于软件的网络，该网络对选定的虚拟机可见，对主机上或外部世界上运行的应用程序不可见\n虚拟机与外网完全断开，只实现虚拟机与虚拟机之间的内部网络通讯模式。\n关系 说明 Guest 与 Host 不能相互访问，彼此不属于同一个网络 Guest 与 Net/LAN 不能相互访问，理由同上 Guest1 与 Guest2 可以相互访问，前提是设置网络时，两台虚拟机设置同一个网络名称 设置方法\n选中 Guest → Settings → Network → Attached to: → 选中 Internal Network → Name 中可以使用默认的，也可以手动输入\nName 相同的 Guest 可以相互访问\nIP，Gateway，DNS\nVirtualBox 的 DHCP 服务器会为它分配 IP, 也可以手动设置静态 IP\nHost-only networking（仅主机）：用于创建包含主机和一组虚拟机的网络，并且无需主机的物理网络接口。在主机上创建类似于环回接口的虚拟网络接口，以提供虚拟机和主机之间的相互连接。\nGeneric networking：通过允许用户选择可以包含在 Oracle VM VirtualBox 中或可以在扩展包中分发的驱动程序，可以使用共享相同通用网络接口的罕见模式。以下子模式可用：\nUDP Tunnel：用于通过现有网络基础结构直接，轻松，透明地互连在不同主机上运行的虚拟机。 VDE（Virtual Distributed Ethernet） networking：用于连接 Linux 或 FreeBSD 主机上的虚拟分布式以太网交换机。目前，此选项需要从源代码编译 Oracle VM VirtualBox，因为 Oracle 软件包不包括它。 https://www.virtualbox.org/manual/UserManual.html#networkingdetails VirtualBox 的四种网络连接方式\n使用 NAT + Host Only 解决宿主机（host）与虚拟机（guest），虚拟机与虚拟机，虚拟机与外网之间的访问 ","description":"","tags":["VirtualBox"],"title":"VrtualBox 网络相关及设置网络互通","uri":"/posts/virtualbox/virtualbox-network/"},{"categories":null,"content":"使用 WireGuard 建立 VPN VPN：Virtual Private Network，虚拟专用网络。在公用网络上建立专用网络，通过加密隧道（tunnel），进行加密通讯。可理解为将两台机器组建为一个局域网进行加密的点对点传输。\n翻墙：而所谓的“翻墙”是在 VPN 的基础上，又对服务器设置了请求转发，将客户端发送到服务器的请求，以服务器发送出去，再将接收到的信息返回给客户端，服务器相当于一个代理人。这里的 VPN 服务器需要既可以和客户端相通，也可以和内部局域网相通。\nWireGuard 是一种利用最新加密技术的及其简单，快速，现代化的 VPN。它旨在比 IPsec 更快，更简单，更精简，更有用，同时避免造成严重的麻烦。它打算比 OpenVPN 具有更高的性能。WireGuard 被设计为通用 VPN，可在嵌入式接口和超级计算机上运行，适用于许多不同的情况。最初针对 Linux 内核发布，现在已跨平台（Window、macOS、BSD、IOS、Android）并广泛部署。它目前正在积极开发中，但是已被认为是业界最安全，最易用，最简单的 VPN 解决方案。\nWireGuard 配置就像设置 SSH 一样简单。通过服务器和客户端之间的公共密钥交换来建立连接。仅允许在其相应的服务器配置文件中具有其公钥的客户端连接。WireGuard 设置了标准的网络接口（例如 wg0 和 wg1），其行为与常见的 eth0 接口非常相似。这样就可以使用 ifconfig 和 ip 等标准工具来配置和管理 WireGuard 接口。\n安装 WireGuard 需要具备服务器的 root 访问权限或者用户具有 sudo 权限。具体安装可见 官方安装文档，部分常用系统的安装方式如下\nFedora 1 $ sudo dnf install wireguard-tools CentOS CentOS 8\n1 2 $ sudo yum install elrepo-release epel-release $ sudo yum install kmod-wireguard wireguard-tools CentOS 7\n1 2 3 $ sudo yum install epel-release https://www.elrepo.org/elrepo-release-7.el7.elrepo.noarch.rpm $ sudo yum install yum-plugin-elrepo $ sudo yum install kmod-wireguard wireguard-tools Ubuntu Ubuntu \u003e= 19.10\n1 $ sudo apt install wireguard 局域网内点对点加密通讯 局域网内可以互通的机器间，为了加密通讯，可以使用该方式。\n机器 局域网 IP（LAN IP） VPN IP 监听端口（Listen Port） 公钥（Public Key） 私钥（Private Key） 机器 A 192.168.1.2/32 10.10.0.2/32 51822 \u003cClient A PublicKey\u003e \u003cClient A PrivateKey\u003e 机器 B 192.168.1.3/32 10.10.0.3/32 51823 \u003cClient B PublicKey\u003e \u003cClient B PrivateKey\u003e 分别在两台机器上使用如下命令生成秘钥\n1 2 3 cd /etc/wireguard umask 077 wg genkey | tee privatekey | wg pubkey \u003e publickey 分别在两台机器的 /etc/wiregruad 目录创建配置文件 wg0\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [Interface] # 当前节点的私钥 PrivateKey = \u003cPrivateKey\u003e # 当前节点在 VPN 网络中的专用 IPv4 和 IPv6 地址，该 IP 地址在 VPN 网络中必须唯一，多个 IP 可以使用“,”分割，例如 Address = 10.10.0.1/32,fd86:ea04:1115::1/64 Address = \u003cVPN IP\u003e # 当前节点与对等方通讯时监听的端口 ListenPort = \u003cListenPort\u003e [Peer] # 对等方的公钥 PublicKey = \u003cPeer PublicKey\u003e # 对等方的局域网 IP 和监听的端口号 Endpoint = \u003cPeer LAN IP\u003e:\u003cPeer ListenPort\u003e # 对等方在 VPN 网络中的 IP AllowedIPs = \u003cPeer VPN IP\u003e 其中 [Interface] 下配置当前机器的配置信息，[Peer] 下配置对等方的配置信息\n机器 A 配置文件\n1 2 3 4 5 6 7 8 9 [Interface] PrivateKey = \u003cClient A PrivateKey\u003e Address = 10.10.0.2/32 ListenPort = 51822 [Peer] PublicKey = \u003cClient B PublicKey\u003e Endpoint = 192.168.1.3:51823 AllowedIPs = 10.10.0.3/32 机器 B 配置文件\n1 2 3 4 5 6 7 8 9 [Interface] PrivateKey = \u003cClient B PrivateKey\u003e Address = 10.10.0.3/32 ListenPort = 51823 [Peer] PublicKey = \u003cClient A PublicKey\u003e Endpoint = 192.168.1.2:51822 AllowedIPs = 10.10.0.2/32 分别启动两台机器上的 WireGuard 服务\n1 sudo wg-quick up wg0 查看连接状态\n1 sudo wg show 在两台机器上使用 VPN IP 进行访问\n1 2 3 4 # 在机器 B 上 ping 机器 A 的 VPN IP ping 10.10.0.2 # 在机器 A 上 ping 机器 B 的 VPN IP ping 10.10.0.3 推荐的扩展配置 如果局域网内有多台服务器需要进行加密传输，只需要在配置文件中添加多个 [Peer] 信息并重启服务即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [Interface] PrivateKey = \u003cClient A PrivateKey\u003e Address = 10.10.0.2/32 ListenPort = 51822 [Peer] PublicKey = \u003cClient B PublicKey\u003e Endpoint = 192.168.1.3:51823 AllowedIPs = 10.10.0.3/32 [Peer] PublicKey = \u003cClient C PublicKey\u003e Endpoint = 192.168.1.4:51824 AllowedIPs = 10.10.0.4/32 如果需要动态添加 [Peer] 信息，可以在 [Interface] 下添加 SaveConfig = true，并使用命令方式添加 [Peer]\n1 2 3 4 5 6 7 8 9 10 11 [Interface] PrivateKey = \u003cClient A PrivateKey\u003e Address = 10.10.0.2/32 ListenPort = 51822 # 在服务运行时每当添加新对等项时自动更新配置文件 SaveConfig = true [Peer] PublicKey = \u003cClient B PublicKey\u003e Endpoint = 192.168.1.3:51823 AllowedIPs = 10.10.0.3/32 1 2 3 4 # 该命令可以在不重启服务的情况下动态添加/修改 Peer 的信息 sudo wg set wg0 peer \u003cPeer PublicKey\u003e allowed-ips \u003cPeer Address\u003e endpoint \u003cPeer LAN IP\u003e:\u003cPeer ListenPort\u003e # 给新添加的 Peer 添加路由信息 ip -4 route add \u003cPeer Address\u003e dev wg0 还可以在 [Peer] 下添加 PersistentKeepalive = 25，让当前机器每隔 25 秒就和指定 Peer 进行一次通讯，保持在线状态。\n1 2 3 4 5 6 7 8 9 10 11 12 [Interface] PrivateKey = \u003cClient A PrivateKey\u003e Address = 10.10.0.2/32 ListenPort = 51822 SaveConfig = true [Peer] PublicKey = \u003cClient B PublicKey\u003e Endpoint = 192.168.1.3:51823 AllowedIPs = 10.10.0.3/32 # 每隔 25 秒与该 Peer 进行通讯，保持当前服务的在线状态 PersistentKeepalive = 25 如果当前接口很少发送流量，但是它随时可能从对等方接收流量，并且它位于 NAT 之后，则接口可能会受益于 25 秒的持续 keepalive 间隔\n跨局域网的加密网络通讯 对于在不同局域网内的客户端，如果需要构建加密网络，则需要有一台可以连通这两个局域网的机器做为服务端。例如需要在家中访问公司局域网内的服务，则需要有一台在公网上的机器作为服务端。\n加密网络构建成功后，局域网 A 和局域网 B 内的机器就相当于在同一个局域网内了，可以使用 VPN IP 互相访问。\n机器 公网 IP（Public IP） VPN IP 监听端口（Listen Port） 公钥（Public Key） 私钥（Private Key） 服务端（公网） 182.96.234.245 10.10.0.1/32 51820 \u003cVPN Server PublicKey\u003e \u003cVPN Server PrivateKey\u003e 客户端 A（局域网 A） 10.10.0.2/32 \u003cClient A PublicKey\u003e \u003cClient A PrivateKey\u003e 客户端 B（局域网 B） 10.10.0.3/32 \u003cClient B PublicKey\u003e \u003cClient B PrivateKey\u003e 配置 WireGuard 服务器端 编辑配置文件\n在服务器上生成一对密钥\n1 2 3 cd /etc/wireguard umask 077 wg genkey | tee privatekey | wg pubkey \u003e publickey 创建配置文件 /etc/wireguard/wg0.conf 并添加以下内容\n1 2 3 4 5 6 7 8 9 [Interface] PrivateKey = \u003cVPN Server PrivateKey\u003e Address = 10.10.0.1/32 ListenPort = 51820 # 定义打开该接口后要执行的操作。这里设置了 Linux IP 伪装规则，以允许所有客户端共享服务器的 IPv4 和 IPv6 地址。此处注意需要将 eth0 替换为外网网卡名。 PostUp = iptables -A FORWARD -i wg0 -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE; ip6tables -A FORWARD -i wg0 -j ACCEPT; ip6tables -t nat -A POSTROUTING -o eth0 -j MASQUERADE # 定义关闭该接口后要执行的操作。这里设置清除上方设置的规则。此处注意需要将 eth0 替换为外网网卡名。 PostDown = iptables -D FORWARD -i wg0 -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE; ip6tables -D FORWARD -i wg0 -j ACCEPT; ip6tables -t nat -D POSTROUTING -o eth0 -j MASQUERADE SaveConfig = true 开启 IP 转发\n因为我们要通过 VPN 服务器将局域网 A 内机器与局域网 B 内机器相互通讯的包进行转发，所以要开启 VPN 服务器的 IP 转发功能\n在 /etc/sysctl.conf 文件中添加如下配置，然后执行 sysctl -p 使其生效\n1 2 net.ipv4.ip_forward = 1 net.ipv6.conf.all.forwarding = 1 对于使用了 firewalld 防火墙的机器，还需要执行 firewall-cmd --add-forward 开启网络端口和源之间的数据包转发功能。可以将该命令添加到配置文件的 PostUp 中，然后在 PostDown 中添加 firewall-cmd --remove-forward\n设置防火墙规则\n允许 SSH 连接和 WireGuard 监听的 VPN 端口\n1 2 3 4 5 6 7 8 # Fedora/CentOS/RedHat sudo firewall-cmd --zone=public --add-port=22/tcp --permanent sudo firewall-cmd --zone=public --add-port=51820/udp --permanent sudo firewall-cmd --reload # Ubuntu sudo ufw allow 22/tcp sudo ufw allow 51820/udp 验证\n1 2 3 4 5 # Fedora/CentOS/RedHat firewall-cmd --zone=public --list-ports # Ubuntu sudo ufw status verbose 配置 WireGuard 客户端 生成客户端的一对密钥\n1 2 3 cd /etc/wireguard umask 077 wg genkey | tee privatekey | wg pubkey \u003e publickey 创建配置文件 /etc/wireguard/wg0.conf 并添加以下内容\n1 2 3 [Interface] PrivateKey = \u003cClient A PrivateKey\u003e Address = 10.10.0.2/32 1 2 3 [Interface] PrivateKey = \u003cClient B PrivateKey\u003e Address = 10.10.0.3/32 将客户端与服务端进行连接 在客户端配置文件中添加服务端的信息\n1 2 3 4 5 6 7 [Peer] PublicKey = \u003cVPN Server PublicKey\u003e # VPN Server 的公网 IP和监听端口号 Endpoint = 182.96.234.245:51820 # 将当前客户端发送到 10.10.0.X 的请求都经由 VPN Server 进行转发 AllowedIPs = 10.10.0.0/24 PersistentKeepalive = 25 在服务端的配置文件中添加客户端的信息\n1 2 3 4 5 6 7 8 9 [Peer] PublicKey = \u003cClient A PublicKey\u003e # 客户端 A 在 VPN 网络中的 IP，如果有多个可以使用“,”分割 AllowedIPs = 10.10.0.2/32 [Peer] PublicKey = \u003cClient B PublicKey\u003e # 客户端 B 在 VPN 网络中的 IP，如果有多个可以使用“,”分割 AllowedIPs = 10.10.0.3/32 启动/关闭服务端和客户端 打开/关闭接口\n1 2 3 4 # 打开接口 wg-quick up wg0 # 关闭接口 wg-quick down wg0 此时使用 ip addr 可查看到多了一个 wg0 的网络接口，wg0.conf 配置文件名称与其对应，其 IP 地址即为配置文件中 Address 的内容\n设置/取消 WireGuard 服务开机自启动\n1 2 3 4 # 设置开机自启动 sudo systemctl enable wg-quick@wg0 # 取消开机自启动 sudo systemctl enable wg-quick@wg0 测试连接 在客户端/中 ping 服务端和另一个客户端\n1 2 3 # 在客户端 A 中 ping 服务端和客户端 B ping 10.10.0.1 ping 10.10.0.3 此时所有客户端和服务器均相当于在同一个局域网内，所以是可以互相 ping 通的\n如果连接成功，可以使用 sudo wg show 查看节点间数据传输的信息\n1 2 latest handshake: 1 minute, 17 seconds ago transfer: 98.86 KiB received, 43.08 KiB sent 如果 received 一直显示 0 Kib，则说明双方连接有问题\n翻墙 翻墙与 跨局域网的加密网络通讯 极其相似，唯一区别就是需要对客户端的配置配置做一些修改，并且需要保证 VPN 服务器既可以和国内网络进行通信，也可以访问国外网站。\n关闭客户端\n1 wg-quick down wg0 修改客户端配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 [Interface] PrivateKey = \u003cClient A PrivateKey\u003e Address = 10.10.0.2/32 # 客户端默认的 DNS 可能解析不了国外的域名，所以指定一个可以解析的 DNS DNS = 1.1.1.1 [Peer] PublicKey = \u003cVPN Server PublicKey\u003e # VPN Server 换成了可以访问外网的服务器 Endpoint = 193.124.213.167:51820 # 将客户端发送的所有请求都通过 VPN 服务器进行转发 AllowedIPs = 0.0.0.0/0, ::/0 PersistentKeepalive = 25 启动客户端\n1 wg-quick up wg0 在客户端访问 Google 进行测试\n1 ping google.com AllowedIPs 设置为 0.0.0.0/0, ::/0，会将客户端的所有流量都通过 VPN 服务器转发，所有会出现两个结果\n客户端和客户端间依旧可以通过 VPN IP 进行通讯 即使访问国内的网站也会通过 VPN 服务器进行转发，所以访问国内网站会比较慢。这个问题 WireGuard 官方并没有解决方案。如有需要可参考 优化国内外流量 调试信息 如果您使用的是 Linux 内核模块，并且内核支持动态调试，则可以通过为模块启用动态调试来获得有用的运行时输出\n1 2 3 4 # 启用动态调试 sudo modprobe wireguard \u0026\u0026 sudo echo module wireguard +p \u003e /sys/kernel/debug/dynamic_debug/control # 查看调试信息 sudo journalctl -kf 如果接口访问不同，可以通过 tcpdump 抓包来观察\n1 tcudump -nn -i ens3 udp and port 51820 如果防火墙已经设置成功，但是 tcpdump 抓包依旧显示有问题，可以尝试重置 ipables\n1 sudo iptables -P INPUT ALLOW \u0026\u0026 sudo iptables -F 该命令很危险，如果在生产环境使用，请认真了解透彻后再使用。\n","description":"","tags":["Linux","VPN"],"title":"使用 WireGuard 建立 VPN","uri":"/posts/linux/wireguard-vpn/"},{"categories":null,"content":"在 Linux 中安装 Minikube Minikube 是一种可以轻松在本地运行 Kubernetes 的工具。Minikube 在笔记本电脑的虚拟机（VM）内运行一个单节点 Kubernetes 集群，以供希望试用 Kubernetes 或每天使用它开发的用户使用。引用自 Installing Kubernetes with Minikube\n安装 kubectl 要安装 MiniKube 需要首先安装 kubectl\nkubectl 官方文档\n在 Linux 上使用 curl 安装 kubectl 的二进制程序 下载最新的发布程序\n1 curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl 给 kubectl 二进制文件添加可执行权限\n1 chmod +x ./kubectl 移动二进制文件到 PATH 目录\n1 sudo mv ./kubectl /usr/local/bin/kubectl 测试以确定安装的版本信息\n1 kubectl version --client 安装成功会输出类似如下的信息\nClient Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.0\", GitCommit:\"9e991415386e4cf155a24b1da15becaa390438d8\", GitTreeState:\"clean\", BuildDate:\"2020-03-25T14:58:59Z\", GoVersion:\"go1.13.8\", Compiler:\"gc\", Platform:\"linux/amd64\"} 启用 shell 自动补全功能 安装 bash-completion\n1 yum/dnf/apt install bash-completion 设置自动开启 kubectl 自动补全\n1 echo \"source \u003c(kubectl completion bash)\" \u003e\u003e ~/.bashrc 安装 VirtualBox Minikube 在 Linux 上支持 VirtualBox，KVM2，Docker驱动，需要首先在系统上安装三个中的一个，阿里推荐使用 VirtualBox。\n下载对应版本，使用 Linux 自带包管理器安装即可\n安装 MiniKube 通过阿里提供的国内镜像进行安装\n1 curl -Lo minikube https://kubernetes.oss-cn-hangzhou.aliyuncs.com/minikube/releases/v1.11.0/minikube-linux-amd64 \u0026\u0026 chmod +x minikube \u0026\u0026 sudo mv minikube /usr/local/bin/ 启动 minikube, 使用 virtualbox 驱动和国内 docker 镜像\n1 minikube start --vm-driver=virtualbox --registry-mirror=https://xxxxxxxx.mirror.aliyuncs.com 启动过程会输入如下类似信息\n1 2 3 4 5 6 7 8 9 😄 minikube v1.11.0 on Ubuntu 18.04 ✨ Using the virtualbox driver based on existing profile 👍 Starting control plane node minikube in cluster minikube 🏃 Updating the running virtualbox \"minikube\" VM ... 🐳 Preparing Kubernetes v1.18.3 on Docker 19.03.8 ... \u003e download many file ... 🔎 Verifying Kubernetes components... 🌟 Enabled addons: default-storageclass, storage-provisioner 🏄 Done! kubectl is now configured to use \"minikube\" 其他可能用到的命令 重置 minikube, 删除所有缓存的镜像，重头开始\n1 rm -rf ~/.minikube 查看 minikube 状态\n1 minikube status 打开 minikube 的 dashboard\n1 minikube dashboard 停止 minikube\n1 minikube stop 参考文档 Install Minikube Minikube - Kubernetes 本地实验环境 安装 minikuber ","description":"","tags":["Kubernetes"],"title":"在 Linux 中安装 Minikube","uri":"/posts/kubernetes/kubernetes-minikube-install-on-linux/"},{"categories":null,"content":"Java 使用 Process.waitFor()执行 python 返回 137 在 Java 中使用 Process 类的 waitFor() 方法执行 python 程序，返回结果值为 137。参考如下 Linux 程序退出状态码\n状态码 含义 0 命令成功结束 1 一般性未知错误 2 不适合的 shell 命令 126 命令不可执行 127 没找到命令 128 无效的退出参数 128+x 与 Linux 信号 x 相关的严重错误，相当于 kill x 130 通过 Ctrl+C 终止的命令 255 正常范围之外的退出状态码 137 = 128 + 9，即 python 程序被 kill -9 命令杀死了\n使用如下命令查看日志\n1 egrep -i -r 'killed process' /var/log 可见\n1 /var/log/messages:Jun 10 09:28:33 10-20-73-69 kernel: Killed process 56524 (python) total-vm:7681564kB, anon-rss:6813304kB, file-rss:24kB 使用主机内存共 15G，可用内存 11G，同时跑两个该 python 程序即可造成 OOM，所以 Linux 内核将不可运行的算法程序直接 kill 掉了\n参考文档 解析 java 结果 137 Linux 内核 OOM killer 机制 ","description":"","tags":["Exception","Java"],"title":"Java 使用 Process.waitFor()执行 python 返回 137","uri":"/posts/java/java-process-return-137/"},{"categories":null,"content":"高级-网络管理与配置实战 网络(网段)数量 = 2 ^ 可变网络 ID 位数 一个网络的主机数量 = 2 ^ 主机 ID 位数 - 2 = 2 ^ (32 - 网路 ID 位数) -2 网络 ID=IP 地址\u0026子网掩码(netmask) CIDR 表示法 192.168.1.25/19, IP/网络 ID 位数\nhttps://developer.aliyun.com/lesson_1713_13918#_13918\n","description":"","tags":["Linux"],"title":"高级-网络管理与配置实战","uri":"/posts/linux/%E9%98%BF%E9%87%8C%E4%BA%91linux%E8%BF%90%E7%BB%B4%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/%E9%98%B6%E6%AE%B5%E4%BA%8C-%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/linux-network-manage-actual-combat/"},{"categories":null,"content":"进阶-TCP/IP 协议及 OSI 七层模型 OSI 参考模型（open system interface） 封包过程 A、P、S、T、N、D：报文首部 CRC：根据首部计算出的校验位 解包过程 冲突检测的载波侦听多路访问 CSMA/CD 在早期的 10M 带宽的网络中使用，现在已不在使用\n使用的是总线形拓扑结构，当发送数据时，先监听总线中如果没有正在传输数据，才进行传输。 如果有多台机器同时发送了数据，会造成数据碰撞，进而损坏数据。 使用回退算法生成一个等待时间，然后再发送数据。此时成功与否也是不确定的。 Hub 集线器 因为电缆传输的物理信号强度会随着距离的增大而减弱，所以可以使用中继器将两个电缆连接到一起，进而达到放大信号，增加传输距离的目的。\n常用电缆物理信号最大传输距离：\n细缆：185m 粗缆：500m 双绞线：100m Hub：多端口中继器，工作在物理层\nHub 并不记忆该信息包是由哪个 MAC 地址发出，哪个 MAC 地址在 Hub 的哪个端口。向所有连接在其上的机器均发送数据包\n特点：\n共享带宽 半双工 冲突域：如果两台机器同时向网络中发送数据会发生冲突，则说这两台机器在同一个冲突域中。\n以太网桥和交换机（switch） 一般只有两个接口，而交换机有多个端口。网桥是半双工的，交换机是全双工的。两者均工作在数据链路层\n交换式以太网的优势 扩展了网络带宽 分割了网络冲突域，使网络冲突被限制在最小的范围内 交换机作为更加智能的交换设备，能够提供更多用户所要求的功能：优先级，虚拟网，远程检测…… 以太网桥的工作原理 以太网桥监听数据帧中源 MAC 地址，学习 MAC，建立 MAC 表 对于未知的 MAC 地址，网桥将转发到除接收该帧的端口之外的所有端口 当网桥接到一个数据帧时，如果该帧的目的位于接收端口所在的网端上，他就过滤掉该数据帧；如果目的 MAC 地址在位于另外一个端口，网桥就将该帧转发到该端口 当网桥接到广播帧的时候，他立即转发到除接收端口之外的所有其他端口（即不能隔断广播域：当一个主机向外发送广播，而另一个机器收到该广播消息，则说这两个机器在同一个广播域。） A 机器向 B 机器发送数据包\n网桥将 A 的 MAC 地址及其所在端口记录到 MAC 地址表中\nB 回应数据包，网桥会将 B 的 MAC 地址及其端口添加到 MAC 地址表中\n当 A 向 B 再次发送数据时，网桥会根据 MAC 地址表找到对应的端口，此时不在将数据包向 C 和 D 发送，使得上下两部分网络分割开来，达到分割冲突域的目的，将四个机器形成的冲突域分割成两个由 2 台机器构成的冲突域，减少了冲突域中机器的数量，提升效率。\nHub 和交换机对比 集线器属于 OSI 的地一层物理层设备，而网桥属于 OSI 的第二层数据链路层设备 从工作方式看，集线器是一种广播模式，所有端口在一个冲突域里面。网桥则可以通过端口隔离冲突 Hub 是所有共享总线和共享带宽。网桥每个端口占一个带宽 路由器（router） 路由器工作在网络层\n为了实现路由，路由器需要做下列事情：\n分割广播域：广播数据发送到路由器后，不会被路由器转发到其他设备 选择路由表中到达目标最好的路径：查看路由表命令route -n 维护和检查路由信息 连接广域网 路由：把一个数据包从一个设备发送到不同网络里的另一个设备上去。这些工作依靠路由器来完成。路由器只关心网络的状态和决定网络中的最佳路径。路由的实现依靠路由器中的路由表来完成。\n由路由器隔开的两个网络称为两个网段。因此说路由器是广域网设备，而交换机是局域网设备。局域网通信是基于广播机制，而广域网通信是基于单播机制（点对点模式）。\n路由器可以与两个不同网段进行通讯，是因为路由器实现了“网关”的功能。\n网关（Gateway）：又称网间连接器，协议转换器。网关在网络层以上实现网络互联，是复杂的网络互联设备，仅用于两个高层协议不同的网络互联。网关既可以用于广域网互连，也可以用于局域网互连。网关是一种充当转换重任的计算机系统或设。使用在不同的通信协议，数据格式或语言，甚至体系结构完全不同的两种系统之间，网关是一个翻译器。与网桥只是简单地传达信息不同，网关对收到的信息要重新打包，以适应目的系统的需求 网关的结构和路由器类似，不同的是互连层。路由器中一般包含多个网关。每个网关可以与同在同一网段的机器进行通讯。\n由于历史原因，许多有关 TCP/IP 的文献曾经把网络层使用的路由器称为网关，在今天很多局域网采用都是路由来接入网络，因此通常指的网关就是路由器的 IP。\n网段数量=2^可变网络 ID 位数\n判断两个 IP 是否在同一网段，即判断俩个 IP 的网络 ID 是否相同\n网络 ID=IP 地址\u0026子网掩码\n示例\nIP 地址为 192.168.1.100，子网掩码为 255.255.255.0，则网络 ID 为\nIP: 11000000 10101000 00000001 01100100 netmask: 11111111 11111111 11111111 00000000 网络 ID: 11000000 10101000 00000001 00000000 即 : 192 168 1 0 判断 172.20.222.123/20 和 172.20.230.100/20 是否在同一网段\n172.20.222.123/20 IP: 10101100 00010100 11011110 01111011 netmask: 11111111 11111111 11110000 00000000 netID: 10101100 00010100 11010000 00000000 即: 172 20 208 0 172.20.230.100/20 IP: 10101100 00010100 11100110 01100100 netmask: 11111111 11111111 11110000 00000000 netID: 10101100 00010100 11100000 00000000 即: 172 20 224 0 网络 ID 不同，因此不在同一网段 判断 192.168.1.100/16 和 192.168.2.100/24 是否在一个网段\n1. A 与 B 通讯，A 使用自己的子网掩码和 B 的 IP 得到 B 的 netID 与 A 的 netID 进行比较 A netID: 192.168.0.0 B IP: 192.168.2.100 A netmask: 255.255.0.0 B netID: 192.168.0.0 在同一网段 2. B 与 A 通讯，B 使用自己的子网掩码和 A 的 IP 得到 A 的 netID 与 B 的 netID 进行比较 B netID: 192.168.2.0 A IP: 192.168.1.100 B netmask: 255.255.255.0 A netID: 192.168.1.0 不在同一网段 VLAN（虚拟局域网） 三层楼，每层都有一个交换机，负责把同层的办公电脑连接起来。同时没一层都有销售部，人事部，工程部的员工。希望各部门只能内部访问，不能访问其他部门的主机。此时即用到 VLAN 技术（Virtual Local Area Network），虚拟局域网。\n可将两个 VLAN 的网络，连接到一个路由器上，然后通过路由器进行网络安全策略的设置。同时，如果有多个 VLAN 网络，使用该方法，则每一个 VLAN 网络均会占用一个接口，比较浪费接口。因此，可以使用 trunk 的方式进行连接。\n使用 trunk 进行广播数据包传输时，会修改数据包，在数据包中添加 VLAN 的信息，使得接收方的交换机可以知道该数据包是发送给哪个 VLAN 网络的。而通过 trunk 进行通讯的协议包括 ISL（思科内部使用），802.1Q（IEEE 国际标准）\nVLAN 网络间的通讯，需要使用路由进行连接，如果是单个交换机中进行的 vlan 划分，则只需要一根 trunk 线进行连接即可。此时，VLAN10 与 VLAN20 计算机间的通讯，需要经过 router 进行转发，而 VLAN10 或 VLAN20 内部计算机间的通讯不需要经过 router。\n多交换机进行 VLAN 划分\n分层的网络结构 从搭建网络角度划分\n访问层/接入层：普通的计算机接入到普通的交换机上 分布层：普通交换机间使用路由器进行连接，达到隔离广播域，安全控制等功能 核心层：实现快速转发。当某一服务器需要被许多客户机访问时，如果将其接入在普通交换机下，会受普通交换机的性能限制，使得访问速度慢，因此将该服务器接入在高级交换机上，达到对请求的快速转发的目的。 TCP/IP 协议栈 Transmission Control Protocol/Internet Protocol，传输控制协议/因特网互联协议\nTCP/IP 协议是一个 Protocol Stack，包括 TCP、IP、UDP、ICMP、RIP、TELNET、FTP、SMTP、ARP 等许多协议。\n最早发源于美国国防部（缩写 DoD）的因特网的前身 ARPA 网项目，1983 年 1 月 1 日，TCP/IP 取代了旧的网络控制协议 NCP，成为今天互联网和局域网的基石和标准，由互联网工程任务组负责维护\n共定义了 4 层，和 ISO 参考模型的分层有对应关系\nTCP/IP 协议栈分成与 OSI 参考模型对应关系 常见网络协议与对应分层 linux 查看所有协议命令：cat /etc/services\nApplication 应用层\n常见协议：http、https、ftp、nfs、dns、tftp、smtp、pop3、imap、telnet、ssh、QQ\nTransport 传输层\n常见协议：TCP、UDP\n使用 Application 层协议对应的端口号标记上层协议类型\nInternet 网络层\n常见协议：IP\n可靠性 vs 高效性\nReliable（可靠） Best-Effort（高效） Connection Type Connection-oriented Connectionless Protocol TCP（传输控制协议） UDP（用户数据包协议） Sequencing Yes（数据包有序） No（数据包无序） Uses E-mail、File sharing、Downloading Voice streaming、Video streaming TCP 协议 TCP 特性 工作在传输层 面向连接：需要提前与发送方建立连接 全双工 半关闭：可以仅单向发送数据 错误检查 将数据打包成段，排序 确认机制：接收方是否成功接收到数据，需要通知发送方 数据恢复，重传 流量控制，滑动窗口 拥塞控制，慢启动和拥塞避免算法 TCP 包头 源端口和目的端口：计算机上的进程要和其他进程通信是要通过计算机端口的，而一个计算机端口某个时刻只能被一个进程占用，所以通过指定源端口和目标端口，就可以知道是哪两个进程需要通信。其中源端口和目的端口各使用 16bit 表示的，可推算计算机的端口个数为 2^16=65536 个。 序号：表示本报文段所发送数据的第一个字节的编号。在 TCP 连接中所传送的字节流的每一个字节都会按顺序编号。由于序列号由 32bit 表示，所以没 2^32=4294967296 个字节，就会出现序号回绕，再次从 0 开始。 确认号：表示接收方期望收到发送方下一个报文段的第一个字节数据的序号。 数据偏移：表示 TCP 报文段的首部长度，共 4bit。由于 TCP 首部包含一个长度可变的选项部分，需要指定这个 TCP 报文段到底有多长。他指出 TCP 报文段的数据起始处距离 TCP 报文段的起始处有多远。该字段的单位是 32bit（4Byte），4bit 最大表示 15，多亿数据偏移也就是 TCP 首部最大值为 60Byte。 URG：紧急位。表示本报文段中是否包含紧急数据。后面的紧急指针字段只有当 URG=1 时才有效 ACK：确认位。表示前面的确认号是否有效。只有当 ACK=1 时，前面的确认才有效。TCP 规定，连接建立后，ACK 必须为 1，带 ACK 标志的 TCP 报文段称为确认报文段 PSH：推位。提示接收端应用程序应立即从 TCP 接收缓冲区中读走数据，为接收后续数据腾出空间。如果为 1，则表示对方应当立即把数据题交给上层应用，而不是缓存起来，如果应用程序不将接受到的数据读走，就会一直停留在 TCP 接收缓冲区中。 RST：复位标志。如果接收到 RST=1 的报文，说明上次发送给主机的数据有问题，主机拒绝响应 SYN：同步位。在建立连接时使用，用来同步序号。当 SYN=1，ACK=0 时，表示这是一个请求建立连接的报文段；当 SYN=1，ACK=1 时，表示对方同意建立连接。SYN=1，说明这是一个请求建立连接或同意建立连接的报文。只有在前两次握手中 SYN 才置为 1，带 SYN 标志的 TCP 报文段称为同步报文段 FIN：结束位。表示通知对方本端要关闭连接了，标记数据是否发送完毕。如果 FIN=1，即告诉对方：“数据已经发送完毕，你可以释放连接了”，带 FIN 标志的 TCP 报文段称为结束报文段 TCP 协议端口 PORT 传输层通过 port 号，确定应用层协议。\nIANA：互联网数字分陪机构（负责域名，数字资源，协议分配）\n0-1023：系统端口或特权端口（仅管理员可用），众所周知，永久的分配给固定的应用使用。例如：22/tcp（ssh）、80/tcp（http）、443/tcp（https）、21/tcp（ftp）、23/tcp（telnet）、53/tcp/udp（dns）、69/tcp（tftp）、161/udp（snmp）、25/（smtp）、110/（pop3）、142/（imap） 1024-49151：用户端口或注册端口，但要求并不严格，分配给程序注册为某应用使用。例如：1433/tcp（SqlServer）、1521/tcp（oracle）、3306/tcp（mysql）、11211/tcp/udp（memcached） 49152-65535：动态端口或私有端口，客户端程序随机使用的端口 自定义随机端口号范围：vim /proc/sys/net/ipv4/ip_local_port_range TCP 三次握手 A 机器发出一个数据包并将 SYN 置为 1，表示希望建立连接。这个包中的序列号假设是 x B 机器收到 A 机器发过来的数据包后，通过 SYN 得知这是一个建立连接的请求，于是发送一个响应包并将 SYN 和 ACK 标记都置为 1。假设这个包中的序列号是 y，而确认序号必须是 x+1，表示收到了 A 发过来的 SYN。 A 收到 B 的响应包后需进行确认，确认包中将 ACK 置为 1，并将确认序号设置为 y+1，表示收到了来自 B 的 SYN。 三次握手确认的信息\nhttps://edu.aliyun.com/lesson_1358_11677#_11677 IEEE 802.3（以太网协议） IEEE 802.a 802.b 802.n 802.ac（无线网协议） 物理层及数据链路层 802.11\n查看网卡属性 mii-tool -v eth0或``ethtool eth0`\n网卡工作在物理层和数据链路层\n双绞线：物理层 wifi（802.11）、ppoe、ppp、ethernet、switch：数据链路层\n","description":"","tags":["Linux"],"title":"进阶-TCP/IP 协议及 OSI 七层模型","uri":"/posts/linux/%E9%98%BF%E9%87%8C%E4%BA%91linux%E8%BF%90%E7%BB%B4%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/%E9%98%B6%E6%AE%B5%E4%BA%8C-%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/linux-tcp-ip-osi/"},{"categories":null,"content":"https://www.virtualbox.org/wiki/Advanced_Networking_Linux\n","description":"","tags":["VirtualBox","Linux"],"title":"Linux 上安装 VirtualBox 的网络设置","uri":"/posts/virtualbox/linux-virtual-box-network/"},{"categories":null,"content":"计算机网络基础 计算机网络概述 计算机网络概念 计算机网络： 是指自主计算机的互连集合\n自主计算机：指分布在不同地理位置的多台独立的主机 互连：指使用通信介质和网络设备将计算机互相连接起来，遵循共同的网络协议，实现通信。 计算机网络是网络硬件和网络协议的统一体\n计算机网络组成结构 通讯终端（主机或服务器等） 通信介质（网线等） 交换设备（路由器和交换机等） ISP：Internet Service Provider，互联网服务提供商 使用通信介质将通讯设备和交换设备连接起来，达到互连的效果\n网络交换技术 电路交换 是面向连接的\n是目前电话通讯中使用的核心交换技术\n示例\nA 和 B 通话经过 4 个交换机 通话在 A 到 B 的已建立的连接上进行 特点\n面向连接的特性 通信资源的独占性 不适合计算机网络通信，因为计算机网络通讯具有突发性和灵活性的特点\n报文交换 基于存储转发原理\n发送方将发送的报文发送给报文交换机，报文交换机收到报文后会暂时存储下来，然后根据报文中的目的地地址信息转发给下一个报文交换机，最终发送接收方。\n特点\n报文交换不需要事先建立连接，可以直接发送数据，比较灵活 每个报文分段占用线路 缺点\n时延要比电路交换大 要完整地接收传来的整个报文，因此要求交换机有较大缓冲区 分组交换 也使用存储转发技术，把较长的报文划分成较短的“分组”，以“分组”为数据传输单元。\n示例\n计算机 A 将报文分组后（A1、A2、A3），通过分组交换机（R1、R2、R3、R4）发送给计算机 E。\n特点\n分组分段地占用通信链路，通信资源利用率高 每个分组独立传输，灵活性好，网络适应能力强 分组交换技术适合计算机网络\n三种交换技术的比较 电路交换：需要提前建立连接，然后把整个数据包进行传输 报文交换：使用存储转发技术，不需要提前建立连接，将整个报文进行传输 分组交换：使用存储转发技术，将整个报文分组后进行传输 实现分组交换的两种方式 数据报方式\n每个数据的分组都有独立的信息，所以 A1，A2 可以通过 R1 → R2 链路来传输，A3 可以通过 R1 → R3 → R2 链路来传输；发送方 A 不需要提前和接收方 E 建立连接。\n虚电路方式\nA 与 E 通讯时，需要事先呼叫 E，建立一个通讯的链路（虚电路），每个分组都包含一个虚电路号，通过预留的链路进行传输。\n网络拓扑结构 星型拓扑 由一个中心节点和一些外围节点组成 缺点：中心节点如果故障，则整个网络无法正常工作 环型拓扑 节点分布在一个闭合环形线路上，数据沿一个方哪个向绕环逐点传递 缺点：可靠性差，只要一个节点故障，就会影响整个网络的运行 总线型拓扑 一条公共线路作为传输总线，每个节点连接到公共总线上 缺点：存在总线争用问题，节点增多时网络效率低 树型拓扑 形状像一棵倒置的树，节点按层次进行连接 缺点：网络可靠性差，一旦根节点故障，则整个网络瘫痪 网状型拓扑 每两个节点之间都有一条线路相连，应用于广域网 缺点：控制复杂 小结 计算机网络概念 网络交换技术：电路交换，报文交换，分组交换 网络拓扑结构：星型，环型，总线型，树形，网状型 数据通信技术基础 信息，数据，信号 信息发送前要编码成数据，数据要用信号表示才能发送到对方。 对方从信号中还原出数据，进而得到信息。 信号 模拟信号：是连续的，取遍某个区间内的所有值。 数字信号：是离散的，只包含几个值，如 0，1。 信号编码方式：数据 → 信号 数据 → 模拟信号 需要传输的数据为101101，为了使用这些数据能够适应信道的传输，可通过幅移键控或频移键控或相移键控三种方法把它转换成可以在信道中传输的模拟信号。\n数据 → 数字信号 需要传输的数据为10001101，为了使用这些数据能够适应信道的传输，可通过不归零编码或曼彻斯特编码或差分曼彻斯特编码三种方法把数据转换成可以在信道中传输的数字信号。\n不归零编码\n高电压代表数据 1，低电压代表数字 0 曼彻斯特编码\n在每一个传输周期之间都有信号的跳变，由低电位调变为高电位代表 1，由高电位跳变为低电位代表 0 差分曼彻斯特编码\n在每一个传输周期之间的前半个传输码源如果和后半个传输码源一致，代表 1，否则代表 0。 数据传输方式分类 分类方式一：并行传输和串行传输 并行传输：是指在两点之间的适当数量的并行路径上，一组信号元的同时传输。 串行传输：是指信号元在两点之间的单一路径上的顺序传输。 分类方式二：单工，半双工，全双工 单工传输：信息只能由一方 A 传到另一方 B 半双工传输：信息既可由 A 传到 B，又能由 B 传到 A，但同时只能有一个方向上的传输存在 全双工传输：线路上同时存在 A 到 B 和 B 到 A 的双向信号传输 小结 信号：模拟信号，数字信号 信号编码方式： 模拟信号：ASK，FSK，PSK 数字信号：非归零码，曼彻斯特编码，差分曼彻斯特编码 数据传输方式 并行传输，串行传输 单工，半双工，全双工 双绞线的制作 传输介质 分为有线介质和无线介质两种\n有线介质：\n双绞线：是由两条相互绝缘的导线按照一定的密度相互缠绕在一起而制作成的一种通用配线。局域网中所使用的双绞线分为两类：屏蔽双绞线（STP）与非屏蔽双绞线（UTP） 同轴电缆\n光纤\n无线介质：\n无线介质 双绞线和 RJ-45 接口 RJ-45 接口：是一种能沿固定方向插入并自动防止脱落的塑料街头\n每条双绞线的两端，按照一定的线序标准（T568A 标准或 T568B 标准），连接好水晶头后，便可连接网卡，集线器，交换机等设备上的 RJ-45 接口。\nT568A 和 T568B 标准 是 RJ-45 接头的打线标准\n正线：T568B--T568B，平时使用的网线 反线：T568B--T568A，用来连接相同类的设备 T568B 线序：白橙 橙 白绿 蓝 白蓝 绿 白棕 棕 T568A 线序：是将 T568B 的 1，3 进行对调，2，6 进行对调。 网线制作：\n使用网线夹取出最外层绝缘体剥离 2cm 左右 按线序将内部的线排列整齐，让相邻网线间没有空隙 使用网线钳将线掐断，掐齐 水晶头卡簧向下，将网线插入到水晶头，尽量往里，确保线序没有被改变，外部绝缘皮也要进入一部分 使用网线钳将水晶头加紧 使用网线测试仪进行测试 网络体系结构 相互连通的两个计算机系统必须高度协调工作才行，而这种“协调”是相当复杂的 -“分层”可将庞大而复杂的问题，转化为若干较小的局部问题，而这些较小的局部问题就比较易于研究和处理\n计算机网络的体系结构是计算机网络的各层及其协议的集合 OSI 参考模型 OSI 参考模型： 理论模型\nTCP/IP 参考模型： 因特网标准，OSI 参考模型的一种实现\nOSI 参考模型定义网络通信的层次结构，层次之间的相互关系与各层提供的服务 只要遵循 OSI 标准，一个系统就可以和位于世界上任何地方的，也遵循这一标准的其他任何系统进行通信 OSI 参考模型-分层原则 网中各节点都具有相同的层次 不同节点的同等层具有相同的功能 同一节点内相邻层之间通过接口通信 每层可以使用下层提供的服务，冰箱上层提供服务 不同节点的对等层通过协议来实现对等层次之间的通信 OSI 参考模型-层次结构 物理层（physical layer）：利用传输介质实现比特序列的传输 数据链路层（data link layer）：采用差错控制与流量控制方法，使得有差错的物理线路变成无差错的数据链路 网络层（network layer）：实现路由选择，分组转发与拥阻控制等功能，为“分组”传输选择“最佳”的路由 运输层（transport layer）：向高层用户提供可靠的“端-端”通信服务，向高层屏蔽下层数据通信的具体细节 会话层（session layer）：维护两个通信计算机之间的进程通信，管理数据交换 表示层（presentation layer）：处理两个通信的计算机系统的数据表示方式，完成数据的格式变换，加密与解密，压缩与恢复 应用层（application layer）：为应用软件提供多种网络服务，例如万维网，文件传输，电子邮件与其他服务等 执行流程\n主机 A 与主机 B 要实现通信，两台机器都遵循 OSI 参考模型，首先，数据由主机 A 的应用进程产生，然后依次向下层处理，每层都在数据前添加一个具有该层特点的首部，最终数据传输到物理层后，将数据转换成可以在网络中传输的信号（比特序列），通过传输介质将这些比特序列传输到接收方主机 B 的物理层，然后依次向高层处理，将具有每层特点的首部去掉，最终获取到真实的数据。\n由高层至低层添加首部的过程称为封装，由低层至高层去除首部的过程称为解封装。\n小结 网络体系结构 OSI TCP/IP OSI 参考模型 应用层，表示层，会话层，运输层 网络层，数据链路层，物理层 OSI 参考模型与 TCP/IP 参考模型比较 TCP/IP 参考模型是基于 Internet 通讯的需求，在此基础上实现了一些具体的协议，在此基础上完善基础的通讯标准\n网络接口层：负责通过网络发送和接收 IP 数据报 互联网层：使用 IP 协议提供“尽力而为（best effort）”网络分组传输服务。将运输层报文段封装成 IP 数据报，选择适当的发送路径，并将数据报发送到下一个结点。 运输层：负责在会话的进程之间建立和维护“端-端”的连接。定义了两种不同的协议：传输控制协议（TCP）和用户数据报协议（UDP）。 应用层：为应用软件提供多种网络服务，通过具体的网络协议（例：HTTP，FTP 等）进行正常的网络传输。 TCP/IP 技术栈 总结 两种参考模型的比较 TCP/IP 参考模型 应用层，运输层，互联网层，网络接口层 TCP/IP 协议栈 局域网技术 局域网概念 根据网络规模分类 广域网\n覆盖范围大，传输距离远，传输率低，误码率高\n城域网\n覆盖范围介于局域网和广域网之间，几公里到几十公里\n局域网\n局部区域范围内的计算机网络 范围：几米至及公里，一个或相邻的建筑物内 特点：覆盖范围小，传输速率高，误码率低 应用：多用于单位内部网络建设 局域网常用拓扑结构 局域网中常见的拓扑结构有以下三种：\n总线型（使用最多） 星型 环型 局域网体系结构 局域网是一种通信网络，只涉及 OSI 模型中的数据链路层和物理层，不涉及高层内容\nIEEE 的 802 委员会将局域网分为两个子层：\nMAC 子层：与计入到传输媒体有关的内容都放在 MAC 子层。主要用来解决多个节点如何使用共享介质的问题 LLC 子层：与媒体接入无关的部分都集中在 LLC。其主要功能是数据链路的建立和释放，LLC 帧的封装和拆卸，差错控制，提供与高层的接口等 物理地址 在局域网中，硬件地址又称为物理地址，或 MAC 地址，是在数据链路层使用的地址。MAC 地址共 48 比特，6 字节。前三个字节代表的是生产厂商编号，后三个字节代表的是网卡的编号\nMAC 地址通常表示为 12 个 16 进制数，每两个 16 进制数之间用冒号隔开，08:00:20:0A:8C:6D 就是一个 MAC 地址\n物理地址的使用 数据链路层中数据是以数据帧（frame）为单位进行传输的。封装成帧就是在一段数据的前后分别添加首部和尾部，然后就构成了一个帧，确定了帧的界限。\n数据帧首部中的源地址和目的地址就是用 MAC 地址来表示的\n发送数据帧时，帧首部写入目的主机的 MAC 地址\n收到数据帧后，首先检查帧首部的目的 MAC 地址，如果是发给自己的，就接收数据帧，否则就丢弃\nCSMA/CD 协议 目前局域网采用的最通用的通信协议标准是以太网（Ethernet）技术\n最初的以太网是一个总线型的网络，任何一个主机发出信号，都能被所有主机收到\n以太网需要解决如下问题：\n寻址问题：如何在广播式的网络完成一对一通信（解决方式为：MAC 地址） 冲突问题：两台主机同时使用网络会发生冲突（解决方式为：CSMA/CD 协议） 以太网使用载波监听多路访问/冲突检测协议（CSMA/CD）来解决总线使用权的问题，处理网络中产生的冲突问题\n多路访问：网络中的每个节点都能访问总线，通过总线发送数据 载波侦听：在发送数据前，节点要先“听”一下总线上是否有数据信号。如果检测到有数据信号，节点便等待直到总线空闲。如果“听”到总线没有数据信号，那么节点就将数据帧发送处去。 冲突检测：在发送数据帧的同时，还需要继续监听总线，检测是否发生冲突。如果检测到了冲突，就马上停止数据发送。等待一个随机的时间后，再次重发。 为什么需要“冲突检测”\n当某个站监听到总线是空闲时，也可能总线并非真正的空闲\nA 向 B 发出的信息，要经过一定的时间后才能传送到 B\nB 若在 A 发送的信息到达 B 之前发送自己的帧（因为这时 B 的载波监听检测不到 A 所发送的消息），则必然要在某个时间和 A 发送的帧发生碰撞\n冲突带来的问题\n碰撞的结果是两个帧都变得无用（冲突使信号相互叠加，使得原来的信号被破坏），而且这些无用的数据浪费了网络资源\n节点在检测到冲突的时候，就马上停止数据发送。但是之前已经发出的数据还是会被接收方接收到，而且是不完整的数据。所以接收方需要知道是否曾经发生冲突，收到的数据是否完整\n争用期（解决不完整数据问题）\n从开始发送数据，到检测到冲突，这段时间是不确定的，它的最大值称为争用期。如果在争用期内没有检测到冲突，以后也不会有冲突产生了。\n在以太网中，争用期=2 倍总线长度/信号的传播速度\n最短帧长（解决不完整数据问题）\n以太网取 51.2μs 为争用期的长度。对于 10Mb/s 以太网，在争用期内可以发送 512bit，即 64 字节。以太网在发送数据时，若前 64 字节没有发生冲突，则后续的数据就不会发生冲突。（10Mb/s*51.2μs=512bit）\n以太网规定了最短有效帧长为 64 字节，凡长度小于 64 字节的帧都是由于冲突而异常中止的无效帧。\n小结 局域网概念 拓扑结构，体系结构 物理地址 MAC 地址 数据帧 CSMA/CD 协议 载波监听，多路访问，冲突检测 争用期，最短帧长 广域网技术 相距较远的局域网通过路由器与广域网相连组成了一个覆盖范围很广的互联网\n广域网实现的通信\n租用线路：是电信公司根据客户的需求建立的专用线路，例如 PPP 协议 电路交换：电信运营商的电话线，需要维护一个物理线路 分组交换：不依赖于永久性的依赖链路 广域网 PPP 协议 点对点协议（Point-to-Point Protocol），是因特网上广泛使用的数据链路层协议，用于点对点的链路\nPPP 设计目的主要是用来通过拨号或专线放哪个是建立点对点连接发送数据。用户使用拨号电话线接入因特网时，一般都是使用 PPP 协议（PPPOE）\nPPP 协议有三个组成部分\n一个将 IP 数据报封装到串行链路的方法 链路控制协议 LCP（Link Control Protocol） 网络控制协议 NCP（Network Control Protocol） PPP 协议的数据封装\n标志字段：表示帧的开始和结束，固定使用 01111110 地址字段：由于 PPP 协议用于点对点通信，不存在寻址的问题，固定使用 11111111 控制字段：PPP 协议不提供数据传输的可靠性，同时也没有流量控制和差错功能，固定使用 11000000 协议字段：PPP 帧内可以封装多个协议的数据包，当封装某个协议的数据包时，就填写这个协议的编号 FCS：帧校验字段，PPP 采用 CRC 校验 链路控制协议 LCP 数据链路的建立，配置，维护和终止都是有链路控制协议（LCP）来完成的，LCP 包封装在 PPP 帧的数据字段中\n认证协议 口令认证协议（PAP）： 非常简单，用户向系统发送用户名和口令，系统验证用户名和口令，如果正确就接受连接，否则就拒绝连接。认证是通过两次握手实现的。\n挑战握手协议（CHAP）： 对 PAP 协议做了改进，不直接发送用户名和密码。取代密码的是 Hash（哈希值）\n首先向用户发送一个 CHAP 包，数据部分包含一个随机数 用户收到后，使用事先定义好的函数作用于随机数和自己的口令，生成一个值，将这个值和用户名放入 CHAP 包发给系统 系统收到后，根据其中的用户名查到对应的口令，用同一个函数对查到的口令和查问值进行运算，如果计算结果与用户的值相同，说明是合法用户，并且口令正确。 网络控制协议 NCP PPP 使用网络控制协议（NCP）来建立两端网络层的连接，协商网络层的选项和传递网络层数据。NCP 不是一个协议，而是一组协议，包括 IPCP，IP，IPX 等。\n互联网协议控制协议（IPCP）主要用来协商网络层选项，设置用户的 IP 地址。报文在 PPP 帧中封装。\nPPP 协议工作过程 用户通过专用的呼叫设备与路由器对端建立物理链路的连接 使用 LCP 协议与对端建立数据链路的连接 通过 PAP 或 CHAP 协议进行认证 通过 IPCP 协议协议协商网络层参数和 IP 地址等信息 正式传输网络层的数据（可能使用 IP 协议） 数据传输结束后，通过 IPCP 协议终止网络层的活动 通过 LCP 协议终止数据链路层的连接 总结 广域网概念 广域网概念，广域网协议 广域网 PPP 协议 数据帧封装 链路控制协议 LCP 认证协议 网络控制协议 NCP 工作过程 交换机相关知识 如下图所示是具有 24 个 RJ-45 端口的交换机，它一般用于小型局域网\n交换机连接计算机示意图如下图所示\n例子：一个机房需要连接 50 台计算机，如果使用具有 24 个端口的交换机，则需要 3 台交换机连接计算机\n交换机工作原理 交换机是工作在 OSI 数据链路层的设备。它的主要功能是 MAC 地址学习，通信过滤（数据帧单点转发），避免回路等\n在每个交换机内部都维护有一张表（MAC 地址表），这个表记录了交换机上每个端口所连接主机的 MAC 地址信息\n交换机收到一个数据帧后，能够识别出这个帧的结构，根据帧的目的地址，将这个帧转发到对应的某个端口上去，而不是广播到其他所有端口。\n交换机 MAC 地址表 交换机具有 MAC 地址学习功能。交换机就是通过识别数据帧的源 MAC 地址，学习到 MAC 地址和源端口的对应关系，主要过程如下\n当第一次使用交换机时，交换机 MAC 地址表是空表，没有任何记录，此时交换机会将源 MAC 地址与源端口建立映射，并将其写入交换机的 MAC 地址表中 将数据帧（含有目标 MAC 地址）从所有其他端口转发出去 当接收者收到数据帧并返回信息时，交换机便记住对应的 MAC 地址与端口的映射，并将其对应关系写入到 MA 地址表中，以便下次的转发。 示例 PC1（MAC 地址为 M1）想要发送数据帧给 PC2（MAC 地址为 M2），其 MAC 地址学习过程如下：\n交换机收到 PC1 发来的数据帧，将其 MAC 地址和对应交换机端口号记录到 MAC 地址表中 搜索发现目的 MAC 不在当前地址表，所以会将数据帧从所有端口转发出去 PC3 和 PC4 发现数据包不是发送给自己的，就丢弃该数据帧。而 PC2 发现这个数据包是发送给自己的，就将自己的 MAC 地址发送给 PC1 该数据包到达交换机后，会将 PC2 的 MAC 地址和交换机的端口记录到 MAC 地址表中 以后进行数据发送，即可根据 MAC 地址表直接对数据帧进行转发 交换机数据交换方式 交换机监测发送到每个交换机端口的数据帧，通过数据帧中的有关信息（源主机的 MAC 地址，目的主机的 MAC 地址），在交换机内部建立一张 MAC 地址与端口映射表 交换机根据收到数据帧中的源 MAC 地址，首先查找 MAC 地址表，如果找到该映射项（对应的端口号），则更新映射的生存期；如果没有找到，则建立该地址同交换机端口的映射，并将其写入 MAC 地址表中 如果数据帧中的目的 MAC 地址在 MAC 地址表中找到，则判断该数据怎属于广播帧还是单播帧：如果是广播帧，则向所有端口（除接收该数据帧的端口外）转发该数据帧；如果是单播帧，则查找已有 MAC 地址表，根据 MAC 地址表中存在对应的映射，按照该映射项进行数据转发 如果数据帧中的目的 MAC 地址不在 MAC 地址表，则向所有端口转发。一旦收到接收者返回的信息，便记住该 MAC 地址与端口的映射，并将数据帧通过该端口转发出去 交换机总结 初识交换机设备 交换机工作原理 交换机 MAC 地址表 交换机数据交换方式 路由器相关知识 路由器工作在 OSI 参考模型的第三层（网络层），具有网络层功能，它连接不同的网络，在网络之间转发 IP 数据报\n路由器具有多个输入端口和多个输出端口。其任务是转发 IP 数据报（分组）。将路由器某个输入端口收到的分组，按照目的地，从路由器的某个输出端口转发给下一个路由器\n路由器的使用 连接两个不同的局域网，并且使局域网接入广域网\n目前家庭中，常使用路由器连接多台计算机同时接入 Internet\n路由器的分类 家用路由器 功能比较简单，价格便宜 支持拨号，内置 DHCP 服务器（可以为共享上网计算机动态分配地址），并可进行静态地址分配 模块化结构的路由器 通常中高端路由器采用模块化结构，底端路由器采用非模块化结构 可以在中小型企业网中担当核心路由器 路由器端口 主要分为三类：\n局域网端口：局域网接口主要用于路由器与局域网进行连接。RJ-45 接口是最常见的端口，即双绞线以太网端口 广域网端口：路由器要实现与广域网的连接。会用到同步串口（Serial），这种端口连接网络的两端，都需要实时同步。 配置端口： 路由器的配置端口有“Console”和“Aux”端口两种。 -“Console”端口常在本地配置路由器连接计算机时使用。使用 Console 线的一端连接路由器的 Console 端口，另一端连接计算机，用户可通过计算机运行终端仿真程序，在本地进行路由器配置 -“Aux”端口在路由器远程配置连接时使用 路由器工作原理 路由器的主要功能分为路由选择和分组转发\n分组转发将从端口收到的数据包根据目的地查找转发表从输出端口表送出去 路由选择根据相邻路由器之间通过路由协议实现相邻路由器的相互学习，生成路由表，路由选择需要一直维护和更新这张路由表，转发表就是从路由表转换而来的。 如果接收的数据包的分组是属于路由消息的，路由器就会将这个消息，放到路由选择处理器中，生成路由表\n如果接受到的数据包分组是本身 IP 协议传递的数据包，就按照分组转发的转发表中对应的信息，将数据包转发出去\n主机和路由器根据 IP 数据报的目的 IP 地址，通过查找路由表确定下一站\n路由表 路由表中记录了如何达到其他网络的信息\n每条路由表项主要由三部分组成：目的网络，子网掩码和下一站\n路由表是以目的网络号为目的地，而不是以目的主机的 IP 地址为目的地\n路由表记录的是到达下一站要如何传输，而不是传输的全部路径\n总结 初始路由器 路由器工作原理 路由表 配置 VLAN VLAN 基础知识 VLAN：虚拟局域网（Virtual Local Area Network）\nVLAN 是划分出来的逻辑网络，是二层网络 VLAN 端口不受物理位置的限制：可将交换机上的物理端口进行任意组合 VLAN 隔离广播域：不在同一 vlan 中的端口，不能互相访问 示例：\n使用 VLAN 技术，将交换机上的 1，2 两个端口划分到一个 vlan 中，将 3，4 两个端口划分到另一个 vlan 中。这时 1 口连接的 PC 机所发出的广播包，只能被 2 口所连的 PC 机接收，不能被 3 口，4 口所接收。\n交换机上配置 vlan 命令 交换机全局模式下：\nSwitch(config)# vlan 10 // 创建 vlan10：vlan vlan-id Switch(config)# exit Switch(config)# interface f0/1 // 进入 F0/1 物理端口 Switch(config)# switchport mode access // 设置当前端口模式为 access 模式 Switch(config)# switchport access vlan 10 // 将端口 F0/1 划分到 VLAN 10 中 Switch(config)# show vlan // 显示 vlan 信息 Switch(config)# Switch(config)# Switch(config)# Switch(config)# 示例：\n使用四根网线（正线）依次连接交换机的 F0/1，F0/2，F0/3，F0/4 端口，使用 console 线连接 PC 机的 com 口和交换机的 console 口，此时，使用该 PC 机通过超级终端登录到交换机即可设置 VLAN。\nSwitch\u003e enable // 进入特权模式 Switch# configure terminal // 进入全局模式 Enter conofiguration commands, one per line. End with CNTL/Z. Switch(config)# vlan 10 // 创建 10 号 vlan Switch(config-vlan)# exit // 退出到全局模式 Switch(config)# vlan 20 // 创建 20 号 vlan Switch(config-vlan)# exit // 退出到全局模式 Switch(config)# do show vlan // 显示 vlan 的配置 VLAN Name Status Ports ---- ------- ----------- ---------------- 10 VLAN0010 active 20 VLAN0020 active Swith(config)# int f0/1 // 进入到 f0/1 端口 Switch(config-if)# switchport mode access // 设置端口模式为 access Switch(config-if)# switchport access vlan 10 // 将 f0/1 端口划分到 vlan 10 Switch(config-if)# int f0/2 // 键入到 f0/2 端口 Switch(config-if)# switchport mode access // 设置端口模式为 access Switch(config-if)# switchport access vlan 10 // 将 f0/2 端口划分到 vlan 10 Switch(config-if)# exit // 退出 Switch(config) # int range f0/3-4 // 同时设置 f0/3，f0/4 Switch(config-if-range)# switchport mode access // 设置端口模式为 access Switch(config-if-range)# switchport access vlan 20 // 将 f0/3，f0/4 端口划分到 vlan 20 Switch(config-if-range)# exit // 退出 Switch(config)# do show vlan // 查看当前 vlan 信息 VLAN Name Status Ports ---- ------- ----------- ---------------- 10 VLAN0010 active Fa0/1，Fa0/2 20 VLAN0020 active Fa0/3，Fa0/4 设置 PC 机的 ip 地址为 192.168.10.1，网关为 192.168.10.254，子网掩码 255.255.255.0.\n设置另外三台机器的 IP 地址分别为 192.168.10.2，192.168.20.1，192.168.20.2.\n使用 ping 命令，分别测试与各个机器的连通性。\nVLAN 总结 VLAN 基础知识 交换机上配置 vlan 无线路由器配置 无线路由器是应用于用户上网，带有无线覆盖功能的路由器 无线路由器可以看作是一个转发器，将家中墙上接出的宽带网络信号通过天线抓转发给附近的无线网络设备 一般的无线路由器信号范围为半径 50 米 无线路由器一般只能支持 15-20 个设备同时在线使用 WAN 接口：Wide Area Network，广域网。就是 UPLink 到外部网络的接口 LAN 接口：Local Area Network，局域网。用来连接内部局域网有线设备 相关概念\nSSID：是无线网络的标志符，用来识别在特定无线网络上识别到的无线设备身份 信道：以无线信号作为传输媒体的数据信号传送通道。无线宽带路由器可在许多信道上运行。如 802.11g，802.11b 无线标准有 11 条信道，但只有 3 条是非重叠信道（信道 1，6，11）。 无线路由器的配置 网线连接 电话线入户\n使用一根网线连接 PC 机的网口和无线路由器的 LAN 口 外部接入的上行电路（此处为电话线），通过“猫”转接后，将网线接入到路由器的 WAN 口 专线入户\n使用一根网线连接 PC 机的网口和无线路由器的 LAN 口 直接将外部接入的上行电路网线接入到路由器的 WAN 口 设置路由器 管理 IP：192.168.1.1 默认用户名：admin 默认密码：admin\n浏览器输入管理 IP，根据设置向导设置即可。\n详细说明 QSS 安全设置\n默认是开启的，当有新的设备接入时，不需要设置密码，按以下路由器上的 QSS 功能按钮就可以接入了\n网络参数 → WAN 口设置\nWAN 口连接类型：自动检测 连接模式：选择自动连接即可，只要路由器给电，即自动完成对外网的连接 网络参数 → LAN 口设置\n当前局域网中的机器都会通过如下的设置来识别该路由器\nMAC 地址： IP 地址： 子网掩码： 无线设置 → 基本设置\nSSID 号：网络名 信道：自动 开启无线功能和 SSID 广播，方便其他设备查找到该网络\n无线设置 → 无线安全设置\n设置 PSK 密码\nDHCP 服务器 → DHCP 服务\n路由器要给当前局域网的设备提供 IP 地址，在该处设置地址池等。\n时区时间设置\nIP 地址 为了在通信时能够相互识别，接入 Internet 中的每一台主机都被分配有一个唯一的标识：32 位二进制地址，该地址称为 IP 地址\n一个 IP 地址可以唯一确定 IP 网络中的一个站点 每个 IP 地址是一个 32Bit（4Byte）的二进制数字 采用了点分十进制的写法 点分十进制 操作 值 机器中存放的 IP 地址是 32 位二进制代码 10000000100011111000100110010000 每隔 8 位插入一个空格，提高可读性 10000000 10001111 10001001 10010000 将 8 位二进制转换为十进制数 128 143 137 144 采用点分十进制法进一步提高可读性 128.143.137.144 IP 地址结构 IP 地址采用了层次结构的表达方式，每个 IP 地址分为两部分：\n网络号：代表主机或路由器所处的物理网络 主机号：代表所处物理网络中的编号 在相同的一个网段中，所有 IP 地址的网络号都相同，但所有 IP 地址的主机号必须不相同。\n网络号 主机号 192.168.1 1 192.168.1 2 192.168.1 ... 202.113.1 1 202.113.1 2 202.113.1 3 每个网络接口都有一个 IP 地址\n一个路由器的端口意味着它连接的是一个网段，路由器的不同端口连接着不通的网段，也就是网络号不一样。\nIP 地址分类 IP 地址类型 网络位 主机位 硬性规定 A 类 8 24 网络位最高位必须是 0 B 类 16 16 网络位最高两位必须是 10 C 类 24 8 网络位最高三位必须是 110 D，E 类不常用 - - - A 类地址 A 类 IP 地址的第 1 个字节表示网络 ID，后 3 个字节表示主机 ID 其中在网络 ID 的第 1 字节中，第一位为“0”。主机号代表在所处物理网络中的编号 B 类地址 B 类地址前 2 个字节表示网络 ID，后 2 个字节表示主机 ID 其中在网络 ID 的第一个字节的前 2 位设为“10”，接下来的 14 位（从第 3 到第 16 位结束）表示网络 ID C 类地址 C 类地址前 3 个字节表示网络 ID，后 1 个字节表示主机 ID 其中网络 ID 的第 1 个字节的前三位设位“110”，接下来的 21 位（从第 4 到第 24 位结束）表示网络 ID IP 地址的使用范围 网络类别 最大网络数 第一个可用的网络号 最后一个可用的网络号 每个网络中的最大主机数 A 126(2^7-2) 1 126 16777214 B 16383(2^14-1) 128.0 191.255 65534 C 2097151(2^21-1) 192.0.0 223.255.255 254 每个网络中的最大主机数 = 2^主机 ID 位数-2 = 2^(32-网络 ID 位数)-2\n子网掩码 记载 IP 地址的分类\n子网掩码是一个 32Bit 的数字，与 IP 地址是一一对应的，用来标识 IP 地址中哪些位是网络位，哪些位是主机位 子网掩码的格式同 IP 地址一样，由连续的“1”和连续的“0”组成。为了理解方便，也采用点分十进制表示 示例\nIP 地址为：192.168.3.1 子网掩码为：255.255.255.0 IP 地址：192.168.3.1 子网掩码：11111111 11111111 11111111 00000000\n子网掩码连续“1”的部分对应的 IP 地址的网络 ID 部分，连续“0”部分对应 IP 地址的主机 ID 部分 即网络 ID 是 192.168.3（网络地址是 192.168.3.0），主机 ID 是 1 无类别域间路由（CIDR） 无类别域间路由（Classless Inter-Domain Routing，CIDR）：是一个用于给用户分配 IP 地址以及在互联网上有效地路由 IP 数据包的对 IP 地址进行归类的方法。\n由 [IP 地址结构](#IP 地址结构) 可知，IP 地址由 32 位二进制组成，包含网络 ID 和主机 ID。在之前的分类网络中，IP 地址的分类把 32 位 IP 地址按每 8 位一段分开。使得网络 ID 只能为 8，16，24 位。由此造成可分配的最小地址块有 256 个地址（24 位网络 ID，8 位主机 ID），这对大多数企业来说太少了。大一点的地址块包含 65536 个地址(16 位网络位，16 位主机位)，这对大公司来说都太多了。这造成了 IP 地址数量与实际所需数量之间有较大差异。\n无类别域间路由是基于可变长子网掩码来进行任意长度的网络 ID 分配。并使用一个后缀说明网络 ID 的位数，例如 172.20.0.123/22，表示该 IP 包含 22 位网络位，因此可以计算出它的子网掩码为 11111111 11111111 11111100 00000000，即为 255.255.252.0\n练习：\n计算 200.222.123.23/26 的子网掩码（netmask）和最多主机数 子网掩码： 11111111 11111111 11111111 11000000 即： 255.255.255.192 最多主机数 由 CIDR 表示的 IP 地址可知，网络位占 26 字节，因此主机位占 32-26=6 字节，6 字节最大可以表示 2^6-2=62 个主机 IP 如果局域网中只有 2 台机器进行通讯，则将子网掩码设置为什么，最省 IP 资源。 由 每个网络中的最大主机数 = 2^主机 ID 位数-2 = 2^(32-网络 ID 位数)-2 可得： 2 = 2^主机 ID 位数 -2 可得 主机 ID 位数=2 则 网络 ID 位数=32-主机 ID 位数=30 则 子网掩码为 11111111 11111111 11111111 11111100 255 255 255 252 子网划分 从 1985 年起，在 IP 地址中又增加了一个“子网号字段”，使两级的 IP 地址变成为三级的 IP 地址。这种做法叫做子网划分\n基本概念：将原来属于主机位的比特“借”过来作为子网号\n划分子网纯属一个的单位内部的事情。单位对外仍然表现为没有划分子网的网络\n子网划分方法 子网的划分，实际上就是向 IP 地址中原来表示主机 ID 的 bit 位借位，作为子网 ID 需要重新确定子网掩码。就要确定向原来主机位借多少位，即子网掩码中有多少个“0”变为“1” 子网划分过程：\n确定借用多少位主机位：如果需要划分 m 个子网，假设需要借用 N 位主机位，那么两者应该满足 2^N-2 \\geq m 确定子网划分后的新的子网掩码 确定每个子网的网络地址（即每个网段的第一个地址）是什么 确定每个子网的广播地址（即每个网段的最后一个地址）是什么 确定每个子网中有效主机范围是什么 子网划分实例 一个 B 类的网络 128.1.0.0，要划分 6 个子网\n这里 m=6，根据 2^N-2\u003e=m，N 的最小值为 3 使用新的子网掩码标识借用 3 位 第一个子网：128.1.32.0 最后一个子网：128.1.192.0 第一个子网的第一个可用 IP 地址：128.1.32.1 第一个子网的最后一个可用 IP 地址：128.1.63.254 所有子网的信息 IP 网络号 IP 地址形式 子网掩码 最小 IP 地址 最大 IP 地址 128.1.32.0 10000000 00000001 001xxxxx xxxxxxxx 255.255.254.0 128.1.32.1 128.1.63.254 128.1.64.0 10000000 00000001 010xxxxx xxxxxxxx 255.255.224.0 128.1.64.1 128.1.95.254 128.1.96.0 10000000 00000001 011xxxxx xxxxxxxx 255.255.224.0 128.1.96.1 128.1.127.254 128.1.128.0 10000000 00000001 100xxxxx xxxxxxxx 255.255.224.0 128.1.128.1 128.1.159.254 128.1.160.0 10000000 00000001 101xxxxx xxxxxxxx 255.255.224.0 128.1.160.1 128.1.191.254 128.1.191.0 10000000 00000001 111xxxxx xxxxxxxx 255.255.224.0 128.1.223.254 总结 IP 子网 IP 子网划分方法 IP 子网划分举例 Internet 与万维网 Internet 概念 Internet 又称为互联网，采用 TCP/IP 协议，将各种不同类型，不同规模，不同地理位置的物理网络联接成一个整体的全球性的计算机网络\nInternet 应用\n万维网通讯 电子邮件 文件传输 即时通讯 电子商务 信息查询 远程登录 ... 万维网通讯 万维网（World Wide Web）：又称 WWW。是无数个网络站点和网页的集合，是由超级链接构成的信息网络。\n站点：连接到网络的终端设备，如 PC，服务器等 网页：即万维网文档，包含文本信息，图形，图像，声音，动画等 使用统一资源定位符（URL）来表示万维网上的“网页” 使用超文本标记语言（HTML）来编写“网页”，其文件扩展名通常是 *.html 或 *.htm 等（超文本文档） 超链接：是指从一个网页指向另一个网页 网页传输：Web 浏览器与 Web 服务器之间，使用超文本传输协议（HTTP）进行传输，实现超链接 URL：统一资源定位符，Web 中用 URL 作为标识网页及其他资源的全球地址。由以 “://” 隔开的两大部分组成，并且在 URL 中的字符对大小写没有要求 http://www.baidu.com Web 浏览器与 Web 服务器 超文本传输协议 HTTP Hypertext Transfer Protocol，是专门用于在 Web 浏览器和 Web 服务器之间传输超文本的。Web 浏览器浏览网页时，要向 Web 服务器发出访问请求，Web 服务器响应浏览器提交的访问请求后，向客户端传送网页信息。\n请求报文：从客户向服务器发送请求报文，通过 URL 指明所需文档的名字和位置 应答报文：从服务器到客户的应答报文，里面包含服务器的应答和浏览器所需的文档 持续连接：万维网服务器在发送响应后仍然在一段时间内保持这条连接，使同一个客户（浏览器）和该服务器可以继续在这条连接上传送后续的 HTTP 请求报文和响应报文（HTTP/1.1 协议） Web 代理\n服务器相关知识 服务器（Server）是指在网络中提供各种服务的计算机，承担网络中的数据存储，转发，发布任务，是网络应用的基础和核心。\n硬件方面：相对于普通 PC 机而言，服务器在稳定性，安全性，性能等方面都要求更高 软件方面：服务器一定是要运行一个能够管理资源并能够为多个用户提供服务的操作系统，即服务器操作系统，如 Windows 2008 Server，UNIX，Linux 等。 设备 塔式服务器 机架式服务器 刀片式服务器 操作系统 Windows\n目前较流行的是 Windows Server 2008\nUNIX\n能在所有级别计算机上运行的操作系统。主要支持大型的文件系统服务，数据服务等\nLinux\n具有完善的网络功能和较高的安全性\n常用网络服务 WWW 服务\nDNS 服务\n因特网上的每个主机都有一个 IP 地址，如 112.25.3.2。但 IP 地址不容易记忆 域名是用来标识因特网上主机的另一种方式，例如 “www.baidu.com” 如何为每个域名找到对应的 IP 域名系统（Domain Name System，DNS）提供这样的服务 进行域名和 IP 地址转换时，使用最多的是 DNS 正向查找。即，将域名转换成 IP 地址，然后再使用所查到的 IP 地址去访问目标服务器；如果是将 IP 地址转换成域名，则称为 DNS 反向查找 一个域名采用分层次的命名方式，由若干部分组成，各个部分之间用小数点间隔，最顶层的域名（baidu.com）在最右边，最底层域名在最左边，例如 www.baidu.com 将域名转换为对应的 IP 的过程称为域名解析，域名解析由域名服务器来完成。 FTP 服务\nFTP（File Transfer Protocol）是最常用的网络协议之一，主要功能是进行传输文件 FTP 提供交互式的访问，允许客户指明文件的类型与格式，并允许文件具有存储权限 FTP 也是基于 Client/Server 模式，客户端可以通过网络连接到 FTP 服务器，根据用户自己的权限进行上传或下载文件 FTP 服务器进程由两大部分组成:\n控制连接：专门用来传输控制信息，如用户标识，口令，用户命令等，负责接受新的连接请求 数据连接：主要用来传输目录文件列表，下载文件和上传文件，负责处理单个请求 电子邮件服务\n电子邮件把邮件发送到收件人使用的邮件服务器，并放在其中的收件人邮箱中（发送邮件的协议：SMTP） 收件人和可以随时上网到自己使用的邮件服务器进行读取 读取邮件的协议：POP3 和 IMAP DHCP 服务\n动态主机配置协议（Dynamic Host Configuration Protocol，DHCP）提供了一种简便的方式，能够自动地为网络中没有 IP 地址的主机分配 IP 地址，子网掩码等信息，不在需要手动进行配置 减少管理员的工作量 避免 IP 地址冲突问题 自动更新功能 工作原理 总结 服务器相关知识 常用网路服务 DNS 服务 FTP 服务 电子邮件服务 DHCP 服务 ","description":"","tags":["Linux"],"title":"计算机网络基础","uri":"/posts/linux/%E9%98%BF%E9%87%8C%E4%BA%91linux%E8%BF%90%E7%BB%B4%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/%E9%98%B6%E6%AE%B5%E4%BA%8C-%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/linux-computer-network-basic/"},{"categories":null,"content":"Linux 服务器运维基本操作 SSH 远程连接 SSH 为 Secure Shell 的缩写，是一种网络安全协议，转为远程登录会话和其他网络服务提供安全性的协议。通过使用 SSH，可以把传输的数据进行加密，有效防止远程管理过程中的信息泄露问题。\n从客户端来看，有两种验证方式\n基于密码 基于密钥 非对称加密\n有一对密钥：公钥和私钥\n公钥用来加密，私钥用来解密\n基于用户名密码验证 当客户端发起 ssh 请求，服务器会把自己的公钥发送给用户 用户会根据服务器发来的公钥对密码进行加密 加密后的信息回传给服务器，服务器用自己的私钥解密，如果密码正确，则用户登录成功 基于密钥验证 https://edu.aliyun.com/lesson_1718_14301#_14301\n挂载（mount）命令 在 Linux 系统中，挂载是指将一个设备（通常是存储设备）挂接到一个已存在的目录上。通过访问这个挂载目录来访问存储设备中的文件。\n命令格式：\n1 mount [-t vfstype] [-o options] device dir -t vfstype：指定文件系统类型，通常不必指定，mount 会自动选择正确的类型。\n常用类型有：\n光盘或光盘镜像：iso9660 DOS fat16 文件系统：msdos Windows 9x fat32 文件系统 Windows NT ntfs 文件系统：ntfs UNIX（Linux）文件网络共享：nfs -o options：主要用来描述设备的挂载方式。 常用类型有：\nloop：用来把一个文件当成硬盘分区挂接上系统 ro：采用只读方式挂接设备 rw：采用读写方式挂接设备 iocharset：指定访问文件系统所用的字符集 device：要挂接（mount）的设备\ndir：设备在系统上的挂载点（mount point）\n挂载光盘镜像文件 建立挂载点\n1 mkdir /mnt/vcdrom 挂载 iso 文件\n1 # mount -t iso9660 -o loop /path/to/iso/myiso.iso /mnt/vcdrom 其他相关命令：\n将当前光驱中的光盘制作成镜像文件\n1 2 3 # cp /dev/cdrom /path/to/output/ios/myiso.iso 或 # dd if=/dev/cdrom of=/path/to/ouput/iso/myios.ios 将文件和目录制作成光盘镜像文件\n1 # mkisofs -r -J -V myiso -o /path/to/output/iso/myiso.iso /path/to/input/ 上方命令将 /path/to/input/ 目录下的所有目录和文件制作成光盘镜像文件 /path/to/output/iso/myiso.iso，卷标为：myiso\n挂载移动硬盘/U 盘 对 Linux 系统而言，USB 接口的移动设备当作 SCSI 设备对待。\n插入移动硬盘之前，应先用 fdisk -l 或 more /proc/partitions 查看系统的硬盘和硬盘分区情况\n1 # fdisk -l 插入移动硬盘/U 盘后\n1 # fdisk -l 系统会多了一个 SCSI 硬盘 /dev/sdc 和磁盘分区 /dev/sdc1，/dev/sdc1 就是我们要挂载的 U 盘。可能为 /dev/sd 开头的任意设备\n创建挂载点\n1 # mkdir -p /mnt/usb 挂载设备\n1 # mount -t vfat /dev/sdc1 /mnt/usb 如果汉字文件名显示为乱码或不显示，可使用如下命令\n1 # mount -t vfat -o iocharset=cp936 /dev/sdc1 /mnt/usb 挂载 Windows 文件共享 Windows 网络共享的核心是 SMB/CIFS，在 linux 下要挂载 windows 的磁盘共享，就必须安装和使用 samba 软件包。如果未安装，可在 www.samba.org 下载。此处没有关于 Windows 设置共享的说明\n创建挂载点\n1 # mkdir -p /mnt/samba 挂载\n1 # mount -t smbfs -o username=administrator,password=1234 //192.168.1.105/c$ /mnt/samba administrator 和 1234 是 ip 地址为 192.168.1.105 的 Windows 计算机的一个用户名和密码，c$ 是这台计算机的一个磁盘共享。\n上方方法未进行测试，之前使用的挂载方式如下\n1 # mount -t cifs -o username=administractor,password=1234,uid=1001,gid=1001 //192.168.1.105/share /mnt/windows 将 192.168.1.105 机器上的共享文件夹 share 挂载到 /mnt/windows 目录下，其中 username，password 为 Windows 机器的一个用户名和密码，uid 和 gid 为 linux 上一个用户的 uid 和 gid，指定 uid 和 gid 可使当前挂载点所属者和所属组为指定用户，否则默认为 root 用户\n挂载 UNIX 系统 NFS 文件共享 Linux 服务端配置 在 Linux 客户端挂载 NFS 磁盘共享前，必须先配置好 NFS 服务端。\n服务端安装 nfs-utils 和 rpcbind\n1 2 3 4 5 // CentOS # yum install -y nfs-utils rpcbind // Ubuntu # apt install nfs-kernel-server 修改 etc/exports，添加共享目录\n1 2 3 /home/export/dir1 192.168.1.101(rw) /home/export/dir2 *(rw) /home/export/dir3 linux-client-hostname(rw) 此处 /home/export下的 dir1，dir2，dir3 为共享目录，192.168.1.101，*，linux-client-hostname 是被允许挂载此共享 linux 客户机的 IP 地址或主机名。如果要使用主机名 linux-client-hostname，必须在服务端主机 /etc/hosts 文件中添加 linux-client-hostname 主机 IP 定义。\n1 192.168.1.103 linux-client-hostname 启动 rpcbind 和 NFS 服务\n1 2 # systemctl start rpcbind # systemctl start nfs 或\n1 2 # /etc/rc.d/init.d/rpcbind start # /etc/rc.d/init.d/nfs start 如对 /etc/export 的配置进行了修改，使用如下命令重新加载配置\n1 # exportfs -rv 或\n1 2 # systemct restart rpcbind # systemctl restart nfs Linux 客户端配置 linux 客户端挂载其他类 Unix 系统的 NFS 共享，客户端安装 nfs 客户端\n1 2 3 4 // CentOS # yum install -y nfs-utils // Ubuntu # apt install nfs-common 在客户端（192.168.1.101）查看服务端（192.168.1.105）分享盘信息\n1 showmount -e 192.168.1.105 创建挂载点\n1 mkdir -p /mnt/nfs 挂载\n1 # mount -t nfs -o rw 192.168.1.105:/home/export/dir2 /mnt/nfs 此处挂载失败可以尝试\n1 # mount -t nfs -o rw -o v3 192.168.1.105:/home/export/dir2 /mnt/nfs 其他命令：\nrpcinfo -p localhost：查看 rpcbind 服务注册的端口列表 服务端其他参数 参数 说明 ro 只读访问 rw 读写访问 sync 所有数据在请求时写入共享 async nfs 在写入数据前可以响应请求 secure nfs 通过 1024 以下的安全 TCP/IP 端口发送 insecure nfs 通过 1024 以上的端口发送 wdelay 如果多个用户要写入 nfs 目录，则归组写入（默认） no_wdelay 如果多个用户要写入 nfs 目录，则立即写入，当使用 async 时，无需此设置 hide 在 nfs 共享目录中不共享其子目录 no_hide 共享 nfs 目录的子目录 subtree_check 如果共享 /usr/bin 之类的子目录时，强制 nfs 检查父目录的权限（默认） no_subtree_check 不检查父目录权限 all_squash 共享文件的 UID 和 GID 映射匿名用户 anonymous，适合公用目录 no_all_squash 保留共享文件的 UID 和 GID（默认） root_squash root 用户的所有请求映射成如 anonymous 用户一样的权限（默认） no_root_squash root 用户具有根目录的完全管理访问权限 anonuid=xxx 指定 nfs 服务器 /etc/passwd 文件中匿名用户的 UID anongid=xxx 指定 nfs 服务器 /etc/passwd 文件中匿名用户的 GID 取消挂载 1 # umount /mnt/nfs ","description":"","tags":["Linux"],"title":"Linux 服务器运维基本操作","uri":"/posts/linux/%E9%98%BF%E9%87%8C%E4%BA%91linux%E8%BF%90%E7%BB%B4%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/%E9%98%B6%E6%AE%B5%E4%B8%89-linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%90%E7%BB%B4/linux-server-basic-operate-and-maintenance/"},{"categories":null,"content":"linux 使用 vsftpd 搭建 FTP 服务器 测试使用的系统 Ubuntu18.4，CentOS7，vsftpd 版本 3.0.3, vsftpd-3.0.2 与其配置文件有差别，暂未测试\n安装 vsftpd CentOS\n1 $ sudo dnf install vsftpd Ubuntu\n1 $ sudo apt-get install vsftpd 配置 FTP 服务 vsftpd-3.0.3 的配置文件为 /etc/vsftpd.conf，该文件本身有详细的文档说明，所以这里只修改一些有用的配置，使你能快速的搭建起 FTP 服务。关于配置的详细信息可以使用 man 手册查看\n1 man vsftpd.conf 允许对 FTP 服务器的文件系统进行修改 将 write_enable 设置为 YES，来允许用户（匿名，本地，虚拟用户均可）可以对文件系统进行修改，包括删除/修改以及向 FTP 服务器上传文件等。\n1 write_enable=YES 允许本地用户登录 FTP 服务 允许 /etc/passwd 中的用户登录 ftp 服务\n1 local_enable=YES 允许匿名用户登录 1 2 3 4 5 6 7 8 # Allow anonymous login anonymous_enable=YES # No password is required for an anonymous login (Optional) no_anon_password=YES # Maximum transfer rate for an anonymous client in Bytes/second (Optional) anon_max_rate=30000 # Directory to be used for an anonymous login (Optional) anon_root=/example/directory/ Chroot Jail 为防止用户访问除其 home 目录外的文件夹，修改/添加如下属性\n1 2 chroot_list_enable=YES chroot_list_file=/etc/vsftpd.chroot_list ","description":"","tags":["Linux","FTP"],"title":"linux 使用 vsftpd 搭建 FTP 服务器","uri":"/posts/linux/linux-vsftpd/"},{"categories":null,"content":"PostgreSQL psql 的使用，SQL 语法，数据类型，递归 SQL 用法 PostgreSQL 交互工具的使用 psql 工具\npsql -h ip -p port -U username -d database\n两个比较有用的帮助，在 psql shell 中输入：\n\\?：可以得到 psql 的一些快捷命令 \\h command：查看某个 SQL 命令的帮助，例如 \\h create table 常用的快捷命令\n\\dt：输出当前搜索路径下的表 \\set VERBOSITY verbose：设置详细的打印输入，例如可以报出问题代码 PostgreSQL 数据类型介绍 查看数据库支持的所有数据类型，包括自定义类型：\\d pg_type 或 select * from pg_type;\n1 2 3 Table \"pg_catalog.pg_type\" Column | Type | Collation | Nullable | Default ----------------+--------------+-----------+----------+--------- ","description":"","tags":["PostgreSQL"],"title":"PostgreSQL psql 的使用，SQL 语法，数据类型，递归 SQL 用法","uri":"/posts/database/postgresql-introduction/"},{"categories":null,"content":"Java 中时间相关的类 部分时间系统 格林尼治标准时（GMT）/世界时（UT）：Greenwich Mean Time/Universal Time，以地球自转为基础的时间计量系统，指当太阳横穿格林尼治本初子午线时的时间，由于地球自转速度变化的影响，这个时刻可能和真太阳时相差 16 分钟。\n太阳时：太阳时是指以太阳日为标准来计算的时间。可以分为真太阳时和平（均）太阳时。\n真太阳时：以真太阳日为标准来计算的叫真太阳时，日晷所表示的时间就是真太阳时。 平太阳时（MT）：mean solar time，以平太阳日为标准来计算的叫平太阳时，钟表所表示的时间就是平太阳时。 原子时（IAT）：international atomic time，以物质的原子内部发射的电磁振荡频率为基准的时间计量系统。秒长定义为 铯-133 原子基态的两个超精细能级间在零磁场下跃迁辐射 9192631770 周所持续的时间。这是一种均匀的时间计量系统。初始历元规定为 1958 年 1 月 1 日世界时 0 时，但事后发现，在该瞬间原子时与世界时的时刻之差为 0.0039 秒，这一差值就作为历史事实而保留下来。\n协调世界时（UTC）：Universal Time Coordinated，原子时与地球自转没有直接联系，由于地球自转速度长期变慢的趋势，原子时与世界时的差异将逐渐变大。为了保证时间与季节的协调一致，便于日常使用，建立了以原子时秒长为计量单位，在时刻上与\"平均太阳时\"之差小于 0.9 秒的时间系统，称为世界协调时。\n在不需要精确到秒的情况下，通常将 GMT 和 UTC 视作等同\nJava 中时间相关的类 epoch：时代，代表 1970-01-01 00:00:00\njava.util.Date 构造方法\npublic Date(){}\n1 2 3 4 public Date() { // `System.currentTimeMillis()`：返回将当前系统时间转为 UTC 时间后距离 1970-01-01 00:00:00 的毫秒数，均按 UTC 时间计算 this(System.currentTimeMillis()); } public Date(long date)\n1 2 3 public Date(long date) { fastTime = date; } Date 类中保存的是以 UTC 时间计算距离 epoch 的毫秒数，该毫秒数是按 UTC 时间系统计算的，是时区无关的。他的 zoneid 属性保存了时区信息，就是当前系统的时区，不能直接改变。\n常用方法\npublic static Date from(Instant instant) {}：将 Instant 对象转为 Date 对象 public Instant toInstant() {}：将 Date 对象转为 Instance 对象 public long getTime() {}：获取当前时间距离 epoch 的 UTC 毫秒数 public boolean equals/before/after(Date when) {}：时间比较 java.util.Calendar 日历类，注意 Month 是从 0 开始\n获取实例方法\npublic static Calendar getInstance(){}：其中时区和地区信息均是系统默认的 public static Calendar getInstance(TimeZone zone){}：指定时区，地区信息是系统默认 public static Calendar getInstance(Locale aLocale){}：指定地区，时区信息是系统默认 public static Calendar getInstance(TimeZone zone, Locale aLocale){}：指定时区和地区 其他常用方法\npublic long getTimeInMillis() {}：获取当前时间距离 epoch 的 UTC 毫秒数 public void setTimeInMillis(long millis) {}：使用 UTC 毫秒数修改时间 public void set(int field, int value) {}：为指定字段设置值，field 可使用Calendar.属性方式传入 public int get(int field) {}：获取去某一字段的值，field 可使用Calendar.属性方式传入 public final void setTime(Date date) {}：使用 Date 类型对象设置时间 public void setTimeZone(TimeZone value) {}：设置时区 public final Instant toInstant() {}：转换为 Instant 类型对象 public final void set(int year, int month, int date, int hourOfDay, int minute, int second) {}：设置年月日时分秒的值 java.util.TimeZone 表示时区，通常 java.util.Date 和 java.util.Calendar 类会使用到\n获取系统默认时区对象\npublic static TimeZone getDefault() {} 其他方法\npublic static synchronized String[] getAvailableIDs() {}：获取所有受支持的时区 ID，主要包括两种格式：Asia/Shanghai和CST public static synchronized String[] getAvailableIDs(int rawOffset) {}：根据给定偏移量，获取受支持的时区 ID，偏移量为毫秒 public static synchronized TimeZone getTimeZone(String ID) {}：根据字符串类型的时区 ID 获取 TimeZone 类型对象，受支持的 ID 可使用前两个方法获取 public static TimeZone getTimeZone(ZoneId zoneId) {}：根据 ZoneId 类型的时区 ID 获取 TimeZone 类型对象，ZoneId 是 jdk1.8 之后才有的 java.text.SimpleDateFormat java.time.LocalDateTime 不包含任何时区信息\n方法\npublic static LocalDateTime now() {}：使用系统时钟和系统默认时区的当前时间 public static LocalDateTime parse(CharSequence text) {}：将字符串根据本地时间格式转换为 LocalDateTime 对象，该对象是不包含时区信息的 public static LocalDateTime parse(CharSequence text, DateTimeFormatter formatter) {}：按指定格式将字符串转为 LocalDateTime 对象，该对象是不包含时区信息的 java.time.LocalDate\njava.time.LocalTime\njava.time.Instant\njava.time.ZonedDateTime\n","description":"","tags":["Java"],"title":"Java 中时间相关的类","uri":"/posts/java/time-in-java/"},{"categories":null,"content":"Nginx 中 location 与 root，alias，proxy_pass 的使用 location 与 root root 后的文件路径是否有 / 效果是相同的，会将 location 后面的 xxx 拼接到 root 配置的路径后\n1 2 3 location /xxx/ { root /path/to/static; } 1 2 3 location /xxx/ { root /path/to/static/; } /xxx/index.html 均可以访问到 /path/to/static/xxx/index.html 资源\nlocation 与 alias 按如下方式配置，alias 配置的路径后必须包含 /，不会将 location 后面的 xxx 拼接到 alias 配置的路径后\n1 2 3 location /xxx/ { alias /path/to/static/; } 使用 /xxx/index.html 访问，可访问到 /path/to/static/index.html 文件\nlocation 与 proxy_pass 对 proxy_pass 的配置包含如下两种情况\nbackend 后面没有 /\n1 2 3 location /xxx/ { proxy_pass http://192.168.1.1:8080; } backend 后面有 /\n1 2 3 location /xxx/ { proxy_pass http://192.168.1.1:8080/; } 如果此时有一个请求为 Url 为 /xxx/endpoint\n第 1 种向 backend 发送的请求为 http://192.168.1.1:8080/xxx/endpoint，包含 location 中的配置 第 2 种向 backend 发送的请求为 http://192.168.1.1:8080/endpoint，不包含 location 中的配置 ","description":"","tags":["Nginx"],"title":"Nginx 中 location 与 root，alias，proxy_pass 的使用","uri":"/posts/nginx/nginx-location-root-alias-proxypass/"},{"categories":null,"content":"Spring JPA 自动生成主键，创建时间和更新时间 自定义的基本 DO 父类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 import org.hibernate.annotations.GenericGenerator; import org.springframework.data.annotation.CreatedDate; import org.springframework.data.annotation.LastModifiedDate; import org.springframework.data.jpa.domain.support.AuditingEntityListener; import javax.persistence.*; import java.io.Serializable; import java.util.Date; /** * 标识该类是一个父类 * 不需要映射数据表，但是该类中的属性会被子类继承，并映射为数据表的列中 * 不能在使用 @Entity 和 @Table 注解 */ @MappedSuperclass /** * 可标注在标注了 @Entity 或 @MappedSuperclass 的类上 * 指定实体或超类的监听类 * AuditingEntityListener：监听捕获实体类在持久化和更新时的审计信息 */ @EntityListeners(AuditingEntityListener.class) public class BaseDO implements Serializable { /** * 唯一 ID * @GenericGenerator：Hibernate 通用生成器，此处使用 uuid 策略 * @GeneratedValue：指定主键生成策略 */ @Id @Column(length = 32) @GenericGenerator(name = \"jpa-uuid\", strategy = \"uuid\") @GeneratedValue(generator = \"jpa-uuid\") private String id; /** * 创建时间 * @Temporal：只能标注在 java.util.Date 和 java.util.Calendar 类型的属性上，指定映射 Data 和 Calendar 的数据库字段类型 * @CreatedDate：声明该字段为一个创建日期字段 */ @Temporal(TemporalType.TIMESTAMP) @CreatedDate @Column(nullable = false) private Date createTime; /** * 更新时间 * @LastModifiedDate：声明该字段为一个更新日期字段 */ @Temporal(TemporalType.TIMESTAMP) @LastModifiedDate private Date updateTime; public String getId() { return id; } public BaseDO setId(String id) { this.id = id; return this; } public Date getCreateTime() { return createTime; } public BaseDO setCreateTime(Date createTime) { this.createTime = createTime; return this; } public Date getUpdateTime() { return updateTime; } public BaseDO setUpdateTime(Date updateTime) { this.updateTime = updateTime; return this; } } BaseDO 的子类 RegionDO\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import javax.persistence.Column; import javax.persistence.Entity; import javax.persistence.Table; @Entity @Table(name = \"tb_region\", schema = \"lincao\") public class RegionDO extends BaseDO { /** * 行政区划名称 */ @Column private String region; /** * 行政区划 ID, 12 位 */ @Column(length = 12) private String regionCode; public String getRegion() { return region; } public RegionDO setRegion(String region) { this.region = region; return this; } public String getRegionCode() { return regionCode; } public RegionDO setRegionCode(String regionCode) { this.regionCode = regionCode; return this; } } 在 Application.java 上添加 @EnableJpaAuditing 注解，启动 JPA 审核功能\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.data.jpa.repository.config.EnableJpaAuditing; @SpringBootApplication /** * 注解方式启动 JPA 审核功能 */ @EnableJpaAuditing public class Application { public static void main(String[] args) { // Spring 应用启动起来 SpringApplication.run(Application.class, args); } }d Repository(DAO)层\n1 2 3 4 5 6 7 8 import icu.intelli.dataobject.RegionDO; import org.springframework.data.jpa.repository.JpaRepository; import org.springframework.stereotype.Repository; @Repository public interface RegionDAO extends JpaRepository\u003cRegionDO, String\u003e { } 只需要生成主键时可以不添加 @EntityListeners(AuditingEntityListener.class) 和 @EnableJpaAuditing 注解\n还可以使用 @Version 注解，自动生成版本号\n","description":"","tags":["Spring Boot","Spring Data JPA","Java"],"title":"Spring Data JPA 自动生成主键，创建时间和更新时间","uri":"/posts/java/spring-boot-jpa-auto-primary-key/"},{"categories":null,"content":"configure，make，make install 介绍 configure（配置） configure 是一个可执行脚本，主要用来测试系统环境，并生成 Makefile 文件。包含多种选项，可通过 ./configure --help 查看。最常用的选项是 ./configure --prefix=/path/to/install，指定应用安装位置，如不指定，通常默认安装在 /usr/local 目录下\nmake（编译） 根据 Makefile 脚本编译源代码。\nmake install（安装） 将编译后的程序，依赖库，文档等拷贝到指定目录（/path/to/install）\n其他常用命令 make all 或 make world：编译所有文件，可能包含文档等 make clean：删除所有被 make 创建的文件 make distclean：同时删除 ./configure 和 make 产生的临时文件 make check：测试编译好的软件 make uninstall：卸载已安装应用，需要 Makefile 中指定了安装路径 ","description":"","tags":["Linux"],"title":"configure，make，make install 介绍","uri":"/posts/linux/configure-make-make-install/"},{"categories":null,"content":"安装比特币程序 安装钱包 安装挖矿程序 运行完整节点 验证是否加入成功：BITNODES 配置文件生成器：Bitcoin Core Config Generator ","description":"","tags":["Bitcoin"],"title":"安装比特币程序","uri":"/posts/bitcoin/bitcoin-install/"},{"categories":null,"content":"源码方式编译安装 nginx 下载 nginx 源码包 http://nginx.org/en/download.html\n解压\n1 2 tar -zxvf nginx-1.16.1.tar.gz cd nginx-1.16.1/ 检查系统环境信息，并生成 MAKEFILE 文件\n1 ./configure --prefix=/path/to/install/nginx 可以不指定 --prefix, 默认将 nginx 安装到 /usr/local 目录下\n如果缺少依赖，安装依赖\n1 sudo apt install gcc libpcre3-dev zlib1g-dev openssl 编译安装\n1 make \u0026\u0026 make install ","description":"","tags":["Nginx"],"title":"源码方式编译安装 nginx","uri":"/posts/nginx/nginx-install-by-sources/"},{"categories":null,"content":"MySQL 设置大小写及字符集 MySQL 设置不区分表名大小写 Windows 默认不区分，Linux 默认区分。0 代表区分，1 代表不区分。\n1 2 [mysqld] lower_case_table_names=1 MySQL 设置默认字符集 查看默认字符集\n1 show variables like 'character_set%' 设置默认字符集\n1 2 3 4 [mysql] default-character-set=utf8mb4 [mysqld] character_set_server=utf8mb4 重启服务\n1 systemctl restart mysqld ","description":"","tags":["MySQL"],"title":"MySQL 设置大小写及字符集","uri":"/posts/database/mysql-install-normal-config/"},{"categories":null,"content":"Frdora 启动页面出现多个内核选项 问题描述 Fedora 开机启动时，开机页面包含多个不同版本的内核\n解决办法 首先查看当前系统的 Linux 内核版本\n1 $ uname -r 查看系统中已安装的所有内核\n1 $ sudo rpm -qa | grep ^kernel 删除旧版本内核\n1 $ sudo dnf remove kernel- 重启电脑\n1 $ reboot ","description":"","tags":["Linux","Fedora"],"title":"Frdora 启动页面出现多个内核选项","uri":"/posts/linux/fedora/fedora-remove-multiple-kernel/"},{"categories":null,"content":"MySQL XA 错误 异常信息 Caused by: com.atomikos.datasource.ResourceException: XA resource 'XA1DBMS1': resume for XID '3132372E302E302E312E746D30303037303030303032:3132372E302E302E312E746D3730' raised -7: the XA resource has become unavailable\n解决方式 在数据库连接 url 中添加如下内容\n1 pinGlobalTxToPhysicalConnection=true 参考文档 已知问题说明文件\n","description":"","tags":["Exception","MySQL"],"title":"MySQL XA 错误","uri":"/posts/database/mysql-xa-exception/"},{"categories":null,"content":"Ubuntu18.4LST 安装 已提供的软件包说明\nubuntu-18.04.4-desktop-amd64.iso：Ubuntu 官方 ISO 镜像 dbeaver-ce_latest_amd64.deb：数据库管理工具 google-chrome-stable_current_amd64.deb：谷歌 Chrome 浏览器 jetbrains-toolbox：用于安装 IDEA，PyCharm 等开发工具 wps-office_11.1.0.9505_amd64.deb：WPS 的 Linux 版安装包 下载镜像 软件包中已经给准备好了：\n官方镜像版本库 官方 18.04.4 ISO 镜像下载 制作 U 盘启动盘 在 Windows 上创建 USB 启动盘 制作启动盘的准备工作 一个大于 4GB 的 U 盘 Windows XP 以上的操作系统 Rufus，一个开源的制作启动盘的软件 Ubuntu 的 ISO 镜像文件 选择使用的 USB 使用 Rufus 执行以下操作来配置 U 盘\n启动 Rufus 插入 U 盘 Rufus 将会在 Device 处显示插入的 U 盘信息 通过下拉框选中作为启动盘的 U 盘 选择引导方式和分区方案 Boot selection 选择 FreeDOS Partition scheme 选择 MBR 选择 Ubuntu ISO 文件 点击Boot selection 右侧的 SELECT 选择下载的 Ubuntu ISO 文件\n选择适当的 ISO 文件，然后单击 Open\n将 ISO 文件写入启动盘 Volume label 会根据 Ubuntu 镜像自动更新\n将其他参数保留其默认值，然后单击 START 启动写入流程\n附加文件下载 可能会提醒您 Rufus 需要附加文件才能完成 ISO 写入。如果出现下方对话框，请选择 YES\n写入警告提醒 选择 Write in ISO Image mode selected 并且点击 OK\nRufus 会警告在所选的 U 盘上的数据会被清除。请确认选中的设备是否正确，会清除所有数据的!!。确认后点击 OK 即可\n正式编写 ISO 文件 现在 Rufus 会将 ISO 写入到 U 盘，进度条中会有提示信息，总时间显示在 Rufus 的右下角。大约 10 分钟左右可以写入完毕，视电脑配置而定。\n写入完成 当 Rufus 完成写入后，状态栏会变为绿色，并且在中心位置显示 READY（就绪） 字样。选择 CLOSE 以完成写入过程。\n开始安装系统 进入 Ubuntu 安装程序 将启动盘插入电脑，重启计算机，并连续点击 ESC\n出现下方页面后，按 F9\n启动菜单 F1 系统信息 F2 系统检测 F9 启动设备选项 F10 设置 BIOS F11 系统恢复 F12 网络启动 ENTER - 继续启动 更多咨询，请参考:www.hp.com/go/techcenter/startup 使用 ↑/↓ 选择启动盘的名称，按 Enter。我的启动盘是USB 硬盘(UEFI) - Generic STORAGE DEVICE (GENERIC STORAGE DEVICE)\n启动选项菜单 操作系统的管理员(UEFI) - ubuntu (SK hynix SC311 SATA 128GB) USB 硬盘(UEFI) - Generic STORAGE DEVICE (GENERIC STORAGE DEVICE) 内置网络设备(IPv4 UEFI) 内置网络设备(IPv6 UEFI) 从 EFI 文件启动 及移动选择，**ENTER**确定。 按**F10**进入**BIOS**设置，**ESC**退出。 如下页面使用 ↑/↓ 选择 Install Ubuntu，然后单击 Enter\nTry Ubuntu without installing Install Ubuntu OEM install (for manufacturers) Check disc for defects 此时正式进入 Ubuntu 的安装页面。\n选择安装语言 默认选择 English，可以选择为 Chinese，选中后点击 Continue\n选择键盘样式 默认即可，关于输入法，需要后续手动安装。\n选择安装类型 可以选择标准安装或最小化安装，此处选择标准安装\n是否清空磁盘 为了安装一个干净的系统，建议提前将数据备份到外部存储设备，此处选择删除所有数据。\n选择系统安装位置 将操作系统安装在哪个磁盘上，因为公司电脑是 128 固态 + 1T 机械的组合方式，所以将系统安装到固态硬盘中，系统运行速度会更快。\n手动分配存储空间 点击 3.6 中的 advanced partitioning tool，手动对磁盘进行分区\n提前说明 先给一个我的分区方式，如果各位对分区有更好的方式，请告诉我，因为我对此处也不是很了解。\n固态硬盘\n/boot 1024M 1G /tmp 5120M 5G / 其余 机械硬盘\n/home 204800M 200G /var 204800M 200G /usr 204800M 200G /usr/local 102400M 100G /opt 102400M 100G 剩余 200G 以后哪里需要挂哪里 再给一份分好后的样式\n固态硬盘 机械硬盘 实际操作 首先点击 减号-，将除了 Type 为 efi 的分区全部删除。 请观察 /dev/sda，/dev/sdb 下 free space 的空间大小，较小的是固态硬盘，较大的是机械硬盘。在我这 sdb 为固态硬盘，sda 为机械硬盘，分区规划按硬盘类型分，而不是按盘符，请自己查看对应关系。 选中固态硬盘的 free space 后，点击 加号+，弹出如下页面，在 Size 框中输入分区的大小，在 Mount point 处选择将分区挂载到哪个挂载点。点击 OK 即可。重复该步骤，按照上方所给的分区规划，进行分区（也可自行安排）。 Device for boot loader installation 注意选择我们的固态硬盘 分区完毕后点击 Install Now 开始安装。 选择时区 此处请选择中国，用鼠标点击以下中国区域后，点击 Continue 即可（图片有误，请选择中国）\n创建一个普通用户 添加一个普通用户，用来使用 Ubuntu，请勿在正式环境使用 root 用户执行所有操作\n正在安装 安装成功，重启电脑 出现如下提示，证明系统已经安装完毕，点击 Restart Now 会自动重启电脑，此时可以将启动盘拔出电脑了。\n安装完毕后的一些设置 修改 apt 包管理器的源为国内源 点击 Super，也叫 Win，徽标键。在搜索框中搜索 Software\u0026Updates，鼠标点击启动。\n点击下方选项框，选择 Other.. -\u003e China，此处我选择使用阿里的镜像\n安装无线网卡驱动 Ubuntu18.4 和 Ubuntu20.4 均不自带无线网卡驱动，这样是连不了 wifi 的。\n依旧使用 4.1 中的 Software\u0026Updates，点击菜单中的 Additional Drivers，按下图方式选中使用，如果没有请稍等一会，记得需要插网线哦。\n给 root 用户设置个密码 1 $ sudo passwd root 根据提示输入两次密码即可\n一些常用软件的安装 输入法的安装 RIME 输入法官网\n此处安装 RIME 输入法，搜狗官方也提供有搜狗输入法，如需安装请自行了解\n1 2 3 sudo apt -f install ibus-rime ibus engine rime 如果执行第二条命令后发生报错或警告，请重启电脑即可。\n1 $ reboot 设置输入法 点击右上角右上角，弹出框中的扳手图标。 点击 Region\u0026Language 点击 加号+，选择 Chinese，然后选择 Chinese(Rime)\n稍等片刻，使用 Super+Space 即可切换输入法。\nDocker 安装 docker docker 官方安装文档\n按顺序执行如下命令即可，已将安装包下载源修改为 Alibaba 镜像源\n1 2 3 4 5 6 7 8 9 10 11 12 $ sudo apt-get remove docker docker-engine docker.io containerd runc $ sudo apt-get update $ sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common $ curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - $ sudo add-apt-repository \"deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\" $ sudo apt-get update $ sudo apt-get install docker-ce docker-ce-cli containerd.io 修改 docker 库使用阿里镜像仓库 阿里云容器镜像服务\n进入 阿里云 docker 镜像加速器，使用支付宝扫码登录后，按照提示操作即可。\n将当前用户添加到 docker 组 将当前用户加入到 docker 组后，在执行 docker 命令时，就不需要添加 sudo 了\n查看 docker 组 id\n1 2 $ sudo cat /etc/group | grep docker docker:x:999: 我的 docker 组 id 为 999，如果有不同的，请将后续命令中的 id 号更改为对应的\n将当前用户添加到 docker 组\n1 $ sudo usermod -aG 999 `whoami` 重启计算机，因为用户的组信息需要重新登录才会加载到内存\n1 $ reboot 查看是否已在 docker 组中\n1 $ id 安装 IntelliJ IDEA 最近发现 JetBrains 提供的 ToolBox 挺好的，可以管理其公司旗下的所有软件，例如 PyCharm，WebStrom，IDEA 等。此处使用 ToolBox 安装 IDEA. ToolBox 安装包已提供\n安装 toolbox\n1 $ ./jetbrains-toolbox 使用 toolbox 安装 IDEA，启动 Toolbox 后，需要等待一会，现在 IntelliJ IDEA Ultimate 已经更新到 2020.1 版本，点击 Install 按钮右侧的倒三角可以选择版本安装。\n数据库管理工具 DBeaver 安装 开源的，使用 JAVA 语言基于 eclipse 开发的数据库管理工具。已提供安装包\n1 $ sudo apt -f install dbeaver-ce_latest_amd64.deb Google Chrome 浏览器安装 已提供安装包\n1 $ sudo apt -f install google-chrome-stable_current_amd64.deb WPS 安装 首先使用 Ctrl+Alt+F3 进入到纯命令行界面，如果 F3 不行就试试 F4，F5。\n1 $ sudo apt -f install wps-office_11.1.0.9505_amd64.deb 全程确认即可\n截图软件安装 我使用 Flameshot\n1 $ sudo apt -f install flameshot GIMP 安装 GIMP，类似于 PhotoShop 的图像处理软件，开源免费\n1 $ sudo apt -f install gimp 其他说明 软件自启管理 Super，然后搜索 Startup Application 进行设置即可\n","description":"","tags":["Linux","Ubuntu"],"title":"Ubuntu18.4LST 安装","uri":"/posts/linux/ubuntu/ubuntu18-4-install/"},{"categories":null,"content":"Ubuntu20.4 无线网卡 rtl8821ce 驱动安装 问题描述 新换的电脑，安装的 Ubuntu20.4 LST 版本的系统，回家之后发现没有 wifi 按钮连接不了 wifi。\n查看系统是否有无线网卡 使用 ip addr 显示如下，发现没有无线网卡\n1 2 3 4 5 6 7 8 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: eno1: \u003cNO-CARRIER,BROADCAST,MULTICAST,UP\u003e mtu 1500 qdisc fq_codel state DOWN group default qlen 1000 link/ether f8:b4:6a:24:22:04 brd ff:ff:ff:ff:ff:ff 使用 iwconfig 显示如下，依旧没有无线网卡\n1 2 3 lo no wireless extensions. eno1 no wireless extensions. 使用 lspci -v 显示如下，发现包含 PCIe Wireless，即电脑是有无线网卡的，网卡型号为 RTL8821CE\n1 02:00.0 Network controller: Realtek Semiconductor Co., Ltd. RTL8821CE 802.11ac PCIe Wireless Network Adapter 该网卡在 Ubuntu 上缺少驱动，需要手动安装\n解决方式 百度搜了一堆，都是从 git 上拉取源文件，然后修改 Makefile，make，make install，modprobe -a 8821ce，均未解决实际问题。\n在 github 的该项目 处，发现如下描述\nUbuntu \u0026 Debian\n1 2 sudo apt install bc module-assistant build-essential dkms sudo m-a prepare Ubuntu users may also install the prebuilt rtl8821ce-dkms package, an older version of the driver maintained by the Ubuntu MOTU Developers group for bionic, eoan and focal. It has been known to work in cases where the newer driver available here does not. Bugs and issues with that package should be reported at Launchpad rather than here.\n点击上方 rtl8821ce-dkms 是 18.04 版本的 deb 包，安装后不符合要求，因此通过 packages.ubuntu.com 搜索 rtl8821ce-dkms，获取到了对应版本的 deb 包，安装成功后，重启电脑，就可以使用无线网卡进行连接了。下方图片红色框中的红色字对应不同 Ubuntu 版本的名称。\n全部执行命令如下:\n1 2 3 4 $ sudo apt install bc module-assistant build-essential dkms $ sudo m-a prepare $ sudo dpkg -i rtl8821ce-dkms_5.5.2.1-0ubuntu3_all.deb $ sudo reboot ","description":"","tags":["Linux","Ubuntu"],"title":"Ubuntu20.4 无线网卡 rtl8821ce 驱动安装","uri":"/posts/linux/ubuntu/ubuntu20.4-rtl8821ce-drivers/"},{"categories":null,"content":"常用软件包下载网站 pkgs.org packages.ubuntu.com packages.debian.org gnu.org http://rpmfind.net/ ","description":"","tags":["Linux"],"title":"常用软件包下载网站","uri":"/posts/linux/linux-package-download/"},{"categories":null,"content":"截图工具 Flameshot 安装命令 Ubuntu\n1 sudo apt install flameshot Fedora\n1 sudo dnf install flameshot 启动命令 1 flameshot gui ","description":"","tags":["Linux"],"title":"截图工具 Flameshot","uri":"/posts/linux/linux-flameshot/"},{"categories":null,"content":"Docker 的网络模式 官方网站\n使用 docker run 创建 Docker 容器时，可以使用 --net 选项指定容器的网络模式。\nDocker 的网络子系统可使用驱动程序插入。默认情况下，有几个驱动程序，它们提供核心联网功能：\nbridge(网桥网络)：默认的网络驱动程序。如果未指定，默认使用该网络类型。当您的应用程序在需要通信的独立容器中运行时，通常会使用网桥网络。请参阅网桥网络 host(主机网络)： overlay(覆盖网络)： macvlan(Macvlan 网络)： none(禁用网络)： Network plugins(网络插件)：您可以在 Docker 中安装和使用第三方网络插件。 ","description":"","tags":["Docker"],"title":"Docker 的网络模式","uri":"/posts/docker/docker-network/"},{"categories":null,"content":"Docker 给运行中的容器添加挂载点 方式一：修改配置文件方式 注意：此方式需要重启 docker 服务\n查看需要修改的容器ID\n1 2 3 [root@localhost ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b19505cec84d tomcat \"catalina.sh run\" 3 days ago Up 4 minutes 0.0.0.0:8888-\u003e8080/tcp affectionate_driscoll 停止docker服务\n1 systemctl stop docker 修改配置文件 /var/lib/docker/containers/{container-id}/hostconfig.json，在 Binds 中添加一个挂载点数组，:前为宿主机目录，后面为 docker 容器目录\n1 2 3 4 5 6 7 8 9 10 11 12 { \"Binds\":[ \"/host/folder:/container/folder\", \"/host/folder2:/container/folder2\" ], \"ContainerIDFile\":\"\", \"LogConfig\":{ \"Type\":\"json-file\", \"Config\":{ } }, 修改配置文件 /var/lib/docker/containers/{container id}/config.v2.json，修改 MountPoints 的配置，注意对应关系\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 \"MountLabel\":\"\", \"ProcessLabel\":\"\", \"RestartCount\":0, \"HasBeenStartedBefore\":true, \"HasBeenManuallyStopped\":false, \"MountPoints\":{ \"/container/folder\":{ \"Source\":\"/host/folder\", \"Destination\":\"/container/folder\", \"RW\":true, \"Name\":\"\", \"Driver\":\"\", \"Type\":\"bind\", \"Propagation\":\"rprivate\", \"Spec\":{ \"Type\":\"bind\", \"Source\":\"/host/folder\", \"Target\":\"/container/folder\" }, \"SkipMountpointCreation\":false }, \"/container/folder2\":{ \"Source\":\"/host/folder2\", \"Destination\":\"/container/folder2\", \"RW\":true, \"Name\":\"\", \"Driver\":\"\", \"Type\":\"bind\", \"Propagation\":\"rprivate\", \"Spec\":{ \"Type\":\"bind\", \"Source\":\"/host/folder2\", \"Target\":\"/container/folder2\" }, \"SkipMountpointCreation\":false } }, \"SecretReferences\":null, \"ConfigReferences\":null, \"AppArmorProfile\":\"\", 启动 docker 服务\n1 systemctl start docker 启动 docker 容器\n1 docker start container-id 方式二：提交现有容器为镜像，然后重新运行 查看当前容器\n1 2 3 [root@localhost ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 1c12559054c6 tomcat \"catalina.sh run\" About a minute ago Up About a minute 8080/tcp mount-test 将当前容器提交为新镜像\n1 2 3 docker commit old-container-id new-image-name docker commit 1c12559054c6 mount-test-temp 查看镜像\n1 2 3 [root@localhost ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE mount-test-temp latest 9df6912cea3f 6 seconds ago 529MB 使用该镜像运行新的容器, 并添加挂载目录\n1 2 3 docker run -itd -v /host/folder:/container/folder image-name docker run -itd -v /host/folder:/container/folder mount-test-temp 如需将新容器名称修改为与旧容器相同\n停止并删除旧容器\n1 docker stop old-container-id; docker rm old-container-id 重命名新容器\n1 docker rename new-container-id old-container-name 方式三：export 容器为镜像，使用 import 为新镜像 将容器导出为文件\n1 docker export -o outfile/path/outfile.tar container-id -o：将输入内容写到文件，即将容器导出为文件\n将导出的文件添加为新镜像\n1 docker import outfile/path/outfile.tar new-image-name 查看镜像\n1 2 3 [root@localhost ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE export-test-temp latest 42c12cbe83f0 4 seconds ago 521MB 使用该镜像运行新的容器，并添加挂载目录\n1 2 3 docker run -itd -v /host/folder:/container/folder image-name docker run -itd -v /host/folder:/container/folder mount-test-temp 如需将新容器名称修改为与旧容器相同\n停止并删除旧容器\n1 docker stop old-container-id; docker rm old-container-id 重命名新容器\n1 docker rename new-container-id old-container-name 参考文档 docker-修改容器的挂载目录三种方式\n","description":"","tags":["Docker"],"title":"Docker 给运行中的容器添加挂载点","uri":"/posts/docker/docker-running-add-mount/"},{"categories":null,"content":"MBR 分区结构和 GPT 分区结构 MBR 和 GPT MBR MBR（Master Boot Record，主引导记录）是计算机硬盘驱动器的第一个扇区。它告诉计算机硬盘驱动器的分区情况，以及如何加载操作系统。\nMBR 对比 GPT 存在的缺点\n最大只支持 2TB 的硬盘 每个磁盘最多可以分为 4 个主分区（或 3 个主分区和 1 个扩展分区） MBR 有自己的启动代码，一旦启动代码被破坏，系统无法启动。需要修复启动代码才可重新启动。GPT 本身并不包含启动代码，需要使用 UEFI 引导启动 GPT GPT（GUID partition table，GUID 分区表）是 EFI 标准定义的一种较新的硬盘分区表结构。与 MBR 分区方案相比，GPT 提供更加灵活的磁盘分区机制。具有以下优点：\n支持 2TB 以上的大硬盘（最大 18EB） 每个磁盘的分区个数没有限制 分区大小没有限制 分区表自带备份 每个分区可以有一个名称（不同于卷标） 传统 BOIS 引导和 UEFI 引导启动 BIOS BIOS（Basic Input Output System，基本输入输出系统）是一组固化到计算机内主板上一个 ROM 芯片上的程序，它保存着计算机最重要的基本输入输出的程序、开机后自检程序和系统自启动程序，它可从 CMOS 中读写系统设置的具体信息。\n老式电脑中有一个 BIOS 设置，它主要负责开机时检测硬件功能和引导操作系统启动的功能。\nUEFI UEFI（Unified Extensible Firmware Interface，统一可扩展固件接口）规范为个人计算机操作系统和平台固件之间的接口定义了一个新模型。该接口由数据表组成，这些数据表包含与平台有关的信息，以及操作系统及其加载程序可用的启动和运行时服务调用。它们共同提供了用于引导操作系统和运行预引导应用程序的标准环境。UEFI 引导时省去了 BIOS 自检过程，所以可加快开机启动速度。\nBIOS 和 UEFI 区别 BIOS 通常用于指代植根于 IBM PC 设计的英特尔®架构固件实现。基于较旧的标准和方法，BIOS 最初是用 16 位实模式 x86 汇编代码编码的，直到最近使用率下降之前，基本上保持不变。\n相比之下，UEFI 标准通过描述用于将控制权转移到操作系统或从一个或多个芯片和固件供应商构建模块化固件的抽象接口集，反映了 PC 发展的 30 年。UEFI 论坛规范的抽象旨在使生产者代码和消费者代码的开发脱钩，从而使每个人都可以更独立地进行创新，并且可以更快地将两者推向市场。UEFI 还克服了 IBM PC 设计所假定的硬件扩展限制，从而可以将其跨高端企业服务器广泛部署到嵌入式设备。UEFI 是“与处理器架构无关的“，支持 x86，x64，ARM 和 Itanium。\nFAT32 和 NTFS 等 FAT32，NTFS，exFAT 等均属于文件系统。\n文件的系统是操作系统用于明确磁盘或分区上的文件的方法和数据结构，即在磁盘上组织文件的方法。\nFAT（File Allocation Table）：文件配置表 NTFS（New Technology File System）文件系统是一个基于安全性的文件系统，是 Windows NT 所采用的独特的文件系统结构，它是建立在保护文件和目录数据基础上，同时照顾节省存储资源、减少磁盘占用量的一种先进的文件系统 CDFS 是大部分的光盘的文件系统 exFAT（Extended File Allocation Table File System，扩展 FAT）一种适合于闪存的文件系统，为了解决 FAT32 等不支持 4G 及其更大的文件而推出 Ext 是 GNU/Linux 系统中标准的文件系统 RAW 文件系统是一种磁盘未经处理或者未经格式化产生的文件系统 Btrfs ZFS HFS HFS+ ReiserFS JFS VMFS XFS UFS VXFS ReFS WBFS PFS MBR（GPT）与 FAT（NTFS 等）区别 MBR 和 GPT 是两种不同的磁盘分区结构，用来记录各个分区在磁盘中的位置等信息；而 FAT，NTFS 等是文件系统，是在对磁盘分区后，每个分区对文件的管理方式。\n","description":"","tags":["Computer"],"title":"MBR 分区结构和 GPT 分区结构","uri":"/posts/computer/mbr-and-gpt/"},{"categories":null,"content":"黑客屏保 安装所需依赖包\n1 sudo dnf install ncurses* 下载源码包\n1 wget https://jaist.dl.sourceforge.net/project/cmatrix/cmatrix/1.2a/cmatrix-1.2a.tar.gz 解压源码包\n1 tar -zxvf cmatrix-1.2a.tar.gz 进入源码包\n1 cd cmatrix-1.2a/ 释放编译文件\n1 sudo ./configure --prefix=/opt/cmatrix/ 编译\n1 sudo make 安装\n1 sudo make install 可将命令建立软链接到 bin\n1 sudo ln -s /opt/cmatrix/bin/cmatrix /bin/cmatrix 参考文档 Linux 下 cmatrix 的安装和使用(黑客屏保)\n","description":"","tags":["Linux"],"title":"黑客屏保","uri":"/posts/linux/hacker-screensaver/"},{"categories":null,"content":"IDEA 导入普通 Web 项目 IDEA 版本：IntelliJ IDEA 2020.1(Ultimate Edition)\n普通 Web 项目目录结构介绍 1 2 3 4 5 6 7 8 project/ ├── src └── web ├── classes ├── index.jsp └── WEB-INF ├── lib └── web.xml project：项目目录\nsrc：用来存放 Java 类 web：web 项目的根目录，eclipse 中为 WebRoot classes：src 目录中的 .java 文件编译为 .class 文件后会放入到这里，src 目录中的配置文件等也会放入到这里 WEB-INF：Java 的 WEB 应用的安全目录。里面的内容只有服务端可以访问，客户端不能访问。 lib：存放项目依赖的 jar 包 web.xml：Web 应用程序配置文件 index.jsp：主页文件 推荐常用的目录结构\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 project/ ├── src │ └── com │ └── domain │ ├── controller │ ├── dao │ ├── entity │ └── service └── web ├── index.jsp ├── static │ ├── css │ ├── img │ └── js └── WEB-INF ├── classes ├── config │ ├── config.properties │ ├── mybatis │ └── spring ├── jsp ├── lib └── web.xml IDEA 引入普通 WEB 项目 以如下项目结构为例\n指定存放 Java 类的目录\nFile → Project Structure...【Ctrl+Alt+Shift+s】\n指定 Java 文件编译后的目录\n此处，将其指定为 WEB-INF 下的 classes 目录\n设置使用 tomcat 运行项目时，项目文件的输出位置\n此处设置为项目目录下的 out 文件夹\n设置项目依赖的 jar 包位置\n选择当前项目 WEB-INF 下的 lib 文件夹，并选择将该 lib 添加到哪个模块下\n指定 web.xml 和 web 根目录的位置\n选择需要添加 Web 部分的模块\n指定 web.xml 位置和 web 根目录位置\n预览项目结构效果图\n使用 tomcat 运行项目，并导出 war 包 注意：此处需确保前两步没有问题\n创建 IDEA 嵌入式 tomcat 可以运行的 Artifacts\n选择为哪个模块创建 war exploded（这个 exploded 是可以运行在嵌入到 IDEA 中的 tomcat 的文件，相当于将 war 包解压后的目录，关于如何打 war 包，请继续向后看）\n此处可以看到输出文件夹在之前 Project 中设置的 /project/out/ 目录下\n创建可打成 war 包的 Artifacts\n效果图如下\n配置 IDEA 使用嵌入式的 tomcat\n添加一个本地的 tomcat\n为该 tomcat 添加第二步中配置的 war exploded\n选择war exploded\n保存后即可运行\n导出 war 包 Build → Build Artifacts...\n结果预览\n","description":"","tags":["IDEA","Java"],"title":"IDEA 导入普通 Web 项目","uri":"/posts/java/idea-import-normal-web-project/"},{"categories":null,"content":"Nginx 代理解决跨域请求问题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 user root; worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; server { listen 8100; server_name localhost; location / { root /root/software/nginx/html/dist; try_files $uri $uri/ /index.html add_header 'Access-Controller-Allow-Origin' '*'; index index.html index.htm; } location /api/ { proxy_pass http://127.0.0.1:8110/; add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Methods' '*'; add_header 'Access-Control-Allow-Headers' 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization,token'; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Connection close; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; proxy_max_temp_file_size 0; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; } } } ngx_http_headers_module\n","description":"","tags":["Nginx"],"title":"Nginx 代理解决跨域请求问题","uri":"/posts/nginx/nginx-proxy-solve-cors/"},{"categories":null,"content":"Linux 文本处理\u0026正则表达式\u0026Vim 文本处理 抽取文本的工具\n文本内容：less 和 cat 文件截取：head 和 tail 按列抽取：cut 按关键字抽取：grep 文件查看 文件查看命令 cat，tac，rev\ncat [OPTION]... [FILE]...\n-E：显示行结束符 $ -n：对显示出的每一行进行编号 -A：显示所有控制符 -b：非空行编号 -s：压缩连续空行成一行 tac：从最后一行显示到第一行\nrev：行的顺序不变，每行中的字符反向输出\n分页查看文件内容 more，less\nmore：分页查看文件\n语法：more [OPTIONS...] FILE... OPTIONS： -d：显示翻页（space）及退出（q）帮助而不是响铃 -f：计算行数时，以实际上的行数而非自动换行过后的行数（有些单行字数太长的会被自动换行） -l：取消遇见特殊字元 ^L（送纸字元）时会暂停的功能 -p：取消滚动，清理屏幕并显示文字 -c：取消滚动，显示文本并清理行尾 -u：不显示下引号（根据环境变量 TERM 指定的 terminal 而有所不同） -s：将多个空白行压缩为一行 -NUM：一次显示 NUM 行 +NUM：从第 NUM 行开始显示 +/STRING：从搜索字符串匹配开始显示文件 -V：输出版本信息并退出 查看时常用的命令 Enter：向下 n 行，需要定义。默认为 1 Ctrl+f，空格：向下滚动一屏 Ctrl+b：返回上一屏 =：输出当前行的行号 :f：输出当前文件名和当前行号 v：调用 vi 编辑器 !命令：调用 shell 脚本并执行命令 q：退出 less：一页一页地查看文件或 STDIN 输出\n语法 less [OPTIONS] file OPTIONS -b [N]：设置缓冲区大小 -e：当文件显示结束后自动退出 -f：强迫打开特殊文件，例如外围设备代号，目录和二进制文件 -g：直标志最后搜索的关键词 -i：忽略搜索时的大小写 -m：显示类似 more 的百分比 -N：显示行号 -o 文件名：将 less 输出的内容在指定文件中保存起来 -Q：不使用警告音 -s：显示连续空行为一行 -S：行过长时将超出部分舍弃 -x 数字：将 tab 键显示为规定的数字空格 查看时有用的命令包括 e，Ctrl+e，j，Ctrl+N，Enter：下一行\ny，Ctrl+y，k，Ctrl+k，Ctrl+p：上一行\nf，Ctrl+f，Ctrl+v，Space：下一屏\nb，Ctrl+b，ESCv：上一屏\nz：下一屏，并设置缓冲区为当前窗口高度\nw：上一屏，并设置缓冲区为当前窗口高度\nESCSpace：下一屏，但是在文件结尾不停止\nd，Ctrl+d：下半屏，并设置缓冲区为窗口一半的高度\nu，Ctrl+u：上半屏，并设置缓冲区为窗口一半的高度\nESC)，右方向键：\nESC(，左方向键：\nF：跟随，类似于 tail -f\nr，Ctrl+r，Ctrl+l：重新绘制屏幕\nR：重新绘制屏幕，丢弃缓存输入\n/文本：向下搜索文本\n?文本：向上搜索文本\nn/N：跳到下一个/上一个匹配\nESCn/N：跳到下一个/上一个匹配，跨越文件\n\u0026文本：只显示匹配的行\ng，\u003c，ESC\u003c：跳到第一行\nG，\u003e ESC\u003e：跳到最后一行\np，%：跳到文件的开始\nt：跳到下一个标签\nT：跳到上一个标签\n{，(，[：查找对应的} ) ]\n}，)，]：查找对应的{ ( [\nESCCtrl+f \u003cc1\u003e \u003cc2\u003e：查找右括号\u003cc2\u003e\nESCCtrl+f \u003cc1\u003e \u003cc2\u003e：查找左括号\u003cc1\u003e\nh：显示帮助\nq：　退出\nless命令是 man 命令使用的分页器 可以结合管道，将一些命令的执行结果做分页处理.\n例如：ll /etc | less 或 ll /etc | more\n显示文本前或后行内容 head，tail，tailf\nhead [OPTION]... [FILE]...\n-c #：指定获取前#字节 -n #：指定获取前 n 行 -#：指定行数 tail [OPTION]... [FILE]...\n-c #：指定获取后#字节 -n #：指定获取后#行 -#：指定行数 -f，--follow=descriptor：跟踪显示文件 fd 新追加的内容，常用日志监控 -F，--follow=name --retry：跟踪文件名. tailf：类似于 tail -f，当文件不增长时并不访问文件，比较省资源\n可以结合管道，将一些命令的执行结果做处理.\n例如：ifconfig | head -10, ifconfig | tail -10, ifconfig | head -2 | tail -1\n口令生成器：cat /dev/urandom | tr -dc 'a-zA-Z0-9_' | head -c32\n文本处理 按列抽取文本 cut cut [OPTION]... [FILE]...\n-d DELEMITER：指明分隔符，默认 tab\n-f FILEDS：\n#：第#个字段 #,#[,#]：离散的多个字段，例如 1,3,6 #-#：连续的多个字段，例如 1-6 混合使用：例如 1-3,7 -c：按字符切割\n--output-delimiter=STRING：指定输出分隔符\n示例\n取出用户名和 uid\n1 2 3 cut -d : -f 1,3 /etc/passwd 或指定输出分隔符 cut -d : -f 1,3 --output-delimiter=* /etc/passwd 取出分区利用率\n1 df | tr -s ' ' % | cut -d% -f5 取出网卡的 ip 地址\n1 2 3 4 5 ifconfig eth0| head -n2 | tail -n1 | tr -s ' ' '/' | cut -d/ -f3 或 ifconfig eth0| head -n2 | tail -n1 | tr -s ' ' | cut -d' ' -f3 或 ifconfig eth0 | head -2 | tail -1 | tr -dc '[0-9]. '| tr -s ' ' | cut -d' ' -f2 横向合并 paste paste [OPTION]... [FILE]...：合并两个文件同行号的列到一行\n-d 分隔符：指定分隔符，默认用 TAB -s：将列变成行来显示 示例 paste f1 f2 paste -s f1 f2 分析文本 文本数据统计：wc（word count） 计数行总数，单词总数，字节总数和字符总数\n可以对文件或 STDIN 中的数据运行\n1 2 3 $ wc story.txt 39 237 1901 story.txt 行数 单词数 字节数 文件名 常用选项\n-l：只计数行数 -w：只计数单词总数 -c：只计数字节总数 -m：只计数字符总数 -L：显示文件中最长行的长度 示例\n查看文档中的所有单词个数 1 cat /etc/profile | tr -cs 'a-zA-Z' '\\n' | wc -l 文本排序 sort 把整理过的文本显示在 STDOUT，不改变原始文件\n语法：sort [OPTION]... [FILE]...\n常用选项：\n-r：倒序 -R：随机排序 -n：按数字大小排序 -f：忽略字符串中的字符大小写 -u：删除输出中的重复行 -t c：使用 c 作为字段界定符 -k X：按照使用 c 字符分割的 X 列来整理能够使用多次 示例\n按照 uid 排序\n1 sort -t: -k3 /etc/passwd 抽奖\n1 seq 63 | sort -R | head -n1 查找分区利用率最大的值\n1 df | tr -s ' ' '%' | cut -d% -f5 | sort -nr | head -n1 uniq 从输入中删除前后相接的重复的行\n语法：uniq [OPTION]... [FILE]...\n常用选项：\n-c：显示每行重复出现的次数\n-d：仅显示重复过的行\n-u：仅显示不曾重复的行 注：连续且完全相同方为重复\n常和 sort 命令一起配合使用\n1 sort userlist.txt | uniq -c 比较文件：diff 比较两个文件之间的区别\n语法：diff [OPTION]... FILES\n选项：\n-u： 示例\n不加参数的 diff f1 f2\n使用 paste 查看 f1 和 f2\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ paste f1 f2 aaa\taaa bbb\tbbb ccc\tcc ddd\teee eee\tfff fff\tggg ggg\thhh hhh\tjjj iii\tkkk jjj\tlll kkk\tmmm lll\tnnn ooo 使用 diff f1 f2 查看区别\n1 2 3 4 5 6 7 8 9 10 11 12 $ diff f1 f2 3,4c3 \u003c ccc \u003c ddd --- \u003e cc 9d7 \u003c iii 12a11,13 \u003e mmm \u003e nnn \u003e ooo 说明\n3,4c3 表示 f1 文件的 3-4 行被修改（c：change）为 f2 文件的第 3 行，其中 \u003c ccc，\u003c ddd 表示删除（\u003c）了 f1 的第 3 行的 ccc 和第 4 行的 ddd，--- 表示上方为 f1，下方为 f2，\u003e cc 表示 f2 中第 3 行增加（\u003e）了 cc\n9d7 表示 f1 文件的第 9 行被删除（d：delete）了，f1 中被删除（\u003c）的行内容是 iii\n12a11,13 表示在 f1 的第 12 行添加（a：add）了内容，对应 f2 文件的 11-13 行，f2 中增加（\u003e）的内容是 mmm，nnn，ooo\n使用 -u 选项\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 $ diff -u f1 f2 --- f1\t2020-04-14 13:52:17.972393288 +0800 +++ f2\t2020-04-14 14:22:36.610610276 +0800 @@ -1,12 +1,13 @@ aaa bbb -ccc -ddd +cc eee fff ggg hhh -iii jjj kkk lll +mmm +nnn +ooo 说明:\n--- 表示变动前的文件，+++ 表示变动后的文件\n-1,12，- 表示 f1，1 表示从第 1 行开始，12 表示连续 12 行\n+1,13，+ 表示 f2，1 表示从第一行开始，13 表示连续 13 行\n-1,12 +1,13 即表示下面显示的是 f1 的从第 1 行开始连续 12 行以及 f2 从第 1 行开始连续 13 行的内容\n下方具体变动部分，带 - 的表示从 f1 中删除的，带 + 表示 f2 中新增的，不带任何标识的表示没有发生变化\n修补文件 patch patch：复制在其他文件中进行的改变\n语法：patch [OPTION]... [ORIGFILE [PATCHFILE]]\n选项\n-b：备份每一个原始文件 示例\n1 2 3 4 # 将`diff -u f1 f2`输出的结果保存在一种叫“补丁”的文件中 $ diff -u f1 f2 \u003e f1.patch # 使用“补丁”文件对 f1 进行升级操作 $ patch -b f1 f1.patch 练习 查出 /tmp 的权限，以数字方式显示\n1 stat /tmp |head -n4|tail -n1|cut -d/ -f1|cut -d'1' -f2 Linux 文本处理三剑客 grep：文本过滤工具。grep，egrep，fgrep（不支持正则表达式搜索）\nsed：stream editor，文本编辑工具\nawk：Linux 上的实现 gawk，文本报告生成器\ngrep grep：Global search REgular expression and Print out the line\n作用：文本搜索工具，根据用户指定的“模式”对目标文本逐行进行匹配检查；打印匹配到的行\n模式：pattern，由正则表示式字符及文本字符所编写的过滤条件\n语法：grep [OPTION]... PATTERN [FILE]...\n选项：\n--color=auto：对匹配到的文本着色显示 -v：显示不被 pattern 匹配到的行 -i：忽略字符大小写 -n：显示匹配的行号 -c：统计匹配的行数 -o：仅显示匹配到的字符串 -q：静默模式，不输出任何信息 -A #：after，后#行 -B #：before，前#行 -C #：context，前后各#行 -e：实现多个选项间的逻辑 or 关系 grep -e 'cat' -e 'dog' file -w：匹配整个单词 -E：使用 ERE -F：相当于 fgrep，不支持正则表达式 -f file：根据模式文件处理 sed awk 正则表达式 文件通配符参考 文件管理#文件通配符\nREGEXP：Regular Expressions，由一类特殊字符及文本字符所编写的模式，其中有些字符（元字符）不代表字符字面意义，而表示控制或通配的功能.\n程序支持：grep，sed，awk，vim，less，nginx，varnish等\n分两类：\n基本正则表达式：BRE 扩展正则表达式：ERE 正则表达式引擎：采用不同算法，检查处理正则表达式的软件模块，例如：PCRE（Perl Compatible Regular Expressions）\n元字符分类：字符匹配，匹配次数，位置锚定，分组\n帮助文档：man 7 regex\n基本正则表达式 基本正则表达式元字符 字符匹配：\n.：匹配任意单个字符 []：匹配指定范围内的任意单个字符，示例：[wang]，[0-9]，[a-z]，[a-zA-Z] [^]：匹配指定范围外的任意单个字符 [:alnum]：字母和数字 [:alpha:]：任何大小写字母，等同于 [a-zA-Z] [:lower:]：小写字母，等同于 [a-z] [:upper:]：大写字母，等同于 [A-Z] [:blank:]：空白字符（空格和制表符） [:space:]：水平和垂直的空白字符（比 [:blank:] 包含范围更广） [:cntrl:]：不可打印的控制字符（退格，删除，警铃等） [:digit:]：十进制数字，等同于 [0-9] [:xdigit:]：十六进制数字 [:graph:]：可打印的非空白字符 [:print:]：可打印字符 [:punct:]：标点符号 匹配次数\n用在要指定次数的字符后面，用于指定前面的字符要出现的次数\n*：匹配前面的字符任意次，包括 0 次。贪婪模式：尽可能长的匹配 .*：任意长度的任意字符 \\?：匹配其前面的字符 0 或 1 次 \\+：匹配其前面的字符至少 1 次 \\{n\\}：匹配前面的字符 n 次 \\{m,n\\}：匹配前面的字符至少 m 次，至多 n 次 \\{,n\\}：匹配前面的字符至多 n 次 \\{n,\\}：匹配前面的字符至少 n 次 位置锚定\n定位出现的位置\n^：行首锚定，用于模式的最左侧 $：行尾锚定，用于模式的最右侧 ^PATTERN$：用于模式匹配整行 ^$：空行 ^[[:space:]]$：空白行 \\\u003c或\\b：词首锚定，用于单词模式的左侧 \\\u003e或\\b：词尾锚定，用于单词模式的右侧 \\\u003cPATTERN\\\u003e：匹配整个单词 分组\n\\(\\)：将一个或多个字符捆绑在一起，当作一个整体处理，如：\\(root\\)+ \\|：或，示例：a\\|b：a 或 b，C\\|cat：c 或 cat，\\(C\\|c\\)at：Cat 或 cat 例如 grep \"^\\(a\\|b\\)\" /etc/passwd， 后向引用：\n分组括号中的模式匹配到的内容会被正则表达式引擎记录于内部的变量中，这些变量的命名方式为：\\1，\\2，\\3，...\n\\1 表示从左侧起第一个左括号以及与之匹配有括号之间的模式所匹配到的字符串\n示例：\\(string1\\+\\(string2\\)*\\)\n\\1：string1\\+\\(string2\\)* \\2：string2 后向引用引用的是前面的分组括号中的模式所匹配字符，而非模式本身 示例：grep \"\\(root\\).*\\1\" /etc/passwd\n练习 显示 /proc/meminfo 文件中以大小 s 开头的行（要求：使用两种方法）\n1 2 grep \"^[Ss]\" /proc/meminfo grep \"^\\(s\\|S\\)\" /proc/meminfo 显示 /etc/passwd 文件中不以 /bin/bash 结尾的行\n1 grep \"/bin/bash$\" /etc/passwd 显示用户 rpc 默认的 shell 程序\n找到 /etc/passwd 中的两位或三位数\n1 grep \"[0-9]\\{2,3\\}\" /etc/passwd 显示 CentOS7 的 /etc/grub2.cfg 文件中，至少以一个空白字符开头的且后面有非空白字符的行\n1 grep \"^[[:space:]]\\{1,\\}[^[:space:]]\" /etc/grub2.cfg 找出 netstat -tan 命令结果中以 LISTEN 后跟任意多个空白字符结尾的行\n1 netstat -tan | grep \"LISTEN[[:space:]]*$\" 显示 CentOS7 上所有系统用户的用户名和 UID\n1 cut -d: -f1,3 /etc/passwd 添加用户 bash，testbash，basher，sh，nologin（其 shell 为 /sbin/nologin），找出 /etc/passwd 用户名和 shell 同名的行\n利用 df 和 grep，取出磁盘各分区利用率，并从大到小排序\n扩展正则表达式 egrep 及扩展正则表达式 egrep = grep -E\negrep [OPTIONS] PATTERN [FILE]...\n扩展正则表达式元字符 字符匹配\n.：任意字符 []：指定范围的字符 [^]：不在指定范围的字符 次数匹配\n*：匹配前面字符任意次数，包括 0 次 ?：0 或 1 次 +：1 次或多次 {m}：m 次 {m,n}：至少 m，至多 n 次 {m,}：至少 m 次 {,n}：至多 n 次 位置锚定\n^：行首 $：行尾 \\\u003c，\\b：词首 \\\u003e，\\B：词尾 分组\n()：分组 \\1, \\2, ...：后向引用 |：或者 练习 显示三个用户 root，linux，wang 的 UID 和默认 shell\n1 cut -d: -f1,7 /etc/passwd | grep -E \"^((root)|(linux)|(wang))\" 找出 /etc/rc.d/init.d/functions 文件中行首为某单词（包括下划线）后面跟一个小括号的行\n1 egrep \"^\\b()\" /etc/rc.d/init.d/functions 使用 egrep 取出 /etc/rc.d/init.d/functions 中其基名\n1 echo \"/etc/rc.d/init.d/functions\" | egrep -o \"[^/]+$\" 使用 egrep 取出上面路径的目录名\n1 echo \"/etc/rc.d/init.d\" | egrep -o \".*[^/]\" | egrep -o \".*/\" 统计 last 命令中以 root 登录的每个主机 IP 地址登录次数\n1 echo \"/etc/rc.d/init.d\" | egrep -o \".*[^/]\" | egrep -o \".*/\" 利用扩展正则表达式分别表示 0-9，10-99，100-199，200-249，250-255\n0-9：[0-9] 10-99：[1-9][0-9] 100-199：1[0-9]{2} 200-249：2[0-4][0-9] 250-255：25[0-5] 显示 ifconfig 命令结果中所有 IPv4 地址\n1 ifconfig | grep -Eo \"(([1-9]?[0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([1-9]?[0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\" 将此字符串：welcome to linux 中的每个字符去重并排序，重复次数多的排在前面\nvim vi：Visual Interface，文本编辑器 文本：ASCII，Unicode 文本编辑器种类 行编辑器：sed 全屏编辑器：nano，vi vim：Vi Improved 其他编辑器 gedit：一个简单的图形编辑器 gvim：一个 Vim 编辑器的图形版本 Vim 命令小抄 打开文件 语法：vim [OPTION]... FILE...\n选项：\n+#：打开文件后，让光标处于第#行行首，+ 默认最后一行行首 +/PATTERN：打开文件后，直接让光标处于第一个被 PATTERN 匹配到的行的行首 -b：二进制方式打开文件 -d file1 file2 ...：比较多个文件 -m：制度打开文件 -e：ex 模式，也可以直接使用 ex file 如果该文件存在，文件被打开并显示内容；如果文件不存在，当编辑后第一次存盘时会创建它\nvim：一个模式编辑器 击键行为依赖与 vim 的“模式”\n3 种主要模式：\n命令（Normal）模式：默认模式，可用来移动光标，剪切/粘贴文本等 插入（Insert）或编辑模式：修改文本内容 扩展命令（EXtended command）模式：保存，退出等 模式转换 命令模式 --\u003e 插入模式\ni：insert，在光标所在处输入 I：在光标所在行的行首输入 a：append，在光标所在处后面输入 A：在光标所在行的行尾输入 o：在光标所在行的下方打开一个新行 O：在光标所在行的上方打开一个新行 graph LR 命令模式--i,I,a,A,o,O--\u003e插入模式 插入模式--ESC--\u003e命令模式 命令模式--:--\u003e扩展命令模式 扩展命令模式--ESC,Enter--\u003e命令模式 关闭文件 扩展命令模式\n:q：退出 :q!：强制退出，丢弃所做的修改 wq：保存退出 x：保存退出 wq!：强制保存并退出 命令模式\nZZ：保存退出 ZQ：不保存退出 扩展命令模式 插入模式使用 : 进入扩展命令模式，创建一个命令提示符 :，处于屏幕的左下角\n命令：\nw：写（存）磁盘文件 wq：写入并退出 x：写入并退出 q：退出 q!：不存盘退出，将丢失所有更改 r filename：读指定文件内容到当前文件中 w filename：将当前文件内容写入另一个文件 !command：执行命令 r!command：读入命令的输出 命令模式 光标跳转 字符间跳转\nh：左 l：右 j：下 k：上 #COMMAND：跳转由#指定的个数的字符 单词间跳转\nw：下一个单词的词首 e：当前或下一个单词的词尾 b：当前或前一个单词的词首 #COMMAND：由#指定一次跳转的单词数 当前页跳转\nH：页首 M：页中间行 L：页底 zt：将光标所在行移动到屏幕顶端 zz：将光标所在行移动到屏幕中间 zb：将光标所在行移动到屏幕底端 行首行尾跳转\n^：跳转至行首第一个非空白字符 0：跳转至行首 $：跳转至行尾 行间移动\n#G：扩展命令模式下，跳转到第#行 G：跳到最后一行 1G，gg：跳转到第一行 句间移动\n)：下一句 (：上一句 段落间移动\n}：下一段 {：上一段 翻屏操作 Ctrl+f：向文件尾部翻一屏 Ctrl+b：向文件首部翻一屏 Ctrl+d：向文件尾部翻半屏 Ctrl+u：向文件首部翻半屏 修改操作 字符编辑\nx：剪切光标处的字符 #x：剪切光标处起始的#个字符 xp：交换光标所在处的字符及其后面字符的位置（剪切后粘贴） ~：转换大小写 J：删除当前行后的换行符 替换命令（r，replace）\nr：替换光标所在处的字符 R：切换成 REPLACE 模式 删除（剪切）指令（d，delete）\nd：删除命令，可结合光标跳转字符，实现范围删除 #dh/#dl：向左/右删除 # 个字符 #dj/#dk：删除当前行并向下/上删除 # 行 d$：删除至行尾 d^：删除到非空行首 d0：删除到行首 dw：从光标处删除到下一个单词的词首 de：从光标处删除到下一个单词的词尾 db：从光标处删除到上一个单词的词首 dG：从光标所在行删除到文件末尾 dgg：从光标所在行删除到文件顶端 #d*：* 代表任意可以移动光标的操作 dd：删除光标所在行，剪切 #dd：删除下 # 行 D：从当前光标位置删除至行尾，等同于d$ 复制指令（y，yank）\ny：复制，行为类似于 d 命令 y$： y0： y^： ye： yw： yb： #y*：* 代表任意可以移动光标的操作 #yy：复制多行 Y：复制整行 粘贴指令（p，paste）\np：缓存区存的如果为整行，则粘贴当前光标所在行的下方；否则，粘贴至当前光标所在处的后面 p：缓存区存的如果为整行，则粘贴当前光标所在行的上方；否则，粘贴至当前光标所在处的前面 改变命令（c，change）\nc 相当于 d 剪切后使用 i 进入插入模式\nc：修改后切换成插入模式 c$： c^： c0： cb： ce： cw： #COMMAND： cc：删除当前行并输入新内容，相当于 S #cc：删除多行并进入插入模式 C：删除当前光标到行尾，并切换成插入模式，相对于 c$ 撤销更改（u）\nu：撤销最近的更改 #u：撤销之前#次更改 U：撤销光标落在这行后所有此行的更改 Ctrl+r：重做最后的“撤销”更改 .：重复前一个操作 n.：重复前一个操作 n 次 缩进命令\n\u003e\u003e：向右缩进一个 Tab \u003c\u003c：向左缩进一个 Tab #\u003e\u003e/#\u003c\u003c：向右/左缩进 # 个 Tab 其他命令\n#istrESC：粘贴 str # 次 \u003cstart position\u003e\u003ccommand\u003e\u003cend position\u003e COMMAND： y：复制 d：删除 gU：变大写 gu：变小写 示例： 0y$：从行首拷贝到行尾 ye：从当前位置拷贝到本单词的最后一个字符 di\"：光标在 \"\" 之间，则删除 \"\" 之间的内容 yi(：光标在 () 之间，则复制 () 之间的内容 vi[：光标在 [] 之间，则选中 [] 之间的内容 dtx：删除字符直到遇见光标后的第一个 x 字符 ytx：复制字符直到遇见光标后的第一个 x 字符 可将上方的 d，y 互换，达到相应效果\n扩展命令模式 地址定界 格式：:#COMMAND 或 :#,@COMMAND\n#：具体第#行\n#,@：从#行开始到 @ 行结束\n#,+@：从#行开始到 #+@ 行结束\n:2,+3：表示从 2 到 5 行 .：当前行\n$：最后一行\n:.,$-1：从当前行到倒数第二行 %：全文，相当于 1,$\n/pattern1/,/pattern2/：从第一次被 pattern1 匹配到的行开始，一直到被 pattern2 匹配到的行结束\n#,/pattern/：从第#行开始到第一次被 pattern 匹配到的行结束\n/pattern/,$：从第一次配 pattern 匹配到的行开始到文件结束\n使用方式：后跟一个编辑命令\nd： y： w file：将范围内的行另存至指定文件中 r file：在指定位置插入指定文件中的所有内容 查找 /PATTERN：从当前光标所在处向文件尾部查找 ?PATTERN：从当前光标所在处向文件顶部查找 n：与命令同方向 N：与命令反方向 查找并替换 s：在扩展模式下完成查找替换操作\n格式：:范围 s/要查找的内容/替换为的内容/修饰符 范围：可使用上方的地址界定格式 要查找的内容：可使用模式 替换为的内容：不能使用模式，但可以使用 \\1, \\2,...等后向引用；还可以使用 \u0026 引用前面查找时查找到的整个内容 修饰符： i：忽略大小写 g：全局替换，如果不指定，默认替换的只有每一行中的第一个 gc：全局替换，每次替换前询问 查找替换中的分隔符 / 可替换为其他字符，例如 s@/etc@/var@g s#/bin/nologin#/bin/nologin 练习：\n将 /etc/default/grub 文件中的 GRUB_CMDLINE_LINUX 行的引号内追加 xyz\n1 :%s/\\(.*CMD.*\\)\"/\\1 xyz\" 复制 /etc/profile 至 /tmp 目录，用查找替换命令删除 /tmp/profile 文件中的行首的空白字符\n复制 /etc/rc.d/init.d/functions 文件到 /tmp 目录，用查找替换命令为 /tmp/functions 的每行开头为空白字符的行的行首添加一个#号\n复制 /etc/fstab 到/tmp 目录，用查找替换命令为 /tmp/fstab 的每行不以#开头的行首添加一个#号\n1 :%s/^[^#]\\|^$/#\u0026 vim 寄存器 有 26 个命名寄存器和 1 个无命名寄存器，常存放不同的剪贴板内容，可以在不同会话间共享 寄存器名称a，b，...，z 使用格式：[次数]\"\u003c寄存器名称\u003e\u003cCOMMAND\u003e 3\"tyy：表示复制 3 行到 t 寄存器中 \"tp：表示将 t 寄存器内容粘贴 未指定寄存器，将使用无命名寄存器 有 10 个数字寄存器，用 0，1，...，9 表示，0 存放最近复制内容，1 存放最近删除内容。当新的文本变更和删除时，1 转存到 2，2 转存到 3，以此类推。数字寄存器不能在不同回话间共享 vim 的标记和宏（macro） ma：将当前位置标记为 a，26 个字母均可做标记，例如：mb，mc 等 'a：跳转到 a 标记的位置；实用的文档内标记方法，文档中跳跃编辑时很有用 qa：录制宏 a，a 为宏名称 q：停止录制宏 @a：执行宏 a @@：重新执行上次执行的宏 vim 编辑二进制文件 vim -b binaryfile：以二进制方式打开文件 :%!xxd：扩展命令模式下，利用 xxd 命令切换为可读的十六进制 :%!xxd -r：扩展命令模式下，利用 xxd 命令转换回二进制 可视化模式 允许选择的文本块\nv：面向字符 V：面向行 Ctrl+v：面向块 可视化键可用于与移动键结合使用： w，)，}，箭头等\n突出显示的文字可被删除，复制，变更，过滤，搜索，替换等\n多文件模式 vim FILE1 FILE2 FILE3 ...\n:next：下一个 :prev：前一个 :first：第一个 :last：最后一个 wall：保存所有 qall：退出所有 wqall：保存并退出所有 使用多个“窗口” 多文件分割：vim -o|-O FILE1 FILE2 ...\n-o：水平分割 -O：垂直分割 Ctrl+w，Arrow：在窗口间切换 单文件窗口分割\nCtrl+w s：split，水平分割 Ctrl+w v：vertical，垂直分割 Ctrl+w q：取消相邻窗口 Ctrl+w o：取消全部窗口 wqall：退出 定制 vim 的工作特性 配置文件：永久有效\n全局配置文件：/etc/vimrc 个人配置文件：~/.vimrc 扩展模式下进行设置：仅对当前 vim 进程有效\n行号 启用：set number，简写为 set nu 禁用：set nonumber，简写为 set nonu 忽略字符的大小写 启用：set ic 禁用：set noic 自动缩进 启用：set ai 禁用：set noai 智能缩进 启用：set smartindent，简写为 set si 禁用：set nosmartindent，简写为 set nosi 高亮搜索 启用：set hlsearch 禁用：set nohlsearch 语法高亮 启用：syntax on 禁用：syntax off 显示 Tab（^I）和换行符（$） 启用：set list 禁用：set nolist 文件格式 启用 windows 格式：set fileformat=dos，简写为 set ff=dos 启用 unix 格式：set fileformat=unix，简写为 set ff=unix 设置文本宽度 set testwidth=65 set wrapmargin=15 设置光标所在行的标识线 启用：set cursorline，简写为 set cul 禁用：set no cursorline 复制保留格式 启用：set paste 禁用：set nopaste 了解更多 set 帮助\n:help option-list :set 或 :set all vi/vim 内置帮助\n:help :help topic vimtutor 练习 在 vim 中设置 tab 缩进为 4 个字符 复制 /etc/rc.d/init.d/functions 文件至 /tmp 目录，替换 /tmp/functions 文件中的 /etc/sysconfig/init 为 /var/log 删除 /tmp/functions 文件中所有以 # 开头，且 # 后面至少有一个空白字符的行的行首的 # 号 ","description":"","tags":["Linux"],"title":"Linux 文本处理\u0026正则表达式\u0026Vim","uri":"/posts/linux/%E9%98%BF%E9%87%8C%E4%BA%91linux%E8%BF%90%E7%BB%B4%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/%E9%98%B6%E6%AE%B5%E4%B8%80-linux%E5%85%A5%E9%97%A8/linux-text-process-regular-expression-vim/"},{"categories":null,"content":"Docker 备份与迁移 以下列出三种方式，请根据实际需求选择其中的一种即可\n方式一：将容器提交为一个镜像 根据容器的改变创建一个新镜像\n语法：docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]] Options： -a, --author string：作者（例如：\"John Hannibal Smith hannibal@a-team.com\"） -c, --change list：将 Dockerfile 指令应用于创建的映像 -m, --message string：提交描述 -p, --pause：提交期间暂停容器（默认为 true） 示例\n提交容器为镜像\n1 docker commit old-container-id new-image-name 此时使用 docker images 即可查看到刚提交的镜像\n方式二：将容器导出为文件 导出容器的文件系统为一个 tar 压缩包\n语法：docker export [OPTIONS] CONTAINER Options： -o, --output string：写到文件而不是 STDOUT 导入 tar 包内容来创建文件系统映像\n语法：docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]] Options： -c, --change list：将 Dockerfile 指令应用于创建的映像 -m, --message string：为引入的镜像设置描述信息 示例\n将容器导出为 tar 包\n1 docker export -o /path/to/outfile.tar container-id 将已导出的 tar 包恢复成镜像\n1 docker import /path/to/outfile.tar new-image-name 方式三：将容器所用的镜像或镜像导出为文件 保存一个或多个镜像到 tar 压缩文件\n语法：docker save [OPTIONS] IMAGE [IMAGE...] Save one or more images to a tar archive（默认输出到 STDOUT） Options： -o, --output string：保存为一个文件，而不是输出到 STDOUT 从 tar 压缩包或 STDIN 加载一个镜像\n语法：docker load [OPTIONS] Options： -i, --input string：从文件中加载，而不是 STDIN -q, --quiet Suppress the load output 示例\n将容器所用的镜像导出为 tar 包\n1 docker save -o /path/to/outfile.tar postgres:10 将导出的 tar 包引入为镜像\n1 docker load -i /path/to/outfile.tar ","description":"","tags":["Docker"],"title":"Docker 备份与迁移","uri":"/posts/docker/docker-backup/"},{"categories":null,"content":"Git 提交规范 现在市面上比较流行的 git 的 commit message 方案时 约定式提交规范(ConventionalCommits)，其受到 Angular 提交准则 的启发，并很大程度上以其为依据。\n标准格式如下\n\u003ctype\u003e([scope]): \u003csubject\u003e \u003cBLANK LINE\u003e [body] \u003cBLANK LINE\u003e [footer] 格式说明\n\u003ctype\u003e([scope]): \u003csubject\u003e 称为页眉(head)，[body] 称为正文，[footer] 称为页脚。 页眉与正文，正文与页脚之间必须包含 1 个空行(\u003cBLANK LINE\u003e) 其中 type、subject、BLANK LINE 是必填信息，其他信息可选填 每次提交的信息不超过 100 个字符 type: 和 subject 之间包含 1 个空格 属性及其可选值说明 type(提交类型) 必填项，用来说明此次提交的类型\n提交类型可指定为下面其中的一个\n主要 type\nfeat：增加新的特征 fix：修复 bug Angular 提交准则中其他推荐 type\nbuild：对构建系统或者外部依赖项进行了修改 ci：对 CI 配置文件或脚本进行了修改 docs：对文档进行了修改 pref：提高性能的代码更改 refactor：既不是修复 bug 也不是添加特征的代码重构 style：不影响代码含义的修改，比如空格、格式化、缺失的分号等 test：增加确实的测试或者矫正已存在的测试 其他推荐 type\nimprovement：在不添加新功能或修复 bug 的情况下改进当前的实现 scope(作用域) 可填项，取值范围可以是任何指定提交更改位置的内容\nsubject(主题) 必填项，包括对本次修改的简洁描述\n填写准则：\n使用命令式，现在时态：“改变”不是“已改变”也不是“改变了” 不要大写首字母 不要在末尾填写句号 body(正文) 可填项，包括修改的动机以及和之前行为的对比\n填写准则：\n使用命令式，现在时态 对小的修改不做要求，但重大需求，更新等必须添加 body 来说明 多个改动可以换行说明，但是如果改动过多，建议分解为多个 commit 进行提交 footer(页尾) 可填项，主要包括对不兼容修改的说明以及引用提交的问题\n对不兼容修改的说明 不兼容修改指的是本次提交修改了不兼容之前版本的 API 或者环境变量，例如版本升级，接口参数减少，接口删除，迁移等。\n所有不兼容修改都必须在页尾中作为中断更改块提到，以 BREAKING CHANGES: 开头，后面跟 1 个空格，其余的信息就是对此次修改的描述，修改理由和修改注释。\n示例：\nBREAKING CHANGE: isolate scope bindings definition has changed and the inject option for the directive controller injection was removed. To migrate the code follow the example below: Before: 。。。 。。。 After: 。。。 。。。 The removed `inject` wasn't generaly useful for directives so there should be no code using it. 引用提交的问题(affect issue) 如果本次提交目的是修改 issue 的话，需要在页脚引用该 issue\n例如关闭 issue\nCloses #234 如果修改了多个 bug，以逗号隔开\nCloses #123, #245, #992 回滚设置 当此次提交包含回滚(revert)操作，那么页眉以 revert: 开头，同时在正文中添加 This reverts commit hash，其中 hash 值表示被回滚前的提交\nrevert:\u003ctype\u003e(\u003cscope\u003e)：\u003csubject\u003e \u003cBLANK LINE\u003e This reverts commit hash \u003cother-body\u003e \u003cBLANK LINE\u003e \u003cfooter\u003e 实现示例 只有页眉和页尾\nfeat: allow provided config object to extend other configs BREAKING CHANGE: `extends` key in config file is now used for extending other config files 只有页眉\ndocs: correct spelling of CHANGELOG 使用了作用域\nfeat(lang): added polish language 修复了 bug\nfix: minor typos in code see the issue for details on the typos fixed fixes issue #12 参考文档 git-guide\n","description":"","tags":["Git"],"title":"Git 提交规范","uri":"/posts/git/git-commit-specificate/"},{"categories":null,"content":"Linux 系统安装与基本操作 CentOS 安装 分区介绍 dev：device，这个目录中包含了所有 Linux 系统中使用的外部设备，比如硬盘，U 盘等。\n多个外部设备按如下方式命名:\n/dev/sda, /dev/sdb, ... /dev/sdz, /dev/sdaa ...\n基于 MBR 的分区类型：\n主分区：单块硬盘中最多分出 4 个主分区，其中只有一个是活动状态，用来引导计算机启动。命名 1-4 扩展分区：单块硬盘上最多 1 个，用来划分更小的分区(即逻辑分区)。扩展分区 + 主分区 \u003c=4，命名 1-4 逻辑分区：命名 5- 挂载：给分区分配一个目录名(这个目录名叫 mount point)，就叫挂载 mount\n分区规划：\n/：相当于 C 盘 /boot：存放引导数据，例如 linux kernel 等，利于修复。1G swap：交换分区，建议是物理内存的 2 倍。物理内存\u003e=8G 可以不设置或设置为 1-2G，随意。 /data：自定义分区，可选 ...：其他挂载点 文件验证 sha256sum /dev/sr0：计算下载文件的 sha256 码，可用于验证文件是否损坏\n安装过程中的快捷键 可以使用 Ctrl+Alt+F1~F6 来查看各种安装信息等。\n可以使用 cat /proc/meminfo 查看内存等信息，使用 Shift+Page Up/Page Down 翻页\n可以使用 cat /proc/partitions 查看分区信息\nrpm -qa | wc -l 查看安装了多少个包\nLinux 基本操作 init 3 切换到纯字符界面 init 5 切换到图形界面，需要登陆 字符界面和图形界面称为模式，可通过 runlevel 查看系统的运行模式\nstartx 也可以切换到图形界面，并且不需要登陆，该命令只是代表用户启动了一个应用，因此不需要登陆，并且不会修改运行模式。\ninit 的其他命令：\ninit 6 相当于 reboot init 0 相当于 poweroff(关机并断电)，halt(关机不断电) Ctrl+Alt+F1 切换回图形界面\nCtrl+Alt+FX 或 chvt X 临时切换到字符界面，X=[2, 6]\ntty 查看当前终端号\nwhoami 查看当前系统用户\nnmcli connection modify 网卡相关\ncat /etc/centos-release 或 lsb_release 查看操作系统版本\nuname -r 查看 Linux 内核版本\nlscpu 查看 CPU 配置\nfree -h 或 cat /proc/meminfo 查看内存信息，使用 Shift+Page Up/Page Down 翻页\nlsblk 查看硬盘信息\nmii-tool netcardName 查看指定(netcardName)网卡信息\nwho am i 查看的那个用户和终端以及登陆时间和 IP\nwho 查看当前已经登陆的账户信息\ncat /etc/shells 查看系统支持的 shell 类型\n/bin/sh 根据 shell 路径切换 shell\necho $SHELL 查看当前系统使用的 shell 类型\nexit 或 logout 或 Ctrl+D 退出登陆\nclear或 Ctrl+L 清屏\nhostname 查看主机名\n/etc/motd 修改每日提示语句(message of the day)\n用户登陆 设置开机自动登陆：\n修改 /etc/gdm/custom.conf，添加：\n1 2 3 4 5 [daemon] # 开启自动登陆 AutomaticLoginEnable=true # 自动登陆 root 用户 AutomaticLogin=root root 用户 一个特殊的管理账户 也被称为超级用户 root 已接近完整的系统控制 对系统损害几乎有无限的能力 除非必要，不要登陆为 root 普通(非特权)用户 权限有限 造成损害的能力比较有限 使用 id -u 根据 uid 来查看账号类型，0：管理员，1：普通用户\n终端(Terminal) 设备终端\n键盘鼠标显示器\n物理终端(/dev/console)\n控制台 console\n虚拟终端(tty：teletyperwriters，/dev/tty# #为[1-6])\ntty 可有 n 个，Ctrl+Alt+F[1-6]\n图形终端(/dev/tty7) startx，xwindows\nCentOS 6：Ctrl + Alt + F7 CentOS 7：在哪个终端启动，即位于哪个虚拟终端 串行终端(/dev/ttyS#)\nttyS\n伪终端(pty：pseudo-tty，/dev/pts/#)\npty，SSH 远程连接\n查看当前的终端设备\n1 tty 交互式接口 交互式接口：启动终端后，在终端设备附加一个交互式应用程序\nGUI：Graphic User Interface X protocol，window manager，desktop\nDesktop： GNOME(C，图形库 gtk) KDE(C++，图形库 qt) XFCE(轻量级桌面) CLI：Command Line Interface shell 程序(命令解释器)：sh(Stephen R. Bourne 史蒂夫·伯恩)，csh，tcsh，ksh(korn)，bash(bourn again shell)，zsh\n什么是 shell shell 是 Linux 系统的用户界面，提供了用户与内核进行交互操作的一种接口。\nshell 也被称为 Linux 的命令解释器(command interpreter)\nshell 是一种高级程序设计语言\nbash shell GNU Bourne-Again Shell(bash)是 GNU 计划中重要的工具软件之一，目前也是 Linux 标准的 shell，与 sh 兼容\nCentOS 默认使用\n显示当前使用的 shell\necho ${SHELL}\n显示当前系统使用的所有 shell\ncat /etc/shells\n命令提示符 命令提示符号：prompt\n1 2 3 [root@localhost ~]# # 管理员 $ 普通用户 显示提示符格式\n1 [root@localhost ~]# echo $PS1 修改提示符格式\n设置颜色：\n1 \\[\\e[F;Bm\\] 示例：\n1 2 白底黑字 \\[\\e[30;47m\\] 背景色和特殊背景可以同时使用，特殊背景可以同时使用多个，使用格式：\n1 \\[\\e[F;B;Bm\\] 示例：\n1 2 3 4 白底黑字高亮 \\[\\e[30;47;1m\\] 或 \\[\\e[30;1;47m\\] 白底黑字高亮闪烁 \\[\\e[30;47;5;1m\\] 或 \\[\\e[30;1;47;5m\\] 颜色说明\n字体颜色(F) 背景色(B) 特殊背景(B) 30 黑 40 黑 0 关闭所有颜色 31 红 41 深红 1 高亮 32 绿 42 绿 2 低亮 33 黄 43 黄 3 斜体 34 蓝 44 蓝 4 下划线 35 紫 45 紫 5 闪烁 36 深绿 46 深绿 6 闪烁 37 白 47 白 7 反显 null null 8 隐藏 null null 9 删除线 可将其放到任意提示符前面，来对他后面的命令提示符颜色进行修改\n命令提示符符号说明\n1 PS1=\"\\[\\e[1;5;41;33m\\][\\u@\\h \\W]\\\\$\\[\\e[0m\\]\" 符号 说明 \\e[F;Bm 设置颜色 \\u 当前用户名 \\H 主机名全称 \\h 主机名简称 \\W 当前工作目录基名 \\w 当前工作目录全名 \\d 当前日期，格式：weekday month date，例如：Fri Apr 03 \\t 24 小时格式时间，HH:mm:ss \\T 12 小时格式时间，HH:mm:ss \\A 24 小时格式时间，HH:mm \\v BASH 版本信息 \\! 命令历史数 \\# 开机后命令历史数 \\\\$ 用户身份提示字符 通过命令行修改，重新登陆后会失效，可通过添加文件的方式持久化修改：\n1 2 3 vi /etc/profile.d/xxx.sh 添加 PS1=\"\\[\\e[1;33m\\][\\u@\\h \\W]\\\\$\\[\\e[0m\\]\" 执行命令 输入命令后回车：\n提醒 shell 程序找到键入命令所对应的可执行程序或代码，并由其分析后提交给内核分配资源，将其运行起来。\n在 shell 中可执行的命令有两类\n内部命令：由 shell 自带的，而且通过某命令形式提供\nhelp 内部命令列表 enable 内部命令列表 enable cmd 启用内部命令 enable -n cmd 禁用内部命令 enable -n 查看所有禁用的内部命令 外部命令：在文件系统路径下有对应的可执行程序文件\n查看路径：which -a | --skip-alis 或 whereis 区别指定的命令是内部或外部命令\n1 type COMMAND 1 2 # 查看某个命令的列表 type -a COMMAND 当输入一个命令后，先去寻找内部命令，如果没有再去找外部命令\n执行外部命令 Hash 缓存表：\n系统初始 hash 表为空，当外部命令执行时，默认会从 PATH 路径下寻找该命令，找到后会将这条命令的路径记录到 hash 表中，当再次使用该命令时，shell 解释器首先会查看 hash 表，存在将执行之，如果不存在，将会去 PATH 路径下寻找，利用 hash 缓存表可大大提高命令的调用速率\nhash 常见用法：\nhash 显示 hash 缓存 hash -l 显示 hash 缓存，可作为输入使用 hash -p path name 将命令全路径 path 起别名为 name hash -t name 打印缓存中 name 的路径 hash -d name 清除 name 缓存 hash -r 清除缓存 shell 解析器查找命令优先级**：alias \u003e 内部命令 \u003e hash 表 \u003e $PATH**\n命令别名 显示当前 shell 进程所有可用的别名：\n1 alias 定义别名 NAME，其相当于执行命令 VALUE：\n1 alias NAME='VALUE' 在命令行中定义的别名，仅对当前 shell 进程有效\n如果想要永久有效，要定义在配置文件中：\n仅对当前用户有效：~/.bashrc 对所有用户有效：/etc/bashrc 编辑配置给出的新配置不会立即生效，bash 进程重新读取配置文件：\nsource /path/to/config_file . /path/to/config_cile 撤销别名：\n1 2 unalias [-a] NAME [name ...] -a 取消所有别名 如果别名同原命令同名，如果要执行原命令，可使用：\n1 2 3 4 5 6 \\ALIASNAME \"ALIASNAME\" 'ALIASNAME' command ALIASNAME # 只适合外部命令 /path/command 命令格式 格式：COMMAND [OPTIONS...] [ARGUMENTS...]\nOPTIONS：用于启动或关闭命令的某个或某些功能 短选项：-c 例如：-l，-h 长选项：--word 例如：--all，--human-readable ARGUMENTS：命令的作用对象，比如文件名，用户名等 注意：\n多个选项以及多个参数命令之间使用空白字符分隔 取消和结束命令执行：Ctrl+c，Ctrl+d 多个命令可以用 ; 符号分开 一个命令可以用 \\ 分成多行 日期和时间 Linux 的两种时钟：\n系统时钟：由 Linux 内核通过 CPU 的工作频率进行的 硬件时钟：主板 相关命令：\ndate：显示和设置系统时间 date +%s date -d @1509536033 date MMDDHHmmYYYY.ss hwclock，clock：显示硬件时钟 -s，--hctosys 以硬件时钟为准，校正系统时钟 -w，--systohc 以系统时钟为准，校正硬件时钟 时区： /etc/localtime\n1 2 [root@localhost ~]# ll /etc/localtime lrwxrwxrwx. 1 root root 35 Dec 30 23:45 /etc/localtime -\u003e ../usr/share/zoneinfo/Asia/Shanghai 调整时区\n1 2 3 4 5 6 7 # 查看所有时区 timedatectl list-timezones # 修改时区 timedatectl set-timezone Asia/Shanghai 或 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 与网络时间同步\n安装 ntp\n1 # yum install ntp 停止 ntpd 服务\n1 # systemctl stop ntpd 设置同步的网站\n1 # ntpdate ntp.api.bz 启动 ntpd 服务\n1 # systemctl start ntpd 同步硬件时钟与系统时钟相同\n1 # hwclock -w 设置 ntpd 服务开机启动\n1 # systemctl enable ntpd 查看当前时间信息\n1 # timedatectl 显示日历：\n1 2 3 4 cal cal -y cal 2019 cal 9 1752 ","description":"","tags":["Linux"],"title":"Linux 系统安装与基本操作","uri":"/posts/linux/%E9%98%BF%E9%87%8C%E4%BA%91linux%E8%BF%90%E7%BB%B4%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/%E9%98%B6%E6%AE%B5%E4%B8%80-linux%E5%85%A5%E9%97%A8/linux-install-and-basic-operate/"},{"categories":null,"content":"文件管理 文件系统结构元素 文件系统 文件和目录被组织成一个单根倒置树结构 文件系统从根目录开始，用 / 表示 根文件系统（rootfs）：root filesystem 文件名区分大小写（具体来说是由文件系统决定的，而不是操作系统决定） 以 . 开头的文件为隐藏文件 路径分隔符 / 文件有两类数据 元数据：metadata，就是文件的属性 数据：data，就是文件的具体内容 -文件系统分层结构：LSB（Linux Standard Base） FHS：Filesystem Hierarchy Standard http://www.pathname.com/fhs/ Linux 标准目录结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 / ├── bin ├── boot ├── dev ├── etc ├── home ├── lib ├── lib64 ├── media ├── mnt ├── proc ├── root ├── run ├── sbin ├── sys ├── tmp ├── usr └── var boot：引导文件存放目录，内核文件（vmlinuz），引导加载器(bootloader、grub)都存放在此目录\n1 2 Linux 内核： -rwxr-xr-x. 1 root root 8.9M Oct 22 03:34 vmlinuz-5.3.7-301.fc31.x86_64 dev：设备，例如硬盘，光盘等，也包含逻辑上的设备\n1 2 3 4 5 6 7 8 9 10 11 12 13 硬盘，b：block，块设备 brw-rw----. 1 root disk 8, 0 Jan 8 22:22 /dev/sda 光盘 字符设备，c：charactor，字符设备 crw-rw-rw-. 1 root root 1, 5 Jan 8 20:02 /dev/zero 黑洞，会吞噬所有东西 crw-rw-rw-. 1 root root 1, 3 Jan 8 20:02 /dev/null 用于产生随机数 crw-rw-rw-. 1 root root 1, 8 Jan 8 20:02 /dev/random etc：配置文件存放目录\nhome/USERNAME：普通用户家目录\n上图中 home 目录下包含三个用户的家目录，alice、bob、eve root：root 用户的家目录\nrun：运行中生成的数据\nbin：所有用户使用的基本命令；不能关联至独立分区，OS 启动即会用到的程序\nsbin：管理类的基本命令；不能关联至独立分区，OS 启动即会用到的程序\ntmp：临时数据\nusr：操作系统大部分的数据\nvar：variable data files，存放可变的内容\ncache：应用程序缓存数据目录 lib：应用程序状态信息数据 local：专用于为 /usr/local 下的应用程序存储可变数据 lock：锁文件 log：日志目录及文件 opt：专用于为 /opt 下的应用程序存储可变数据 run：运行中的进程相关数据，通常用于存储进程 pid 文件 spool：应用程序数据池 tmp：保存系统两次重启之间产生的临时数据 lib：启动时程序依赖的基本共享库文件以及内核模块文件（/lib/modules）\nlib64：专用于 x86_64 系统上的辅助共享库文件存放位置\nLinux 其他目录 proc：process，用于输出内核与进程信息相关的虚拟文件系统，不在内存上 sys：用于输出当前系统上硬件设备相关信息的虚拟文件系统 虚拟机刷新硬盘 echo '- - -' \u003e /sys/class/scsi_host/hostX/scan X 为对应的数字 mnt：mount，做外围设备挂载点 media：便携式移动设备挂载点 selinux：security enhanced Linux，selinux 相关的安全策略等信息的存储位置 Linux 上的应用程序的组成部分 二进制程序：/bin、/sbin、/usr/bin、/usr/sbin、/usr/local/bin、/usr/local/sbin 库文件：/lib、/lib64、/usr/lib、/usr/lib64、/usr/local/lib、/usr/local/lib64 配置文件：/etc、/etc/DIRECTORY、/usr/local/etc 帮助文件：/usr/share/man、/usr/share/doc、/usr/local/share/man、/usr/local/share/doc 文件名规则 文件名最长 255 个字节 包括路径在内文件名称最长 4095 个字节 蓝色-\u003e目录 绿色-\u003e可执行文件 红色-\u003e压缩文件 浅蓝色-\u003e链接文件 灰色-\u003e其他文件，在 /etc/DIR_COLORS 文件中配置 除了斜线和 NUL，所有字符都有效。但使用特殊字符的目录名和文件不推荐使用，有些字符需要用引号来引导他们 -标准 Linux 文件系统（如 ext4），文件名大小写敏感 例如：MAIL，Mail，mail，mAil Linux 下的文件类型 - 普通文件 d 目录文件 b 块设备 c 字符设备 l 符号链接文件 p 管道文件 pipe s 套接字文件 socket 显示当前工作目录 每个 shell 和系统进程都有一个当前的工作目录\nCWD：current work directory\n显示当前 shell CWD 的绝对路径\npwd：printing working directory\n1 2 -P 显示真实物理路径 -L 显示链接路径（默认） 绝对和相对路径\n绝对路径 以正斜杠开始 完整的文件的位置路径 可用于任何想指定一个文件名的时候 相对路径 不以斜线开始 指定相对于当前工作目录或某目录的位置 可以作为一个简短的形式指定一个文件名 基名：basename 1 2 $ basename /etc/sysconfig/network-scripts/ \u003e network-scripts 目录名：dirname 1 2 $ dirname /etc/sysconfig/network-scripts/ \u003e /etc/sysconfig 更改目录 cd：change directory，改变目录\n使用绝对或相对路径：\n1 2 cd /home/wang/ cd home/wang 切换至父目录：cd ..\n切换至当前用户主目录：cd 或 cd ~\n切换至指定用户主目录：cd ~username\n切换至以前的工作目录：cd -\n选项：-P，切换到软链接的真实目录\n相关的环境变量：\nPWD：当前目录路径，echo $PWD OLDPWD：上一次目录路径，echo $OLDPWD 列出目录内容 ls 列出当前目录的内容或指定目录\n用法：ls [options] [files_or_dirs] 示例： ls -a 显示隐藏文件 ls -l 显示额外的信息 ls -R 目录递归通过，列出所有子目录 ls -ld 目录和符号链接信息，显示目录本身属性 ls -1 文件分行显示 ls -S 按文件从大到小排序 ls -t 按 mtime（modify time）排序 ls -u 配合-t 选项，显示并按 atime（access time）从新到旧排序 ls -U 按文件创建时间排序 ls -X 按文件后缀排序 ls -r 反转顺序 ls --time=mtime/atime/ctime 显示修改/访问/元数据改变时间 stat file 同时显示修改，访问，元数据改变时间 查看文件状态 stat\n用法：Usage: stat [OPTION]... FILE...\n文件：\nmetadata：元数据，文件的属性 data：数据，文件的真实数据 三个时间戳：\naccess time：访问时间，atime，读取文件内容 modify time：修改时间，mtime，改变文件内容（数据） change time：改变时间，ctime，元数据发生改变 文件通配符 * 匹配零个或多个字符 ? 匹配任何单个字符 ~ 当前用户家目录 ~mage 用户 mage 的家目录 ~+ 当前工作目录 ~- 前一个工作目录 [0-9] 匹配数字范围 [a-z] 字母 [A-Z] 字母 [abcd] 匹配列表中的任何一个字符 [^abcd] 匹配列表中的所有字符以外的字符 预定义的字符类 man 7 glob [:digit:] 任意数字，相当于 0-9 [:lower:] 任意小写字母 [:upper:] 任意大写字母 [:alpha:] 任意大小写字母 [:alnum:] 任意数字或字母 [:blank:] 水平空白字符 [:space:] 水平或垂直空白字符 [:punct:] 标点符号 [:print:] 可打印字符 [:cntrl:] 控制（非打印）字符 [:graph:] 图形字符 [:xdigit:] 十六进制字符 [[:lower:]] 代表一小写字母 练习\n显示 /var 目录下所有以 l 开头，以一个小写字母结尾，且中间出现至少一位数字的文件或目录\n1 ls -d /var/l*[[:digit:]]*[[:lower:]] 显示 /etc 目录下以任意一位数字开头，且以非数字结尾的文件或目录\n1 ls -d /etc/[0-9]*[^0-9] 显 /etc 目录下以非字母开头，后面跟了一个字母及其他任意长度任意字符的文件或目录\n1 ls -d /etc/[^[:alpha:]][[:alpha:]]* 显示 /etc 目录下所有以 rc 开头，并后面是 0-6 之间的数字，其他为任意字符的文件或目录\n1 ls -d /etc/rc[0-6]* 显示 /etc 目录下，所有以 .d 结的文件或目录\n1 ls -d /etc/*d 显示 /etc 目录下，所有以 .con 结尾，且以 m，n，r，p 开头的文件或目录\n1 ls -d /etc/[mnrp]*.con 只显示 /root 下的隐藏文件和目录\n1 2 ls -d /root/.* ls -daI \"[^.]*\"\" 只显示 /etc 下的非隐藏目录\n1 ls -d /etc/*/ 创建和查看文件 创建空文件和刷新时间 touch 命令\n格式：touch [OPTION] ... FILE ... -a 仅改变 atime 和 ctime -m 仅改变 mtime 和 ctime -t [[CC]YY]MMDDhhmm[.ss] 指定 atime 和 mtime 的时间戳 -c 如果文件不存在，则不予创建 练习\n创建 -a 文件 1 touch -- -a 或 touch ./-a 创建 ~filename 文件 1 touch '~filename' 或 touch ./~filename 复制，转移和删除文件 复制文件和目录 cp（copy） 语法：\ncp [OPTION]... [-T] SOURCE DEST cp [OPTION]... SOURCE... DIRECTORY cp [OPTION]... -t DIRECTORY SOURCE... 目标\n/\n源 不存在 存在且为文件 存在且为目录 一个文件 新建 DEST，并将 SRC 中内容填充至 DEST 中 将 SRC 中的内容覆盖至 DEST 中\n注意数据丢失风险! 建议用 -i 选项 在 DEST 下新建与原文件同名的文件，并将 SRC 中内容填充至新文件中 多个文件 提示错误 提示错误 在 DESC 下新建与原文件同名的文件，并将原文件内容复制进新文件中 目录\n需使用 -r 选项 创建指定 DEST 同名目录，复制 SRC 目录中所有文件至 DEST 下 提示错误 在 DEST 下新建与原目录同名的目录，并将 SRC 中内容复制至新目录中 常用选项：\n-i 覆盖前提示 -n 不覆盖 -r，-R 递归复制目录及内部的所有内容 -a 归档，相当于 -dR --preserv=all -d 不复制原文件，只复制链接名，相当于 --no-dereference --preserv=links -p 等同 --preserv=mode,ownership,timestamp -v --verbose 打印复制过程 -f --force 强制复制，如果会覆盖原文件，不会有提示 -u --update 只复制比目标更新或不存在的文件 -b 目标存在，覆盖前先备份 --backup=numbered 目标存在，覆盖前先备份，加数字后缀 --preserv[=ATTR_LIST] mode 权限 ownership 属主属组 timestamp links xatt context all 特殊文件使用 cp 会出问题，例如 cp /dev/sdb ./，该命令会将整个硬盘复制过来，应该使用 cp -a /dev/sdb命令，复制所有属性，8 代表设备类型，16 代表该设备的编号\n1 2 3 4 5 6 7 8 9 10 11 [root@localhost ~]# ll -a /dev/sdb brw-rw----. 1 root disk 8, 16 Jan 13 19:58 /dev/sdb [root@localhost ~]# cp /dev/sdb . 立即 Ctrl+C [root@localhost ~]# ll -a /dev/sdb ./sdb brw-rw----. 1 root disk 8, 16 Jan 13 19:58 /dev/sdb -rw-r-----. 1 root root 101433344 Jan 13 21:09 ./sdb [root@localhost ~]# cp -a /dev/sdb . [root@localhost ~]# ll -a /dev/sdb ./sdb brw-rw----. 1 root disk 8, 16 Jan 13 19:58 /dev/sdb brw-rw----. 1 root disk 8, 16 Jan 13 19:58 ./sdb 练习\n定义别名命令 baketc，每天将 /etc/ 目录下所有文件，被分到 /app 独立的子目录下，并要求子目录格式为 backupYYYY-mm-dd，备份过程可见\n1 2 3 mkdir /app/ alias baketc='cp -av /etc/ /app/backup`date +%F`' baketc 创建 /app/rootdir 目录，并复制 /root 下所有文件到该目录内，要求保留原有权限\n1 2 mkdir /app/rootdir cp -rp /root/ /app/rootdir 复制 file，file.bak\n1 cp file{,.bak} 相当于 cp file file.bak 移动和重命名文件 mv（move） 语法\nmv [OPTION]... [-T] SOURCE DEST mv [OPTION]... SOURCE... DIRECTORY mv [OPTION]... -t DIRECTORY SOURCE... 常用选项\n-i 交互式 -f 强制 -b 目标存在，复制前先备份 rename\nrename [options] \u003cexpression\u003e \u003creplacement\u003e \u003cfile\u003e... 把 *.conf 文件中的 conf 替换为 conf.bak\n1 rename conf conf.bak *.conf 删除 rm（remove） 语法\nrm [OPTION]... [FILE]... 常用选项\n-i 交互式 -f 强制删除 -r 递归删除 --no-preserve-root 不保留根，从/目录开始删除 示例\nrm -rf /\n练习\n将 rm file 命令修改为 mv file /data\n1 alias rm='mv -t /data' 删除目录下的 -foo 文件\nrm -- -foo 或 rm ./-foo 已被删除但未释放空间的操作\n在 /boot 目录下创建一个 800M 的 bigfile 文件，if(input file), of(output file), bs(block store), count\n1 dd if=/dev/zero of=/boot/bigfile bs=1M count=800 查看已被删除，但没有释放的文件\n1 lsof | grep deleted 将已存在的文件内存置为 0\n1 \u003e /boot/bigfile 目录操作 tree 显示目录树\n-d 只显示目录 -L level 指定显示的层级数目 -P 只显示由指定 pattern 匹配到的路径 mkdir（make directory） 创建目录 - -p parent，如果存在不报错，不存在会创建当前目录及父级目录 - -v 显示详细信息 - -m MODE 创建目录时直接指定权限\nrmdir（remove directory） 删除空目录 - -p 递归删除父空目录 - -v 显示详细信息\nrm -f 递归删除目录树\n练习\n如何创建 /testdir/dir1/x，/testdir/dir1/y，/testdir/dir1/x/a，/testdir/dir1/x/b，/test/dir1/y/a，/testdir/dir1/y/b\n1 2 3 4 5 6 7 8 9 10 /testdir └── dir1 ├── x │ ├── a │ └── b └── y ├── a └── b mkdir -p /testdir/dir1/{x,y}/{a,b} 如何创建 /testdir/dir2/x，/testdir/dir2/y，/testdir/dir2/x/a，/testdir/dir2/x/b\n1 2 3 4 5 6 7 8 /testdir └── dir2 ├── x │ ├── a │ └── b └── y mkdir -p /testdir/dir2/{x/{a,b},y} 如何创建 /testdir/dir3，/testdir/dir4，/testdir/dir5/dir6，/testdir/dir5/dir7\n1 2 3 4 5 6 7 /testdir ├── dir3 ├── dir4 └── dir5 ├── dir6 └── dir7 mkdir -p /testdir/dir{3,4,5/dir{6,7}} 索引节点 索引节点介绍 inode（index node）：索引节点表中包含文件系统所有文件列表\n一个节点（索引节点）是索引节点表中的一个表项，包含有关文件的信息(元数据)，包括：文件类型，权限，UID，GID 链接数（指向这个文件名路径名称个数）\n该文件的大小和不同的时间戳 指向磁盘上文件的数据块指针 有关文件的其他数据 文件和目录\n文件引用是一个 inode 号 人是通过文件名来引用一个文件，计算机使用 inode 一个目录是目录下所有文件的文件名和文件 inode 号之间的映射 inode 表结构 前 12 个直接指针，直接之上内存的数据区域\n如 Blocks 大小为 4096B，则前 12 个直接指针就可以保存 48KB 文件\n一级指针可存储文件大小计算\n假设每个指针占用 4 个字节，则一级指针指向的 Block 可保存 4096/4 个指针，即可指向 1024 个 Block，一级指针可存储文件数据大小为 1024*4096=4MB\n二级指针可存储文件大小计算\n同样假设 Blocks 大小为 4094，则二级指针可保存的 Block 指针数量为(4096/4)*(4096/4)=1014*1024，则二级指针可保存的文件数量大小为(1024*1024)*4096=4GB\n三级指针可存储文件大小计算\n以一级，二级指针计算方法类推，三级指针可存储的文件数据大小为(1024*1024*1024)*4096=4TB\n示例 查看每个分区最大的节点编号\n1 2 3 4 5 [root@localhost ~]# df -i Filesystem Inodes IUsed IFree IUse% Mounted on ... /dev/vda1 524288 326 523962 1% /boot ... 查看每个分区的容量\n1 2 3 4 5 [root@localhost ~]# df -h Filesystem Size Used Avail Use% Mounted on ... /dev/vda1 1014M 136M 879M 14% /boot ... 可知/boot 目录的最大节点编号为 524288，最大可用内存为 879M\n此时，在/boot 文件夹中创建一个大文件，每块 1M，创建 900 块，共占用 900M\u003e879M\n1 dd if=/dev/zero of=/boot/bigfile bs=1M count=900 错误提示：\n1 2 3 4 dd: error writing‘/boot/bigfile’: No space left on device 878+0 records in 877+0 records out 919797760 bytes (920 MB) copied, 1.58615 s, 580 MB/s 此时，节点编号还有剩余，硬盘内存已被占满\n1 2 3 4 5 6 7 8 9 10 [root@localhost ~]# df -i Filesystem Inodes IUsed IFree IUse% Mounted on ... /dev/vda1 2192 327 1865 15% /boot ... [root@localhost ~]# df -h Filesystem Size Used Avail Use% Mounted on ... /dev/vda1 1014M 1014M 840K 100% /boot ... 删除刚创建的大文件，还原到初始环境\n1 [root@localhost ~]# rm -f /boot/bigfile 因为/boot下最多包含 524288 个节点，因此创建 524288 万个文件进行测试（1 个文件可能占用多个节点编号）\n1 [root@localhost ~]# echo /boot/dir/f{1..524288} | xargs touch 错误提示\n1 2 3 4 5 touch: cannot touch‘f523963’: No space left on device touch: cannot touch‘f523964’: No space left on device ... touch: cannot touch‘f524287’: No space left on device touch: cannot touch‘f524288’: No space left on device 此时，硬盘内存并未占满，节点号已经用光了\n1 2 3 4 5 6 7 8 9 10 [root@localhost boot]# df -h Filesystem Size Used Avail Use% Mounted on ... /dev/vda1 1014M 411M 604M 41% /boot ... [root@localhost boot]# df -i Filesystem Inodes IUsed IFree IUse% Mounted on ... /dev/vda1 524288 524288 0 100% /boot ... 还原环境\n1 [root@localhost boot]# rm -rf /boot/dir/* 内存占满或节点耗尽的提示均为：\n1 No space left on device mv，cp 与 inode 的关系 mv 与 inode 关系 mv 一个文件时\n链接数递减，从而释放的 inode 号可以被重用 把数据块放在空闲列表中 删除目录项 数据实际上不会马上删除，但当另一个文件使用数据块时将被覆盖 cp 与 inode 关系 cp 一个文件时\n分配一个空闲的 inode 号，在 inode 表中生成新条目 在目录中创建一个目录项，将名称与 inode 编号关联 拷贝数据，生成新文件 软链接和硬链接 硬链接 对一个文件起多个名字\n创建硬链接会增加额外的记录项以引用文件 对应与同一文件系统上一个物理文件 每个文件引用相同的 inode 号 创建时链接数递增 删除文件时 rm 命令递减链接计数 文件要存在，至少有一个链接数 当链接数为 0 时，该文件被删除 不能跨驱动器或分区创建 语法： 1 ln filename [linkname] 软链接（符号链接） 相当于 Windows 上的桌面快捷方式\n一个符号链接指向另一个文件 ls -l 显示链接的名称和引用的文件 一个符号链接的内容是它引用文件的名称 可以对目录创建软链接 可以跨分区 指向的是另一个文件的路径；齐大小为指向的路径字符串的长度；不增加或减少目录文件 inode 的引用计数； 语法 1 ln -s filename [linkname] filename 一般使用相对路径，该相对路径一定是相对于 linkname 指定文件的路径 硬链接和软链接的区别 硬链接和原文件是同一个文件，只是名称不同 硬链接不能跨分区创建，软链接可以跨分区创建 硬链接会增加链接数，软链接不会增加链接数 硬链接的 inode 号与原文件相同，软链接有自己的 inode 号 删除原文件，通过硬链接依旧可以访问文件，而软链接不可以 硬链接的大小就是原文件的大小，软链接文件的大小是其链接文件的路径大小 硬链接不支持目录，软链接支持目录（目录默认链接数为 2，因为其内有一个 . 目录，代表当前目录） 硬链接的相对路径是相对当前所在目录，软链接的相对路径是相对被链接文件的相对路径 确定文件内容 文件可以包含多种类型的数据。检查文件的类型，然后确定适当的打开命令或应用程序使用\n语法：file [options] \u003cfilename\u003e ...\n常用选项：\n-b 列出文件辨识结果时，不显示文件名称 -f filelist 列出 filelist 文本文件中包含的文件名的文件类型 -F 使用指定分隔符号替换输出文件名后默认的 : 分割符 -L 查看对应软链接对应文件的文件类型 --help 显示命令在线帮助 每个文件的头部都包含 magic number（魔数），根据魔数可知文件的类型\n标准 IO 及管道 标准输入和输出 程序：指令 + 数据\n读入数据：Input 输出数据：Output -打开的文件都有一个fd：file descriptor（文件描述符） Linux 给程序提供三种 I/O 设备\n标准输入（STDIN）：0，默认接受来自键盘的输入 标准输出（STDOUT）：1，默认输出到终端窗口 标准错误（STDERR）：2，默认输出到终端窗口 I/O 重定向：改变默认位置\n**文件描述符：**每个运行中的程序都有一个进程号，在 /proc/进程号/fd 目录下即可看到该进程的输出输出等信息\n把输出和错误重定向到文件 STDOUT 和 STDERR 可以被重定向到文件\n语法：命令 操作符号 文件名\n支持的操作符包括\n\u003e，1\u003e，\u003e\u003e，1\u003e\u003e 把 STDOUT 重定向到文件 2\u003e，2\u003e\u003e 把 STDERR 重定向到文件 \u0026\u003e，\u0026\u003e\u003e 把所有输出重定向到文件 \u003e 覆盖重定向标准输出数据流\n使用 set -C 命令禁止将内容覆盖到已有文件，但可追加 使用 \u003e| file 强制覆盖 使用 set +C 允许覆盖 \u003e\u003e 追加重定向标准输出数据流\n2\u003e 覆盖重定向标准错误输出数据流\n2\u003e\u003e 追加重定向标准错误输出数据流\n将标准输出和标准错误输出重定向不同位置\n1 2 3 COMMAND \u003e /path/to/file.out 2\u003e /path/to/error.out 例如 $ ls /existfile /noexistfile \u003e file1 2\u003e file2 合并标准输出和错误输出为同一个数据流进行重定向\n将标准输出和标准错误输出重定向到 file\n1 2 3 4 5 6 $ ls /existfile /noexistfile \u0026\u003e file 或 $ ls /existfile /noexistfile \u003e file 2\u003e\u00261 第二种需要注意顺序， $ ls /existfile /noexistfile 2\u003e$1 \u003e file 此种情况将标准错误重定向到标准输出后，会立即将错误信息输出到控制台，然后将之后的标准输出再输出到文件 将标准输出和错误输出都隐藏\n1 2 3 $ ls /existfile /noexistfile \u0026\u003e /dev/null $ ls /existfile /noexistfile \u003e /dev/null 2\u003e\u00261 $ ls /existfile /noexistfile 2\u003e /dev/null \u003e\u00262 () 合并多个程序的 STDOUT\n1 (cal 2007;cal 2008) \u003e all.txt 将文件的内容作为标准输入 \u003c 将标准输入重定向\n某些命令能够接受从文件中导入的 STDIN\ntr 'a-z' 'A-Z' \u003c /etc/issue\n此命令会把/etc/issue 中的小写字符都转换成大写字符\n\u003c\u003ck 多行输入重定向，k 代表终止词，一般使用 EOF，即 \u003c\u003cEOF，End Of File\n直到 k 位置的所有文本都发送给 STDIN\n有时被称为就地文本（heretext）\n1 2 3 4 5 6 7 8 9 $ mail -s \"Please Call\" admin@example.com \u003c\u003cEND \u003e Hi Wang, \u003e \u003e Please give me a call when you yet in. We may need \u003e to do some maintenance on server1 \u003e \u003e Details when you're on-site \u003e Zhang \u003e END tr 命令 语法：tr [OPTION]... SET1 [SET2] 转换和删除字符\n选项：\n-c，-C，--complement：取字符集的补集 -d，--delete：删除所有属于第一字符集的字符 -s，--squeeze-repeats：把连续重复的字符以单独一个字符表示 -t，--truncate-set1：将第一个字符集对应字符转化为第二字符集对应的字符 SET 的值：\n\\NNN：八进制 \\\\：反斜线 \\a：audible BEL \\b：退格键 \\f：form feed \\n：换行符 \\r：回车符 \\t：水平的 Tab 键 \\v：垂直的 Tab 键 CHAR1-CHAR2：ASCII 表中从 CHAR1 到 CHAR2 的所有字符 [CHAR*]：in SET2，copies of CHAR until length of SET1 [CHAR*REPEAT]：REPEAT copies of CHAR，REPEAT octal if starting with 0 [:alnum:]：字母和数字 [:alpha:]：字母 [:blank:]：all horizontal whitespace [:cntrl:]：控制（非打印）字符 [:digit:]：数字 [:graph:]：可打印的图形字符，不包括空白字符 [:lower:]：小写字母 [:print:]：可打印的字符，包括空白字符 [:punct:]：标点符号 [:space:]：空白字符 [:upper:]：大写字母 [:xdigit:]：十六进制字符 [=CHAR=]：all characters which are equivalent to CHAR 管道 管道（使用符号 | 表示），用来连接命令\n语法：命令 1 | 命令 2 | 命令 3 | ...\n将命令 1 的 STDOUT 发送给命令 2 的 STDIN，命令 2 的 STDOUT 发送给命令 3 的 STDIN\nSTDERR 默认不能通过管道转发，可利用 2\u003e\u00261 或 |\u0026 实现\n最后一个命令会在当前 shell 进程的子 shell 进程中执行用来\n组合多种工具的功能：ls | tr 'a-z' 'A-Z'\n一些支持管道的命令\nless：一页一页地查看输入\n1 ls -l /etc | less mail：通过电子邮件发送输入\n1 echo \"test email\" | mail -s \"test\" user@example.com lpr：把输入发送给打印机\n1 echo \"test print\" | lpr -P printer_name 管道中的 - 符号\n示例：将 /home 里面的文件打包，但打包的数据不是记录到文件，而是传送到 stdout，经过管道后，将 tar -cvf - /home 传送给后面的 tar -xvf -，后面的这个 - 则是取前一个命令的 stdout，因此，就不需要使用临时 file 了\n1 $ tar -cvf - /home | tar -xvf - 重定向到多个目标（tee）\n命令 1 | tee [-a] 文件名 | 命令 2\n把命令 1 的 STDOUT 保存在文件中，作为命令 2 的输入 -a 追加\n使用：\n保存不通阶段的输出 复杂管道的故障排除 同时查看和记录输出 练习 将 /etc/issue 文件中的内容转换为大写后保存至 /tmp/issue.out 文件中\n1 $ tr a-z A-Z \u003c /etc/issue \u003e /tmp/issue.out 将当前系统登录用户的信息转换为大写后保存至 /tmp/who.out 文件中\n1 2 3 4 $ whoami \u003e whoami $ tr a-z A-z \u003c whoami \u003e /tmp/who.out 或 $ whoami | tr a-z A-Z \u003e /tmp/who.out 一个 linux 用户给 root 发邮件，要求邮件标题为“help”，邮件正文如下：“Hello, I am 用户名. The system version is here, please help me to check it, thanks! 操作系统版本信息”\n1 2 3 [username@local ~]$ mail -s \"help\" root \u003c\u003cEOF \u003e Hello, I am $USER. The system version is here, please help me to check it, thanks! `cat /etc/centos-release` \u003e EOF 将 /root/ 下文件列表显示成一行，并且文件名之间用空格隔开\n1 2 3 4 $ ls \u003e ls.txt $ tr -t '\\n' ' ' \u003c ls.txt 或 $ ls | tr -t '\\n' ' ' 计算 1+2+3+...+99+100 的总和\n1 2 3 4 5 $ echo {1..100} \u003e sum.txt $ tr -t ' ' '+' \u003c sum.txt \u003e rep.txt $ bc \u003c rep.txt 或 $ echo {1..100} | tr -t ' ' '+' | bc 删除 Windows 文本文件中的 ^M 字符\n1 $ tr -d ^M \u003c Windows 处理字符串 “xt.,l 1 jr#!\u0026.logmn2 c*/fe 3 uz 4”, 只保留其中的数字和空格\n1 $ echo 'xt.,l 1 jr#!\u0026.logmn2 c*/fe 3 uz 4' | tr -dc '[0-9 ]' 将 PATH 变量每个目录显示在独立的一行\n1 2 3 4 $ echo $PATH \u003e PATH.txt $ tr -t : '\\n' \u003c PATH.txt 或 $ echo $PATH | tr -t : '\\n' 将指定文件中 0-9 分别替换成 a-j\n1 $ tr -t 0-9 a-j \u003c file 将文件 /etc/cenos-release 中每个单词（由字母组成）显示在独立一行，并无空行\n文件查找和压缩 locate 命令 locate 命令依赖与 mlocate 数据库进行搜索，对新创建或刚删除的数据不会立即更新数据库，因此可能搜索不到或搜索到已删除的数据，可以使用updatedb 命令来手动更新 mlocate 数据库。\nlocate 命令搜索很快，因此适合搜索磁盘上稳定不变的数据。\n语法：locate [OPTIONS]... KEYWORD 选项 -i：不区分大小写的搜索 -n N：只列举前 N 个匹配项目 -r：使用正则表达式 find 命令 实时查找工具，通过遍历指定路径完成文件查找\n工作特点\n查找速度略慢 精确查找 实时查找 可能只搜索用户具备读取和执行权限的目录 语法：find [OPTION]... [查找路径] [查找条件] [处理动作]\n查找路径：指定具体目标路径；默认为当前目录 查找条件：指定的查找标准，可以文件名，大小，类型，权限等标准进行；默认为找出指定路径下的所有文件 处理动作：对符合条件的文件做操作，默认输出至屏幕 查找条件\n指定搜索层级 maxdepth level：最大搜索目录深度，指定目录为第 1 级 mindepth level：最小搜索目录深度 先处理目录内的文件，再处理目录 depth 根据文件名和 inode 查找： -name \"文件名称\"：支持使用通配符，*，?，[]，[^] -iname \"文件名称\"：不区分字母大小写 -inum n：按 inode 号查找 -samefile name：相同 inode 号的文件 -links n：链接数为 n 的文件 -regex \"PATTERN\"：以 PATTERN 匹配整个文件路径，而非文件名称 根据属主，属组查找 -user USERNAME：查找属主为指定用户（UID）的文件 -group GRPNAME：查找属组为指定组（GID）的文件 -uid UserID：查找属主为指定的 UID 号的文件 -gid GroupID：查找属组为指定的 GID 号的文件 -nouser：查找没有属主的文件 -nogroup：查找没有属组的文件 根据文件类型查找 -type TYPE f：普通文件 d：目录文件 l：符号链接文件 s：套接字文件 b：块设备文件 c：字符设备文件 p：管道文件 根据文件大小来查找： -size [+|-]#UNIT：常用单位：k、M、G、c（byte） #UNIT：(#-1, #), 如 6k 表示 (5k, 6k] -#UNIT：[0, #-1], 如 -6k 表示 [0, 5k] +#UNIX：(#, ∞), 如 +6k 表示 (6k, ∞) 空文件或目录 -empty：find /app -type d -empty 组合条件 -a：与 -o：或 -not，!：非 德·摩根定律 (非 A)或(非 B) = 非(A 且 B)\n(非 A)且(非 B) = 非(A 或 B) 示例：\n!A -o !B = !(A -a B) !A -a !B = !(A -o B)\n示例\nfind -name sonw.png find -iname snow.png find / -name \"*.txt\" find /var -name \"*log\" find -user joe -group joe find -user joe -not -group joe find -user joe -o -user jane find -not \\(-user joe -o -user jane\\) find / -user joe -o -uid 500 找出 /tml 目录下，属主不是 root，且文件名不以 f 开头的文件 1 2 find /tmp \\(-not -user root -a -not -name 'f*'\\) -ls find /tmp -not \\(-user root -o -name 'f*'\\) -ls 排除目录： 查找 /etc 下，除了 /etc/sane.d 目录的其他所有 .conf 后缀的文件\n1 find /etc -path 'etc/sane.d' -a -prune -o -name '*.conf' 查找 /etc 下，除了 /etc/sane.d 和 /etc/fonts 两个目录的所有 .conf 后缀的文件\n1 find /etc \\(-path 'etc/sane.d' -o -path 'etc/fonds'\\) -a -prune -o -name '*.conf' ","description":"","tags":["Linux"],"title":"文件管理","uri":"/posts/linux/%E9%98%BF%E9%87%8C%E4%BA%91linux%E8%BF%90%E7%BB%B4%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/%E9%98%B6%E6%AE%B5%E4%B8%80-linux%E5%85%A5%E9%97%A8/linux-file-manage/"},{"categories":null,"content":"关闭 Linux 警告声 可以通过下面的命令关掉它\n1 rmmod pcspkr 如果你想重新打开它，可以使用下面的方法\n1 modprobe pcspkr 当然，上面的方法只是临时起效，重新启动后 beep 依旧，彻底关掉 beep 的方法如下\n如果用的是 bash 作 shell，在 ~/.bashrc 的最后添加\n1 2 setterm -blength 0 xset -b 在 console 下\n1 setterm -blength 0 在 X-win 的 terminal 下\n1 xset -b 参考文档 去掉 linux 警告音 嘟嘟声 错误提示音关闭方法\n","description":"","tags":["Linux"],"title":"关闭 Linux 警告声","uri":"/posts/linux/linux-close-warn/"},{"categories":null,"content":"Hadoop 介绍 Hadoop 是什么 Hadoop 是一个由 Apache 基金会所开发的分布式系统基础架构。 主要解决，海量数据的存储和海量数据的分析计算问题。 广义上来说，Hadoop 通常是指一个更广泛的概念——Hadoop 生态圈。 Hadoop 发展史 Lucene 框架是 Doug Cutting 开创的开源软件，用 Java 书写代码，实现了与 Google 类似的全文搜索功能，它提供了全文检索引擎的架构，包括完整的查询引擎和索引引擎。\n2001 年年底，Lucene 成为 Apacha 基金会的一个子项目。\n对于海量数据的场景，Lucene 面对与 Google 同样的困难，存储数据困难，检索速度慢。\n学习和模仿 Google 解决这些问题的方法：微型版 Nutch。\n可以说 Google 是 Hadoop 的思想之源（Google 在大数据方面的三篇论文）\nGFS → HDFS Map-Resuce → MR BigTable → HBase 2003 年至 2004 年，Google 公开了部分 GFS 和 MapReduce 思想的细节，以此为基础 Doug Cutting 等人用了 2 年业余时间实现了 DFS 和 MapReduce 机制，使 Nutch 性能飙升。\n2005 年 Hadoop 作为 Lucene 的子项目 Nutch 的一部分正式引入 Apache 基金会。\n2006 年 2 月份，Map-Reduce 和 Nutch Distributed File System（NDFS）分别被纳入称为 Hadoop 的项目中。\n名称来源于 Doug Cutting 儿子的玩具大象。\nHadoop 就此诞生并迅速发展，标志着大数据时代的来临。\nHadoop 三大发行版本 Hadoop 三大发行版本：Apache、Cloudera、Hortonworks。\nApache 版本最原始（最基础）的版本，对于入门学习最好。 Cloudera 在大型互联网企业中用的较多，收费。 Hortonworks 文档较好。 Apache Hadoop 官网地址 下载地址 Cloudera Hadoop 官网地址 下载地址 2008 年成立的 Cloudera 是最早将 Hadoop 商用的公司，为合作伙伴提供 Hadoop 的商用解决方案，主要是包括支持、咨询服务、培训。 2009 年 Hadoop 的创始人 Doug Cutting 也加盟 Cloudera 公司。Cloudera 产品主要为 CDH、Coudera Manager、Cloudera Support。 CDH 是 Cloudera 的 Hadoop 发行版，完全开源，比 Apache Hadoop 在兼容性，安全性，稳定性上有所增强。 Cloudera Manager 是集群的软件分发及管理监控平台，可以在几小时内部署好一个 Hadoop 集群，并对集群的节点及服务进行实时监控。Cloudera Suppert 即是对 Hadoop 的技术支持。 Cloudera 的标价为每年每个节点 4000 美元。Cloudera 开发并贡献了可实时处理大数据的 Impala 项目。 Hortonworks Hadoop 官网地址 下载地址 2011 年成立的 Hortonworks 是雅虎与硅谷风投公司 Benchmark Capital 合资组建。 公司成立之初就吸纳了大约 25 名至 30 名专门研究 Hadoop 的雅虎工程师。上述工程师在 2005 年开始协助雅虎开发 Hadoop，贡献了 Hadoop 80% 的代码。 雅虎工程副总裁，雅虎 Hadoop 开发团队负责人 Eric Baldeschwieler 出任 Hortonworks 的首席执行官。 Hortonworks 的主打产品是 Hortonworks Data Platform（HDP），也同样是 100% 开源的产品，HDP 除常见的项目外还包括了 Ambari，一款开源的安装和管理系统。 HCatalog，一个元数据管理系统，HCatelog 现已集成到 Facebook 开源的 Hive 中。 Hadoop 的优势（4 高） 高可靠性：Hadoop 底层维护多个数据副本（至少 3 份），所以即使 Hadoop 某个计算元素或存储出现故障，也不会导致数据的丢失。 高扩展性：在集群分配任务数据，可方便的扩展数以千计的节点。 高效性：在 MapReduce 的思想下，Hadoop 是并行工作的，以加快任务的处理速度。 高容错性：能够自动将失败的任务重新分配。 Hadoop 组成（面试重点） Hadoop1.x 和 Hadoop2.x 区别 在 Hadoop1.x 时代，Hadoop 中的 MapResuce 同时处理业务逻辑运算和资源的调度，耦合性较大，在 Hadoop2.x 时代，增加了 Yarn。Yarn 只负责资源的调度，MapResuce 只负责运算。\nHDFS 架构概述 HDFS：Hdoop Distributed File System，Hadoop 分布式文件系统\nNameNode（nn）：存储文件的元数据，如文件名、文件目录结构、文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的 DataNode 等。\n相当于目录\nDataNode（dn）：在本地文件系统存储文件块数据，以及块数据的校验和。\n相当于目录指向的大量数据\nSecondary NameNode（2nn）：用来监控 HDFS 状态的辅助后台程序，每隔一段时间获取 HDFS 元数据的快照。\n辅助 NameNode 的\nYARN 架构 YARN：Yet Another Resource Negotiator，另一种资源协调者\nResourceManager（RM）主要作用如下\n处理客户端请求 监控 NodeManager 启动或监控 ApplicationMaster 资源的分配与调度 NodeManager（NM）主要作用如下\n管理单个节点上的资源 处理来自 ResourceManager 的命令 处理来自 ApplicationManager 的命令 ApplicationMaster（AM）作用如下\n负责数据的切分 为应用程序申请资源并分配给内部的任务 任务的监控与容错 Container Container 是 YARN 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。\nMapReduce 架构概述 MapReduce 将计算过程分为两个阶段：Map 和 Reduce\nMap 阶段并行处理输入数据 Reduce 阶段对 Map 结果进行汇总 大数据技术生态体系 Hadoop 推荐系统框架图 Hadoop 运行环境搭建 虚拟机环境准备 克隆虚拟机\n修改克隆虚拟机的静态 IP\n/etc/sysconfig/network-scripts/ifcfg-eth0\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 TYPE=\"Ethernet\" PROXY_METHOD=\"none\" BROWSER_ONLY=\"no\" BOOTPROTO=\"static\" IPADDR=\"192.168.122.101\" GATEWAY=\"192.168.122.1\" NETMASK=\"255.255.255.0\" DNS1=\"8.8.8.8\" DEFROUTE=\"yes\" IPV4_FAILURE_FATAL=\"no\" IPV6INIT=\"yes\" IPV6_AUTOCONF=\"yes\" IPV6_DEFROUTE=\"yes\" IPV6_FAILURE_FATAL=\"no\" IPV6_ADDR_GEN_MODE=\"stable-privacy\" NAME=\"eth0\" UUID=\"a5227980-3d9c-4718-8125-0b2023521442\" DEVICE=\"eth0\" ONBOOT=\"yes\" 修改主机名\n/etc/hostname\n192-168-122-101 在 /etc/hosts 文件中添加\n1 2 192.168.122.101 192-168-122-101 192.168.122.102 192-168-122-102 关闭防火墙\n1 systemctl stop firewalld 创建 hadooptest 用户\n1 useradd hadooptest 配置 hadooptest 用户具有 root 权限\n/etc/sudoers，在如下部分添加 hadooptest 用户\n1 2 3 ## Allow root to run any commands anywhere root ALL=(ALL) ALL hadooptest ALL=(ALL) ALL 在 /opt 目录下创建文件夹\n创建 module 和 software 文件夹\n将这两个文件夹所有者和所属组给 hadooptest 用户和 hadooptest 组\n安装 JDK，并设置环境变量 解压 software 文件夹中的 jdk-8u241-linux-x64.tar.gz 到 module 目录\n1 tar -zxvf /opt/software/jdk-8u241-linux-x64.tar.gz -C /opt/module 配置环境 ~/.bash_profile\n1 2 3 4 5 6 # Java Environment JAVA_HOME=/opt/module/jdk1.8.0_241 PATH=$JAVA_HOME/bin:$PATH CLASSPATH=.:$JAVA_PATH/lib export JAVA_HOME PATH CLASSPATH 使配置生效\n1 source ~/.bash_profile 安装 Hadoop 解压 software 文件夹中的 hadoop-2.7.7.tar.gz 到 module 目录\n1 tar -zxvf /opt/software/hadoop-2.7.7.tar.gz -C /opt/module 配置环境 ~/.bash_profile\n1 2 3 4 5 # Hadoop Environment HADOOP_HOME=/opt/module/hadoop-2.7.7 PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH export HADOOP_HOME PATH 使配置生效\n1 source ~/.bash_profile Hadoop 目录结构 bin： hadoop：管理 hadoop 集群 hdfs：管理 hdfs yarn：管理资源调度 etc：配置文件 include：其他代码的源文件 lib：本地库 sbin：hadoop 及集群的启动和停止 hadoop-daemon.sh： slaves.sh：启动集群时使用 start-all.sh：启动整个集群 start-dfs.sh：启动文件系统 start-yarn.sh：启动 yarn yarn-daemon.sh： stop-xxx.sh：停止 share： doc：说明文档 hadoop：官方提供的案例 Hadoop 运行模式 Hadoop 运行模式包括：本地模式，伪分布式模式以及完全分布式模式。\nHadoop 官方网站：http://hadoop.apache.org/\n本地运行模式 官方 Grep 案例 查找符合 'dfs[a-z.]+' 正则表达式的字段\n1 2 3 4 $ mkdir input $ cp etc/hadoop/*.xml input $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar grep input output 'dfs[a-z.]+' $ cat output/* 注：output 文件夹一定不能存在\n1 1\tdfsadmin 官方 WordCount 案例 创建输入文件夹\n1 $ mkdir wcinput 创建输入文件\n1 $ vim wcinput/wc.input 内容\ntianyi huichao lihua zhangchen xiaoheng xinbo xinbo gaoyang gaoyang yanjing yanjing 运行程序\n1 bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar wordcount wcinput wcoutput 查看结果\n1 cat wcoutput/* gaoyang\t2 huichao\t1 lihua\t1 tianyi\t1 xiaoheng\t1 xinbo\t2 yanjing\t2 zhangchen\t1 伪分布式模式 修改配置文件 etc/hadoop/hadoop-env.sh，修改 JAVA_HOME 位置\n1 2 3 4 5 6 7 8 9 # Set Hadoop-specific environment variables here. # The only required environment variable is JAVA_HOME. All others are # optional. When running a distributed configuration it is best to # set JAVA_HOME in this file, so that it is correctly defined on # remote nodes. # The java implementation to use. export JAVA_HOME=/opt/module/jdk1.8.0_241 etc/hadoop/core-site.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u003cconfiguration\u003e \u003c!-- 指定 HDFS 中 NameNode 的地址 --\u003e \u003cproperty\u003e \u003cname\u003efs.defaultFS\u003c/name\u003e \u003cvalue\u003ehdfs://localhost:9000\u003c/value\u003e \u003c/property\u003e \u003c!-- 指定 Hadoop 运行时产生文件的存储目录--\u003e \u003cproperty\u003e \u003cname\u003ehadoop.tmp.dir\u003c/name\u003e \u003c!-- 默认：/tmp/hadoop-${user.name} --\u003e \u003cvalue\u003e/opt/module/hadoop-2.7.7/data/tmp\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e etc/hadoop/hdfs-site.xml\n1 2 3 4 5 6 7 \u003cconfiguration\u003e \u003c!-- 指定 HDFS 副本的数量 --\u003e \u003cproperty\u003e \u003cname\u003edfs.replication\u003c/name\u003e \u003cvalue\u003e1\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e 如果只有 1 台服务器，value 设置为 \u003e1 的值，也只有 1 份备份。在添加足够节点后，会自动将指定数量的数据备份到其他节点\n启动集群 格式化 NameNode（第一次启动时格式化，以后就不要总格式化）\n1 $ bin/hdfs namenode -format 在格式化之前要关闭 NameNode 和 DataNode 进程，删除 data 和 logs 目录。\n执行结束后会创建 hadoop.tmp.dir 指定的文件夹，并在该目录下生成相应数据。\n启动 NameNode daemon 和 DataNode daemon\n1 2 $ sbin/hadoop-daemon.sh start namenode $ sbin/hadoop-daemon.sh start datanode 或\n1 $ sbin/start-dfs.sh hadoop daemon 的日志默认输出在 $HADOOP_LOG_DIR 目录（默认值为 $HADOOP_HOME/logs）。\n使用 jps 命令可以查看是否启动成功\n1 2 3 4 $ jps 3027 NameNode 3125 DataNode 3197 Jps NameNode 信息的浏览器访问接口，默认是：http://localhost:9870/ 或 http://localhost:50070/\n设置执行 MapReduce 作业所需的 HDFS 目录（集群使用的目录）\n1 2 3 4 5 $ bin/hdfs dfs -mkdir /user $ bin/hdfs dfs -mkdir -p /user/\u003cusername\u003e 示例 $ bin/hdfs dfs -mkdir -p /user/hadooptest/input 此时，可在通过访问 NameNode 信息的浏览器访问接口 Utilities → Browse the file system 查看创建的文件信息\n输入文件复制到分布式文件系统中：\n1 2 3 4 5 $ bin/hdfs dfs -mkdir input $ bin/hdfs dfs -put etc/hadoop/*.xml input 示例 $ bin/hdfs dfs -put etc/hadoop/*.xml /user/hadooptest/input 运行 hadoop 官方提供的 grep 示例\n1 2 3 4 $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar grep input output 'dfs[a-z.]+' 示例 $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar grep /user/hadooptest/input /user/hadooptest/output 'dfs[a-z.]+' 检查输出文件：将输出文件从分布式文件系统复制到本地文件系统并检查它们：\n1 2 3 4 5 6 7 $ bin/hdfs dfs -get output output $ cat output/* 示例 $ mkdir ./output $ bin/hdfs dfs -get /user/hadooptest/output/* ./output $ cat output/* 或，查看分布式文件系统上的输出文件\n1 2 3 4 $ bin/hdfs dfs -cat output/* 示例 $ bin/hdfs dfs -cat /user/hadooptest/output/* 停止 hadoop daemon\n1 $ sbin/stop-dfs.sh 查看日志文件 hadoop daemon 的日志默认输出在 $HADOOP_LOG_DIR 目录（默认值为 $HADOOP_HOME/logs）.\nhadoop-hadooptest-namenode-192-168-122-101.log hadoop-hadooptest-datanode-192-168-122-101.log 单节点启动 YARN 并运行 MapReduce 程序 您可以通过设置一些参数并另外运行 ResourceManager 守护程序和 NodeManager 守护程序，以伪分布式模式在 YARN 上运行 MapReduce 作业。\n分析 配置集群在 YARN 上运行 MR 启动，测试集群增，删，查 在 YARN 上执行 WordCount 案例 执行步骤 配置 etc/hadoop/yarn-env.sh\n1 2 # some Java parameters export JAVA_HOME=/opt/module/jdk1.8.0_241 etc/hadoop/yarn-site.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u003cconfiguration\u003e \u003c!-- Reducer 获取数据的方式 --\u003e \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.aux-services\u003c/name\u003e \u003cvalue\u003emapreduce_shuffle\u003c/value\u003e \u003c/property\u003e \u003c!-- 指定 YARN 的 ResourceManager 的地址 --\u003e \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.hostname\u003c/name\u003e \u003cvalue\u003e192-168-122-101\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.env-whitelist\u003c/name\u003e \u003cvalue\u003eJAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e etc/hadoop/mapred-env.sh\n1 2 # export JAVA_HOME=/home/y/libexec/jdk1.6.0/ export JAVA_HOME=/opt/module/jdk1.8.0_241 etc/hadoop/mapred-site.xml:\n1 $ cp etc/hadoop/mapred-site.xml.template etc/hadoop/mapred-site.xml 1 2 3 4 5 6 7 8 9 10 11 12 \u003cconfiguration\u003e \u003c!-- 指定 MR 运行在 YARN 上 --\u003e \u003cproperty\u003e \u003cname\u003emapreduce.framework.name\u003c/name\u003e \u003c!-- 默认是 local，可以的值 local，classic 或 yarn --\u003e \u003cvalue\u003eyarn\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003emapreduce.application.classpath\u003c/name\u003e \u003cvalue\u003e$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e 启动 ResourceManager daemon 和 NodeManager daemon\n1 2 $ sbin/yarn-daemon.sh start resourcemanager $ sbin/yarn-daemon.sh start nodemanager 或\n1 $ sbin/start-yarn.sh 使用 jps 查看启动状态\n1 2 3 4 5 6 $ jps 3027 NameNode 5267 NodeManager 5299 Jps 5012 ResourceManager 3125 DataNode ResourceManager 的浏览器访问接口，默认为：http://localhost:8088/\n运行一个 MapReduce 任务\n1 2 3 4 # 删除之前在 hdfs 中生成的 output 文件夹 $ hdfs dfs -rm -r /user/hadooptest/output # 运行官方示例 grep $ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar grep /user/hadooptest/input/*.xml /user/hadooptest/output 'dfs[a-z.]+' 可在 http://localhost:8088/ 接口查看执行信息\n停止 daemons\n1 $ sbin/stop-yarn.sh 配置历史服务器 MapReduce 任务执行结束后，可以看到如下图的 HISTORY\n如需查看历史信息，需要配置历史服务器\n配置 etc/hadoop/mapred-site.xml 1 2 3 4 5 6 7 8 9 10 11 12 \u003cconfiguration\u003e \u003c!-- 历史服务器端地址 --\u003e \u003cproperty\u003e \u003cname\u003emapreduce.jobhistory.address\u003c/name\u003e \u003cvalue\u003e192-168-122-101:10020\u003c/value\u003e \u003c/property\u003e \u003c!-- 历史服务器 web 端地址 --\u003e \u003cproperty\u003e \u003cname\u003emapreduce.jobhistory.webapp.address\u003c/name\u003e \u003cvalue\u003e192-168-122-101:19888\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e 启动历史服务 1 $ sbin/mr-jobhistory-daemon.sh start historyserver 查看历史服务器是否启动 1 2 $ jps 6702 JobHistoryServer 查看 HISTORY 历史信息 此处可能需要在客户机的 /etc/hosts 文件中添加域名和 IP 的映射关系，例如\n``` 192.168.122.101 192-168-122-101 ``` 配置日志的聚集 日志聚集概念：应用运行完成以后，将程序运行日志信息上传到 HDFS 系统上\n日志聚集功能好处：可以方便的查看到程序运行详情，方便开发测试\n注意：开启日志聚集功能，需要重新启动 NodeManager，ResourceManager 和 HistoryManager.\n配置 etc/hadoop/yarn-site.xml 1 2 3 4 5 6 7 8 9 10 11 12 \u003cconfiguration\u003e \u003c!-- 开启日志聚集功能 --\u003e \u003cproperty\u003e \u003cname\u003eyarn.log-aggregation-enable\u003c/name\u003e \u003cvalue\u003etrue\u003c/value\u003e \u003c/property\u003e \u003c!-- 日志保留时间设置 7 天 --\u003e \u003cproperty\u003e \u003cname\u003eyarn.log-aggregation.retain-seconds\u003c/name\u003e \u003cvalue\u003e604800\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e 关闭 HistoryManager，ResourceManager 和 NodeManager 1 2 3 $ sbin/mr-jobhistory-daemon.sh stop historyserver $ sbin/yarn-daemon.sh stop resourcemanager $ sbin/yarn-daemon.sh stop nodemanager 启动 NodeManager，ResourceManager 和 HistoryManager 1 2 3 $ sbin/yarn-daemon.sh start nodemanager $ sbin/yarn-daemon.sh start resourcemanager $ sbin/mr-jobhistory-daemon.sh start historyserver 删除 HDFS 上已经存在的输出文件 1 bin/hdfs dfs -rm -r /user/hadooptest/output 执行 Grep 程序 1 $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar grep /user/hadooptest/input /user/hadooptest/output 'dfs[a-z.]+' 查看日志 配置文件说明 Hadoop 配置文件分为两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。\n默认配置文件 要获取的默认文件 文件存放在 Hadoop 的 jar 包中的位置 core-default.xml haddop-common-2.7.7.jar/core-default.xml hdfs-defalult.xml hadoop-hdfs-2.7.7.jar/hdfs-default.xml yarn-defaulte.xml hadoop-hdfs-2.7.7.jar/yarn-default.xml mapred-default.xml hadoop-mapreduce-client-core-2.7.7.jar/mapred-default.xml 自定义配置文件 core-site.xml，hdfs-site.xml，yarn-site.xml，mapred-site.xml 四个配置文件存放在 $HADOOP_HOME/etc/hadoop 这个路径下，用户可根据项目需求重新进行修改配置。\n完全分布式运行模式（开发重点） 虚拟机准备 参考 [Hadoop 运行环境搭建](#Hadoop 运行环境搭建）\n步骤分析\n准备 3 台客户机（关闭防火墙，设置静态 IP，修改主机名称） 安装 JDK 配置环境变量 安装 Hadoop 配置环境变量 配置集群 单点启动 配置 ssh 群起并测试集群 编写集群分发脚本 xsync scp（secure copy）安全拷贝 scp 定义：scp 可以实现服务器与服务器之间的数据拷贝。（from server1 to server2） 基本语法 1 2 scp -r $pdir/$fname $user@$host:$pdir/$fname 命令 递归 要拷贝的文件路径/名称 用户名@主机：目的路径/名称 rsync 远程同步工具 rsync 主要用于备份和镜像。具有速度快，避免复制相同内容和支持符号链接的优点。\nrsync 和 scp 区别：用 rsync 做文件的复制要比 scp 的速度快，rsync 只对差异文件做更新。scp 是把所有文件都复制过去。\n基本语法\n1 2 rsync -rvl $pdir/$fname $user@$host:$pdir/$fname 命令 选项参数 要拷贝的文件路径/名称 目的用户@主机：目的路径/名称 选项参数和说明\n选项 功能 -r 递归 -v 显示复制过程 -l 拷贝符号链接 xsync 集群分发脚本 需求：循环复制文件到所有节点的相同目录下 需求分析 rsync 命令原始拷贝 1 rsync -rvl /opt/module root@192.168.122.103:/opt/module 期望脚本 xsync 要同步的文件名称 说明：在 /home/hadooptest/bin 这个目录下存放的脚本，hadooptest 用户可以在系统任何地方直接执行 脚本实现 在 /home/hadooptest 目录下创建 bin 目录，并在 bin 目录下 xsync 创建文件，内容如下\n1 2 3 4 5 [hadooptest@192-168-122-101 ~]$ ls [hadooptest@192-168-122-101 ~]$ mkdir bin [hadooptest@192-168-122-101 ~]$ cd bin [hadooptest@192-168-122-101 bin]$ touch xsync [hadooptest@192-168-122-101 bin]$ vim xsync 在该文件中编写如下代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #!/bin/bash #1 获取输入参数个数，如果没有参数，直接退出 pcount=$# if((pcount==0)); then echo no args; exit; fi #2 获取文件名称 p1=$1 fname=`basename $p1` echo fname=$fname #3 获取上级目录到绝对路径 pdir=`cd -P $(dirname $p1); pwd` echo pdir=$pdir #4 获取当前用户名称 user=`whoami` #5 循环 for((host=102; host\u003c104; host++)); do echo ----------192-168-122-$host---------- rsync -rvl $pdir/$pname $user@192-168-122-$host:$pdir done 修改 xsync 具有执行权限\n1 $ chmod 777 xsync 调用脚本形式：xsync 文件名称\n1 xsync /home/hadooptest/bin 注意：如果将 xsync 放到 /home/hadooptest/bin 目录下仍然不能实现全局使用，可以将 xsync 移动到 /user/local/bin 目录下。\n集群配置 集群部署规划 - 192-168-122-101 192-168-122-102 192-168-122-103 HDFS NameNodeDataNode DataNode SecondaryNameNodeDataNode YARN NodeManager ResourceManagerNodeManager NodeManager NameNode 和 SecondaryNameNode 占用内存 1:1，所以尽量避免将这两个放在同一个节点上\nResourceManager 占用内存也较大，所以也要和 NameNode，SecondaryNameNode 分开\n配置集群 核心配置文件\n配置 etc/hadoop/core-site.xml\n1 2 3 4 5 6 7 8 9 10 11 12 \u003cconfiguration\u003e \u003c!-- 指定 HDFS 中 NameNode 的地址 --\u003e \u003cproperty\u003e \u003cname\u003efs.defaultFS\u003c/name\u003e \u003cvalue\u003ehdfs://192-168-122-101:9000\u003c/value\u003e \u003c/property\u003e \u003c!-- 指定 Hadoop 运行时产生文件的存储目录--\u003e \u003cproperty\u003e \u003cname\u003ehadoop.tmp.dir\u003c/name\u003e \u003cvalue\u003e/opt/module/hadoop-2.7.7/data/tmp\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e HDFS 配置文件\n配置 etc/hadoop/hadoop-env.sh\n1 2 3 4 5 6 7 # The only required environment variable is JAVA_HOME. All others are # optional. When running a distributed configuration it is best to # set JAVA_HOME in this file, so that it is correctly defined on # remote nodes. # The java implementation to use. export JAVA_HOME=/opt/module/jdk1.8.0_241 配置 etc/hadoop/hdfs-site.xml\n1 2 3 4 5 6 7 8 9 10 11 12 \u003cconfiguration\u003e \u003c!-- 指定 HDFS 副本的数量 --\u003e \u003cproperty\u003e \u003cname\u003edfs.replication\u003c/name\u003e \u003cvalue\u003e3\u003c/value\u003e \u003c/property\u003e \u003c!-- 指定 Hadoop 辅助名称节点主机配置 --\u003e \u003cproperty\u003e \u003cname\u003edfs.namenode.secondary.http-address\u003c/name\u003e \u003cvalue\u003e192-168-122-103:50090\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e YARN 配置文件\n配置 etc/hadoop/yarn-env.sh\n1 2 # some Java parameters export JAVA_HOME=/opt/module/jdk1.8.0_241 配置 etc/hadoop/yarn-site.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u003cconfiguration\u003e \u003c!-- Site specific YARN configuration properties --\u003e \u003c!-- Reducer 获取数据的方式 --\u003e \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.aux-services\u003c/name\u003e \u003cvalue\u003emapreduce_shuffle\u003c/value\u003e \u003c/property\u003e \u003c!-- 指定 YARN 的 ResourceManager 的地址 --\u003e \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.hostname\u003c/name\u003e \u003cvalue\u003e192-168-122-102\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.env-whitelist\u003c/name\u003e \u003cvalue\u003eJAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e MapReduce 配置文件\n配置 etc/hadoop/mapred-env.sh\n1 2 # export JAVA_HOME=/home/y/libexec/jdk1.6.0/ export JAVA_HOME=/opt/module/jdk1.8.0_241 配置 etc/hadoop/mapred-site.xml\n1 2 3 4 5 6 7 8 9 10 11 \u003cconfiguration\u003e \u003c!-- 指定 MR 运行在 YARN 上 --\u003e \u003cproperty\u003e \u003cname\u003emapreduce.framework.name\u003c/name\u003e \u003cvalue\u003eyarn\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003emapreduce.application.classpath\u003c/name\u003e \u003cvalue\u003e$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e 在集群上分发配置好的 Hadoop 配置文件 1 $ xsync /opt/module/hadoop-2.7.7/ 集群单点启动 关掉所有节点 jps 显示的进程，删除所有节点 data 和 logs 目录\n初始化 101 上的 hdfs 文件系统\n1 [hadooptest@192-168-122-101 hadoop-2.7.7]$ bin/hdfs namenode -format 启动 101 上的 NameNode 和 DataNode\n1 2 3 4 5 6 [hadooptest@192-168-122-101 hadoop-2.7.7]$ sbin/hadoop-daemon.sh start namenode [hadooptest@192-168-122-101 hadoop-2.7.7]$ sbin/hadoop-daemon.sh start datanode [hadooptest@192-168-122-101 hadoop-2.7.7]$ jps 2474 Jps 2380 DataNode 2287 NameNode 启动 102 上的 DataNode\n1 2 3 4 5 [hadooptest@192-168-122-102 hadoop-2.7.7]$ sbin/hadoop-daemon.sh start datanode [hadooptest@192-168-122-103 hadoop-2.7.7]$ jps 1698 SecondaryNameNode 1739 Jps 1597 DataNode 启动 103 上的 DataNode\n1 [hadooptest@192-168-122-103 hadoop-2.7.7]$ sbin/hadoop-daemon.sh start datanode 启动 103 上的 secondarynamenode\n1 2 3 4 5 [hadooptest@192-168-122-103 hadoop-2.7.7]$ sbin/hadoop-daemon.sh start secondarynamenode [hadooptest@192-168-122-103 hadoop-2.7.7]$ jps 1698 SecondaryNameNode 1739 Jps 1597 DataNode 查看 NameNode 访问接口\n1 http://192.168.122.101:50070 此处暂未使用单点启动 yarn，可使用后续配置群集启动 HDFS 和 YARN\nSSH 无密登录配置 配置 ssh 基本语法\n1 ssh 另一台电脑的 IP 地址 ssh 连接时出现 Host key verification failed 的解决方法\n免密登录原理 流程介绍 A 服务器生成公钥（A）和私钥（A） 将公钥（A）拷贝到服务器 B 中 A 服务器通过 ssh 与 B 建立链接，向 B 发送使用私钥（A）进行加密后的数据 服务器 B 接收到数据后，使用公钥（A）进行解密 服务器 B 通过 ssh 向服务器 A 发送使用公钥（A）加密后的数据 服务器 A 使用私钥（A）对数据进行解密 在 101 服务器（服务器 A）上生成密钥对\n1 2 [hadooptest@192-168-122-101 .ssh]$ cd ~/.ssh [hadooptest@192-168-122-101 .ssh]$ ssh-keygen -t rsa 一路回车，生成如下两个文件\nid_rsa：私钥\nid_rsa.pub：公钥\n将 101 服务器（服务器 A）的公钥拷贝到 102 服务器（服务器 B）\n1 [hadooptest@192-168-122-101 .ssh]$ ssh-copy-id 192.168.122.102 此时查看 102 服务器（服务器 B）的 .ssh 文件夹，已生成如下文件\n1 2 [hadooptest@192-168-122-102 .ssh]$ ls authorized_keys 此时从 101 服务器（服务器 A）登录 102 服务器（服务器 B）不在需要输入密码\n1 2 3 [hadooptest@192-168-122-101 .ssh]$ ssh 192.168.122.102 Last login: Thu Apr 9 12:02:31 2020 from gateway [hadooptest@192-168-122-102 ~]$ 依次将 101 服务器（服务器 A）的公钥拷贝到 103 和 101 上\n1 2 [hadooptest@192-168-122-101 .ssh]$ ssh-copy-id 192.168.122.103 [hadooptest@192-168-122-101 .ssh]$ ssh-copy-id 192.168.122.101 此时使用如下命令连接 101、102、103 不在需要输入密码\n1 [hadooptest@192-168-122-101 .ssh]$ ssh 192.168.122.10X 注意事项说明及后续必须操作\n此处需要将 101 服务器的公钥拷贝到自己服务器上一份，是因为通过 ssh 192.168.122.101 连接本机的时候也需要输入密码。\n为 101 设置免登录到 102、103 是因为 101 上的 NameNode 需要访问另外两个节点上的 DataNode\n还需要使用相同方法，为 102 服务器生成密钥对，并将公钥拷贝到 101 和 103，因为 102 上的 ResourceManager 需要管理 101 和 103 上的 NodeManager，\n1 2 [hadooptest@192-168-122-102 .ssh]$ ssh-keygen -t rsa [hadooptest@192-168-122-102 .ssh]$ ssh-copy-id 192.168.122.101; ssh-copy-id 192.168.122.102; ssh-copy-id 192.168.122.103 还需在 101 上采用 root 帐号，配置以下无密登录到 101、102、103。\n1 2 3 4 [hadooptest@192-168-122-101 .ssh]$ su root [root@192-168-122-101 .ssh]# cd ~/.ssh [root@192-168-122-101 .ssh]# ssh-keygen -t rsa [root@192-168-122-101 .ssh]# ssh-copy-id 192.168.122.101; ssh-copy-id 192.168.122.102; ssh-copy-id 192.168.122.103; .ssh 文件夹下（~/.ssh）的文件功能解释 文件名 作用 known_hosts 记录 ssh 访问过计算机的公钥（public key） id_rsa 生成的私钥 id_rsa.pub 生成的公钥 authorized_keys 存放授权过得无密登录服务器公钥 群起集群 配置 etc/hadoop/slaves 在文件中添加如下信息\n192-168-122-101 192-168-122-102 192-168-122-103 此处存放的是所有 DataNode 节点\n注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。\n同步所有节点配置文件\n1 xsync etc/hadoop/slaves 关闭之前启动的所有进程 101 服务器\n1 2 [hadooptest@192-168-122-101 hadoop-2.7.7]$ sbin/hadoop-daemon.sh stop datanode [hadooptest@192-168-122-101 hadoop-2.7.7]$ sbin/hadoop-daemon.sh stop namenode 102 服务器\n1 [hadooptest@192-168-122-102 hadoop-2.7.7]$ sbin/hadoop-daemon.sh stop datanode 103 服务器\n1 2 [hadooptest@192-168-122-103 hadoop-2.7.7]$ sbin/hadoop-daemon.sh stop datanode [hadooptest@192-168-122-103 hadoop-2.7.7]$ sbin/hadoop-daemon.sh stop secondarynamenode 启动集群 在 101 上启动 dfs，因为 NameNode 在 101 上\n1 [hadooptest@192-168-122-101 hadoop-2.7.7]$ sbin/start-dfs.sh dfs.sh 会启动集群上的所有 NameNode、DataNode、SecondaryNameNode\n在 102 上启动 yarn，因为 ResourceManager 在 102 上\n1 [hadooptest@192-168-122-102 hadoop-2.7.7]$ sbin/start-yarn.sh 注意：NameNode 和 ResourceManager 如果不是同一台机器，不能在 NameNode 上启动 YARN，应该在 ResourceManger 所在的机器上启动 YARN。\n集群基本测试 依次使用 jps 查看各节点上启动的进程，对比开始的架构设计表\n查看 NameNode 的管理页面：http://192.168.122.101:50070/\n查看 ResourceManager 管理界面：http://192.168.122.102:8088/\n使用命令创建几个文件，并在 NameNode 管理界面查看是否创建成功\n上传文件到集群 上传小文件\n1 2 [hadooptest@192-168-122-101 hadoop-2.7.7]$ hdfs dfs -mkdir -p /user/hadooptest/input [hadooptest@192-168-122-101 hadoop-2.7.7]$ hdfs dfs -put ./README.txt /user/hadooptest/input/README.txt 上传大文件\n1 [hadooptest@192-168-122-101 hadoop-2.7.7]$ hdfs dfs -put /opt/software/hadoop-2.7.7.tar.gz /user/hadooptest/input 由下图可见，已对文件生成了 3 个副本，同时块大小为 128M\n由下图可见，文件大小小于 128M，只有 1 块 由下图可见，文件大小大于 128M，将文件分成了 2 (多）块，第 0 块大小为 128M 1 [hadooptest@192-168-122-101 hadoop-2.7.7]$ cd data/tmp/dfs/data/current/BP-1241632574-192.168.122.101-1586406239550/current/finalized/subdir0/subdir0/ 上传文件后查看文件存放在什么位置 查看 HDFS 文件存储路径\n1 /opt/module/hadoop-2.7.7/data/tmp/dfs/data/current/BP-1241632574-192.168.122.101-1586406239550/current/finalized/subdir0/subdir0 查看 HDFS 在磁盘存储文件内容\n1 2 3 [hadooptest@192-168-122-101 subdir0]$ cat blk_1073741825 For the latest information about Hadoop, please visit our website at: ...此处省略若干行... 拼接大文件\n1 2 [hadooptest@192-168-122-101 subdir0]$ cat blk_1073741826 \u003e\u003e temp.text [hadooptest@192-168-122-101 subdir0]$ cat blk_1073741827 \u003e\u003e temp.text 解压\n1 tar -zxvf temp.text 会发现解压后的文件和上传的 tar.gz 解压后的文件完全一致\n下载\n1 [hadooptest@192-168-122-101 hadoop-2.7.7]$ hadoop fs -get /user/hadooptest/input/hadoop-2.7.7.tar.gz ./ 集群启动停止方式总结 各个服务组件逐一启动/停止 分别启动/停止 HDFS 组件\n1 sbin/hadoop-daemon.sh start/stop namenode/datanode/secondarynamenode 启动/停止 YARN\n1 sbin/yarn-daemon.sh start/stop resourcemanager/nodemanager 各个模块分开启动/停止（配置 ssh 是前提）常用 整体启动/停止 HDFS\n1 sbin/start-dfs.sh / sbin/stop-dfs.sh 整体启动/停止 YARN\n1 sbin/start-yarn.sh / sbin/stop-yarn.sh 官网不建议使用 start-all.sh 和 stop-all.sh\n集群时间同步 crond 系统定时任务介绍 重新启动 crond 服务\n1 systemctl restart crond crontab 定时任务设置\n基本语法\n1 crontab [选项] 选项说明\n选项 功能 -e 编辑 crontab 定时任务 -l 查询 crontab 任务 -r 删除当前用户所有的 crontab 任务 参数说明\n1 crontab -e 进入 crontab 编辑页面。会打开 vim 编辑你的工作。\n格式：* * * * * 执行的任务\n项目 含义 范围 第一个* 一小时当中的第几分钟 0-59 第二个* 一天中的第几小时 0-23 第三个* 一个月当中的第几天 1-31 第四个* 一年中的第几个月 1-12 第五个* 一周中的星期几 0-7（0 和 7 都代表星期日） 特殊符号\n特殊符号 含义 * 代表任何时间。比如第一个 * 就代表一小时中每分钟都执行依次的意思 , 代表不连续的时间。比如 0 8,12,16 * * * 命令，就代表在每天的 8 点、12 点、16 点都执行一次命令。 - 代表连续的时间。比如 0 5 * * 1-6 命令，代表在周一到周六的凌晨 5 点执行命令 */n 代表每隔多久执行一次。比如 */10 * * * * 命令，代表每隔 10 分钟执行依次 特定时间执行命令\n时间 含义 45 22 * * * 命令 在 22 点 45 分执行命令 0 17 * * 1 命令 在每周 1 的 17 点执行命令 0 5 1,15 * * 命令 每月 1 号和 15 号的凌晨 5 点执行命令 40 4 * * 1-5 命令 每周一到周五的凌晨 4 点 40 分执行一次命令 */10 4 * * * 命令 每天的凌晨 4 点开始，每隔 10 分钟执行一次命令 0 0 1,15 * 1 命令 每月 1 号和 15 号，每周 1 的 0 点 0 分都会执行命令。注意：星期几和几号最好不要同时出现，因为他们定义的都是天，非常容易让管理员混乱。 案例实操\n每隔 1 分钟，向 /root/bailongma.txt 文件中添加一个 11 的数字\n1 */1 * * * * /bin/echo \"11\" \u003e\u003e /root/bailongma.txt 集群时间同步 时间同步的方式：找一台机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步。比如，每隔 10 分钟同步一次时间。\ngraph LR 时间服务器 101-- 102 定时去获取 101 时间服务器主机的时间--\u003e其他机器 102 对时间服务器 101 的操作\n检查 ntp 是否安装 修改 ntp 配置文件 修改 1：授权 192.168.122.0-192.168.122.255 网段上的所有机器可以从这台机器上查询和同步时间 修改 2：集群在局域网中，不使用其他互联网上的时间 添加 3：当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步 修改 /etc/sysconfig/ntpd 文件，让硬件时间与系统时间一起同步 重新启动 ntpd 服务 设置 ntpd 服务开机启动 对其他机器 102 的操作\n在其他机器配置 10 分钟与时间服务器同步一次 1 # crontab -e 编写内容如下 1 */10 * * * * /user/sbin/ntpdate 192.168.122.101 修改任意机器时间 十分钟后查看机器是否与时间服务器同步 实际操作步骤 时间服务器配置（必须 root 用户）\n检查 ntp 是否安装\n1 2 3 4 [root@192-168-122-101 ~]# rpm -qa | grep ntp fontpackages-filesystem-1.44-8.el7.noarch ntp-4.2.6p5-29.el7.centos.x86_64 ntpdate-4.2.6p5-29.el7.centos.x86_64 修改 ntp 配置文件\n1 [root@192-168-122-101 ~]# vim /etc/ntp.conf 修改 1：授权 192.168.122.0-192.168.122.255 网段上的所有机器可以从这台机器上查询和同步时间\n1 2 3 # Hosts on local network are less restricted. # restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap restrict 192.168.122.0 mask 255.255.255.0 nomodify notrap 修改 2：集群在局域网中，不使用其他互联网上的时间\n1 2 3 4 5 6 7 # Use public servers from the pool.ntp.org project. # Please consider joining the pool (http://www.pool.ntp.org/join.html). # 注释掉所有 # server 0.centos.pool.ntp.org iburst # server 1.centos.pool.ntp.org iburst # server 2.centos.pool.ntp.org iburst # server 3.centos.pool.ntp.org iburst 添加 3：当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步\n1 2 3 4 5 6 # Enable writing of statistics records. #statistics clockstats cryptostats loopstats peerstats # 如果没有网络使用本地时间 server 127.127.1.0 # 配置时间的准确度等级 fudge 127.127.1.0 stratum 10 修改 /etc/sysconfig/ntpd 文件\n1 2 3 [root@192-168-122-101 ~]# vim /etc/sysconfig/ntpd # 增加如下内容（让硬件时间与系统时间一起同步） SYNC_HWCLOCK=yes 重新启动 ntpd 服务\n1 [root@192-168-122-101 ~]# systemctl restart ntpd 设置 ntpd 服务开机自启\n1 [root@192-168-122-101 ~]# systemctl enable ntpd 其他机器配置（必须 root 用户）\n在其他机器配置 10 分钟与时间服务器同步一次\n1 [root@192-168-122-102 hadooptest]# crontab -e 添加如下内容\n1 */10 * * * * /usr/sbin/ntpdate 192.168.122.101 修改其他机器时间，过 10 分钟再次查看是否自动同步\n1 2 3 [root@192-168-122-102 hadooptest]# date -s \"2018-11-11 11:11:11\" [root@192-168-122-102 hadooptest]# date https://edu.aliyun.com/lesson_1800_15237#_15237\n常见错误及解决方案 a b c d e f g h DataNode 和 NameNode 进程同时只能有一个工作问题分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 查看 namenode 版本信息 $ cat data/tmp/dfs/name/current/VERSION #Wed Apr 08 15:06:15 CST 2020 namespaceID=2123298218 clusterID=CID-72ce9cc8-d69a-46eb-99bb-35f61fa021b2 cTime=0 storageType=NAME_NODE blockpoolID=BP-532632266-192.168.122.101-1586329575011 layoutVersion=-63 # 查看 datanode 版本信息 $ cat data/tmp/dfs/data/current/VERSION #Wed Apr 08 15:10:36 CST 2020 storageID=DS-7b7060fc-7b94-44e3-bd96-99a0328234e4 clusterID=CID-72ce9cc8-d69a-46eb-99bb-35f61fa021b2 cTime=0 datanodeUuid=8ffe08fd-6105-4154-8c86-7a6b29361d42 storageType=DATA_NODE layoutVersion=-56 ","description":"","tags":["Hadoop"],"title":"Hadoop 介绍","uri":"/posts/hadoop/hadoop-introduce/"},{"categories":null,"content":"Kong 限流（Rate Limiting） 官方地址\n速率限制在给定的几秒钟，几分钟，几小时，几天，几月或几年内，开发人员可以发出多少个 HTTP 请求。如果基础服务/路由（或不建议使用的 API 实体）没有身份验证层，则将使用客户端 IP 地址，否则，如果已配置身份验证插件，则将使用使用者。\n注意：此插件与 0.13.1 之前的 Kong 版本和 0.32 之前的 Kong Enterprise 版本捆绑在一起的功能与此处记录的功能不同。有关详细信息，请参阅 CHANGELOG。\n术语 plugin：在将请求代理到上游 API 之前或之后，在 Kong 的内部运行该插件 Servic：代表外部上游 API 或微服务的 Kong 实体 Route：代表一种将下游请求映射到上游服务的方式的 Kong 实体 Consumer：Kong 对其发出的请求进行代理；它可能代表用户或者外部非服务。 Credential：与使用者（Consumer）相关联的唯一字符串，也称为 API 密钥 Upstream service：指在 Kong 后面你自己的 API/服务，客户请求将被转发到这里 配置 该插件兼容以下协议的请求：\nhttp https 此插件部分兼容 DB-less 模式。\n此插件可以与本地策略（不使用数据库）或 redis 策略（使用独立的 redis，因此与无数据库兼容）一起正常运行。\n该插件不适用于需要写入数据库的集群策略。\n在 Service 上启动该插件 使用数据库\n通过下面的请求在服务上配置该插件\n1 2 3 4 5 $ curl -X POST http://kong:8001/services/{service}/plugins \\ --data \"name=rate-limiting\" \\ --data \"config.second=5\" \\ --data \"config.hour=10000\" \\ --data \"config.policy=local\" 不用数据库\n通过在声明式配置文件中添加如下部分在服务上配置该插件\n1 2 3 4 5 6 7 plugins: - name: rate-limiting service: {service} config: second: 5 hour: 10000 policy: local {service} 是此插件将针对的服务的 id 或 name。\n在 Route 上启用该插件 使用数据库\n通过下方请求将该插件配置到 Route：\n1 2 3 4 5 $ curl -X POST http://kong:8001/routes/{route}/plugins \\ --data \"name=rate-limiting\" \\ --data \"config.second=5\" \\ --data \"config.hour=10000\" \\ --data \"config.policy=local\" 不用数据库\n在声明式配置文件中添加如下部分配置此插件到 Route\n1 2 3 4 5 6 7 plugins: - name: rate-limiting route: {route} config: second: 5 hour: 10000 policy: local {route} 是此插件将针对的 Route 的 id 或 name。\n在 Consumer 上配置此插件 使用数据库\n你可以使用 http://localhost:8001/plugins 端点在指定的 Consumers 上启用该插件：\n1 2 3 4 5 $ curl -X POST http://kong:8001/consumers/{consumer}/plugins \\ --data \"name=rate-limiting\" \\ --data \"config.second=5\" \\ --data \"config.hour=10000\" \\ --data \"config.policy=local\" 不用数据库\n在声明式配置文件中添加如下部分配置此插件到 Consumer\n1 2 3 4 5 6 7 plugins: - name: rate-limiting consumer: {consumer} config: second: 5 hour: 10000 policy: local {consumer} 是此插件配置针对的 Consumer 的 id 或 username。\n你可以在同一个请求中联合使用 consumer.id 和 service.id，进一步缩小该插件的作用域。\n全局插件 使用数据库，所有的插件都可以使用 http://kong:8001/plugins 端点进行配置 没用数据库，所有插件都可以在声明式配置文件中通过 plugins: 部分进行配置 与任何 Service，Route 或 Consumer（或 API，如果您使用的是 Kong 的较旧版本）无关的插件均被视为“全局”插件，并将在每个请求上运行。阅读 插件参考 和 插件优先级 部分以获取更多信息。\n参数 配置该插件时可以使用的所有参数如下表\n表单参数 描述 name 使用的插件的名字，这里是 rate-limiting service.id 该插件针对的 Service 的 id route.id 该插件针对的 Route 的 id consumer.id 该插件针对的 Consumer 的 id enabled\n默认值：true 是否应用该插件 config.seond\n半可选 开发者没秒可以发送的 HTTP 请求量。必须至少存在一个限制条件。 config.minute\n半可选 开发者每分钟可以发送的 HTTP 请求量。必须至少存在一个限制条件。 config.hour\n半可选 开发者每小时可以发送的 HTTP 请求量。必须至少存在一个限制条件。 config.day\n半可选 开发者每天可以发送的 HTTP 请求量。必须至少存在一个限制条件。 config.month\n半可选 开发者每月可以发送的 HTTP 请求量。必须至少存在一个限制条件。 config.year\n半可选 开发者每年可以发送的 HTTP 请求量。必须至少存在一个限制条件。 config.limit_by\n可选 默认值：consumer 汇总限制时使用的实体：consumer，credential，ip，service。如果无法确定 consumer，credential 或 service，系统将总是回退到 ip。 config.policy\n可选\n默认值：cluster 用于检索和增加限制的限流策略。可用值是 local（计数器将存储在节点上的本地内存中），cluster（计数器存储在数据存储区中并在节点之间共享）和 redis（计数器存储在Redis服务器上并在节点之间共享）。在 DB-less 模式下，必须至少指定 local 或 redis 之一。请参阅 实施注意事项，以了解有关应使用哪种策略的详细信息。 config.fault_tolerant\n可选\n默认值：true 一个布尔值，它确定即使 Kong 在连接第三方数据库时遇到问题，是否也应代理该请求。如果 true，无论如何，请求都会被代理，从而有效禁用限流功能，直到该数据存储再次工作。如果是 false，客户端将会收到 500 错误 config.hide_client_headers\n可选\n默认值：false 可选隐藏信息丰富的响应头 config.redis_host\n半可选 当使用 redis 策略，该属性指定 Redis 服务的地址 config.redis_port\n可选\n默认值：6379 当时用 redis 策略，该属性指定 Redis 服务的端口 config.redis_password\n可选 当使用 redis 策略，该属性指定连接到的 Redis 服务的密码 config.redis_timeout\n可选\n默认值：2000 当使用 redis 策略，该属性指定任意命令提交到 Redis 服务的超时时间毫秒数 config.redis_database\n可选\n默认值：0 当时用 redis 策略，该属性指定使用的 Redis 数据库 发送给客户端的头信息 当启用了该插件，Kong 会将一些其他的头信息发送回客户端，以告知允许的限制，有多少请求可用以及恢复配额之前需要花费多长时间，例如：\n1 2 3 RateLimit-Limit: 6 RateLimit-Remaining: 4 RateLimit-Reset: 47 此插件还将发送头信息，告诉标明时间范围内的限制以及剩余的请求数量：\n1 2 X-RateLimit-Limit-Minute: 10 X-RateLimit-Remaining-Minute: 9 或者，如果设置了多个时间限制，它将返回多个时间限制的组合：\n1 2 3 4 X-RateLimit-Limit-Second: 5 X-RateLimit-Remaining-Second: 4 X-RateLimit-Limit-Minute: 10 X-RateLimit-Remaining-Minute: 9 如果达到配置的任何限制，则插件将使用以下 JSON 正文向客户端返回 HTTP / 1.1 429 状态码。\n1 { \"message\": \"API rate limit exceeded\" } 注意事项\n头信息中的 RateLimit-Limit，RateLimit-Remaining 和 RateLimit-Reset 是基于HTTP的Internet-Draft（Internet 草案）中 RateLimit标头字段，并且将来可能会更改，以确保规范更新。\n实施注意事项 此插件支持 3 种策略，每种都有各自的优点和缺点\n策略 优点 缺点 cluster 准确，无需额外的组件来支持 具有相对最大的性能影响，每个请求都强制对基础数据存储区进行读取和写入。 redis 准确，对性能的影响小于 cluster 策略 必须安装外部的 redis，具有比 local 策略较大的性能影响 local 对性能的影响最小 不准确，除非在 Kong 前面使用了一个 Hash 一致的负载均衡器，否则在扩展节点数时，它会发散 这有 2 个常见的使用示例\n每笔交易都很重要。例如，这些是具有财务后果的交易。这里要求最高的准确性。 后端保护。在这里精度不那么重要，而只是用来保护后端服务免于过载。即可以由特定用户使用，也可以从总体上防御攻击。 注意事项\n仅限企业版 Kong 社区版不提供该限流插件对 Redis Sentinel 支持。Kong 企业版订阅用户可以选择将 Redis Sentinel 与 Kong 限流插件一起使用以交付高可用性的主从部署\n每笔交易都很总要 在此场景下，local 策略是不可选的。这里的决定是在redis策略的额外性能与其额外的支持工作之间进行的。基于此平衡，选择应该使用 cluster 还是 redis。\n建议从 cluster 策略开始，如果性能急速下降，则可以选择迁移到 redis。请记住，现有使用情况指标无法从数据存储库移植到 Redis。通常，对于寿命很短的指标（每秒或每分钟）来说这不是问题，而对于寿命较长（数月）的指标则可能产生较大影响，因此你可能需要更仔细地设计交换机。\n后端保护 由于准确性不太重要，因此可以使用 local 策略。可能需要进行一些实验才能获取正确的配置。例如，如果用户每秒绑定100个请求，并且您拥有一个相对平衡的 5 节点 Kong 集群，则将本地限制设置为每秒 30 个请求即可。如果你担心有太多的 false-negatives，增加该值的大小。\n请记住，随着集群扩展到更多节点，用户将获取更多的请求，同样，当集群缩减时，false-negatives 的可能性也会增加。因此，通常在扩展时更新你的限制。\n可以通过在 Kong 前面使用 Hash 负载均衡器来减轻上述不准确性，以确保始终将同一用户定向到同—— Kong 节点。这样即可以减少误差，又可以防止缩放问题。\n使用 local 策略时，很可能会向用户授予比协议更多的权限，但是它可以有效的阻止任何攻击，同时保持最佳性能。\n","description":"","tags":["Kong"],"title":"Kong 限流(Rate Limiting)","uri":"/posts/kong/kong-rate-limiting/"},{"categories":null,"content":"java 网络编程 所谓的网络编程指的就是多台主机之间的数据通讯操作。\n网络编程简介 网络的核心定义在于：有两台以上的电脑就称为网络。实际上在世界上产生第一台之后，就有人开始思考如何将更多的电脑生产出来并将其进行有效的连接。\n网络连接的目的不仅仅是为了进行电脑的串联，更多的情况下是为了彼此之间的数据通讯，包括现在所谓的网络游戏本质上还是网络通讯的问题。而在通讯的实现上就产生了一系列的处理协议：IP、TCP、UDP 等等，也就是说所谓的网络编程就是一个数据的通讯操作而已，只不过这个网络通讯操作需要分为客户端和用户端。\n于是针对于网络程序的开发就有了两种模型：\nC/S（Client/Server，客户端与服务器端）：要开发出两套程序，一套客户端，一套用户端，如果服务器端发生了改变之后客户端也应该进行更新处理；这种开发可以由开发者自定义传输协议，并且使用一些比较私密的端口；安全性比较高，但是开发与维护成本比较高 B/S（Browse/Server，浏览器与服务器端），只开发一套服务端的程序，而后利用浏览器作为客户端进行访问，这种开发与维护的成本较低（只有一套程序），但是由于其使用的是公共的 HTTP 协议，并且使用的是公共的 80 端口，所以安全性较差，现在的开发基本上以\"B/S\"结构为主。 本次所要讲解的网络编程主要就是 C/S 程序模型开发：TCP（可靠的数据连接），UDP（不可靠的数据连接）\nTCP 程序的基本实现 TCP 的程序开发是网络程序的最基本的开发模型，其核心的特点是使用两个类实现数据的交互处理：ServerSocket（服务器端），Socket（客户端）\nServerSocket 与 Socket\n每个服务端服务都需要使用 ServerSocket 来监听一个端口（门牌号），客户端使用 Socket 向该端口发送请求，被 ServerSocket 监听到，进而被服务处理，处理结束后，需要给客户端返回消息，此时服务端需要根据 Socket 来得知将返回的消息发送给哪个客户端。\nServerSocket 的主要目的是设置服务器的监听端口，而 Socket 需要指明要连接的服务器地址和端口。下面实现一个最简单的数据处理操作，即：Echo 程序实现。\nEcho 模型\n实现服务器端的定义\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 import java.io.IOException; import java.io.PrintWriter; import java.net.ServerSocket; import java.net.Socket; import java.util.Scanner; public class EchoServer { public static void main(String[] args) throws IOException { // 设置服务器端的监听端口 ServerSocket server = new ServerSocket(9999); System.out.println(\"等待客户端连接……\"); // 有客户端连接 Socket client = server.accept(); // 1. 首先需要先接收客户端发送来的信息，然后才可以将信息处理后发送回客户端 // 客户端输入流 Scanner scan = new Scanner(client.getInputStream()); // 设置分隔符 scan.useDelimiter(\"\\n\"); //客户端输出流 PrintWriter out = new PrintWriter(client.getOutputStream()); // 循环标记 boolean flag = true; while (flag) { // 现在有数据发送过来 if (scan.hasNext()) { String val = scan.next(); if (\"byebye\".equalsIgnoreCase(val)) { out.println(\"byebye....\"); flag = false; } else { out.println(\"[echo] \" + val); } // 强制刷新缓冲区 out.flush(); } } out.close(); scan.close(); client.close(); server.close(); } } 实现客户端的定义\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.io.PrintWriter; import java.net.Socket; import java.util.Scanner; public class EchoClient { private static final BufferedReader KEYBOARD_INPUT = new BufferedReader(new InputStreamReader(System.in)); public static void main(String[] args) throws IOException { // 定义服务端的连接信息 Socket client = new Socket(\"localhost\", 9999); // 现在客户端需要有输入与输出的操作支持，所以依然要准备 Scanner 与 PrintWrite // 接收服务端的输入内容 Scanner scan = new Scanner(client.getInputStream()); scan.useDelimiter(\"\\n\"); // 向服务端发送数据 PrintWriter out = new PrintWriter(client.getOutputStream()); boolean flag = true; while (flag) { System.out.println(\"请输入要发送的内容：\"); String input = KEYBOARD_INPUT.readLine(); out.println(input); out.flush(); // 服务器端有回应了 if (scan.hasNext()) { String val = scan.next(); System.out.println(val); if (\"byebye\".equalsIgnoreCase(val)) { flag = false; } } } out.close(); scan.close(); client.close(); } } 此时就完成了一个最基础的服务器与客户端之间的通讯\n多线程与网络编程 现在尽管已经实现了一个标准的网络程序开发，但是在整个开发过程之中，本程序存在有严重的性能缺陷，因为该服务器只能为一个线程提供 Echo 服务，如果说现在的服务器需要有多人进行连接访问的时候，那么其他的使用者将无法连接（等待连接）。\n所以现在就可以发现单线程的服务器开发就是一种不合理的做法，那么此时最好的解决方案就是将每一个连接到服务器上的客户端都通过一个线程对象来进行处理，即：服务器上启动多个线程，每一个线程单独为每一个客户端实现 echo 服务支持。\nEcho 多线程模型（BIO）\n修改服务器端程序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 import java.io.IOException; import java.io.PrintWriter; import java.net.ServerSocket; import java.net.Socket; import java.util.Scanner; public class EchoServer { private static class ClientThread implements Runnable { // 描述每一个不同的客户端 private Socket client = null; private Scanner scan = null; private PrintWriter out = null; public ClientThread(Socket client) throws IOException { this.client = client; this.scan = new Scanner(client.getInputStream()); this.scan.useDelimiter(\"\\n\"); this.out = new PrintWriter(client.getOutputStream()); } @Override public void run() { // 循环标记 boolean flag = true; while (flag) { // 现在有数据发送过来 if (scan.hasNext()) { String val = scan.next(); if (\"byebye\".equalsIgnoreCase(val)) { out.println(\"byebye....\"); flag = false; } else { out.println(\"[echo] \" + val); } // 强制刷新缓冲区 out.flush(); } } try { out.close(); scan.close(); client.close(); } catch (IOException e) { e.printStackTrace(); } } } public static void main(String[] args) throws IOException { // 设置服务器端的监听端口 ServerSocket server = new ServerSocket(9999); System.out.println(\"等待客户端连接……\"); // 循环标记 boolean flag = true; while (flag) { // 有客户端连接 Socket client = server.accept(); new Thread(new ClientThread(client)).start(); } server.close(); } } 如果在这类代码里再追加一些集合的数据控制，实际上就可以实现一个 80 年代的聊天室了。\n数据报发送与接收 之前所见到的都属于 TCP 程序开发范畴，TCP 程序最大的特点是可靠的网络连接，但是在网络程序开发之中还存在一种 UDP 的程序，基于数据报的网络编程实现，如果要想实现 UDP 程序，需要两个类 DatagramPacket（数据内容），DatagramSocket（网络发送与接收）。 数据报就好比发送的短消息一样，客户端是否接收到与发送者无关。\n实现一个 UDP 客户端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import java.io.IOException; import java.net.DatagramPacket; import java.net.DatagramSocket; public class UDPClient { public static void main(String[] args) throws IOException { // 连接到 9999 端口 DatagramSocket client = new DatagramSocket(9999); // 接收消息 byte data[] = new byte[1024]; DatagramPacket packet = new DatagramPacket(data, data.length); System.out.println(\"客户端等待接收发送的消息……\"); // 接收消息，所有的消息都在 data 字节数组中 client.receive(packet); System.out.println(\"接收到的消息内容为：\" + new String(data, 0, packet.getLength())); client.close(); } } 实现一个 UDP 服务端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import java.io.IOException; import java.net.DatagramPacket; import java.net.DatagramSocket; import java.net.InetAddress; public class UDPServer { public static void main(String[] args) throws IOException { DatagramSocket server = new DatagramSocket(9000); // 要发送的消息的内容 String str = \"www.example.com\"; DatagramPacket packet = new DatagramPacket(str.getBytes(), 0, str.length(), InetAddress.getByName(\"localhost\"), 9999); server.send(packet); System.out.println(\"消息发送完毕……\"); server.close(); } } UDP 发送的数据一定是不可靠的，但是 TCP 由于要保证可靠的连接所以所需要的服务器资源就越多\n","description":"","tags":["Java"],"title":"java 网络编程","uri":"/posts/java/network-programming/"},{"categories":null,"content":"Kong 熔断（Request Termination） 官方文档\n该插件使用指定的状态码和信息终止传入的请求。这允许（临时）停止在服务或路由撒谎那个的流量，甚至阻止使用者。\n术语 plugin：在将请求代理到上游 API 之前或之后，在 Kong 的内部运行该插件 Servic：代表外部上游 API 或微服务的 Kong 实体 Route：代表一种将下游请求映射到上游服务的方式的 Kong 实体 Consumer：Kong 对其发出的请求进行代理；它可能代表用户或者外部非服务 Credential：与使用者（Consumer）相关联的唯一字符串，也称为 API 密钥 Upstream service：指在 Kong 后面你自己的 API/服务，客户请求将被转发到这里 配置 该插件兼容以下协议的请求\nhttp https 该插件兼容 DB-less 模式\n在一个 Service 上启用该插件 使用数据库\n通过发出以下请求在服务上配置此插件\n1 2 3 4 $ curl -X POST http://kong:8001/services/{service}/plugins \\ --data \"name=request-termination\" \\ --data \"config.status_code=403\" \\ --data \"config.message=So long and thanks for all the fish!\" 没有使用数据库\n通过将此部分添加到声明性配置文件中，在 Service 上配置此插件\n1 2 3 4 5 6 plugins: - name: request-termination service: {service} config: status_code: 403 message: So long and thanks for all the fish! service 是此插件配置将针对的服务的 id 或 name\n在 Route 上启用该插件 使用了数据库\n使用以下命令在 Route 上配置此插件\n1 2 3 4 $ curl -X POST http://kong:8001/routes/{route}/plugins \\ --data \"name=request-termination\" \\ --data \"config.status_code=403\" \\ --data \"config.message=So long and thanks for all the fish!\" 没使用数据库\n通过将此部分添加到声明性配置文件中，在 Route 上配置此插件\n1 2 3 4 5 6 plugins: - name: request-termination route: {route} config: status_code: 403 message: So long and thanks for all the fish! route 是此插件配置将针对的 Route 的 id 或 name\n在 Consumer 上启用该插件 使用数据库\n你可以使用 http://localhost:8001/plugins 端点，在指定的 Consumers 上启用该插件\n1 2 3 4 $ curl -X POST http://kong:8001/consumers/{consumer}/plugins \\ --data \"name=request-termination\" \\ --data \"config.status_code=403\" \\ --data \"config.message=So long and thanks for all the fish!\" 没用数据库\n通过将此部分添加到声明性配置文件中，在 Consumer 上配置此插件\n1 2 3 4 5 6 plugins: - name: request-termination consumer: {consumer} config: status_code: 403 message: So long and thanks for all the fish! route 是此插件配置将针对的使用者的 id 或 username\n你可以在同一个请求上组合使用 consumer.id 和 service.id，以进一步缩小插件的范围\n全局插件 使用数据库，所有的插件都可以使用 http://kong:8001/plugins 端点进行配置 没用数据库，所有插件都可以在声明式配置文件中通过 plugins: 部分进行配置 与任何 Service，Route 或 Consumer(或 API，如果您使用的是 Kong 的较旧版本)无关的插件均被视为“全局”插件，并将在每个请求上运行。阅读 插件参考 和 插件优先级 部分以获取更多信息.\n参数 配置该插件时可以使用的所有参数如下表\n表单参数 描述 name 当前使用插件的名字，该插件为 request-termination service.id 该插件针对的 Service ID route.id 该插件针对的 Route ID consumer.id 该插件针对的 Consumer ID enabled 默认值：true 是否应用该插件 config.status_code 可选项，默认值：503 响应的状态码 config.message 可选项 返回的消息，如果使用了默认的相应生成器 config.body 可选项 返回的原始 Response Body，这与 config.message 字段互斥 config.content_type 可选项，默认值：application/json; charset=utf-8 使用 config.body 配置的原始响应内容类型 一旦应用，每个请求（在 Service、Route、Consumer 或 Global 的已配置插件范围内）将通过发送已配置的响应立即终止。\n用例范例 暂时停用 Service（例如，正在维护中） 暂时停用 Route（例如，该服务的其余部分已启动并正在运行，但是必须禁用特定的端点） 暂时禁用 Consumer（例如，过度消费） 在 logical OR setup 中使用 multiple auth plugins 阻止匿名用户访问 ","description":"","tags":["Kong"],"title":"Kong 熔断（Request Termination）","uri":"/posts/kong/kong-request-termination/"},{"categories":null,"content":"使用 fastjson 将 JSON 字符串有序转为 LinkHashMap 1 JSON.parseObject(jsonStr,LinkedHashMap.class, Feature.OrderedField); ","description":"","tags":["Fastjson","Java"],"title":"使用 fastjson 将 JSON 字符串有序转为 LinkHashMap","uri":"/posts/java/fastjson-jsonstr-to-linked-hash-map/"},{"categories":null,"content":"MySQL 的用户及权限管理 MySQL 版本：5.7\n用户相关常用命令 用户相关信息存储在 mysql.user 表中\n修改用户密码\n1 ALTER USER 'user'@'host' IDENTIFIED BY 'new_password'; 执行 ALTER USER 指令，必须具有全局的 CREATE USER 权限或 mysql 系统数据库的 UPDATE 权限。如果数据库系统设置了 read only 属性，则还需添加 SUPER 权限。\n创建用户\n1 2 CREATE USER 'user'@'host'; CREATE USER 'user'@'host' IDENTIFIED BY 'password'; 如果不指定 host，默认的 host 为 '%'，代表任意 ip 均可使用\n执行 CREATE USER 指令，必须具有全局的 CREATE USER 权限或 mysql 系统数据库的 INSERT 权限。如果数据库系统设置了 read only 属性，则还需添加 SUPER 权限。\n删除用户\n1 DROP USER 'user'@'host' 执行 DROP USER 指令，必须具有全局的 CREATE USER 权限或 mysql 系统数据库的 DELETE 权限。如果数据库系统设置了 read only 属性，则还需添加 SUPER 权限。\n修改用户名\n1 RENAME USER 'user'@'host' TO 'new_user'@'new_host'; 权限相关常用命令 用户信息及全局权限信息保存在 mysql.user 表中，数据库权限信息保存在 mysql.db 表中，表权限信息保存在 mysql.tables_priv 表中，列权限信息保存在 mysql.columns_priv 表中。\n常用格式\n1 GRANT priv_type[ ,priv_type ,...] ON priv_level TO 'user'@'host' [WITH GRANT OPTION] priv_type 包含\nPrivilege Meaning and Grantable Levels ALL [PRIVILEGES] Grant all privileges at specified access level except GRANT OPTION and PROXY ALTER Enable use of ALTER TABLE Statement ALTER TABLE Levels: Global, database, table. ALTER ROUTINE Enable stored routines to be altered or dropped. Levels: Global, database, routine. CREATE Enable database and table creation. Levels: Global, database, table. CREATE ROUTINE Enable stored routine creation. Levels: Global, database. CREATE TABLESPACE Enable tablespaces and log file groups to be created, altered, or dropped. Level: Global. CREATE TEMPORARY TABLES Enable use of CREATE TEMPORARY TABLE. Levels: Global, database. CREATE USER Enable use of CREATE USER, DROP USER, RENAME USER, and REVOKE ALL PRIVILEGES. Level: Global. CREATE VIEW Enable views to be created or altered. Levels: Global, database, table. DELETE Enable use of DELETE. Level: Global, database, table. DROP Enable databases, tables, and views to be dropped. Levels: Global, database, table. EVENT Enable use of events for the Event Scheduler. Levels: Global, database. EXECUTE Enable the user to execute stored routines. Levels: Global, database, routine. FILE Enable the user to cause the server to read or write files. Level:Global. GRANT OPTION Enable privileges to be granted to or removed from other accounts. Levels: Global, database, table, routine, proxy. INDEX Enable indexes to be created or dropped. Levels: Global, database, table. INSERT Enable use of INSERT. Levels: Global, database, table, column. LOCK TABLES Enable use of LOCK TABLES on tables for which you have the SELECT privilege. Levels: Global, database. PROCESS Enable the user to see all processes with SHOW PROCESSLIST. Level: Global. PROXY Enable user proxying. Level: From user to user. REFERENCES Enable foreign key creation. Levels: Global, database, table, column. RELOAD Enable use of FLUSH operations. Level: Global. REPLICATION CLIENT Enable the user to ask where master or slave servers are. Level: Global. REPLICATION SLAVE Enable replication slaves to read binary log events from the master.Level: Global. SELECT Enable use of SELECT. Levels: Global, database, table, column. SHOW DATABASES SHOW DATABASES to show all databases. Level: Global. SHOW VIEW Enable use of SHOW CREATE VIEW. Levels: Global, database, table. SHUTDOWN Enable use of mysqladmin shutdown. Level: Global. SUPER Enable use of other administrative operations such as CHANGE MASTER TO, KILL, PURGE BINARY LOGS, SET GLOBAL, and mysqladmin debug command. Level: Global. TRIGGER Enable trigger operations. Levels: Global, database, table. UPDATE Enable use of UPDATE. Levels: Global, database, table, column. USAGE Synonym for no privileges 1 2 3 4 5 6 7 8 priv_level: { * | *.* | db_name.* | db_name.tbl_name | tbl_name | db_name.routine_name } 授予某用户所有权限\n1 GRANT ALL ON *.* TO 'user'@'host'; 授予某用户对某个数据库的所有权限\n1 GRANT ALL ON db_name.* TO 'user'@'host'; 授予某用户所有权限，包括 GRANT 权限\n1 GRANT ALL ON *.* TO 'user'@'host' WITH GRANT OPTION; 取消授权\n格式与 GRANT 基本相同，只需将 TO 修改为 FROM\n1 REVOKE priv_type[ ,priv_type ,... ,GRANT OPTION] ON priv_level FROM 'user'@'host' ; 查看某用户具有的权限\n1 SHOW GRANTS FOR 'user'@'host'; MySQL 对用户权限的判断流程 首先判断 GLOABLE 权限( mysql.user 表)，如果具备权限，则不再向下一级别判断。 然后判断 database 级权限( mysql.db 表)，如果具备权限，则不再向下一级别判断。 然后判断 table 级权限( mysql.tables_priv 表)，如果具备权限，则不再向下一级别判断。 然后判断 columns 权限( mysql.columns_priv 表)，如果具备权限，则不再向下一级别判断。 示例：如果 mysql.user 表中，wang@% 用户具有 SELECT 权限 则其对所有数据库均具有 SELECT 权限，即使 mysql.db 表中，wang@% 用户对 testdatabase 数据库没有 SELECT 权限，其也可以使用 SELECT 语句查询 testdatabase 数据库中的信息，因为在判断 GLOABLE 权限时，即已经确认具有权限。\n如果 mysql.user 表中，wang@% 用户不具有 INSERT 权限，则其对数据库是否能够 INSERT，需要去下一级别的表中查找，如果在 mysql.db 表中，wang@% 用户对 testdatabase 数据库具有 INSERT 权限，则其可以对 testdatabase 数据库进行 INSERT 操作，对其他数据表/列是否具备 INSERT 权限，需要逐级去 mysql.tables_priv，甚至 mysql.columns_priv 表查看。\n官网：account-management-statements\n","description":"","tags":["MySQL"],"title":"MySQL 用户及权限管理","uri":"/posts/database/mysql-user-and-authorition/"},{"categories":null,"content":"vue 上传文件并携带数据 使用 ElementsUI 的 upload 组件 官方地址\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u003cel-upload class=\"upload-demo\" ref=\"upload\" action=\"https://jsonplaceholder.typicode.com/posts/\" // 后台服务 url :auto-upload=\"false\" :data=\"otherData\" // 添加需要上传的数据 \u003e \u003cel-button slot=\"trigger\" size=\"small\" type=\"primary\"\u003e选取文件\u003c/el-button\u003e \u003cel-button style=\"margin-left: 10px;\" size=\"small\" type=\"success\" @click=\"submitUpload\"\u003e上传到服务器\u003c/el-button\u003e \u003cdiv slot=\"tip\" class=\"el-upload__tip\"\u003e只能上传 jpg/png 文件，且不超过 500kb\u003c/div\u003e \u003c/el-upload\u003e \u003cscript\u003e export default { data() { return { otherData: {\"id\": \"A01\", \"name\": \"zhangsan\"} }; }, methods: { submitUpload() { this.$refs.upload.submit(); } } } \u003c/script\u003e 注意，使用此方法上传文件时，请求头中 ContenType=multipart/form-data，此时使用的是 Form Data 形式的数据，后台 SpringMVC 需使用 @RequestParam 进行接收，对上传的文件可以直接使用 @RequestParam(\"file\")进行封装，但是对于 otherData, 本人使用 String 类型数据进行接收，并使用阿里巴巴的 JSON 类对其进行转换，进而得到相应对象。\n1 2 3 4 5 6 @RequestMapping(value = \"/method\") @ResponseBody public String method(@RequestParam(\"otherDataStr\") String otherDataStr, @RequestParam(value = \"file\", required = false) MultipartFile file) { OtherDataStr otherData = JSON.parseObject(otherDataStr, OtherDataStr.class); ","description":"","tags":["VUE"],"title":"vue 上传文件并携带数据","uri":"/posts/vue/vue-upload-file-and-data/"},{"categories":null,"content":"Dubbo 部署在 Docker 中使用宿主机进行注册 环境说明\ndubbo 版本 2.8.5 provider 部署在虚拟机中安装的 Docker 容器中 customer 部署在主机 使用 redis 作为注册中心，部署在主机 解决方法 修改 docker 容器 /etc/host 文件，将 hostname 对应的那一行 IP 修改为虚拟机 IP\n例如：将 172.1.0.2 foikjen2idio 修改为 192.168.122.234 foikjen2idio\n解释说明 需了解 Dubbo 如何获取 provider 的 IP 和端口，并将其存入注册中心\n参考 RedisRegistry 类等\n其他解决方案（未测试）: 设置容器的 IP 与主机 IP 在同一网段内，使容器 IP 可直接访问（会占用大量的 IP 地址，且 IP 会限制在同一网段，在生产环境中往往不可能）。 通过复杂的 iptables 路由规则，通过多层桥接方式打通网络（此法是可行的，也是今后要考虑的，但是操作起来略麻烦）。 对 Dubbo 进行扩展，扩展 dubbo protocol 配置，增加配置项 publish host、publish port，对应主机的 IP 和 Port，并且在注册服务时将主机的 IP 和 Port 写到注册中心。（这种方法需要对 Dubbo 进行扩展，不太建议） 参考文档 Dubbo 在 docker 容器中遇到的跨主机通信问题\n","description":"","tags":["Dubbo","Docker"],"title":"Dubbo 部署在 Docker 中使用宿主机 IP 进行注册","uri":"/posts/dubbo/dubbo-in-docker-registry/"},{"categories":null,"content":"PostgreSQL 物理，逻辑，进程结构以及系统表系统函数 PostgreSQL 逻辑结构概貌 Cluster：执行init命令后，会自动生成一个用来存放数据库的簇，可通过 cd $PGDATA 进入到其文件夹 Database（s）：在 CLuster 下可以创建多个互相隔离的数据库 Schema（s）：默认有一个 public 的 schema Object：包含 Tables、Index、View、Function（s）、序列 Sequence（s）、Other（s） Field：Tables 中还包含 Row 和 Col PostgreSQL 物理结构概貌 每一个 Object 都有相对应的数据文件（Datafile），大小为编译时通过 --with-segsize 指定，默认 1GB。 Controlfile：控制文件 WALs：日志文件 Archived：归档文件 PostgreSQL 进程结构概貌 用户（APP）先与 postmaster 主进程联系，主进程 fork 出一个 backend process 进程与 APP 进行后续操作 WAL writer 负责将 WAL buffer 写入到 XLOGs 日志，backend process 发现 WAL buffer 满了（等情况）后，也会将 WAL buffer 中的信息写入到 XLOGs 日志 bgwriter 负责将 Shared buffer 中的信息写入到 Datafiles，当 backed process 中新来了一条插入语句，但是 Shared buffer 满了（等情况）的话，backed process 也会将 Shared buffer 中的数据写入到 Datafiles Archiver 将写满的 XLOG 文件归档到 ARCH FILEs PostgreSQL 部分命令 Informational\noptions：S = 显示系统对象，+ = 附加详细信息\n\\d[S+]：查看 tables，views 和 sequences \\d[S+] NAME：tables，views，sequences 或 index 的描述 PostgreSQL 系统表介绍 系统表，系统表之间基本上都是 oid（隐藏字段）关联。例如 pg_attrdef.adrelid 关联 pg_class.oid 查询所有系统表：\\dS 或 select relkind，relname from pg_class where relnamespace = (select oid from pg_namespace where nspname='pg_catalog') and relkind='r' order by 1,2;\\ relkind relname 用途 r pg_aggregate 聚合函数信息，包括聚合函数的中间函数，中间函数的初始值，最终函数等。 r pg_am 系统支持的索引访问方法。（如 bree，hash，gist，gin，spgist） select amname from pg_am; r pg_amop 存储每个索引访问方法操作符家族（pg_opfamily）中的详细操作符信息 r pg_amproc 存储每个索引访问方法操作符家族（pg_opfamily）支持的函数信息。 r pg_attrdef 存储数据表列的默认值（例如创建表时指定了列的 default 值） r pg_attribute 存储数据表列的详细信息。包括隐含的列（ctid，cmin，cmax，xmin，xmax） r pg_auth_memebers 数据库用户的成员关系信息 r pg_authid 存储数据库用户的详细信息（包括是否超级用户，是否允许登录，密码（加密与否和创建用户时是否指定 encrypted 有关），密码失效时间等）。 r pg_cast 数据库的显性类型转换路径信息，包括内建和自定义的。 r pg_class 几乎包括了数据库的所有对象信息（r=ordinary table，i=index，S=sequence，v=view，m=materialized view，c=composite type，t=TOAST table，f=foreign table) r pg_collation 集信息，包括 encoding，collate，ctype 等。 r pg_constraint 存储列上定义的约束信息（例如 PK，FK，UK，排他约束，check 约束，但是不包括非空约束） r pg_conversion 字符集之间的转换相关信息 r pg_database 集群中的数据库信息 r pg_db_role_setting 基于角色和数据库组合的定制参数信息。（alter role set...） r pg_default_acl 存储新创建对象的初始权限信息 r pg_depend 数据库对象之间的依赖信息 r pg_description 数据库对象的描述信息 r pg_enum 枚举类型信息 r pg_event_trigger 事件触发器信息 r pg_extension 扩展插件信息 r pg_foreign_data_wrapper FDW 信息 r pg_foreign_table 外部表信息 r pg_index 索引信息 r pg_inherits 继承表的继承关系信息 r pg_language 过程语言信息 r pg_largeobject 大对象的切片后的真实数据存储在这个表里 r pg_largeobject_metadata 大对象的元信息，包括大对象的 owner 访问权限。 r pg_namespace 数据库中欧哪个的 schema 信息（pg 中称为 namespace） r pg_opclass 索引访问方法的操作符分类信息 r pg_operator 操作符信息 r pg_opfamily 操作符家族信息 r pg_pltemplate 过程语言的模板信息 r pg_proc 数据库服务端函数信息 r pg_range 范围类型信息 r pg_rewrite 表和试图的重写规则信息 r pg_seclable 安全标签信息（SELinux） r pg_shdepend 数据库中的对象之间或者集群中的共享对象之间的依赖关系 r pg_shdescription 共享对象的描述信息 r pg_shseclable 共享对象的安全标签信息（SELinux） r pg_statistic_analyze 生成的统计信息，用于查询计划器计算成本 r pg_tablespace 表空间相关的信息 r pg_trigger 表上的触发器信息 r pg_ts_config 全文检索的配置信息 r pg_ts_config_map 全文检索配置映射信息 r pg_ts_dict 全文检索字典信息 r pg_ts_parser 全文检索解析器信息 r pg_ts_template 全文检索模板信息 r pg_type 数据库中的类型信息 r pg_user_mapping foregin server 的用户配置信息 PostgreSQL 系统视图介绍 获取所有系统视图：\\dvS 或 select relkind, relname from pg_class where relnamespace = (select oid from pg_namespace where nspname='pg_catalog') and relkind='v' order by 1,2; relkind relname 用途 v pg_available_extension_versions 显示当前系统已经编译的扩展插件的版本信息 v pg_available_extensions 显示但那给钱系统已经编译的扩展插件信息 v pg_cursors 当前可用的游标 v pg_group 用户组信息 v pg_indexes 索引信息 v pg_locks 锁信息 v pg_matviews 物化视图信息 v pg_prepared_statements 当前会话中使用 prepare 语法写的预处理 SQL 信息 v pg_prepared_xacts 二阶事物信息 v pg_roles 数据库角色信息 v pg_rules 数据库中使用 create rule 创建的规则信息 v pg_seclables 安全标签信息 v pg_settings 当缉拿数据库集群的参数设置信息 v pg_shadow 数据库用户信息 v pg_stat_activity 会话活动信息 v pg_stat_all_indexes 查询用户权限范围内的所有索引的统计信息 v pg_stat_all_tables 查询用户权限范围内的所有表的统计信息 v pg_stat_bgwriter bgwriter 进程的统计信息 v pg_stat_database 数据库即别的统计信息 v pg_stat_database_conflicts 数据库冲突统计信息 v pg_stat_replication 流复制相关的统计信息 v pg_stat_sys_indexes 系统表相关的索引统计信息 v pg_stat_sys_tables 系统表统计信息 v pg_stat_user_function 用户函数统计信息 v pg_stat_user_indexes 用户表的索引相关的统计信息 v pg_stat_user_tables 用户表统计信息 v pg_stat_xact_all_tables 当前事物的表级统计信息，显示用户可以放问的所有表 v pg_stat_xact_sys_tables 当前事务的表级统计信息，仅显示系统表 v pg_stat_xact_user_functions 当前事务的用户函数的统计信息 v pg_stat_xact_user_tables 当前事务的用户表的统计信息 v pg_statio_all_indexes 所有索引 io 相关的统计信息 v pg_statio_all_sequences 所有序列 io 相关的统计信息 v pg_statio_all_tables 所有表 io 相关的统计信息 v pg_statio_sys_indexes 系统索引 io 相关的统计信息 v pg_statio_sys_sequences 系统序列 io 相关的统计信息 v pg_statio_sys_tables 系统表 io 相关的统计信息 v pg_statio_user_indexes 用户索引 io 相关的统计信息 v pg_statio_user_sequences 用户序列 io 相关的统计信息 v pg_statio_user_tables 用户表 io 相关的统计信息 v pg_stats 数据库中的统计信息，以列为最小统计单位输出 v pg_tables 数据库中的表对象的信息 v pg_timezone_abbrevs 时区缩写信息 v pg_timezone_names 时区信息，包含全名 v pg_user 用户信息 v pg_user_mappings 外部表的用户映射权限信息 v pg_views 视图信息 PostgreSQL 管理函数 https://www.postgresql.org/docs/9.3/functions-admin.html\n配置函数 Name Return Type Description current_setting(setting_name) text get current value of setting set_config(setting_name, new_value, is_local) text set parameter and return new value 示例\n查询配置信息：show enable_seqscan; \u003c=\u003e select * from current_setting(enable_seqscan);\n设置配置信息（会话级别的）\n1 select * from set_config('enable_seqcan', 'off', false) 可通过 begin 开启一个事务，然后设置事务级别的配置\n服务端信号发送函数 Name Return Type Description pg_cancel_backend(pidint) boolean Cancel a backend's current query. You can execute this against another backend that has exactly the same role as the user calling the function. In all other cases, you must be a superuser. (关闭当前查询） pg_reload_conf() boolean Cause server processes to reload their configuration files（重读配置文件 pg_hba.conf，postgresql.conf） pg_rotate_logfile() boolean Rotate server's log file. （将日志写到新文件中） pg_terminate_backend(pidint) boolean Terminate a backend. You can execute this against another backend that has exactly the same role as the user calling the function. In all other cases, you must be a superuser.（关闭当前终端会话） 示例\n重读配置文件：pg_ctl reload 或 select pg_reload_conf(); 或 kill -s SIGHUP 进程号 将日志写到新建的文件中：select pg_rotate_logfile(); 备份控制函数 Name Return Type Description pg_create_restore_point(name text) text Create a named point for performing restore(restricted to superusers) pg_current_xlog_insert_location() text Get current transaction log insert location pg_current_xlog_location() text Get current transaction log write location pg_start_backup(label text [, fast boolean]) text Prepare for performing on-line backup(restricted to superusers or replication roles) pg_stop_backup() text Finish performing on-line backup(restricted to superusers or replication roles) pg_is_in_backup() bool True if an on-line exclusive backup in progress pg_backup_start_time() timestamp with time zone Get start time of an on-linie exclusive backup in progress. pg_switch_xlog() text Force switch to a new transaction log file(restricted to superusers) pg_xlogfile_name(location text) text Convert transaction log location string file name pg_xlogfile_name_offset(location text) text, integer Convert transaction log location string to file name and decimal byte offset within file pg_xlogfile_location_diff(location text, location text) numeric Calculate the difference between two transaction log locations 恢复信息函数 Name Return Type Description pg_is_in_recovery() bool True if recovery is still in progress. pg_last_xlog_receive_location() text Get last transaction log location received and synced to disk by streaming replication. While streaming replication is in progress this will increase monotonically. If recovery has completed this will remain static at the value of the last WAL record received and synced to disk during recovery. If streaming replication is disabled, or if it has not yet started, the function returns NULL. pg_last_xlog_replay_location() text Get last transaction log location replayed during recovery. If recovery is still in progress this will increase monotonically. If recovery has completed then this value will remain static at the value of the last WAL record applied during that recovery. When the server has been started normally without recovery the function returns NULL. pg_last_xact_replay_timestamp() timestamp with time zone Get time stamp of last transaction replayed during recovery. This is the time at which the commit or abort WAL record for that transaction was generated on the primary. If no transactions have been replayed during recovery, this function returns NULL. Otherwise, if recovery is still in progress this will increase monotonically. If recovery has completed then this value will remain static at the value of the last transaction applied during that recovery. When the server has been started normally without recovery the function returns NULL. 恢复控制函数 Name Return Type Description pg_is_xlog_replay_paused() bool True if recovery is paused. pg_xlog_replay_pause() void Pauses recovery immediately. pg_xlog_replay_resume() void Restarts recovery if it was paused. 事务镜像导出函数 Name Return Type Description pg_export_snapshot() text Save the current snapshot and return its identifier 数据库对象管理函数 Name Return Type Description pg_column_size(any) int Number of bytes used to store a particular value (possibly compressed) pg_database_size(oid) bigint Disk space used by the database with the specified OID pg_database_size(name) bigint Disk space used by the database with the specified name pg_indexes_size(regclass) bigint Total disk space used by indexes attached to the specified table pg_relation_size(relation regclass, fork text) bigint Disk space used by the specified fork ('main', 'fsm', 'vm', or 'init') of the specified table or index pg_relation_size(relation regclass) bigint Shorthand for pg_relation_size(..., 'main') pg_size_pretty(bigint) text Converts a size in bytes expressed as a 64-bit integer into a human-readable format with size units pg_size_pretty(numeric) text Converts a size in bytes expressed as a numeric value into a human-readable format with size units pg_table_size(regclass) bigint Disk space used by the specified table, excluding indexes (but including TOAST, free space map, and visibility map) pg_tablespace_size(oid) bigint Disk space used by the tablespace with the specified OID pg_tablespace_size(name) bigint Disk space used by the tablespace with the specified name pg_total_relation_size(regclass) bigint Total disk space used by the specified table, including all indexes and TOAST data 数据库对象存储位置管理函数 Name Return Type Description pg_relation_filenode(relation regclass) oid Filenode number of the specified relation pg_relation_filepath(relation regclass) text File path name of the specified relation 文件访问函数 Name Return Type Description pg_ls_dir(dirname text) setof text List the contents of a directory pg_read_file(filename text [, offset bigint, length bigint]) text Return the contents of a text file pg_read_binary_file(filename text [, offset bigint, length bigint]) bytea Return the contents of a file pg_stat_file(filename text) record Return information about a file 应用锁函数，对于长时间持锁的应用非常有效. 因为长时间的数据库重量锁会带来垃圾回收的问题 Name Return Type Description pg_advisory_lock(key bigint) void Obtain exclusive session level advisory lock pg_advisory_lock(key1 int, key2 int) PostgreSQL进程结构 进程源码大部分再：src/backend/postmaster\npostmaster：所有数据库进程的主进程（负责监听和fork子进程） startup：主要用于数据库恢复的进程 syslogger：记录系统日志 pgstat：收集统计信息 pgarch：如果开启了归档，那么postmaster会fork一个归档进程 checkpointer：负责检查点的进程 bgwriter：负责把shared buffer中的脏数据写入磁盘的进程 autovacuum lanucher：负责回收垃圾数据的进程，如果开启了autovacuum，那么postmaster会fork此进程 autovacuum worker：负责回收垃圾数据的work进程，是lanucher进程fork出来的 PostgreSQL物理结构 对象对应的物理文件再哪里?\n1 2 3 postgres=# select pg_relation_filepath('pg_class'::regclass); pg_realation_filepath ----------------------------- ","description":"","tags":["Database","PostgreSQL"],"title":"PostgreSQL 物理，逻辑，进程结构及系统表系统函数","uri":"/posts/database/postgresql-structure/"},{"categories":null,"content":"Spring Data JPA 连接不同类型的多源数据库 环境说明 Spring Boot：1.5.X Spring Data JPA：1.11.16 编写配置类 数据源配置 DataSourceConfig.java，确保该类会被添加到 IOC 容器中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 import com.alibaba.druid.pool.DruidDataSource; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.Primary; import javax.sql.DataSource; // 表示是 Spring 的配置类 @Configuration public class DataSourceConfig { // 第一个数据源 // 创建一个名为 primaryDataSource 的对象，放到容器中 @Bean(name = \"primaryDataSource\") // 指定读取配置文件的前缀 @ConfigurationProperties(prefix = \"spring.datasource.primary\") // 作为主数据库 @Primary public DataSource primaryDataSource() { /** * 使用 DataSourceBuilder.create().build();会按照如下顺序选择数据源, * 因当前项目使用 Druid 数据源，因此返回 DruidDataSource 对象 * * private static final String[] DATA_SOURCE_TYPE_NAMES = new String[] { * \"org.apache.tomcat.jdbc.pool.DataSource\", * \"com.zaxxer.hikari.HikariDataSource\", * \"org.apache.commons.dbcp.BasicDataSource\", // deprecated * \"org.apache.commons.dbcp2.BasicDataSource\" }; */ // return DataSourceBuilder.create().build(); return new DruidDataSource(); } // 第二个数据源 @Bean(name = \"secondaryDataSource\") @ConfigurationProperties(prefix = \"spring.datasource.secondary\") public DataSource secondaryDataSource() { return new DruidDataSource(); } } 第一个数据源的 JPA 配置 注意修改 Repository 所在位置和实体类所在位置，该配置类需被添加到 IOC 容器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.beans.factory.annotation.Value; import org.springframework.boot.autoconfigure.orm.jpa.JpaProperties; import org.springframework.boot.orm.jpa.EntityManagerFactoryBuilder; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.Primary; import org.springframework.data.jpa.repository.config.EnableJpaRepositories; import org.springframework.orm.jpa.JpaTransactionManager; import org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean; import org.springframework.transaction.PlatformTransactionManager; import org.springframework.transaction.annotation.EnableTransactionManagement; import javax.persistence.EntityManager; import javax.sql.DataSource; import java.util.HashMap; import java.util.Map; /** * 第一个数据源的 JPA 相关配置 */ @Configuration @EnableTransactionManagement @EnableJpaRepositories( entityManagerFactoryRef = \"entityManagerFactoryPrimary\", transactionManagerRef = \"transactionManagerPrimary\", basePackages = {\"icu.intelli.dao.primary\"}) public class PrimaryDataSourceJpaConfig { /** * 注入第一个数据源 */ @Autowired @Qualifier(\"primaryDataSource\") private DataSource primaryDataSource; /** * 实体管理 * @param builder * @return */ @Primary @Bean(name = \"entityManagerPrimary\") public EntityManager entityManager(EntityManagerFactoryBuilder builder) { return entityManagerFactoryPrimary(builder).getObject().createEntityManager(); } @Primary @Bean(name = \"entityManagerFactoryPrimary\") public LocalContainerEntityManagerFactoryBean entityManagerFactoryPrimary(EntityManagerFactoryBuilder builder) { return builder .dataSource(primaryDataSource) .properties(getVendorProperties(primaryDataSource)) // 设置实体类所在位置 .packages(\"icu.intelli.po.primary\") .persistenceUnit(\"primaryPersistenceUnit\") .build(); } /** * 注入 Jpa 属性对象 */ @Autowired private JpaProperties jpaProperties; /** * 从配置文件中读取方言 */ @Value(\"${spring.jpa.primary.dialect}\") private String primaryDialect; /** * JPA 属性设置 * * @param dataSource * @return */ private Map\u003cString, String\u003e getVendorProperties(DataSource dataSource) { // 存放自定义的 jpa 属性 Map\u003cString, String\u003e prop = new HashMap\u003c\u003e(); prop.put(\"hibernate.dialect\", primaryDialect); jpaProperties.setProperties(prop); return jpaProperties.getHibernateProperties(dataSource); } /** * JPA 事务管理设置 * * @param builder * @return */ @Primary @Bean(name = \"transactionManagerPrimary\") public PlatformTransactionManager transactionManagerPrimary(EntityManagerFactoryBuilder builder) { return new JpaTransactionManager(entityManagerFactoryPrimary(builder).getObject()); } } 第二个数据源的 JPA 配置 注意修改 Repository 所在位置和实体类所在位置，该配置类需被添加到 IOC 容器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.beans.factory.annotation.Value; import org.springframework.boot.autoconfigure.orm.jpa.JpaProperties; import org.springframework.boot.orm.jpa.EntityManagerFactoryBuilder; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.jpa.repository.config.EnableJpaRepositories; import org.springframework.orm.jpa.JpaTransactionManager; import org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean; import org.springframework.transaction.PlatformTransactionManager; import org.springframework.transaction.annotation.EnableTransactionManagement; import javax.persistence.EntityManager; import javax.sql.DataSource; import java.util.HashMap; import java.util.Map; /** * 第二数据源的 Jpa 相关配置 */ @Configuration @EnableTransactionManagement @EnableJpaRepositories( entityManagerFactoryRef = \"entityManagerFactorySecondary\", transactionManagerRef = \"transactionManagerSecondary\", basePackages = {\"icu.intelli.dao.secondary\"}) public class SecondaryDataSourceJpaConfig { @Autowired @Qualifier(\"secondaryDataSource\") private DataSource secondaryDataSource; @Bean(name = \"entityManagerSecondary\") public EntityManager entityManager(EntityManagerFactoryBuilder builder) { return entityManagerFactorySecondary(builder).getObject().createEntityManager(); } @Bean(name = \"entityManagerFactorySecondary\") public LocalContainerEntityManagerFactoryBean entityManagerFactorySecondary (EntityManagerFactoryBuilder builder) { return builder .dataSource(secondaryDataSource) .properties(getVendorProperties(secondaryDataSource)) // 设置实体类所在位置 .packages(\"icu.intelli.po.secondary\") .persistenceUnit(\"secondaryPersistenceUnit\") .build(); } @Autowired private JpaProperties jpaProperties; @Value(\"${spring.jpa.secondary.dialect}\") private String secondaryDialect; private Map\u003cString, String\u003e getVendorProperties(DataSource dataSource) { Map\u003cString, String\u003e prop = new HashMap\u003c\u003e(); prop.put(\"hibernate.dialect\", secondaryDialect); jpaProperties.setProperties(prop); return jpaProperties.getHibernateProperties(dataSource); } @Bean(name = \"transactionManagerSecondary\") PlatformTransactionManager transactionManagerSecondary(EntityManagerFactoryBuilder builder) { return new JpaTransactionManager(entityManagerFactorySecondary(builder).getObject()); } } 编写配置文件 该配置文件需要被添加到 Spring 容器中，可以在 SpringBoot 启动类上使用 @PropertySource(\"classpath:jdbc.properties\") 添加\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 # 第一个数据源配置（MySQL） spring.datasource.primary.url=jdbc:mysql://127.0.0.1:3306/database1?autoReconnect=true\u0026autoReconnectForPools=true\u0026useUnicode=true\u0026characterEncoding=utf8 spring.datasource.primary.username=root spring.datasource.primary.password=root spring.datasource.primary.driver-class-name=com.mysql.jdbc.Driver # 第一个数据源其他初始化配置 spring.datasource.primary.type=com.alibaba.druid.pool.DruidDataSource spring.datasource.primary.initial-size=10 spring.datasource.primary.min-idle=10 spring.datasource.primary.max-active=50 spring.datasource.primary.max-wait=60000 spring.datasource.primary.time-between-eviction-runs-millis=60000 spring.datasource.primary.min-evictable-idle-time-millis=300000 spring.datasource.primary.validationQuery=SELECT 'x' spring.datasource.primary.validation-query-timeout=30 spring.datasource.primary.test-while-idle=true spring.datasource.primary.test-on-borrow=true spring.datasource.primary.test-on-return=true spring.datasource.primary.pool-prepared-statements=false spring.datasource.primary.max-open-prepared-statements=100 spring.datasource.primary.max-pool-prepared-statement-per-connection-size=20 spring.datasource.primary.filters=wall,stat spring.datasource.primary.connection-properties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 # 第二个数据源配置（PostgreSQL） spring.datasource.secondary.url=jdbc:postgresql://127.0.0.1:5432/database2 spring.datasource.secondary.username=root spring.datasource.secondary.password=root spring.datasource.secondary.driver-class-name=org.postgresql.Driver # 第二个数据源其他初始化配置 spring.datasource.secondary.type=com.alibaba.druid.pool.DruidDataSource spring.datasource.secondary.initial-size=10 spring.datasource.secondary.min-idle=10 spring.datasource.secondary.max-active=50 spring.datasource.secondary.max-wait=60000 spring.datasource.secondary.time-between-eviction-runs-millis=60000 spring.datasource.secondary.min-evictable-idle-time-millis=300000 spring.datasource.secondary.validationQuery=SELECT version() spring.datasource.secondary.validation-query-timeout=30 spring.datasource.secondary.test-while-idle=true spring.datasource.secondary.test-on-borrow=true spring.datasource.secondary.test-on-return=true spring.datasource.secondary.pool-prepared-statements=false spring.datasource.secondary.max-open-prepared-statements=100 spring.datasource.secondary.max-pool-prepared-statement-per-connection-size=20 spring.datasource.secondary.filters=wall,stat spring.datasource.secondary.connection-properties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000 # JPA 公共配置 spring.jpa.show-sql=true spring.jpa.generate-ddl=true spring.jpa.hibernate.ddl-auto=update # JPA 指定配置 # 第一数据源相关配置（MySQL） spring.jpa.primary.dialect=org.hibernate.dialect.MySQL5Dialect # 第二数据源相关配置（Postgis） spring.jpa.secondary.dialect=org.hibernate.spatial.dialect.postgis.PostgisDialect 测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 import icu.intelli.Application; import icu.intelli.dao.productfileinfo.ProductFileInfoDao; import icu.intellidao2.DecodingTypeRepository; import icu.intelli.entity2.DecodingType; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; import javax.sql.DataSource; import java.util.List; @RunWith(SpringRunner.class) @SpringBootTest(classes = Application.class) public class myTest { @Autowired private ProductFileInfoDao productFileInfoDao; @Autowired private DecodingTypeRepository decodingTypeRepository; @Autowired @Qualifier(\"primaryDataSource\") DataSource primaryDataSource; @Autowired @Qualifier(\"secondaryDataSource\") DataSource secondaryDataSource; @Test public void testDao1() { List list = productFileInfoDao.findByproductInfoId(\"33789241244d466fb2427283f8b24619\"); System.out.println(list); } @Test public void testDao2() { DecodingType one = decodingTypeRepository.findOne(\"A\"); System.out.println(one); } } 参考文档 SpringBoot 1.5.XX 多数据源配置\n","description":"","tags":["Spring Data JPA","Java"],"title":"Spring Data JPA 连接不同类型的多源数据库","uri":"/posts/java/spring-data-jpa-connection-noequale-datasource/"},{"categories":null,"content":"Fedora31 安装 Docker 报错 报错信息 1 2 3 docker: Error response from daemon: OCI runtime create failed: container_linux.go:346: starting container process caused \"process_linux.go:297: applying cgroup configuration for process caused \\\"open /sys/fs/cgroup/docker/cpuset.cpus.effective: no such file or directory\\\"\": unknown. 产生原因 fedora31 默认使用 cgroups v2，docker 暂不支持 cgroups v2.\n官方说明\nThe Docker package has been removed from Fedora 31. It has been replaced by the upstream package moby-engine, which includes the Docker CLI as well as the Docker Engine. However, we recommend instead that you use Package-x-generic-16.pngpodman, which is a Cgroups v2-compatible container engine whose CLI is compatible with Docker's. Fedora 31 uses Cgroups v2 by default. The moby-engine package does not support Cgroups v2 yet, so if you need to run the moby-engine or run the Docker CE package, then you need to switch the system to using Cgroups v1, by passing the kernel parameter systemd.unified_cgroup_hierarchy=0. To do this permanently, run:\n1 sudo grubby --update-kernel=ALL --args=\"systemd.unified_cgroup_hierarchy=0\" 解决方法 法一：修改 /etc/default/grub 文件 在该文件的 GRUB_CMDLINE_LINUX= 里面新增内容\n1 systemd.unified_cgroup_hierarchy=0 保存退出后，执行\n1 grub2-mkconfig 重启机器\n法二：参照官方文档 执行\n1 sudo grubby --update-kernel=ALL --args=\"systemd.unified_cgroup_hierarchy=0\" 参考文档 Fedora 31 安装 docker\n","description":"","tags":["Docker","Fedora"],"title":"Fedora31 安装 Docker 报错","uri":"/posts/linux/fedora/fedora31-docker-install-error/"},{"categories":null,"content":"Docker 给已运行的容器添加端口映射 注： 该方法需要重启 docker 服务\n查看正在运行中的容器 1 2 3 [root@localhost ~]$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b19505cec84d tomcat \"catalina.sh run\" 4 minutes ago Up 2 seconds 0.0.0.0:8888-\u003e8080/tcp affectionate_driscoll 当前容器将容器的 8080 端口与宿主机的 8888 端口进行了映射\n停止需要修改端口映射的容器 1 2 [root@localhost ~]$ docker stop b195 b195 修改相应容器的配置文件 配置文件在 /var/lib/docker/containers/{container id} 目录下\n修改 hostconfig.json 在 PortBindings 中添加/删除新的端口映射关系，此处添加容器的 9080 与宿主机的 9999 端口映射关系\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 { \"Binds\":null, \"ContainerIDFile\":\"\", \"LogConfig\":{ \"Type\":\"json-file\", \"Config\":{ } }, \"NetworkMode\":\"default\", \"PortBindings\":{ \"8080/tcp\":[ { \"HostIp\":\"\", \"HostPort\":\"8888\" } ], \"9080/tcp\":[ { \"HostIp\":\"\", \"HostPort\":\"9999\" } ] }, \"RestartPolicy\":{ \"Name\":\"no\", \"MaximumRetryCount\":0 }, ... } 修改 config.v2.json 修改 Config → ExposedPorts 中的信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 { \"StreamConfig\":{ }, \"State\":{ \"Running\":false, \"Paused\":false, \"Restarting\":false, \"OOMKilled\":false, \"RemovalInProgress\":false, \"Dead\":false, \"Pid\":0, \"ExitCode\":143, \"Error\":\"\", \"StartedAt\":\"2020-03-09T07:46:49.757023507Z\", \"FinishedAt\":\"2020-03-09T07:48:41.124615166Z\", \"Health\":null }, \"ID\":\"b19505cec84d0e0a10a1583e1c5fa71c385e6fde21478e3bf90428169390598f\", \"Created\":\"2020-03-09T07:42:49.197745561Z\", \"Managed\":false, \"Path\":\"catalina.sh\", \"Args\":[ \"run\" ], \"Config\":{ \"Hostname\":\"b19505cec84d\", \"Domainname\":\"\", \"User\":\"\", \"AttachStdin\":false, \"AttachStdout\":false, \"AttachStderr\":false, \"ExposedPorts\":{ \"8080/tcp\":{ }, \"9080/tcp\":{ } }, \"Tty\":false, \"OpenStdin\":false, \"StdinOnce\":false, }, ... } 重启 docker 服务 1 systemctl restart docker 启动相应容器 1 docker start b19505cec84d ","description":"","tags":["Docker"],"title":"Docker 给已运行的容器添加端口映射","uri":"/posts/docker/docker-running-add-port/"},{"categories":null,"content":"VUE 跨域问题 使用 Nginx 结局 将打包后的文件放在 nginx 的 html 文件夹中 可以任意存放位置，只需修改配置文件中对应配置即可\n目录结构类似如下\n1 2 3 4 html/ └── dist ├── index.html └── static 修改 nginx 配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 user root; worker_processes 1; events { worker_connections 1024; } http { # 解决浏览器控制台 Resource interpreted as Stylesheet but transferred with MIME type text/plain 错误 # 主要影响为，造成页面样式显示不正确 include mime.types; default_type application/octet-stream; server { # nginx 的端口和地址 listen 8100; server_name localhost; location / { # 指定 vue 项目打包后文件存放的位置 root /root/software/nginx/html/dist; try_files $uri $uri/ /index.html add_header 'Access-Controller-Allow-Origin' '*'; index index.html index.htm; } # 此处根据 vue 中的配置进行修改 location /api/ { # 被代理的后端服务地址 proxy_pass http://127.0.0.1:8110/; # 解决跨域请求问题的主要代码 add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Methods' '*'; add_header 'Access-Control-Allow-Headers' 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization,token'; # 其他配置，暂不清楚，可查看 nginx 官方文档 proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Connection close; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; proxy_max_temp_file_size 0; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; } } } SpringBoot 项目解决跨域问题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import org.springframework.context.annotation.Configuration; import org.springframework.web.servlet.config.annotation.CorsRegistry; import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter; /** * 解决跨域请求问题 */ @Configuration public class CorsConfig extends WebMvcConfigurerAdapter { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\"/**\") .allowedOrigins(\"*\") .allowCredentials(true) .allowedMethods(\"GET\", \"POST\", \"DELETE\", \"PUT\") .maxAge(3600); super.addCorsMappings(registry); } } ","description":"","tags":["VUE"],"title":"VUE 跨域问题","uri":"/posts/vue/vue-cors/"},{"categories":null,"content":"怎样在 CentOS 7.0 上安装和配置 VNC 服务器 转载自: https://linux.cn/article-5335-1.html?spm=a2c4e.11153940.blogcont529843.16.418e5adbHynoah\n这是一个关于怎样在你的 CentOS 7 上安装配置 VNC 服务的教程。当然这个教程也适合 RHEL 7。在这个教程里，我们将学习什么是 VNC 以及怎样在 CentOS 7 上安装配置 VNC 服务器。\n我们都知道，作为一个系统管理员，大多数时间是通过网络管理服务器的。在管理服务器的过程中很少会用到图形界面，多数情况下我们只是用 SSH 来完成我们的管理任务。在这篇文章里，我们将配置 VNC 来提供一个连接我们 CentOS 7 服务器的方法。VNC 允许我们开启一个远程图形会话来连接我们的服务器，这样我们就可以通过网络远程访问服务器的图形界面了。\nVNC 服务器是一个自由开源软件，它可以让用户可以远程访问服务器的桌面环境。另外连接 VNC 服务器需要使用 VNC viewer 这个客户端。\n一些 VNC 服务器的优点：\n远程的图形管理方式让工作变得简单方便。 剪贴板可以在 CentOS 服务器主机和 VNC 客户端机器之间共享。 CentOS 服务器上也可以安装图形工具，让管理能力变得更强大。 只要安装了 VNC 客户端，通过任何操作系统都可以管理 CentOS 服务器了。 比 ssh 图形转发和 RDP 连接更可靠。 那么，让我们开始安装 VNC 服务器之旅吧。我们需要按照下面的步骤一步一步来搭建一个可用的 VNC。\n首先，我们需要一个可用的桌面环境（X-Window），如果没有的话要先安装一个。\n注意：以下命令必须以 root 权限运行。要切换到 root，请在终端下运行“sudo -s”，当然不包括双引号（“”）\n1. 安装 X-Window 首先我们需要安装 X-Window，在终端中运行下面的命令，安装会花费一点时间。\n# yum check-update# yum groupinstall \"X Window System\" installing x windows\n#yum install gnome-classic-session gnome-terminal nautilus-open-terminal control-center liberation-mono-fonts install gnome classic session\n### 设置默认启动图形界面# unlink /etc/systemd/system/default.target# ln -sf /lib/systemd/system/graphical.target /etc/systemd/system/default.target configuring graphics\n# reboot 在服务器重启之后，我们就有了一个工作着的 CentOS 7 桌面环境了。\n现在，我们要在服务器上安装 VNC 服务器了。\n2. 安装 VNC 服务器 现在要在我们的 CentOS 7 上安装 VNC 服务器了。我们需要执行下面的命令。\n# yum install tigervnc-server -y vnc server\n3. 配置 VNC 然后，我们需要在 /etc/systemd/system/ 目录里创建一个配置文件。我们可以将 /lib/systemd/sytem/vncserver@.service 拷贝一份配置文件范例过来。\n# cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service copying vnc server configuration\n接着我们用自己最喜欢的编辑器（这儿我们用的 nano）打开 /etc/systemd/system/vncserver@:1.service，找到下面这几行，用自己的用户名替换掉。举例来说，我的用户名是 linoxide 所以我用 linoxide 来替换掉：\nExecStart=/sbin/runuser -l \u003cUSER\u003e -c \"/usr/bin/vncserver %i\"PIDFile=/home/\u003cUSER\u003e/.vnc/%H%i.pid 替换成\nExecStart=/sbin/runuser -l linoxide -c \"/usr/bin/vncserver %i\"PIDFile=/home/linoxide/.vnc/%H%i.pid 如果是 root 用户则\nExecStart=/sbin/runuser -l root -c \"/usr/bin/vncserver %i\"PIDFile=/root/.vnc/%H%i.pid configuring user\n好了，下面重启 systemd。\n# systemctl daemon-reload 最后还要设置一下用户的 VNC 密码。要设置某个用户的密码，必须要有能通过 sudo 切换到用户的权限，这里我用 linoxide 的权限，执行“su linoxide”就可以了。\n# su linoxide$ sudo vncpasswd setting vnc password\n确保你输入的密码多于 6 个字符\n4. 开启服务 用下面的命令（永久地）开启服务：\n$ sudo systemctl enable vncserver@:1.service 启动服务。\n$ sudo systemctl start vncserver@:1.service 5. 防火墙设置 我们需要配置防火墙来让 VNC 服务正常工作。\n$ sudo firewall-cmd --permanent --add-service vnc-server$ sudo systemctl restart firewalld.service allowing firewalld\n现在就可以用 IP 和端口号（LCTT 译注：例如 192.168.1.1:1，这里的端口不是服务器的端口，而是视 VNC 连接数的多少从 1 开始排序）来连接 VNC 服务器了。\n6. 用 VNC 客户端连接服务器 好了，现在已经完成了 VNC 服务器的安装了。要使用 VNC 连接服务器，我们还需要一个在本地计算机上安装的仅供连接远程计算机使用的 VNC 客户端。\nremote access vncserver from vncviewer\n你可以用像 Tightvnc viewer 和 Realvnc viewer 的客户端来连接到服务器。\n要用更多的用户连接，需要创建配置文件和端口，请回到第 3 步，添加一个新的用户和端口。你需要创建 vncserver@:2.service 并替换配置文件里的用户名和之后步骤里相应的文件名、端口号。请确保你登录 VNC 服务器用的是你之前配置 VNC 密码的时候使用的那个用户名。\nVNC 服务本身使用的是 5900 端口。鉴于有不同的用户使用 VNC，每个人的连接都会获得不同的端口。配置文件名里面的数字告诉 VNC 服务器把服务运行在 5900 的子端口上。在我们这个例子里，第一个 VNC 服务会运行在 5901（5900 + 1）端口上，之后的依次增加，运行在 5900 + x 号端口上。其中 x 是指之后用户的配置文件名 vncserver@:x.service 里面的 x。\n在建立连接之前，我们需要知道服务器的 IP 地址和端口。IP 地址是一台计算机在网络中的独特的识别号码。我的服务器的 IP 地址是 96.126.120.92，VNC 用户端口是 1。\n执行下面的命令可以获得服务器的公网 IP 地址（LCTT 译注：如果你的服务器放在内网或使用动态地址的话，可以这样获得其公网 IP 地址）。\n# curl -s checkip.dyndns.org|sed -e 's/.*Current IP Address: //' -e 's/\u003c.*$//' 总结 好了，现在我们已经在运行 CentOS 7 / RHEL 7 的服务器上安装配置好了 VNC 服务器。VNC 是自由开源软件中最简单的一种能实现远程控制服务器的工具，也是一款优秀的 Teamviewer Remote Access 替代品。VNC 允许一个安装了 VNC 客户端的用户远程控制一台安装了 VNC 服务的服务器。下面还有一些经常使用的相关命令。好好玩！\n其他命令： 关闭 VNC 服务。\n# systemctl stop vncserver@:1.service 禁止 VNC 服务开机启动。\n# systemctl disable vncserver@:1.service 关闭防火墙。\n# systemctl stop firewalld.service ","description":"","tags":["Linux","CentOS"],"title":"CentOS7 安装 TigerVNC","uri":"/posts/linux/centos/centos7-vnc/"},{"categories":null,"content":"Spring 注解：AOP 功能测试 Spring 注解系列目录\nAOP：指在程序运行期间动态的将某段代码切入到指定方法指定位置进行运行的编程方式。（底层使用动态代理）\n相关名词解释\nProxy（代理）：为目标对象生成代理对象。即在不改变原始代码的情况下，通过代理对象对原始对象的功能进行增强。Spring 主要使用 JDK 动态代理和 CGLIB 代理。 Target（目标对象）：被代理的对象，需要增强的对象，即真正的业务逻辑类。 Joinpoint（连接点）：目标对象中所有可以增强的方法 Advice（通知/增强）：具体的增强方法，例如日志记录等。 Pointcut（切入点）：带有通知的连接点，即目标对象中需要被增强的方法。 Aspect（切面）：通常是一个类，里面定义了切入点和通知。 Weaving（织入）：将增强添加到目标对象的连接点的过程。Spring 使用运行时织入，AspectJ 使用编译期织入和类加载期织入 Introduction（引入）：对目标对象声明额外属性和方法的过程。 从原始代码的所有方法（连接点）中，选择指定的方法（切入点），组合成一个切面类（切面），在不改变原始业务类（目标对象）代码的情况下，通过切面创建（代理）对象（引入），在指定业务方法执行的某一时刻添加（织入）日志记录等功能（通知/增强）。\nSpring 使用 AOP 的步骤 导入 aop 模块：spring-aspects\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-aspects\u003c/artifactId\u003e \u003cversion\u003e4.3.25.RELEASE\u003c/version\u003e \u003c/dependency\u003e 定义业务逻辑类（MathCalculator）：在业务逻辑运行时将日志进行打印（方法之前，方法运行结束，方法出现异常……）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package icu.intelli.aop; public class MathCalculator { public int sum(int i, int j) { System.out.println(\"MathCalculator.sum()...\"); return i + j; } public int div(int i, int j) { System.out.println(\"MathCalculator.div()...\"); return i / j; } } 定义一个日志切面类，并使用注解标注该切面何时何地执行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 package icu.intelli.aop; import org.aspectj.lang.annotation.*; /** * 切面类 * 如果同一连接点上有多个切面时，可以使用 @Order 注解在切面类上或实现 Ordered 接口指定切面的优先级，数字越小优先级越高 */ // 告诉 Spring 该类是切面类 @Aspect public class LogAspects { /** * 抽取公共的切入点表达式 * // 1. 本类引用 * @Pointcut() * public void pointCut() { } */ // 2. 其他的切面类引用 @Pointcut(\"execution(public int icu.intelli.aop.MathCalculator.*(..))\") public void pointCut() { } // @Before 在目标方法之前切入 // public int icu.intelli.aop.MathCalculator.div(int, int)：切入点表达式，指定在哪个方法切入 @Before(\"pointCut()\") public void logStart() { System.out.println(\"@Before 除法运行...参数列表是：{}\"); } // 无论方法正常结束还是异常结束都调用 @After(\"pointCut()\") public void logEnd() { System.out.println(\"@After 除法结束...\"); } @AfterReturning(\"pointCut()\") public void logReturn() { System.out.println(\"@AfterReturning 除法正常返回...运行结果：{}\"); } @AfterThrowing(\"pointCut()\") public void logException() { System.out.println(\"@AfterThrowing 除法异常...异常信息：{}\"); } } 通知方法：\n前置通知（@Before）：在目标方法运行前运行 后置通知（@After）：在目标方法运行结束后运行 返回通知（@AfterReturning）：在目标方法正常返回之后运行 异常通知（@AfterThrowing）：在目标方法运行出现异常后运行 环绕通知（@Around）：动态代理，手动推进目标方法运行（joinPoint.proced()） 将切面类和业务逻辑类（目标方法所在类）都加入到容器中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package icu.intelli.config; import icu.intelli.aop.LogAspects; import icu.intelli.aop.MathCalculator; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * 给配置类中加入 @EnableAspectJAutoProxy 注解，开启基于注解的 AOP 模式 * 在 Spring 中有很多的 @EnableXxx 注解来启动某些功能 */ @EnableAspectJAutoProxy @Configuration public class MainConfig { // 业务逻辑类加入到容器中 @Bean public MathCalculator calculator() { return new MathCalculator(); } // 将切面类加入到容器中 @Bean public LogAspects logAspects() { return new LogAspects(); } } AOPTest 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package icu.intelli; import icu.intelli.aop.MathCalculator; import icu.intelli.config.MainConfig; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class AOPTest { public static void main(String[] args) { AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); // 注意，一定要使用从容器中获取的 Bean，自己创建的 Bean 不支持 AOP MathCalculator mathCalculator = applicationContext.getBean(MathCalculator.class); mathCalculator.div(1, 1); } } 程序输出\n@Before 除法运行...参数列表是：{} MathCalculator.div()... @After 除法结束... @AfterReturning 除法正常返回...运行结果：{} 在切面类中获取方法的返回值等信息 修改 LogAspects.java，在切面方法中添加 JoinPoint 参数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 package icu.intelli.aop; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.*; /** * 切面类 */ // 告诉 Spring 该类是切面类 @Aspect public class LogAspects { /** * 抽取公共的切入点表达式 * // 1. 本类引用 * * @Pointcut() public void pointCut() { } */ // 2. 其他的切面类引用 @Pointcut(\"execution(public int icu.intelli.aop.MathCalculator.*(..))\") public void pointCut() { } // @Before 在目标方法之前切入 // public int icu.intelli.aop.MathCalculator.div(int, int)：切入点表达式，指定在哪个方法切入 @Before(\"pointCut()\") public void logStart(JoinPoint joinPoint) { String methodName = joinPoint.getSignature().getName(); Object[] methodArgs = joinPoint.getArgs(); System.out.println(methodName + \"@Before...参数列表是：{\" + methodArgs + \"}\"); } // 无论方法正常结束还是异常结束都调用 @After(\"pointCut()\") public void logEnd(JoinPoint joinPoint) { String methodName = joinPoint.getSignature().getName(); System.out.println(methodName + \"@After 除法结束...\"); } // 使用 @AfterReturning 的 resulting 参数来指定使用 result 参数接收方法的返回值 @AfterReturning(value = \"pointCut()\", returning = \"result\") public void logReturn(JoinPoint joinPoint, Object result) { String methodName = joinPoint.getSignature().getName(); System.out.println(methodName + \"@AfterReturning 除法正常返回...运行结果：{\" + result + \"}\"); } // 使用 @AfterThrowing 的 throwing 参数来指定使用 exception 参数接收方法的异常信息 @AfterThrowing(value = \"pointCut()\", throwing = \"exception\") public void logException(JoinPoint joinPoint, Exception exception) { String methodName = joinPoint.getSignature().getName(); System.out.println(methodName + \"@AfterThrowing 除法异常...异常信息：{\" + exception + \"}\"); } } 注意：使用 @AfterReturning 和 @AfterThrowing 标注的方法参数，JointPoint 要放在第一个参数位置，Object 和 Exception 放在第二个参数位置\n测试输出\ndiv@Before...参数列表是：{[Ljava.lang.Object;@7b98f307} MathCalculator.div()... div@After 除法结束... div@AfterReturning 除法正常返回...运行结果：{1} 总结 三步：\n将业务逻辑组件和切面类都加入到容器中，告诉 Spring 哪个是切面类（@Aspect） 在切面类上的每一个通知方法上标注通知注解，告诉 Spring 何时何地运行（切入点表达式） 开启基于注解的 AOP 模式 @EnableAspectJAutoProxy 配置文件版 AOP 导入依赖\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-aspects\u003c/artifactId\u003e \u003cversion\u003e4.3.25.RELEASE\u003c/version\u003e \u003c/dependency\u003e 切面类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import org.aspectj.lang.JoinPoint; /** * 切面类 */ public class LogAspects { public void logStart(JoinPoint joinPoint) { String methodName = joinPoint.getSignature().getName(); Object[] methodArgs = joinPoint.getArgs(); System.out.println(methodName + \"@Before...参数列表是：{\" + methodArgs + \"}\"); } public void logEnd(JoinPoint joinPoint) { String methodName = joinPoint.getSignature().getName(); System.out.println(methodName + \"@After 除法结束...\"); } public void logReturn(JoinPoint joinPoint, Object result) { String methodName = joinPoint.getSignature().getName(); System.out.println(methodName + \"@AfterReturning 除法正常返回...运行结果：{\" + result + \"}\"); } public void logException(JoinPoint joinPoint, Exception exception) { String methodName = joinPoint.getSignature().getName(); System.out.println(methodName + \"@AfterThrowing 除法异常...异常信息：{\" + exception + \"}\"); } } 目标对象类\n1 2 3 4 5 6 7 public class MathCalculator { public int div(int i, int j) { System.out.println(\"MathCalculator.div()...\"); return i / j; } } 修改 beans.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop https://www.springframework.org/schema/aop/spring-aop.xsd\"\u003e \u003c!-- 配置需要增强的 bean --\u003e \u003cbean id=\"mathCalculator\" class=\"icu.intelli.aop.MathCalculator\"/\u003e \u003c!-- 配置切面类 --\u003e \u003cbean id=\"logAspects\" class=\"icu.intelli.aop.LogAspects\"/\u003e \u003c!-- 配置 AOP --\u003e \u003caop:config\u003e \u003c!-- 配置切点表达式 --\u003e \u003caop:pointcut id=\"pointcut\" expression=\"execution(* icu.intelli.aop.MathCalculator.*(..))\"/\u003e \u003c!-- 配置切面及通知，可添加 order 属性指定切面的优先级--\u003e \u003caop:aspect ref=\"logAspects\"\u003e \u003caop:before method=\"logStart\" pointcut-ref=\"pointcut\"/\u003e \u003caop:after method=\"logEnd\" pointcut-ref=\"pointcut\"/\u003e \u003caop:after-returning method=\"logReturn\" pointcut-ref=\"pointcut\" returning=\"result\"/\u003e \u003caop:after-throwing method=\"logException\" pointcut-ref=\"pointcut\" throwing=\"exception\"/\u003e \u003c/aop:aspect\u003e \u003c/aop:config\u003e \u003c/beans\u003e 测试类 AOPTest\n1 2 3 4 5 6 7 8 9 10 11 import icu.intelli.aop.MathCalculator; import org.springframework.context.support.ClassPathXmlApplicationContext; public class AOPTest { public static void main(String[] args) { ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"classpath:beans.xml\"); MathCalculator mathCalculator = applicationContext.getBean(MathCalculator.class); mathCalculator.div(0, 1); } } ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：AOP 功能测试","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-aop/"},{"categories":null,"content":"Spring 注解：@Autowired，@Qualifier，@Primary 自动装配 Spring 注解系列目录\n@Autowired 容器中只有一个 BookService 类型的 bean 时\nBookController\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import icu.intelli.service.BookService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Controller; @Controller public class BookController { // 自动注入 bookService @Autowired private BookService bookService; // 打印 bookService public void printBookService() { System.out.println(this.bookService); } } BookService\n1 2 3 4 5 6 import org.springframework.stereotype.Service; @Service public class BookService { } MainConfig，将 BookService 和 BookController 扫描到容器中\n1 2 3 4 5 6 @Configuration // 将 Service 和 Controller 扫描到容器 @ComponentScan({\"icu.intelli.controller\", \"icu.intelli.service\"}) public class MainConfig { } IOCTest\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import icu.intelli.config.MainConfig; import icu.intelli.controller.BookController; import icu.intelli.service.BookService; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); // 获取 bookController BookController bean = applicationContext.getBean(BookController.class); // 调用 printBookService 方法 bean.printBookService(); // 获取容器中的 bookService BookService bean1 = applicationContext.getBean(BookService.class); System.out.println(bean1); } } 运行结果\n1 2 icu.intelli.service.BookService@4d339552 icu.intelli.service.BookService@4d339552 结论：当容器中只有一个同一类型的 bean 时，Spring 对标注了 @Autowired 的属性根据类型进行装配\n容器中有多个个 BookService 类型的 bean 时\n修改 BookService 添加 lable 属性并添加 getter 和 setter 方法，重写 toString 方法，已做区分\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import org.springframework.stereotype.Service; // bean 名称默认为类名首字母小写（bookService） @Service public class BookService { // 默认 lable 为 1 private String lable = \"1\"; public String getLable() { return lable; } public void setLable(String lable) { this.lable = lable; } @Override public String toString() { return \"BookService{\" + \"lable='\" + lable + '\\'' + '}'; } } 在 MainConfig 中注入一个新的 BookService，名称为 bookService2，lable 为 1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 import icu.intelli.service.BookService; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; @Configuration // 将 Service 和 Controller 扫描到容器 @ComponentScan({\"icu.intelli.controller\", \"icu.intelli.service\"}) public class MainConfig { @Bean(\"bookService2\") public BookService bookService() { BookService bookService = new BookService(); bookService.setLable(\"2\"); return bookService; } } 此时 BookController 为\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 import icu.intelli.service.BookService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Controller; @Controller public class BookController { @Autowired private BookService bookService; public void printBookService() { System.out.println(this.bookService); } } IOCTest\n1 2 3 4 5 6 7 8 9 10 11 12 13 import icu.intelli.config.MainConfig; import icu.intelli.controller.BookController; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); BookController bean = applicationContext.getBean(BookController.class); bean.printBookService(); } } 测试输出\nBookService{lable='1'} 可知，此时向 BookController 中注入的是名为 bookService 的 Bean.\n将 BookController 中的private BookService bookService修改为private BookService bookService2\n测试 IOCTest 输出\nBookService{lable='2'} 结论：当容器中有多个同一类型的 bean 时，Spring 对标注了 @Autowired 的属性根据属性名进行装配\n@Qualifier 当容器中存在多个统一类型的 bean 时，可以使用 @Qualifier 指定 bean 名称为属性注入指定的 bean\n修改 BookController，使用 @Qualifier 指定注入名为 bookService 的 bean\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import icu.intelli.service.BookService; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.stereotype.Controller; @Controller public class BookController { @Qualifier(\"bookService\") @Autowired private BookService bookService2; public void printBookService() { System.out.println(this.bookService2); } } 执行 IOCTest 输出\nBookService{lable='1'} @Primary 让 Spring 进行自动装配的时候，默认使用首选的 Bean 装配，也可以使用 @Qualifier 准确指定需要装配哪个 bean\n修改 MainConfig，对 bookService2 添加 @Primary 注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 @Configuration // 将 Service 和 Controller 扫描到容器 @ComponentScan({\"icu.intelli.controller\", \"icu.intelli.service\"}) public class MainConfig { @Primary @Bean(\"bookService2\") public BookService bookService() { BookService bookService = new BookService(); bookService.setLable(\"2\"); return bookService; } } 修改 BookController，此时 BookService 的属性名与 @Primary 注解标注的 Bean 名称不相同\n1 2 3 4 5 6 7 8 9 10 @Controller public class BookController { @Autowired private BookService bookService; public void printBookService() { System.out.println(this.bookService); } } 执行 IOCTest 输出\nBookService{lable='2'} Spring 注入了 @Primary 标注的 bean\n修改 BookController，使用 @Qualifier 指定注入的 bean\n1 2 3 4 5 6 7 8 9 10 11 @Controller public class BookController { @Qualifier(\"bookService\") @Autowired private BookService bookService; public void printBookService() { System.out.println(this.bookService); } } 程序输出\nBookService{lable='1'} 总结 Spring 利用依赖注入（DI），完成对 IOC 容器中各个组件的依赖关系赋值\n@Autowired：自动注入\n默认优先按照类型去容器中找对应的组件，找到即进行赋值 如果找到多个相同的组件，再将属性的名称作为组件 id 去容器中查找 可以结合 @Qualifier 指定需要装配的组件的 id，而不是使用属性名 自动装配默认一定要对属性赋值，如果容器中没有该类型的 bean 就会报错；可以通过指定 @Autowired 的 required 属性为 false，使得如果容器中没有相应的 bean，就不装配 可以使用 @Primary 注解，将 bean 设定为首选，此时 @Autowired 默认装配首选 Bean ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：@Autowired，@Qualifie，@Primary 自动装配","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-autuwired-qualifier-primary/"},{"categories":null,"content":"Spring 注解：@Profile 自动装配 Spring 注解系列目录\nProfile 介绍：Spring 为我们提供的可以根据当前环境，动态的激活和切换一系列组件的功能\n@Profile：指定组件在哪个环境的情况下才被注册到容器中，如果不指定，在任何环境下都能注册这个组件\n此处以数据源为例进行测试\n环境搭建 引入连接池和连接器依赖\n1 2 3 4 5 6 7 8 9 10 11 \u003cdependency\u003e \u003cgroupId\u003ecom.mchange\u003c/groupId\u003e \u003cartifactId\u003ec3p0\u003c/artifactId\u003e \u003cversion\u003e0.9.5.5\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003emysql\u003c/groupId\u003e \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e \u003cversion\u003e5.1.48\u003c/version\u003e \u003c/dependency\u003e 创建数据库配置文件 db.properties\n1 2 3 db.user=root db.password=root db.driverClass=com.mysql.jdbc.Driver 修改 MainConfig 配置类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 package icu.intelli.config; import com.mchange.v2.c3p0.ComboPooledDataSource; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.EmbeddedValueResolverAware; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.PropertySource; import org.springframework.util.StringValueResolver; import javax.sql.DataSource; import java.beans.PropertyVetoException; /** * 配置多个数据源 */ @Configuration // 1. 引入外部配置文件，将其属性添加到运行环境中 @PropertySource(\"classpath:/db.properties\") public class MainConfig implements EmbeddedValueResolverAware { // 1. 使用 @Value 自动设置环境中的变量值 @Value(\"${db.user}\") private String user; private String driverClass; @Bean(\"testDataSource\") // 使用 @Value 自动设置环境中的变量值，可标注在参数上 public DataSource dataSourceTest(@Value(\"${db.password}\") String pwd) throws PropertyVetoException { ComboPooledDataSource dataSource = new ComboPooledDataSource(); dataSource.setUser(user); dataSource.setPassword(pwd); dataSource.setJdbcUrl(\"jdbc:mysql://localhost:3306/test\"); dataSource.setDriverClass(driverClass); return dataSource; } @Bean(\"devDataSource\") public DataSource dataSourceDev(@Value(\"${db.password}\") String pwd) throws PropertyVetoException { ComboPooledDataSource dataSource = new ComboPooledDataSource(); dataSource.setUser(user); dataSource.setPassword(pwd); dataSource.setJdbcUrl(\"jdbc:mysql://localhost:3306/dev\"); dataSource.setDriverClass(driverClass); return dataSource; } @Bean(\"proDataSource\") public DataSource dataSourceProd(@Value(\"${db.password}\") String pwd) throws PropertyVetoException { ComboPooledDataSource dataSource = new ComboPooledDataSource(); dataSource.setUser(user); dataSource.setPassword(pwd); dataSource.setJdbcUrl(\"jdbc:mysql://localhost:3306/prod\"); dataSource.setDriverClass(driverClass); return dataSource; } public void setEmbeddedValueResolver(StringValueResolver resolver) { // 使用 StringValueResolver 解析环境中的变量值 this.driverClass = resolver.resolveStringValue(\"${db.driverClass}\"); } } IOCTest 测试，输出容器中的多个数据源\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package icu.intelli; import icu.intelli.config.MainConfig; import org.springframework.context.annotation.AnnotationConfigApplicationContext; import javax.sql.DataSource; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); String[] namesForType = applicationContext.getBeanNamesForType(DataSource.class); for (String s : namesForType) { System.out.println(s); } } } 程序输出\ntestDataSource devDataSource proDataSource 使用 @Profile 指定环境 修改 MainConfig.java，为三个 DataSource 添加 @Profile 注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 package icu.intelli.config; import com.mchange.v2.c3p0.ComboPooledDataSource; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.EmbeddedValueResolverAware; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.Profile; import org.springframework.context.annotation.PropertySource; import org.springframework.util.StringValueResolver; import javax.sql.DataSource; import java.beans.PropertyVetoException; @Configuration @PropertySource(\"classpath:/db.properties\") public class MainConfig implements EmbeddedValueResolverAware { @Value(\"${db.user}\") private String user; private String driverClass; @Profile(\"test\") @Bean(\"testDataSource\") public DataSource dataSourceTest(@Value(\"${db.password}\") String pwd) throws PropertyVetoException { ComboPooledDataSource dataSource = new ComboPooledDataSource(); dataSource.setUser(user); dataSource.setPassword(pwd); dataSource.setJdbcUrl(\"jdbc:mysql://localhost:3306/test\"); dataSource.setDriverClass(driverClass); return dataSource; } @Profile(\"dev\") @Bean(\"devDataSource\") public DataSource dataSourceDev(@Value(\"${db.password}\") String pwd) throws PropertyVetoException { ComboPooledDataSource dataSource = new ComboPooledDataSource(); dataSource.setUser(user); dataSource.setPassword(pwd); dataSource.setJdbcUrl(\"jdbc:mysql://localhost:3306/dev\"); dataSource.setDriverClass(driverClass); return dataSource; } @Profile(\"prod\") @Bean(\"proDataSource\") public DataSource dataSourceProd(@Value(\"${db.password}\") String pwd) throws PropertyVetoException { ComboPooledDataSource dataSource = new ComboPooledDataSource(); dataSource.setUser(user); dataSource.setPassword(pwd); dataSource.setJdbcUrl(\"jdbc:mysql://localhost:3306/prod\"); dataSource.setDriverClass(driverClass); return dataSource; } public void setEmbeddedValueResolver(StringValueResolver resolver) { this.driverClass = resolver.resolveStringValue(\"${db.driverClass}\"); } } 执行 IOCTest，会发现容器中没有任何 DataSource\n使用了 @Profile 的 bean，只有对应的环境被激活时，才能被注册到环境中，默认是 default 环境\n激活指定环境 使用命令行动态参数激活指定环境 在运行时添加虚拟机参数：\n1 -Dspring.profiles.active=test 此时 IOCTest 输出\ntestDataSource 使用代码的方式激活指定 profile 修改 IOCTest\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package icu.intelli; import icu.intelli.config.MainConfig; import org.springframework.context.annotation.AnnotationConfigApplicationContext; import javax.sql.DataSource; public class IOCTest { public static void main(String[] args) { /** * 因为带参数的 AnnotationConfigApplicationContext 构造器，直接注册并刷新容器， * 所以使用不带参数的 bean，添加自己处理代码 * * public AnnotationConfigApplicationContext(Class\u003c?\u003e... annotatedClasses) { * this(); * register(annotatedClasses); * refresh(); * } */ // AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); // 1. 创建一个 applicationContext AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(); // 2. 设置需要激活的环境 applicationContext.getEnvironment().setActiveProfiles(\"test\", \"dev\"); // 3. 注册主配置类 applicationContext.register(MainConfig.class); // 4. 刷新容器 applicationContext.refresh(); String[] namesForType = applicationContext.getBeanNamesForType(DataSource.class); for (String s : namesForType) { System.out.println(s); } } } 程序输出\ntestDataSource devDataSource 标注在类上 只有是指定环境的时候，整个配置类中的配置才能生效\n在 MainConfig 类上添加 @Profile(\"test\") 注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 package icu.intelli.config; import com.mchange.v2.c3p0.ComboPooledDataSource; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.EmbeddedValueResolverAware; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.Profile; import org.springframework.context.annotation.PropertySource; import org.springframework.util.StringValueResolver; import javax.sql.DataSource; import java.beans.PropertyVetoException; @Profile(\"test\") @Configuration @PropertySource(\"classpath:/db.properties\") public class MainConfig implements EmbeddedValueResolverAware { @Value(\"${db.user}\") private String user; private String driverClass; @Profile(\"test\") @Bean(\"testDataSource\") public DataSource dataSourceTest(@Value(\"${db.password}\") String pwd) throws PropertyVetoException { ComboPooledDataSource dataSource = new ComboPooledDataSource(); dataSource.setUser(user); dataSource.setPassword(pwd); dataSource.setJdbcUrl(\"jdbc:mysql://localhost:3306/test\"); dataSource.setDriverClass(driverClass); return dataSource; } @Profile(\"dev\") @Bean(\"devDataSource\") public DataSource dataSourceDev(@Value(\"${db.password}\") String pwd) throws PropertyVetoException { ComboPooledDataSource dataSource = new ComboPooledDataSource(); dataSource.setUser(user); dataSource.setPassword(pwd); dataSource.setJdbcUrl(\"jdbc:mysql://localhost:3306/dev\"); dataSource.setDriverClass(driverClass); return dataSource; } @Profile(\"prod\") @Bean(\"proDataSource\") public DataSource dataSourceProd(@Value(\"${db.password}\") String pwd) throws PropertyVetoException { ComboPooledDataSource dataSource = new ComboPooledDataSource(); dataSource.setUser(user); dataSource.setPassword(pwd); dataSource.setJdbcUrl(\"jdbc:mysql://localhost:3306/prod\"); dataSource.setDriverClass(driverClass); return dataSource; } public void setEmbeddedValueResolver(StringValueResolver resolver) { this.driverClass = resolver.resolveStringValue(\"${db.driverClass}\"); } } 设置 IOCTest 中环境为 prod\n1 applicationContext.getEnvironment().setActiveProfiles(\"prod\") 程序没有任何输出，因为整个类都没有加载，所以类中的其他 bean 也都不会加载\n","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：@Profile 自动装配","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-profile/"},{"categories":null,"content":"Spring 注解：@Resource，@Inject 自动装配 Spring 注解系列目录\nSpring 也支持 Java 规范的自动装配注解\n@Resource：JSR250 定义 @Inject：JSR330 定义 @Resource 可以和 @Autowired 一样实现自动装配；默认是按照属性名进行装配，可以使用 name 属性指定名称\n不支持 @Primary 功能和 @Autowired 的 require=false 功能\n@Inject 需要导入 javax.inject 的包，和 @Autowired 功能一样，支持 @Primary 功能，但是不支持 require=false 的功能\n1 2 3 4 5 6 \u003c!-- JSR-330 依赖注入 --\u003e \u003cdependency\u003e \u003cgroupId\u003ejavax.inject\u003c/groupId\u003e \u003cartifactId\u003ejavax.inject\u003c/artifactId\u003e \u003cversion\u003e1\u003c/version\u003e \u003c/dependency\u003e ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：@Resource，@Inject 自动装配","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-resouce-inject/"},{"categories":null,"content":"Spring 注解：方法，构造器位置的自动装配 Spring 注解系列目录\n@Autowired 可以标注在：构造器，参数，方法，属性\n将 @Autowired 标注在方法上 创建 Car.java 类\n1 2 3 4 5 6 7 package icu.intelli.bean; import org.springframework.stereotype.Component; @Component public class Boss { } 创建 Boss.java 类，包含一个 Car 属性，并将 @Autowired 标注在 setCar 方法上（注，可以标注在任意方法上）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package icu.intelli.bean; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; @Component public class Boss { private Car car; public Car getCar() { return car; } @Autowired // 标在方法上，Spring 容器创建当前对象，就会调用该方法，完成赋值 // 方法使用的参数，自定义类型的值从 ioc 容器中获取 public void setCar(Car car) { this.car = car; } @Override public String toString() { return \"Boss{\" + \"car=\" + car + '}'; } } 修改 MainConfig 将 Car 和 Boos 扫描到容器\n1 2 3 4 5 @Configuration @ComponentScan({\"icu.intelli.bean\"}) public class MainConfig { } IOCTest\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package icu.intelli.; import icu.intelli.bean.Boss; import icu.intelli.bean.Car; import icu.intelli.config.MainConfig; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); // 打印 boss Boss boss = applicationContext.getBean(Boss.class); System.out.println(boss); // 打印 IOC 容器中的 car 对象 Car car = applicationContext.getBean(Car.class); System.out.println(car); } } 程序输出\nBoss{car=icu.intelli.bean.Car@10d59286} icu.intelli.bean.Car@10d59286 可知，向 Boss 中注入的 Car 是 IOC 容器中的 car\n将 @Autowired 标注有参构造器上 修改 Boss.java，将 @Autowird 标注在有参构造器上\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package icu.intelli.bean; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; @Component public class Boss { private Car car; // 构造器要用的组件（参数），也是从容器中获取 // 如果只有一个有参构造器，这个有参构造器的 @Autowired 可以省略，参数位置的组件还是从 IOC 容器中获取 @Autowired public Boss(Car car) { this.car = car; System.out.println(\"Boss 的有参构造器...\"); } public Car getCar() { return car; } public void setCar(Car car) { this.car = car; } @Override public String toString() { return \"Boss{\" + \"car=\" + car + '}'; } } 运行 IOCTest，程序输出\nBoss 的有参构造器... Boss{car=icu.intelli.bean.Car@24b1d79b} icu.intelli.bean.Car@24b1d79b 可知，Spring 调用了 Boss 的有参构造器创建对象，并且使用的参数是从 IOC 容器中获取的\n将 @Autowired 标注在参数上 标注在有参构造上 修改 Boss.java，将 @Autowired 标注在有参构造的参数位置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package icu.intelli.bean; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; @Component public class Boss { private Car car; public Boss(@Autowired Car car) { this.car = car; System.out.println(\"Boss 的有参构造器...\"); } public Car getCar() { return car; } public void setCar(Car car) { this.car = car; } @Override public String toString() { return \"Boss{\" + \"car=\" + car + '}'; } } 执行 IOCTest 输出\nBoss 的有参构造器... Boss{car=icu.intelli.bean.Car@5123a213} icu.intelli.bean.Car@5123a213 与标注在有参构造上相同，在创建 Boss 对象时，调用其有参构造，并使用 IOC 容器中的组件进行赋值\n标注在普通方法参数上 修改 Boss.java，将 @Autowired 标注在 setCar 方法上\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package icu.intelli.bean; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; @Component public class Boss { private Car car; public Car getCar() { return car; } public void setCar(@Autowired Car car) { this.car = car; } @Override public String toString() { return \"Boss{\" + \"car=\" + car + '}'; } } 运行 IOCTest 输出\nBoss{car=null} icu.intelli.bean.Car@704921a5 并没有对 car 进行赋值\n标注在 @Bean 创建 bean 的方法参数上 修改 Boss.java，不使用 @Component 注解加入到容器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package icu.intelli.bean; public class Boss { private Car car; public Car getCar() { return car; } public void setCar(Car car) { this.car = car; } @Override public String toString() { return \"Boss{\" + \"car=\" + car + '}'; } } 修改 MainConfig，使用 @Bean 方式添加 Boss 对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 @Configuration @ComponentScan({\"icu.intelli.bean\"}) public class MainConfig { @Bean // 此处参数里的 @Autowired 可以省略 public Boss boss(Car car) { Boss boss = new Boss(); // 设置 car boss.setCar(car); return boss; } } 执行 IOCTest，程序输出\nBoss{car=icu.intelli.bean.Car@77846d2c} icu.intelli.bean.Car@77846d2c @Bean+ 方法参数，默认不写 @Autowired，也可以自动装配，注意使用 set 方法\n","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：方法，构造器位置的自动装配","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-autowire/"},{"categories":null,"content":"Spring 注解：向自定义组件中注入 Spring 底层组件及原理 Spring 注解系列目录\n如需向自定义组件中注入 ApplicationContext，BeanFactory 等 Spring 底层组件，只需要让自定义组件实现 xxxAware 接口即可，在创建对象的时候，会调用该接口规定的方法，注入 Spring 容器底层的组件\n为 Red 类注入一些 Spring 底层组件 让 red 类实现需要的 xxxAware 接口即可，如需在其他方法中使用，可将其赋值给全局变量\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package icu.intelli.bean; import org.springframework.beans.BeansException; import org.springframework.beans.factory.BeanNameAware; import org.springframework.context.ApplicationContext; import org.springframework.context.ApplicationContextAware; import org.springframework.context.EmbeddedValueResolverAware; import org.springframework.stereotype.Component; import org.springframework.util.StringValueResolver; @Component public class Red implements ApplicationContextAware, BeanNameAware, EmbeddedValueResolverAware { private ApplicationContext applicationContext; private StringValueResolver stringValueResolver; // 获取 ioc 容器 public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { System.out.println(\"传入的 ioc:\" + applicationContext); this.applicationContext = applicationContext; } // 获取当前 bean 的名字 public void setBeanName(String name) { System.out.println(\"当前 bean 的名字\" + name); } // StringValueResolver, 用来解析字符串中的占位符 public void setEmbeddedValueResolver(StringValueResolver resolver) { String str = resolver.resolveStringValue(\"你好${os.name}, 我是#{300+60}\"); System.out.println(\"解析后的字符串: \" + str); this.stringValueResolver = resolver; } } MainConfig\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package icu.intelli.config; import icu.intelli.bean.Boss; import icu.intelli.bean.Car; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; @Configuration @ComponentScan({\"icu.intelli.bean\"}) public class MainConfig { } IOCTest\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package icu.intelli; import icu.intelli.config.MainConfig; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); System.out.println(\"测试类中获取的 ioc 容器: \" + applicationContext); } } 测试输出\n当前 bean 的名字 red 解析后的字符串：你好 Linux, 我是 360 传入的 ioc:org.springframework.context.annotation.AnnotationConfigApplicationContext@300ffa5d: startup date [Fri Mar 13 14:19:51 CST 2020]; root of context hierarchy 测试类中获取的 ioc 容器: org.springframework.context.annotation.AnnotationConfigApplicationContext@300ffa5d: startup date [Fri Mar 13 14:19:51 CST 2020]; root of context hierarchy 获取到的 IOC 容器就是当前的 SpringIOC 容器\n原理 对 xxxAware 接口方法的调用是 xxxAwareProcessor 来完成的\n以 ApplicationContextAware 为例，执行流程如下：\n在 Red 类的 setApplicationContext 中打断点, debug 启动\n执行 ApplicationContextProcessor 的 postProcessBeforeInitialization 方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public Object postProcessBeforeInitialization(final Object bean, String beanName) throws BeansException { AccessControlContext acc = null; if (System.getSecurityManager() != null \u0026\u0026 (bean instanceof EnvironmentAware || bean instanceof EmbeddedValueResolverAware || bean instanceof ResourceLoaderAware || bean instanceof ApplicationEventPublisherAware || bean instanceof MessageSourceAware || bean instanceof ApplicationContextAware)) { acc = this.applicationContext.getBeanFactory().getAccessControlContext(); } if (acc != null) { AccessController.doPrivileged(new PrivilegedAction\u003cObject\u003e() { @Override public Object run() { invokeAwareInterfaces(bean); return null; } }, acc); } else { invokeAwareInterfaces(bean); } return bean; } 调用 invokeAwareInterfaces 方法，回调相应的 set 方法注入 Spring 底层 Bean\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 private void invokeAwareInterfaces(Object bean) { if (bean instanceof Aware) { if (bean instanceof EnvironmentAware) { ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); } if (bean instanceof EmbeddedValueResolverAware) { ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); } if (bean instanceof ResourceLoaderAware) { ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); } if (bean instanceof ApplicationEventPublisherAware) { ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); } if (bean instanceof MessageSourceAware) { ((MessageSourceAware) bean).setMessageSource(this.applicationContext); } if (bean instanceof ApplicationContextAware) { ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); } } } ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：向自定义组件中注入 Spring 底层组件及原理","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-inject-in-custom-class/"},{"categories":null,"content":"Spring 注解：自动装配总结 Spring 注解系列目录\nSpring 利用依赖注入（DI），完成对 IOC 容器中各个组件的依赖关系赋值 @Autowired：自动注入\n默认优先按照类型去容器中找对应的组件，找到即进行赋值 如果找到多个相同的组件，再将属性的名称作为组件 id 去容器中查找 可以结合 @Qualifier 指定需要装配的组件的 id，而不是使用属性名 自动装配默认一定要对属性赋值，如果容器中没有该类型的 bean 就会报错；可以通过指定 @Autowired 的 required 属性为 false，使得如果容器中没有相应的 bean，就不装配 可以使用 @Primary 注解，将 bean 设定为首选，此时 @Autowired 默认装配首选 Bean Spring 也支持 Java 规范的自动装配注解 @Resource：JSR250 定义\n可以和@Autowired 一样实现自动装配；默认是按照属性名进行装配，可以使用 name 属性指定名称\n不支持 @Primary 功能和 @Autowired 的 require=false 功能\n@Inject：JSR330 定义\n需要导入 javax.inject 的包，和 @Autowired 功能一样，支持 @Primary 功能，但是不支持 require=false 的功能\n@Autowired 和 @Resource，@Inject 区别 @Autowired 是 Spring 定义的，@Resource 和 @Inject 是 Java 定义的\nAutowiredAnnotationBeanPostProcessor：解析完成自动装配功能\n@Autowired 可以标注的不同位置 @Autowired 可以标注在：构造器，参数，方法，属性;\n标注在属性位置 标注在方法位置 标在方法上，Spring 容器创建当前对象，就会调用该方法，完成赋值 方法的参数，自定义类型的值从 ioc 容器中获取 标注在构造器位置 默认加在 ioc 容器中的组件，容器启动会调用无参构造器创建对象，在进行初始化赋值等操作. 可以标在有参构造器上，此时构造器要用的组件（参数），也是从容器中获取 如果组件中只有一个有参构造器，可以省略 @Autowired 注解，效果不变 标注在参数位置 可以标注在有参构造器参数上，效果与标注在有参构造器上一样 可以标注在 @Bean 标注的方法的参数上，会从 ioc 容器中获取该参数的值，可通过 set 方法为返回的 bean 赋值 自定义组件想要使用 Spring 容器底层的一些组件 例如向自定义组件中注入 ApplicationContext，BeanFactory 等\n只需要让自定义组件实现 xxxAware 接口即可，在创建对象的时候，会调用该接口规定的方法，注入 Spring 容器底层的组件\nAware 接口的子接口：\nApplicationContextAware：注入 IOC 容器 ApplicationEventPublisherAware：注入事件派发器 BeanClassLoaderAware：注入类加载器 ...... xxxAware 功能的实现是 xxxAwareProcessor 完成的\n@Profile 注解的使用 @Profile 指定组件在哪个环境的情况下才能被注册到容器中，默认不指定，则在任何环境下均注册这个组件\n加了环境标识的 bean，只有这个环境被激活的时候才能被注册到容器中。默认是 default 环境 写在配置类上，只有是指定环境的时候，整个配置类里面的所有配置才会开始生效 没有标注环境标识的 bean，在任何环境下都是加载的 激活环境的方式：\n在启动时添加动态参数 使用代码创建 applicaitonContext 的方式设置 ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：自动装配总结","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-summary-auto-assembly/"},{"categories":null,"content":"Ajax 跨域问题 跨域的概念 下面要介绍一个知识叫做跨域，这个知识点是源于一个叫同源策略的东西。\n同源策略\n同源策略是浏览器上为安全性考虑实施的非常重要的安全机制。Ajax 默认时能获取到同源的数据，对于非同源的数据，Ajax 默认是获取不到的。\n下面举一个例子，来看看什么叫做同源\n比如说有一个页面，它的地址为 http://www.example.com:80/dir/page.html，在这个网址中要去获取服务器的数据，获取数据的地址如下所示，在下面的地址中，有的是同源，有的是非同源。\nURL 结果 原因 https://www.example.com/dir/other.html 不同源 协议不同，http 与 https http://en.example.com/dir/other.html 不同源 域名不同 http://www.example.com:81/dir/other.html 不同源 端口不同 http://www.example.com/dir/page2.html 同源 协议，域名，端口都相同 http://www.example.com/dir2/other.html 同源 协议，域名，端口都相同 所谓同源就是协议，域名，端口三者都完全一样\n使用 ajax 来请求非同源路径下的数据，示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cbutton onclick=\"ajaxtest()\"\u003e测试 ajax 非同源请求\u003c/button\u003e \u003c/body\u003e \u003cscript\u003e function ajaxtest() { var xhr = null; if (window.XMLHttpRequest) { xhr = new XMLHttpRequest(); } else { xhr = new ActiveXObject(\"Microsoft.XMLHTTP\"); } var param = \"w=\" + \"你好\"; xhr.open(\"post\", \"http://baidu.com\", true); xhr.setRequestHeader(\"Content-Type\", \"application/x-www-form-urlencoded\"); xhr.send(param); xhr.onreadystatechange = function () { if (xhr.readyState == 4) { if (xhr.status == 200) { console.log(\"请求成功...\") } else { console.log(\"请求失败...\") } } else { console.log(\"!4, 请求失败\"); } } } \u003c/script\u003e \u003c/html\u003e 点击按钮，会报 前端页面访问非同源的服务器这种需求是非常常见的，比如在前端页面中获取天气数据，天气数据肯定是存在于别人的服务器上的，我们如果不能使用 ajax 进行访问的话，该怎么办呢? 这里就需要使用到 跨域 了。\n所以，不管是 ajax 还是跨域，都是为了访问服务器数据。简单来说，Ajax 是为了访问自己服务器的数据，跨域是为了访问别人服务器的数据。\n跨域的实现 XMLHttpRequest 对象默认情况下是无法获取到非同源服务器下的数据的。那么怎么获取别人服务器的数据呢? 使用 XMLHttpRequesst 是达不到的，我们只能另辟蹊径。\n我们可以通过 script 标签，用 script 标签的 src 属性引入一个外部文件，这个外部文件是不涉及到同源策略的影响的。\n例如\n1 \u003cscript type=\"text/javascript\" src=\"http://www.baidu.com/xxx.js\"\u003e\u003c/script\u003e 跨域的本质其实就是服务器返回一个方法调用，这个方法是我们事先定义好的，而方法中的参数就是我们想要的数据。\n示例\nweather.html\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003cscript type=\"text/javascript\"\u003e window.onload = function () { var btn = document.querySelector(\"#btn\"); btn.onclick = function () { var cityName = document.querySelector(\"#city\").value; // 动态创建 script 标签，动态指定 src 属性的值 var script = document.createElement(\"script\"); // 引入外部 js/php 文件，动态添加相关参数并指定方法名 script.src = \"http://www.lisi.com/data.php?city=\" + cityName + \"\u0026callback=foo\"; // 将 function 移动到业务逻辑中 window[\"foo\"] = fucntion(data) { console.log(data); } ; var head = document.querySelector(\"head\"); head.appendChild(script); } } \u003c/script\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003e天气查询\u003c/h1\u003e \u003cinput type=\"text\" id=\"city\" placeholder=\"请输入城市名称\"\u003e \u003cinput type=\"button\" id=\"btn\" value=\"查询\"\u003e \u003c/body\u003e \u003c/html\u003e http://www.lisi.com/data.php\n1 2 3 4 5 6 7 8 9 10 \u003c?php $cbName = $_GET[\"callback\"]; $city = $_GET[\"city\"]; if($city == \"beijing\"){ echo $cbName.\"('北京的天气晴')\" }else{ echo $cbName.\"('没有查询到天气信息')\" } ?\u003e 淘宝提示词案例接口\n属性 说明 地址 https://suggest.taobao.com/sug 作用描述 获取淘宝提示词接口 请求类型 GET 参数 q：关键字，callback：回调方法名 返回数据格式 Jsonp 格式 JQuery 获取跨域数据 只需要将 dataType 指定为 jsonp 即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003cscript src=\"https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js\"\u003e\u003c/script\u003e \u003cscript type=\"text/javascript\"\u003e function btnClick() { // 使用 JQuery 来获取跨域数据 // dataType: \"jsonp\" // key 默认就是 callback // value 的值是以 JQuery 开头的字符串，这个字符串就是函数调用的名称 $.ajax({ url: \"http://suggest.taobao.com/sug\", data: { q: \"j\" }, success: function (data) { console.log(data); }, dataType: \"jsonp\", // 修改回调方法的 key 值 jsonp : \"callback\", // 修改回调函数名 jsonpCallback : \"haha\" }); } \u003c/script\u003e \u003c/head\u003e \u003cbody\u003e \u003cinput type=\"button\" id=\"btn\" value=\"测试 JQuery 跨域请求\" onclick=\"btnClick()\"\u003e \u003c/body\u003e \u003c/html\u003e jsonp（json with padding）：是 JSON 的一种“使用模式”，可用于解决主流浏览器的跨域数据访问的问题。用 JSONP 抓到的资料并不是 JSON，而是任意的 JavaScript，用 JavaScript 直译器执行而不是用 JSON 解析器解析。\n","description":"","tags":["JavaScript","Ajax"],"title":"Ajax 跨域问题","uri":"/posts/javascript/ajax-cross-domain/"},{"categories":null,"content":"Spring 注解：@PropertySource 加载外部配置文件 Spring 注解系列目录\n为 Person 类添加 nickName 字段及其 getter 和 setter 方法，并重写 toString 方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 import org.springframework.beans.factory.annotation.Value; public class Person { // 使用 @Value 赋值： // 1. 基本类型数值 // 2. SpEL：#{} // 3. ${}：取出配置文件中的值（在运行环境变量里面的值） @Value(\"张三\") private String name; @Value(\"#{22-2}\") private Integer age; private String nickName; public Person() { } public Person(String name, Integer age) { this.name = name; this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getAge() { return age; } , public void setAge(Integer age) { this.age = age; } public String getNickName() { return nickName; } public void setNickName(String nickName) { this.nickName = nickName; } @Override public String toString() { return \"Person{\" + \"name='\" + name + '\\'' + \", age=\" + age + \", nickName='\" + nickName + '\\'' + '}'; } } 执行 IOCTest，输出\nPerson{name='张三', age=20, nickName='null'} 在类路径下添加配置文件 person.properties\n1 person.nickName=小张三 注解版 导入 person.properties 配置文件，修改 MainConfig\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import icu.intelli.bean.Person; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.PropertySource; // 使用 @PropertySource 读取外部配置文件中的属性，保存到运行环境变量中，使用 ${} 即可获取到该值 @PropertySource({\"classpath:/person.properties\"}) @Configuration public class MainConfig { @Bean public Person person() { return new Person(); } } 使用 @Value 注解给 nickName 属性赋值\n1 2 3 4 5 6 7 8 9 10 11 12 public class Person { // 使用 @Value 赋值： // 1. 基本类型数值 // 2. SpEL：#{} // 3. ${}：取出配置文件中的值（在运行环境变量里面的值） @Value(\"张三\") private String name; @Value(\"#{22-2}\") private Integer age; @Value(\"${person.nickName}\") private String nickName; 测试 IOCTest 输出\nPerson{name='张三', age=20, nickName='小张三'} 配置文件版 修改 beans.xml, 导入 person.properties 配置文件，并使用 property 标签给 nickName 属性赋值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd\"\u003e \u003c!-- 引入外部配置文件，注意需要引入 context 的名称空间 --\u003e \u003ccontext:property-placeholder location=\"classpath:/person.properties\"/\u003e \u003cbean id=\"person\" class=\"icu.intelli.bean.Person\"\u003e \u003cproperty name=\"name\" value=\"张三\"/\u003e \u003cproperty name=\"age\" value=\"#{20-2}\"/\u003e \u003c!-- 使用 ${} 给 nickName 字段赋值 --\u003e \u003cproperty name=\"nickName\" value=\"${person.nickName}\"/\u003e \u003c/bean\u003e \u003c/beans\u003e 测试 IOCTest 输出\nPerson{name='张三', age=18, nickName='小张三'} 通过 ConfigurableEnvironment 获取运行环境变量中的值 IOCTest\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import icu.intelli.bean.Person; import icu.intelli.config.MainConfig; import org.springframework.context.annotation.AnnotationConfigApplicationContext; import org.springframework.core.env.ConfigurableEnvironment; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); ConfigurableEnvironment environment = applicationContext.getEnvironment(); String nickName = environment.getProperty(\"person.nickName\"); System.out.println(nickName); } } 测试输出\n小张三 PropertySources @PropertySource\n1 2 3 4 5 @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Repeatable(PropertySources.class) public @interface PropertySource { @PropertySources\n1 2 3 4 5 6 7 8 @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface PropertySources { PropertySource[] value(); } 可以使用多个 @PropertySource 引入多个配置文件，也可以使用 @PropertySources 引入多个 @PropertySource\n","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：@PropertySource 加载外部配置文件","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-propertysource/"},{"categories":null,"content":"Spring 注解：@Value 属性赋值 Spring 注解系列目录\n注解版 修改 MainConfig，向容器中注入 Person 对象\n1 2 3 4 5 6 7 8 9 10 11 12 import icu.intelli.bean.Person; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class MainConfig { @Bean public Person person() { return new Person(); } } 使用 IOCTest 获取该 Bean\n1 2 3 4 5 6 7 8 9 10 11 12 13 import icu.intelli.bean.Person; import icu.intelli.config.MainConfig; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); Person person = (Person) applicationContext.getBean(\"person\"); System.out.println(person); } } 输出结果\nPerson{name='null', age=null} 修改 Person 类，添加 @Value 注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 package icu.intelli.bean; import org.springframework.beans.factory.annotation.Value; public class Person { // 使用 @Value 赋值: // 1. 基本类型数值 // 2. SpEL: #{} // 3. ${}: 取出配置文件中的值(在运行环境变量里面的值) @Value(\"张三\") private String name; @Value(\"#{22-2}\") private Integer age; public Person() { } public Person(String name, Integer age) { this.name = name; this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getAge() { return age; } public void setAge(Integer age) { this.age = age; } @Override public String toString() { return \"Person{\" + \"name='\" + name + '\\'' + \", age=\" + age + '}'; } } 执行 IOCTest，输出\nPerson{name='张三', age=20} 配置文件版 beans.xml\n1 2 3 4 5 6 7 8 9 10 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"\u003e \u003cbean id=\"person\" class=\"icu.intelli.bean.Person\"\u003e \u003cproperty name=\"name\" value=\"张三\"/\u003e \u003cproperty name=\"age\" value=\"#{20-2}\"/\u003e \u003c/bean\u003e \u003c/beans\u003e IOCTest\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package icu.intelli; import icu.intelli.bean.Person; import org.springframework.context.support.ClassPathXmlApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"classpath:beans.xml\"); Person person = (Person) applicationContext.getBean(\"person\"); System.out.println(person); } } 输出结果\nPerson{name='张三', age=18} ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：@Value 属性赋值","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-value/"},{"categories":null,"content":"Spring 注解：属性赋值总结 Spring 注解系列目录\n@Value 注解汇总可以使用 3 种表达式\n基本类型数值 SpEL：#{} ${}：取出配置文件中的值（在运行环境变量里面的值） 使用 @PropertySource 或 @PropertySources 引入外部配置文件\n","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：属性赋值总结","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-summary-properties-assignment/"},{"categories":null,"content":"Spring 注解：@Bean 指定初始化和销毁方法 Spring 注解系列目录\n环境准备\n创建 Car 类，并添加 init 和 destroy 方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package icu.intelli.bean; public class Car { public Car() { System.out.println(\"car constructor...\"); } public void init() { System.out.println(\"car init...\"); } public void destroy() { System.out.println(\"car destroy...\"); } } 注解版 编辑 MainConfig 配置类，并在 @Bean 注解中使用 initMethod 和 destroyMethod 指定初始化和销毁方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package icu.intelli.config; import icu.intelli.bean.Car; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class MainConfig { // 指定 initMethod 和 destroyMethod @Bean(initMethod = \"init\", destroyMethod = \"destroy\") public Car car() { return new Car(); } } 编辑 IOCTest\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package icu.intelli; import icu.intelli.config.MainConfig; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); System.out.println(\"IOC 容器创建完成...\"); // 关闭 IOC 容器 applicationContext.close(); System.out.println(\"IOC 容器已关闭...\"); } } 执行 IOCTest 输出\ncar constructor... car init... IOC 容器创建完成... car destroy... IOC 容器已关闭... 配置文件版 编辑 beans.xml，在 bean 标签中添加 init-method 和 destroy-method 属性\n1 2 3 4 5 6 7 8 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"\u003e \u003cbean id=\"car\" class=\"icu.intelli.bean.Car\" init-method=\"init\" destroy-method=\"destroy\"\u003e\u003c/bean\u003e \u003c/beans\u003e 修改 IOCTest\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package icu.intelli; import org.springframework.context.support.ClassPathXmlApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"classpath:beans.xml\"); System.out.println(\"IOC 容器创建完成...\"); // 关闭 IOC 容器 applicationContext.close(); System.out.println(\"IOC 容器已关闭...\"); } } 执行 IOCTest 输出\ncar constructor... car init... IOC 容器创建完成... car destroy... IOC 容器已关闭... ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：@Bean 指定初始化和销毁方法","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-bean/"},{"categories":null,"content":"Spring 注解：Bean 的生命周期总结 Spring 注解系列目录\nbean 的生命周期： bean 创建 → 初始化 → 销毁\nSpring 框架默认使用容器管理 bean 的生命周期，我们可以自定义初始化和销毁方法；容器在 bean 进行到当前生命周期时，来调用我们自定义的初始化和销毁方法\n指定初始化和销毁方法\n配置文件方式：指定 init-method 和 destroy-method 注解方式：在 @Bean 注解中指定 initMethod 和 destroyMethod 属性 通过 Bean 实现 InitializingBean 或 DisposableBean 接口定义初始化或销毁逻辑\n使用 JSR250（Java Specification Requests，Java 规范提案）提供的原生注解\n@PostConstruct：在 bean 创建完成并且属性赋值完成后，来执行初始化 @PreDestroy：在容器销毁 bean 之前，通知我们进行清理工作 BeanPostProcess 接口：bean 后置处理器，在 bean 初始化前后进行一些处理工作\n1 2 3 4 5 6 7 8 public interface BeanPostProcessor { // 在 bean 初始化之前调用 Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; // 在 bean 初始化之后调用 Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException; } Spring 中, bean 的整个生命周期 构造方法（对象创建时）\n单实例：在容器启动的时候创建对象 多实例：在每次获取的时候创建对象 初始化前执行 MyBeanPostProcessor.postProcessBeforeInitialization()\n初始化\n对象创建完成，并赋值好，调用初始化方法\n初始化后执行 MyBeanPostProcessor.postProcessAfterInitialization()\n销毁:\n单实例：在容器关闭的时候 多实例：容器不会管理这个 bean；容器不会调用销毁方法 ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：Bean 的生命周期总结","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-summary-bean-life-cycle/"},{"categories":null,"content":"Spring 注解：BeanPostProcessor 后置处理器 Spring 注解系列目录\n在 Dog 和 Cat 类上均添加 @Component 注解\n创建 MyBeanPostProcessor 实现 BeanPostProcessor 接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 package icu.intelli.bean; import org.springframework.beans.BeansException; import org.springframework.beans.factory.config.BeanPostProcessor; import org.springframework.stereotype.Component; /** * 后置处理器：初始化前后进行处理工作 * * @Component 将后置处理器加入到容器里 */ @Component public class MyBeanPostProcessor implements BeanPostProcessor { /** * @param bean * @param beanName * @return * @throws BeansException */ public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { System.out.println(\"MyBeanPostProcessor.postProcessBeforeInitialization()...\" + beanName + \"=\u003e\" + bean); return bean; } /** * @param bean * @param beanName * @return * @throws BeansException */ public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { System.out.println(\"MyBeanPostProcessor.postProcessAfterInitialization()...\" + beanName + \"=\u003e\" + bean); return bean; } } MainConfig 使用 @ComponentScan 将 Dog，Cat，MyBeanPostProcessor 均扫描到容器中\n1 2 3 4 5 6 7 8 9 10 11 package icu.intelli.config; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; @ComponentScan(\"icu.intelli.bean\") @Configuration public class MainConfig { } IOCTest.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package icu.intelli; import icu.intelli.config.MainConfig; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); System.out.println(\"IOC 容器创建完成...\"); // 关闭 IOC 容器 applicationContext.close(); System.out.println(\"IOC 容器已关闭...\"); } } 执行 IOCTest, 程序输出\nMyBeanPostProcessor.postProcessBeforeInitialization()...org.springframework.context.event.internalEventListenerProcessor=\u003eorg.springframework.context.event.EventListenerMethodProcessor@2e3fc542 MyBeanPostProcessor.postProcessAfterInitialization()...org.springframework.context.event.internalEventListenerProcessor=\u003eorg.springframework.context.event.EventListenerMethodProcessor@2e3fc542 MyBeanPostProcessor.postProcessBeforeInitialization()...org.springframework.context.event.internalEventListenerFactory=\u003eorg.springframework.context.event.DefaultEventListenerFactory@4524411f MyBeanPostProcessor.postProcessAfterInitialization()...org.springframework.context.event.internalEventListenerFactory=\u003eorg.springframework.context.event.DefaultEventListenerFactory@4524411f MyBeanPostProcessor.postProcessBeforeInitialization()...mainConfig=\u003eicu.intelli.config.MainConfig$$EnhancerBySpringCGLIB$$47e607b3@401e7803 MyBeanPostProcessor.postProcessAfterInitialization()...mainConfig=\u003eicu.intelli.config.MainConfig$$EnhancerBySpringCGLIB$$47e607b3@401e7803 cat constructor... MyBeanPostProcessor.postProcessBeforeInitialization()...cat=\u003eicu.intelli.bean.Cat@704d6e83 cat afterPropertiesSet... MyBeanPostProcessor.postProcessAfterInitialization()...cat=\u003eicu.intelli.bean.Cat@704d6e83 dog constructor... MyBeanPostProcessor.postProcessBeforeInitialization()...dog=\u003eicu.intelli.bean.Dog@10a035a0 dog postConstruct... MyBeanPostProcessor.postProcessAfterInitialization()...dog=\u003eicu.intelli.bean.Dog@10a035a0 IOC 容器创建完成... dog preDestroy... cat destroy... IOC 容器已关闭... cat constructor... : 创建 cat 对象 MyBeanPostProcessor.postProcessBeforeInitialization()...cat=\u003eicu.intelli.bean.Cat@704d6e83 cat afterPropertiesSet... : 在 cat 初始化之前执行 cat afterPropertiesSet... : 在 cat 初始化之后执行 MyBeanPostProcessor.postProcessAfterInitialization()...cat=\u003eicu.intelli.bean.Cat@704d6e83 : 在 cat 初始化之后，并在 afterPropertiesSet 之后执行 cat destroy... : cat 被销毁时执行 没有定义初始化和销毁方法，后置处理器也会执行\n","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：BeanPostProcessor 后置处理器","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-beanpostprocessor/"},{"categories":null,"content":"Spring 注解：BeanPostProcessor 原理 Spring 注解系列目录\n遍历得到容器中所有的 BeanPostProcessor，挨个执行 beforeInitialization，一旦返回 null，就跳出 for 循环，不会执行后面的 BeanPostProcessor\n1 2 3 4 5 6 7 8 9 10 populateBean(beanName, mbd, instanceWrapper); 给 bean 进行属性赋值 initializeBean() { wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); // 执行自定义初始化方法 invokeInitMethods(beanName, wrappedBean, mbd); wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); } ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：BeanPostProcessor 原理","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-beanpostprocessor-principle/"},{"categories":null,"content":"Spring 注解：BeanPostProcessor 在 Spring 底层的使用 Spring 注解系列目录\nSpring 底层通过使用 BeanPostProcessor 实现 bean 赋值，注入其他组件，@Autowired，生命周期注释功能，@Async 等等功能。\n[Interface] BeanPostProcessor\n[Class] ApplicationContextAwareProcessor\n通过让一个组件类实现 ApplicationContextAware 接口，可以将 IOC 容器注入到该类中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package icu.intelli.bean; import org.springframework.beans.BeansException; import org.springframework.context.ApplicationContext; import org.springframework.context.ApplicationContextAware; import org.springframework.stereotype.Component; @Component public class Dog implements ApplicationContextAware { private ApplicationContext applicationContext; // 当该组件被 Spring 初始化时，会调用该方法将 IOC 容器（ApplicationContext）注入到该类中 public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { this.applicationContext = applicationContext; } } [Class] BeanValidationPostProcessor\n对 JSR-303 进行验证的后置处理器\n[Interface] DestructionAwareBeanPostProcessor\n[Class] InitDestroyAnnotationBeanPostProcessor\n对组件中的 @PostConstruct，@PreDestroy 进行处理，执行由这两个注解标注的方法\n[Interface] MergedBeanDefinitionPostProcessor\n[Class] AutowiredAnnotationBeanPostProcessor\n对组件中的 @Autowire 注解进行处理，使其生效\n","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：BeanPostProcessor 在 Spring 底层的使用","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-beanpostprocessor-in-spring/"},{"categories":null,"content":"Spring 注解：使用 @PostConstruct 和 @PreDestroy Spring 注解系列目录\n创建 Dog 类，标注 @Component 注解，可取消 Cat 类上的 @Component\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 package icu.intelli.bean; import org.springframework.stereotype.Component; import javax.annotation.PostConstruct; import javax.annotation.PreDestroy; @Component public class Dog { public Dog() { System.out.println(\"dog constructor...\"); } /** * 在对象创建并赋值之后调用 */ @PostConstruct public void init() { System.out.println(\"dog postConstruct...\"); } /** * 容器移除对象之前调用 */ @PreDestroy public void destroy() { System.out.println(\"dog preDestroy...\"); } } MainConfig.java\n1 2 3 4 5 6 7 8 9 10 11 package icu.intelli.config; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; @ComponentScan(\"icu.intelli.bean\") @Configuration public class MainConfig { } IOCTest.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package icu.intelli; import icu.intelli.config.MainConfig; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); System.out.println(\"IOC 容器创建完成...\"); // 关闭 IOC 容器 applicationContext.close(); System.out.println(\"IOC 容器已关闭...\"); } } 执行 IOCTest 输出\ndog constructor... dog postConstruct... IOC 容器创建完成... dog preDestroy... IOC 容器已关闭... ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：使用 @PostConstruct 和 @PreDestroy","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-postconstruct-and-predestroy/"},{"categories":null,"content":"Spring 注解：使用 InitializingBean 和 DisposableBean 接口初始化或销毁 Bean Spring 注解系列目录\n创建 Cat 类，实现 InitializingBean 和 disposableBean 接口，使用 @Component 注解，练习使用 @ComponentScan 来将其扫描到容器中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 package icu.intelli.bean; import org.springframework.beans.factory.DisposableBean; import org.springframework.beans.factory.InitializingBean; import org.springframework.stereotype.Component; @Component public class Cat implements InitializingBean, DisposableBean { public Cat() { System.out.println(\"cat constructor...\"); } /** * InitializingBean 的方法，在对象初始化后执行 * * @throws Exception */ public void afterPropertiesSet() throws Exception { System.out.println(\"cat afterPropertiesSet...\"); } /** * DisposableBean 的方法，在 Bean 被销毁时（容器关闭前）执行 * * @throws Exception */ public void destroy() throws Exception { System.out.println(\"cat destroy...\"); } } 修改 MainConfig, 使用 @ComponentScan 将 icu.intelli.bean 中的组件扫描到容器中\n1 2 3 4 5 6 7 8 9 10 11 package icu.intelli.config; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; @ComponentScan(\"icu.intelli.bean\") @Configuration public class MainConfig { } IOCTest.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package icu.intelli; import icu.intelli.config.MainConfig; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); System.out.println(\"IOC 容器创建完成...\"); // 关闭 IOC 容器 applicationContext.close(); System.out.println(\"IOC 容器已关闭...\"); } } 执行 IOCTest 输出\ncat constructor... cat afterPropertiesSet... IOC 容器创建完成... cat destroy... IOC 容器已关闭... ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：使用 InitializingBean 和 DisposableBean 接口初始化或销毁 Bean","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-initializingbean-and-disposablebean-interface/"},{"categories":null,"content":"Spring 注解：@ComponentScan 包扫描 \u0026 指定扫描规则 Spring 注解系列目录\n创建 BookController，BookService，BookDao，并分别使用@Controller，@Service，@Repository注解标注\nBookController\n1 2 3 4 5 6 7 package icu.intelli.controller; import org.springframework.stereotype.Controller; @Controller public class BookController { } BookService\n1 2 3 4 5 6 7 package icu.intelli.service; import org.springframework.stereotype.Service; @Service public class BookService { } BookDao\n1 2 3 4 5 6 7 package icu.intelli.dao; import org.springframework.stereotype.Repository; @Repository public class BookDao { } 注解版 在 MainConfig 类上添加 @ComponentScan 注解\n1 2 3 4 5 6 7 8 9 10 11 package icu.intelli.config; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; @Configuration // 扫描 icu.intelli 及其子包，将被 @Controller，@Service，@Repository，@Component 标注的组件扫描到容器 @ComponentScan(value = \"icu.intelli\") public class MainConfig { } 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import icu.intelli.config.MainConfig; import org.springframework.context.ApplicationContext; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); // 获取容器中所有 Bean 的名字 String[] beanDefinitionNames = applicationContext.getBeanDefinitionNames(); for (String beanDefinitionName : beanDefinitionNames) { System.out.println(beanDefinitionName); } } } 控制台输出\norg.springframework.context.annotation.internalConfigurationAnnotationProcessor org.springframework.context.annotation.internalAutowiredAnnotationProcessor org.springframework.context.annotation.internalRequiredAnnotationProcessor org.springframework.context.annotation.internalCommonAnnotationProcessor org.springframework.context.event.internalEventListenerProcessor org.springframework.context.event.internalEventListenerFactory mainConfig bookController bookDao bookService person 配置文件版 beans.xml 中添加 context:component-scan 标签\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"\u003e \u003c!-- 包扫描，只要标注了 @Controller，@Service，@Repository，@Component --\u003e \u003ccontext:component-scan base-package=\"icu.intelli\"/\u003e \u003cbean id=\"person\" class=\"icu.intelli.bean.Person\"\u003e \u003cproperty name=\"age\" value=\"18\"\u003e\u003c/property\u003e \u003cproperty name=\"name\" value=\"zhangsan\"\u003e\u003c/property\u003e \u003c/bean\u003e \u003c/beans\u003e 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package icu.intelli; import org.springframework.context.ApplicationContext; import org.springframework.context.support.ClassPathXmlApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"classpath:beans.xml\"); // 获取容器中所有 Bean 的名字 String[] beanDefinitionNames = applicationContext.getBeanDefinitionNames(); for (String beanDefinitionName : beanDefinitionNames) { System.out.println(beanDefinitionName); } } } 1 2 3 4 5 6 7 8 9 10 bookController bookDao bookService org.springframework.context.annotation.internalConfigurationAnnotationProcessor org.springframework.context.annotation.internalAutowiredAnnotationProcessor org.springframework.context.annotation.internalRequiredAnnotationProcessor org.springframework.context.annotation.internalCommonAnnotationProcessor org.springframework.context.event.internalEventListenerProcessor org.springframework.context.event.internalEventListenerFactory person @ComponentScan 使用 excludeFilters 属性排除指定类 注解版 修改 MainConfig，修改 @ComponentScan 注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package icu.intelli.config; import icu.intelli.bean.Person; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.FilterType; import org.springframework.stereotype.Controller; import org.springframework.stereotype.Service; @Configuration // 扫描 icu.intelli 包及其所有子包，过滤掉被 Controller 注解和 Service 注解标注的类 @ComponentScan(value = \"icu.intelli\", excludeFilters = { // FilterType 包含 ANNOTATION，ASSIGNABLE_TYPE，ASPECTJ，REGEX，CUSTOM，默认值是 ANNOTATION @ComponentScan.Filter(type = FilterType.ANNOTATION, classes = {Controller.class, Service.class}) }) public class MainConfig { @Bean(value = \"person\") public Person person() { return new Person(\"lisi\", 20); } } 使用 IOCTest 类测试，控制台输出如下，bookController 和 bookService 并没有扫描到 IOC 容器中\n1 2 3 4 5 6 7 8 9 org.springframework.context.annotation.internalConfigurationAnnotationProcessor org.springframework.context.annotation.internalAutowiredAnnotationProcessor org.springframework.context.annotation.internalRequiredAnnotationProcessor org.springframework.context.annotation.internalCommonAnnotationProcessor org.springframework.context.event.internalEventListenerProcessor org.springframework.context.event.internalEventListenerFactory mainConfig bookDao person 配置文件版 修改 beans.xml，在 context:component-scan 标签中添加 context:exclude-filter 标签\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd\"\u003e \u003ccontext:component-scan base-package=\"icu.intelli\"\u003e \u003c!-- 排除被 Controller 和 Service 注解标记的类 --\u003e \u003c!-- type 类型包括 annotation，assignable，aspectj，regex，custom--\u003e \u003ccontext:exclude-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/\u003e \u003ccontext:exclude-filter type=\"annotation\" expression=\"org.springframework.stereotype.Service\"/\u003e \u003c/context:component-scan\u003e \u003cbean id=\"person\" class=\"icu.intelli.bean.Person\"\u003e \u003cproperty name=\"age\" value=\"18\"\u003e\u003c/property\u003e \u003cproperty name=\"name\" value=\"zhangsan\"\u003e\u003c/property\u003e \u003c/bean\u003e \u003c/beans\u003e 使用 IOCTest 类测试，控制台输出如下，bookController 和 bookService 并没有扫描到 IOC 容器中\n1 2 3 4 5 6 7 8 bookDao org.springframework.context.annotation.internalConfigurationAnnotationProcessor org.springframework.context.annotation.internalAutowiredAnnotationProcessor org.springframework.context.annotation.internalRequiredAnnotationProcessor org.springframework.context.annotation.internalCommonAnnotationProcessor org.springframework.context.event.internalEventListenerProcessor org.springframework.context.event.internalEventListenerFactory person @ComponentScan 使用 includeFilters 属性引入指定类 注解版 修改 MainConfig，修改 @ComponentScan 注解，使用 includeFilters 属性，并将 useDefaultFilters 属性设置为 false\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package icu.intelli.config; import icu.intelli.bean.Person; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.FilterType; import org.springframework.stereotype.Controller; import org.springframework.stereotype.Service; @Configuration // 扫描 icu.intelli 包及其所有子包，扫描时只扫描被 Controller 注解和 Service 注解标注的类 @ComponentScan(value = \"icu.intelli\", includeFilters = { // FilterType 包含 ANNOTATION，ASSIGNABLE_TYPE，ASPECTJ，REGEX，CUSTOM，默认值是 ANNOTATION @ComponentScan.Filter(type = FilterType.ANNOTATION, classes = {Controller.class, Service.class}) }, // 不使用默认的扫描规则 useDefaultFilters = false) public class MainConfig { @Bean(value = \"person\") public Person person() { return new Person(\"lisi\", 20); } } 使用 IOCTest 类测试，控制台输出如下，bookController 和 bookService 被扫描到 IOC 容器中，而 bookDao 没有被扫描到 IOC 容器\n1 2 3 4 5 6 7 8 9 10 org.springframework.context.annotation.internalConfigurationAnnotationProcessor org.springframework.context.annotation.internalAutowiredAnnotationProcessor org.springframework.context.annotation.internalRequiredAnnotationProcessor org.springframework.context.annotation.internalCommonAnnotationProcessor org.springframework.context.event.internalEventListenerProcessor org.springframework.context.event.internalEventListenerFactory mainConfig bookController bookService person 配置文件版 修改 beans.xml，在 context:component-scan 标签中添加 use-default-filters=\"false\" 属性和 context:include-filter 标签\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd\"\u003e \u003c!-- use-default-filters=\"false\"，不使用默认的扫描规则 --\u003e \u003ccontext:component-scan base-package=\"icu.intelli\" use-default-filters=\"false\"\u003e \u003c!-- 只扫描被 Controller 和 Service 注解标注的类 --\u003e \u003ccontext:include-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/\u003e \u003ccontext:include-filter type=\"annotation\" expression=\"org.springframework.stereotype.Service\"/\u003e \u003c/context:component-scan\u003e \u003cbean id=\"person\" class=\"icu.intelli.bean.Person\"\u003e \u003cproperty name=\"age\" value=\"18\"\u003e\u003c/property\u003e \u003cproperty name=\"name\" value=\"zhangsan\"\u003e\u003c/property\u003e \u003c/bean\u003e \u003c/beans\u003e 使用 IOCTest 类测试，控制台输出如下，bookController 和 bookService 被扫描到 IOC 容器中，而 bookDao 没有被扫描到 IOC 容器\n1 2 3 4 5 6 7 8 9 bookController bookService org.springframework.context.annotation.internalConfigurationAnnotationProcessor org.springframework.context.annotation.internalAutowiredAnnotationProcessor org.springframework.context.annotation.internalRequiredAnnotationProcessor org.springframework.context.annotation.internalCommonAnnotationProcessor org.springframework.context.event.internalEventListenerProcessor org.springframework.context.event.internalEventListenerFactory person ComponentScan 重复注解 JDK8 提供了 @Repeatable 注解，表明可以在一个类上使用多个 @ComponentScan，定义多个过滤规则\n1 2 @Repeatable(ComponentScans.class) public @interface ComponentScan { 可能需要在 pom.xml 中指定 maven 使用的 jdk 版本\n1 2 3 4 5 6 7 8 9 10 11 12 \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e \u003cartifactId\u003emaven-compiler-plugin\u003c/artifactId\u003e \u003cconfiguration\u003e \u003csource\u003e1.8\u003c/source\u003e \u003ctarget\u003e1.8\u003c/target\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e 此时在 Mainonfig 上使用多个 @ComponentScan 注解并不会报错\n1 2 3 @ComponentScan() @ComponentScan() public class MainConfig { 如果使用的 JDK 版本小于 8，可使用 @ComponentScans 注解达到同样的效果\n1 2 3 4 5 @ComponentScans(value = { @ComponentScan(), @ComponentScan() }) public class MainConfig { FilterType 类型 FilterType 包含：\nANNOTATION：按照注解，默认值 ASSIGNABLE_TYPE：按照给定的类型，包括实现类 ASPECTJ：使用 ASPECTJ 表达式 REGEX：使用正则表达式 CUSTOM：自定义规则 自定义（CUSTOM）TypeFilter 的使用 注解版 定义一个 MyTypeFilter 实现 TypeFilter 接口，输出---\u003e类名，如果类名中包含“er”，返回 true，否则返回 false，即 XxxService，Person 等返回 true\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 package icu.intelli.typefilter; import org.springframework.core.io.Resource; import org.springframework.core.type.AnnotationMetadata; import org.springframework.core.type.ClassMetadata; import org.springframework.core.type.classreading.MetadataReader; import org.springframework.core.type.classreading.MetadataReaderFactory; import org.springframework.core.type.filter.TypeFilter; import java.io.IOException; public class MyTypeFilter implements TypeFilter { /** * @param metadataReader 读取到当前正在扫描的类信息 * @param metadataReaderFactory 可以获取到其他任何类信息的 * @return * @throws IOException */ @Override public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException { // 获取当前类注解的信息 AnnotationMetadata annotationMetadata = metadataReader.getAnnotationMetadata(); // 获取当前正在扫描的类的类信息 ClassMetadata classMetadata = metadataReader.getClassMetadata(); // 获取当前类的资源(类的路径) Resource resource = metadataReader.getResource(); String className = classMetadata.getClassName(); System.out.println(\"---\u003e\" + className); return className.contains(\"er\"); } } 修改 Mainnfig，使用自定义的 MyTypeFilter，注意：这里使用了 useDefaultFilters = false，所以 @Controller，@Service，@Repository，@Component 注解标注的类此时不会被扫描进来\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package icu.intelli.config; import icu.intelli.bean.Person; import icu.intelli.typefilter.MyTypeFilter; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.FilterType; @Configuration @ComponentScan(basePackages = \"icu.intelli\", includeFilters = { @ComponentScan.Filter(type = FilterType.CUSTOM, classes = {MyTypeFilter.class}) }, useDefaultFilters = false) public class MainConfig { @Bean(value = \"person\") public Person person() { return new Person(\"lisi\", 20); } } 测试类输出，icu.intelli 包下的每个类均被 MyTypeFilter 进行匹配\n1 ---\u003eicu.intelli.bean.Person ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：@ComponentScan 包扫描 \u0026 指定扫描规则","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-componentscan/"},{"categories":null,"content":"Spring 注解：@Conditional 按照条件注册 Bean Spring 注解系列目录\nConditional，按照一定的条件进行判断，满足条件才往容器中注册 bean，既可以放在方法上，也可以放在类上\n注解在方法上 MainConfig.java，向容器中添加两个 Person 类的对象，bill 和 linus\n1 2 3 4 5 6 7 8 9 10 11 12 @Configuration public class MainConfig { @Bean(\"bill\") public Person person01() { return new Person(\"Bill Gates\", 62); } @Bean(\"linus\") public Person person02() { return new Person(\"linus\", 48); } } IOCTest.java，输出系统名称和所有在容器中的 Person 类对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); Environment environment = applicationContext.getEnvironment(); // 动态获取操作系统的名称 String property = environment.getProperty(\"os.name\"); System.out.println(\"操作系统的名称为：\" + property); // 获取容器中所有 Person 类对象的名字 String[] namesForType = applicationContext.getBeanNamesForType(Person.class); for (String name : namesForType) { System.out.println(name); } // 获取容器中 Person 类型的对象 Map\u003cString, Person\u003e beansOfType = applicationContext.getBeansOfType(Person.class); System.out.println(beansOfType); } } 此时，程序输出如下，包含 bill 和 linus\n操作系统的名称为：Linux bill linus {bill=Person{name='Bill Gates', age=62}, linus=Person{name='linus', age=48}} 现在有一需求，若系统为 Windos 则，向容器中注入 bill; 若系统为 Linux，则向容器中注入 linus\n如下可知，@Conditional 中需要放置 Condition 类型的数组\n1 2 3 4 5 6 7 public @interface Conditional { /** * All {@link Condition}s that must {@linkplain Condition#matches match} * in order for the component to be registered. */ Class\u003c? extends Condition\u003e[] value(); } 因此，创建 LinuxCondition 和 WindowsCondition，实现 Condition 接口\nLinuxCondition.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package icu.intelli.condition; import org.springframework.beans.factory.config.ConfigurableListableBeanFactory; import org.springframework.beans.factory.support.BeanDefinitionRegistry; import org.springframework.context.annotation.Condition; import org.springframework.context.annotation.ConditionContext; import org.springframework.core.env.Environment; import org.springframework.core.type.AnnotatedTypeMetadata; /** * 判断系统是否时 Linux */ public class LinuxCondition implements Condition { /** * @param context 判断条件能使用的上下文（环境） * @param metadata 注释信息 * @return */ public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { // 1. 能获取到 ioc 使用的 beanfactory ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); //2. 获取类加载器 ClassLoader classLoader = context.getClassLoader(); // 3. 获取当前环境信息 Environment environment = context.getEnvironment(); // 4. 获取到 bean 定义的注册类 BeanDefinitionRegistry registry = context.getRegistry(); // 是否 Linux 系统，Unix Linux return environment.getProperty(\"os.name\").contains(\"nux\"); } } WindosCondition.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package icu.intelli.condition; import org.springframework.context.annotation.Condition; import org.springframework.context.annotation.ConditionContext; import org.springframework.core.env.Environment; import org.springframework.core.type.AnnotatedTypeMetadata; /** * 判断系统是否为 Windos */ public class WindowsCondition implements Condition { public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { Environment environment = context.getEnvironment(); // 是否 Windows 系统，Windows return environment.getProperty(\"os.name\").contains(\"indows\"); } } 修改 MainConfig，添加 @Conditional 注解\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package icu.intelli.config; import icu.intelli.bean.Person; import icu.intelli.condition.LinuxCondition; import icu.intelli.condition.WindowsCondition; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Conditional; import org.springframework.context.annotation.Configuration; @Configuration public class MainConfig { /** * @Conditional({Condition})，按照一定的条件进行判断，满足条件才将 bean 注册到容器中 */ @Conditional({WindowsCondition.class}) @Bean(\"bill\") public Person person01() { return new Person(\"Bill Gates\", 62); } @Conditional({LinuxCondition.class}) @Bean(\"linus\") public Person person02() { return new Person(\"linus\", 48); } } 执行 IOCTest，程序输出\nos.name: Linux linus {linus=Person{name='linus', age=48}} 修改 VM options 为 -Dos.name=\"Windows 10\"，执行 IOCTest，程序输出\nos.name: Windows 10 bill {bill=Person{name='Bill Gates', age=62}} 注解在类上 修改 MainConfig.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * 注解在类上，只有符合条件，这个类中的 bean 注册才能生效 */ @Conditional({LinuxCondition.class}) @Configuration public class MainConfig { @Conditional({WindowsCondition.class}) @Bean(\"bill\") public Person person01() { return new Person(\"Bill Gates\", 62); } @Conditional({LinuxCondition.class}) @Bean(\"linus\") public Person person02() { return new Person(\"linus\", 48); } } 执行 IOCTest，程序输出\nos.name: Windows 10 {} 取消对 VM option 的修改，执行 IOCTest，程序输出\nos.name: Linux linus {linus=Person{name='linus', age=48}} ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：@Conditional 按照条件注册 Bean","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-conditional/"},{"categories":null,"content":"Spring 注解：@Configuration 指定配置类和 @Bean 注册 Bean Spring 注解系列目录\n环境：\nspring：4.3.25.RELEASE jdk：1.8 注册 Bean 创建一个 Person 类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 package icu.intelli.config; public class Person { private String name; private Integer age; public Person() { } public Person(String name, Integer age) { this.name = name; this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public Integer getAge() { return age; } public void setAge(Integer age) { this.age = age; } @Override public String toString() { return \"Person{\" + \"name='\" + name + '\\'' + \", age=\" + age + '}'; } } 注解方式 创建一个配置类 MainConfig\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package icu.intelli.config; import icu.intelli.bean.Person; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; // 配置类==配置文件，@Configuration，告诉 Spring，这是一个配置类 @Configuration public class MainConfig { // 给容器中注册一个 Bean；类型为返回值类型 // id 默认是方法名，可以通过 value 值指定 id @Bean(value = \"person\") public Person person() { return new Person(\"lisi\", 20); } } 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import icu.intelli.bean.Person; import icu.intelli.config.MainConfig; import org.springframework.context.ApplicationContext; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class MainTest { public static void main(String[] args) { // 获取 IOC 容器 ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); // 通过 ID 获取 Bean // Person bean = (Person) applicationContext.getBean(\"person\"); // 根据类型获取 Bean Person bean = applicationContext.getBean(Person.class); System.out.println(bean); } } 1 2 Console: Person{name='lisi', age=20} 配置文件方式 需要在类路径下创建一个 beans.xml\n1 2 3 4 5 6 7 8 9 10 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"\u003e \u003cbean id=\"person\" class=\"icu.intelli.bean.Person\"\u003e \u003cproperty name=\"age\" value=\"18\"\u003e\u003c/property\u003e \u003cproperty name=\"name\" value=\"zhangsan\"\u003e\u003c/property\u003e \u003c/bean\u003e \u003c/beans\u003e 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package icu.intelli; import icu.intelli.bean.Person; import org.springframework.context.ApplicationContext; import org.springframework.context.support.ClassPathXmlApplicationContext; public class MainTest { public static void main(String[] args) { // 获取 IOC 容器 ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"classpath:beans.xml\"); // 通过 ID 获取 Bean Person bean = (Person) applicationContext.getBean(\"person\"); // 根据类型获取 Bean // Person bean = applicationContext.getBean(Person.class); System.out.println(bean); } } 1 2 Console: Person{name='zhangsan', age=18} ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：@Configuration 指定配置类和 @Bean 注册 Bean","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-configuration-and-bean/"},{"categories":null,"content":"Spring 注解：@Import 给容器中快速导入一个组件 Spring 注解系列目录\n@Import 的基本使用 @Import(要导入到容器中的组件)，容器中就会自动注册这个组件，id 默认是全类名.\n初始环境\nMainConfig.java\n1 2 3 4 5 6 7 8 package icu.intelli.config; import org.springframework.context.annotation.Configuration; @Configuration public class MainConfig { } IOCTest.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package icu.intelli; import icu.intelli.config.MainConfig; import org.springframework.context.ApplicationContext; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); // 获取容器中所有对象的名字 String[] beanDefinitionNames = applicationContext.getBeanDefinitionNames(); for (String beanDefinitionName : beanDefinitionNames) { System.out.println(beanDefinitionName); } } } 测试输出\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package icu.intelli; import icu.intelli.config.MainConfig; import org.springframework.context.ApplicationContext; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); // 获取容器中所有对象的名字 String[] beanDefinitionNames = applicationContext.getBeanDefinitionNames(); for (String beanDefinitionName : beanDefinitionNames) { System.out.println(beanDefinitionName); } } } 使用 @Import\n创建 Red 和 Blue 两个类\nRed.java\n1 2 3 4 package icu.intelli.bean; public class Red { } Blue.java\n1 2 3 4 package icu.intelli.bean; public class Blue { } 修改 MainConfig.java, 添加 @Import，向容器中注入 Red 和 Blue 两个类的对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package icu.intelli.config; import icu.intelli.bean.Blue; import icu.intelli.bean.Red; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.Import; /** * @Import 可接收一个 Class\u003c?\u003e[] */ @Import({Red.class, Blue.class}) @Configuration public class MainConfig { } 测试输出如下，Red 和 Blue 对象的名称是其全类名\norg.springframework.context.annotation.internalConfigurationAnnotationProcessor org.springframework.context.annotation.internalAutowiredAnnotationProcessor org.springframework.context.annotation.internalRequiredAnnotationProcessor org.springframework.context.annotation.internalCommonAnnotationProcessor org.springframework.context.event.internalEventListenerProcessor org.springframework.context.event.internalEventListenerFactory mainConfig icu.intelli.bean.Red icu.intelli.bean.Blue @Import 使用 ImportSelector 创建 Yellow 和 Green 两个类\nYellow.java\n1 2 3 4 package icu.intelli.bean; public class Yellow { } Green.java\n1 2 3 4 package icu.intelli.bean; public class Green { } 创建 MyImportSelector 实现 ImportSelector 接口，返回包含 Yellow 和 Green 类的全类名的数组\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package icu.intelli.condition; import org.springframework.context.annotation.ImportSelector; import org.springframework.core.type.AnnotationMetadata; // 自定义逻辑，返回需要注入容器的组件 public class MyImportSelector implements ImportSelector { /** * @param importingClassMetadata 标注 @Import 注解的类的所有注解信息 * @return 需要注入到容器中的组件全类名 */ public String[] selectImports(AnnotationMetadata importingClassMetadata) { // 方法不要返回 null, 否则会出现 NullPointerException // 返回包含 Yellow 和 Green 类的全类名的数组即可将其添加到 IOC 容器中 return new String[]{\"icu.intelli.bean.Yellow\", \"icu.intelli.bean.Green\"}; } } 修改 MainConfig.java，在 @Import 注解中添加 MyImportSelector 类\n1 2 3 4 @Import({Red.class, Blue.class, MyImportSelector.class}) @Configuration public class MainConfig { } 执行 IOCTest，程序输出如下，可见已将 Yellow 和 Green 注入到 IOC 容器中\norg.springframework.context.annotation.internalConfigurationAnnotationProcessor org.springframework.context.annotation.internalAutowiredAnnotationProcessor org.springframework.context.annotation.internalRequiredAnnotationProcessor org.springframework.context.annotation.internalCommonAnnotationProcessor org.springframework.context.event.internalEventListenerProcessor org.springframework.context.event.internalEventListenerFactory mainConfig icu.intelli.bean.Red icu.intelli.bean.Blue icu.intelli.bean.Yellow icu.intelli.bean.Green @Import 使用 ImportBeanDefinitionRegistrar 创建 RainBow 类\n1 2 3 4 package icu.intelli.bean; public class RainBow { } 创建 MyImportBeanDefinitionRegistrar 类实现 ImportBeanDefinitionRegistrar 接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package icu.intelli.condition; import icu.intelli.bean.RainBow; import org.springframework.beans.factory.support.BeanDefinitionRegistry; import org.springframework.beans.factory.support.RootBeanDefinition; import org.springframework.context.annotation.ImportBeanDefinitionRegistrar; import org.springframework.core.type.AnnotationMetadata; public class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar { /** * * @param importingClassMetadata 当前标注 @Import 注解的类的所有注解信息 * @param registry BeanDefinitionRegistry 注册类，把所有需要注册到容器中的 bean，调用 */ public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { // 判断容器中是否包含名称为 icu.intelli.bean.Red 和 icu.intelli.bean.Blue 组件 boolean red = registry.containsBeanDefinition(\"icu.intelli.bean.Red\"); boolean blue = registry.containsBeanDefinition(\"icu.intelli.bean.Blue\"); if (red \u0026\u0026 blue){ // 指定 Bean 的定义信息：Bean 的类型，Bean 的 Scope 等信息 RootBeanDefinition beanDefinition = new RootBeanDefinition(RainBow.class); // 将该 Bean 注册到容器中，beanName 为 rainBow registry.registerBeanDefinition(\"rainBow\", beanDefinition); } } } 修改 MainConfig.java, 将 MyImportBeanDefinitionRegistrar 添加到 @Import 注解中\n1 2 3 4 @Import({Red.class, Blue.class, MyImportSelector.class, MyImportBeanDefinitionRegistrar.class}) @Configuration public class MainConfig { } 运行 IOCTest，程序输出如下，已将 rainBow 注册到 IOC 容器中\norg.springframework.context.annotation.internalConfigurationAnnotationProcessor org.springframework.context.annotation.internalAutowiredAnnotationProcessor org.springframework.context.annotation.internalRequiredAnnotationProcessor org.springframework.context.annotation.internalCommonAnnotationProcessor org.springframework.context.event.internalEventListenerProcessor org.springframework.context.event.internalEventListenerFactory mainConfig icu.intelli.bean.Red icu.intelli.bean.Blue icu.intelli.bean.Yellow icu.intelli.bean.Green icu.intelli.bean.RainBow ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：@Import 给容器中快速导入一个组件","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-import/"},{"categories":null,"content":"Spring 注解：@Lazy 懒加载 Spring 注解系列目录\n由上一篇可知，单实例 bean 默认在容器启动时即创建\n懒加载，使得容器在启动时不创建对象，而是在第一次使用（获取）该 Bean 时创建对象，并初始化。\nMainConfig.class\n1 2 3 4 5 6 7 8 9 10 @Configuration public class MainConfig { @Lazy @Bean(\"person\") public Person person() { System.out.println(\"给容器中添加 Person...\"); return new Person(\"张三\", 25); } } IOCTest\n1 2 3 4 5 6 7 8 9 10 11 public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); System.out.println(\"IOC 容器创建完成...\"); Object bean = applicationContext.getBean(\"person\"); System.out.println(\"完成首次获取 Person...\"); Object bean2 = applicationContext.getBean(\"person\"); } } 测试类输出\nIOC 容器创建完成... 给容器中添加 Person... 完成首次获取 Person... ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：@Lazy 懒加载","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-lazy/"},{"categories":null,"content":"Spring 注解：@Scope 设置组件作用域 Spring 注解系列目录\nScope 的值可以取 4 种 :\nprototype：多实例，每次从容器中获取对象时，均创建一个新的实例 singleton：单实例（默认值） 以下两种仅在 web 项目中可取：\nrequest：同一次请求创建一个实例 session：同一个 session 创建一个实例 设置 scope 的值 注解版 向容器中注入 person 对象，将其设置为多实例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package icu.intelli.config; import icu.intelli.bean.Person; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.Scope; @Configuration public class MainConfig { /** * @return * @see ConfigurableBeanFactory#SCOPE_PROTOTYPE prototype * @see ConfigurableBeanFactory#SCOPE_SINGLETON singleton * @see org.springframework.web.context.WebApplicationContext#SCOPE_REQUEST request * @see org.springframework.web.context.WebApplicationContext#SCOPE_SESSION session * \u003cp\u003e * prototype：多实例 * singleton：单实例（默认值） * request：同一次请求创建一个实例 * session：同一个 session 创建一个实例 */ @Scope(\"prototype\") @Bean(\"person\") public Person person() { return new Person(\"张三\", 25); } } 测试类 IOCTest\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package icu.intelli; import icu.intelli.config.MainConfig; import org.springframework.context.ApplicationContext; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); Object bean = applicationContext.getBean(\"person\"); Object bean2 = applicationContext.getBean(\"person\"); System.out.println(bean.equals(bean2)); } } 测试类输出\nfalse 配置文件版 修改 beans.xml，在 bean 标签中添加 scope 属性\n1 2 3 4 5 \u003c!-- scope 包含 prototype 和 singleton，默认值为 singleton，web 项目应该包含另外两个，未测试--\u003e \u003cbean id=\"person\" class=\"icu.intelli.bean.Person\" scope=\"prototype\"\u003e \u003cproperty name=\"age\" value=\"18\"\u003e\u003c/property\u003e \u003cproperty name=\"name\" value=\"zhangsan\"\u003e\u003c/property\u003e \u003c/bean\u003e 测试类 IOCTest\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package icu.intelli; import org.springframework.context.ApplicationContext; import org.springframework.context.support.ClassPathXmlApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"classpath:beans.xml\"); Object bean = applicationContext.getBean(\"person\"); Object bean2 = applicationContext.getBean(\"person\"); System.out.println(bean.equals(bean2)); } } 测试类输出\nfalse singleton 和 prototype 创建对象的时机 scope 为 singleton 时，IOC 容器启动就会调用方法创建对象放到 IOC 容器中，以后每次获取就是直接从容器中拿（map.get()）\nMainConfig.class\n1 2 3 4 5 6 7 8 9 @Configuration public class MainConfig { @Scope @Bean(\"person\") public Person person() { System.out.println(\"给容器中添加 Person...\"); return new Person(\"张三\", 25); } } IOCTest\n1 2 3 4 5 6 public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); } } 测试类输出\n给容器中添加 Person... scope 为 prototype 时，IOC 容器启动时并不会调用方法创建对象放在容器中，而是在每次获取时调用方法创建对象，并且每次获取都会调用一遍\n修改 MainConfig\n1 2 3 4 5 6 7 8 9 @Configuration public class MainConfig { @Scope(\"prototype\") @Bean(\"person\") public Person person() { System.out.println(\"给容器中添加 Person...\"); return new Person(\"张三\", 25); } } 执行该 IOCTest\n1 2 3 4 5 6 public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); } } 程序并没有输出 给容器中添加 Person...\n修改 IOCTest，获取 person 对象\n1 2 3 4 5 6 7 8 9 10 public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); System.out.println(\"IOC 容器创建完成...\"); // 创建对象 Object bean = applicationContext.getBean(\"person\"); Object bean2 = applicationContext.getBean(\"person\"); } } 程序输出\nIOC 容器创建完成... 给容器中添加 Person... 给容器中添加 Person... ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：@Scope 设置组件作用域","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-scope/"},{"categories":null,"content":"Spring 注解：使用 FactoryBean 接口注册组件 Spring 注解系列目录\n创建 Color.java 类\n1 2 3 4 package icu.intelli.bean; public class Color { } 创建 ColorFactoryBean 类实现 FactoryBean 接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package icu.intelli.bean; import org.springframework.beans.factory.FactoryBean; // 创建一个 Spring 定义的 FactoryBean public class ColorFactoryBean implements FactoryBean\u003cColor\u003e { // 返回一个 Color 对象，这个对象会添加到容器中 public Color getObject() throws Exception { System.out.println(\"调用了 ColorFactoryBean.getObject()...\"); return new Color(); } public Class\u003c?\u003e getObjectType() { return Color.class; } // 是否单例，true：单实例，在容器中保存一份；false：多实例，每次获取都创建一个新对象（通过调用 getObject 方法） public boolean isSingleton() { return false; } } 修改 MainConfig，将 ColorFactoryBean 注册到容器中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package icu.intelli.config; import icu.intelli.bean.ColorFactoryBean; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class MainConfig { @Bean public ColorFactoryBean colorFactoryBean(){ return new ColorFactoryBean(); } } 修改 IOCTest\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package icu.intelli; import icu.intelli.config.MainConfig; import org.springframework.context.ApplicationContext; import org.springframework.context.annotation.AnnotationConfigApplicationContext; public class IOCTest { public static void main(String[] args) { // 获取 IOC 容器 ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class); // 获取容器中所有对象的名字 String[] beanDefinitionNames = applicationContext.getBeanDefinitionNames(); for (String beanDefinitionName : beanDefinitionNames) { System.out.println(beanDefinitionName); } // 根据 bean 名称获取 colorFactoryBean Object bean1 = applicationContext.getBean(\"colorFactoryBean\"); System.out.println(\"bean1 的类型为: \" + bean1.getClass()); // 根据 bean 名称获取 colorFactoryBean Object bean2 = applicationContext.getBean(\"colorFactoryBean\"); System.out.println(\"bean1 == bean2: \" + (bean1 == bean2)); // 添加\u0026前缀，获取容器中 ColorFactoryBean 的实例 Object bean3 = applicationContext.getBean(\"\u0026colorFactoryBean\"); System.out.println(\"bean3 的类型为: \" + bean3.getClass()); } } 运行 IOCTest，结果如下\norg.springframework.context.annotation.internalConfigurationAnnotationProcessor org.springframework.context.annotation.internalAutowiredAnnotationProcessor org.springframework.context.annotation.internalRequiredAnnotationProcessor org.springframework.context.annotation.internalCommonAnnotationProcessor org.springframework.context.event.internalEventListenerProcessor org.springframework.context.event.internalEventListenerFactory mainConfig colorFactoryBean 调用了 ColorFactoryBean.getObject()... bean1 的类型为: class icu.intelli.bean.Color 调用了 ColorFactoryBean.getObject()... bean1 == bean2: false bean3 的类型为: class icu.intelli.bean.ColorFactoryBean 分析\n由于 ColorFactoryBean 中 isSingleton() 返回 false, 因此使用多例模式，执行了两次 getObject() 方法，两个对象 bean1 与 bean2 不相等\n直接通过 beanName:colorFactoryBean 获取到的 bean 类型为 Color 类型\n如果需要获取 ColorFactoryBean 类型的对象，需要在 beanName 前添加一个 \u0026 前缀，即 \u0026colorFactoryBean. 是因为在 BeanFactory 接口中包含如下变量\n1 2 3 4 5 6 7 8 9 public interface BeanFactory { /** * Used to dereference a {@link FactoryBean} instance and distinguish it from * beans \u003ci\u003ecreated\u003c/i\u003e by the FactoryBean. For example, if the bean named * {@code myJndiObject} is a FactoryBean, getting {@code \u0026myJndiObject} * will return the factory, not the instance returned by the factory. */ String FACTORY_BEAN_PREFIX = \"\u0026\"; } ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：使用 FactoryBean 接口注册组件","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-factorybean/"},{"categories":null,"content":"Spring 注解：向容器中注册组件的方式总结 Spring 注解系列目录\n包扫描 + 组件标注注解（@Controller/@Service/@Repository/@Component）【仅适用于自己写的类】\n@Bean【可用于导入第三包里面的组件】\n@Import【快速给容器中导入一个组件】\n1 2 3 4 5 6 7 public @interface Import { /** * {@link Configuration}, {@link ImportSelector}, {@link ImportBeanDefinitionRegistrar} * or regular component classes to import. */ Class\u003c?\u003e[] value(); } {@link Configuration}：Configuration 为需要注入到容器中的类，Spring 会自动将这个组件注入到容器，id 默认是全类名。id 默认是全类名。 {@link ImportSelector}：将返回数组中包含的组件注入到容器中，SpringBoot 中使用该方式较多 {@link ImportBeanDefinitionRegistrar}：手动注册 Bean 到容器中 使用 Spring 提供的 FactoryBean\n默认获取的是工厂 Bean 调用 getObject() 方法创建的对象 要获取工厂 Bean 本身，需要给 id 前面加一个 \u0026 标识 ","description":"","tags":["Spring","Spring Annotation","Java"],"title":"Spring 注解：向容器中注册组件的方式总结","uri":"/posts/java/spring%E6%B3%A8%E8%A7%A3%E7%B3%BB%E5%88%97/spring-anno-summary-registration-methods/"},{"categories":null,"content":"Fedora 垃圾箱位置 ~/.local/share/Trash\n包含三个文件夹\nexpunged files：存放被删除的文件 info：存放被删除文件的信息，包括原始位置和删除时间 ","description":"","tags":["Linux","Fedora"],"title":"Fedora 垃圾箱位置","uri":"/posts/linux/fedora/fedora-trash-location/"},{"categories":null,"content":"Spring Boot 热部署 Spring Boot 基础系列目录\nSpringBoot 的热部署方式 2 种\nSpringLoader 插件 DevTools 工具 SpringLoader 的使用 项目准备 pom.xml 中添加 web 和 thymeleaf 的启动器\n1 2 3 4 5 6 7 8 9 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-thymeleaf\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e 创建 Controller\n1 2 3 4 5 6 7 8 9 @Controller public class UserController { @RequestMapping(\"/show\") public String showPage() { System.out.println(\"showPage...\"); return \"index\"; } } 编写页面，放在 resources 下的 templates 中\n1 2 3 4 5 6 7 8 9 10 \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cspan th:text=\"Hello....\"\u003e\u003c/span\u003e \u003c/body\u003e \u003c/html\u003e 使用 SpringLoader 进行项目的热部署 方式一：以 Maven 插件方式使用 SpringLoader pom.xml 中添加 SpringLoader 插件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-maven-plugin\u003c/artifactId\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espringloaded\u003c/artifactId\u003e \u003cversion\u003e1.2.5.RELEASE\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e 要使插件生效，需要使用 maven 的命令来启动\n1 spring-boot:run 我使用 SpringBoot 2.2.1, 提示不存在 springloaded 这个插件，暂不清楚原因。\nSpringLoader 缺陷\n只能对 Java 代码做热部署处理，但是对页面代码无能为力 使用 springloader 热部署程序是在系统后台以进程的形式运行，使用 idea 或 eclipse 并不能彻底将其关闭，所以再次启动会出现端口占用问题，需要在任务管理器中手动关闭该进程。 此方式很坑，不建议使用\n方式二：在项目中直接使用 jar 包的形式 视频使用的 springboot1.X, eclipse, 将 springloaded 的 jar 包放在了 lib 目录下，我使用 springboot 2.x, idea 使用在 pom.xml 中引入依赖的方式，设置不生效。配上原示例\nRun Configuration → VM arguments 添加\n1 -javaagent:springloaded-1.2.8.RELEASE.jar -noverify 该方式可以直接通过 eclipse 关闭。依旧只能热部署 Java 代码\nDevTools 工具 SpringLoader 与 DevTools 的区别 SpringLoader：在部署项目时，使用的是热部署的方式 DevTools：在部署项目时，使用的是重新部署的方式\nDevTools 的使用 pom.xml 中添加依赖\n视频使用的 springboot1.X, eclipse，我使用 springboot2.x, idea 使用在 pom.xml 中引入依赖的方式，设置不生效。配上原示例\n1 2 3 4 5 6 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-devtools\u003c/artifactId\u003e \u003c!-- 表示当前依赖不向下传递 --\u003e \u003coptional\u003etrue\u003c/optional\u003e \u003c/dependency\u003e 网上说需要 IDEA 开启如下配置\n开启 Build Project Auto...\nCtrl+Alt+Shift+/ → Register\n勾选 compiler.automake.allow.when.app.running\napplication.properties 中添加\n1 2 3 spring.devtools.restart.enabled=true spring.freemarker.cache = false spring.thymeleaf.cache=false 本人试验依旧不生效\n","description":"","tags":["Spring Boot","Java"],"title":"Spring Boot 热部署","uri":"/posts/java/springboot%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97/spring-boot-hot-deploy/"},{"categories":null,"content":"SpringBoot 定时任务 Spring Boot 基础系列目录\n课程内容\nScheduled 定时任务器 整合 Quartz 定时任务框架 Scheduled 定时任务器 Scheduled 定时任务器：是 Spring3.0 以后自带的一个定时任务器\n在 pom.xml 中添加 scheduled 的坐标 1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-context-support\u003c/artifactId\u003e \u003c/dependency\u003e 编写定时任务类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package icu.intelli.scheduled; import org.springframework.scheduling.annotation.Scheduled; import org.springframework.stereotype.Component; import java.time.LocalDateTime; /** * Scheduled 定时任务器 */ @Component public class ScheduledDemo { /** * 定时任务方法 * * @Scheduled：设置定时任务，标记当前方法是定时任务方法 * cron 属性：cron 表达式，定时任务触发时间的字符串表达形式 */ @Scheduled(cron = \"0/2 * * * * ?\") public void scheduledMethod() { System.out.println(\"定时器被触发\" + LocalDateTime.now()); } } 在启动类中开启定时任务的使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package icu.intelli; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.scheduling.annotation.EnableScheduling; /** * @EnableScheduling：开启定时任务自动触发 */ @SpringBootApplication @EnableScheduling public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } Cron 表达式 Cron 表达式是一个字符串，分为 6 或 7 个域，每一个域代表一个含义\nCron 表达式有两种语法格式\nSeconds Minutes Hours Day Month Week Year Seconds Minutes Hours Day Month Week 结构：\ncorn 从左到右（用空格隔开）：秒 分 小时 月份中的日期 月份 星期中的日期 年份\n各字段的含义\n位置 时间域名 允许值 允许的特殊字符 1 秒 0-59 , - * / 2 分钟 0-59 , - * / 3 小时 0-23 , - * / 4 日 1-31 , - * / L W C 5 月 1-12 , - * / 6 星期 1-7 , - * / L C # 7 年（可选） 1970-2099 , - * / Cron 表达式的时间字段除允许设置数值外，还可使用一些特殊的字符，提供列表、范围、通配符等功能，细说如下：\n星号（*）：可用在所有字段中，表示对应时间域的每一个时刻，例如，* 在分钟字段时，表示\"每分钟\"； 问号（?）：该字符只在日期和星期字段中使用，它通常指定为\"无意义的值\"，相当于占位符； 减号（-）：表达一个范围，如在小时字段中使用\"10-12\"，则表示从 10 到 12 点，即 10、11、12； 逗号（,）：表达一个列表值，如在星期字段中使用MON, WED, FRI，则表示星期一，星期三和星期五； 斜杠（/）：x/y 表达一个等步长序列，x 为起始值，y 为增量步长值。如在分钟字段中使用 0/15，则表示为 0，15，30 和 45 秒，而 5/15 在分钟字段中表示 5，20，35，50，你也可以使用 */y，它等同于 0/y； L：该字符只在日期和星期字段中使用，代表\"Last\"的意思，但它在两个字段中意思不同。L 在日期字段中，表示这个月份的最后一天，如一月的 31 号，非闰年二月的 28 号；如果 L 用在星期中，则表示星期六，等同于 7。但是，如果 L 出现在星期字段里，而且在前面有一个数值 X，则表示\"这个月的最后 X 天\"，例如，6L 表示该月的最后星期五； W：该字符只能出现在日期字段里，是对前导日期的修饰，表示离该日期最近的工作日。例如 15W 表示离该月 15 号最近的工作日，如果该月 15 号是星期六，则匹配 14 号星期五；如果 15 日是星期日，则匹配 16 号星期一；如果 15 号是星期二，那结果就是 15 号星期二。但必须注意关联的匹配日期不能够跨月，如你指定 1W，如果 1 号是星期六，结果匹配的是 3 号星期一，而非上个月最后的那天。W 字符串只能指定单一日期，而不能指定日期范围； LW 组合：在日期字段可以组合使用 LW，它的意思是当月的最后一个工作日； 井号（#）：该字符只能在星期字段中使用，表示当月某个工作日。如 6#3 表示当月的第三个星期五（6 表示星期五，#3 表示当前的第三个），而 4#5 表示当月的第五个星期三，假设当月没有第五个星期三，忽略不触发； C：该字符只在日期和星期字段中使用，代表\"Calendar\"的意思。它的意思是计划所关联的日期，如果日期没有被关联，则相当于日历中所有日期。例如 5C 在日期字段中就相当于日历 5 日以后的第一天。1C 在星期字段中相当于星期日后的第一天。Cron 表达式对特殊字符的大小写不敏感，对代表星期的缩写英文大小写也不敏感。 例子：\n@Scheduled(cron = \"0 0 1 1 1 ?\")：每年一月的一号的 1:00:00 执行一次 @Scheduled(cron = \"0 0 1 1 1,6 ?\")：一月和六月的一号的 1:00:00 执行一次 @Scheduled(cron = \"0 0 1 1 1,4,7,10 ?\")：每个季度的第一个月的一号的 1:00:00 执行一次 @Scheduled(cron = \"0 0 1 1 * ?\")：每月一号 1:00:00 执行一次 @Scheduled(cron=\"0 0 1 * * *\")：每天凌晨 1 点执行一次 Spring Boot 整合 Quartz 定时任务框架 Quartz 介绍及使用思路 quartz（开源项目）\nQuartz 是 OpenSymphony 开源组织在 Job scheduling（作业调度）领域又一个开源项目，它可以与 J2EE 与 J2SE 应用程序相结合也可以单独使用。Quartz 可以用来创建简单或为运行十个，百个，甚至是好几万个 Jobs 这样复杂的程序。Jobs 可以做成标准的 Java 组件或 EJBs。Quartz 的最新版本为 Quartz 2.3.0。\n使用思路：\njob 任务，作业，你要做什么事 Trigger 触发器，你什么时候去做 Scheduler 任务调度，你什么时候需要去做什么事 Quartz 的基本使用 建立普通 maven 项目，在 pom.xml 中引入 quartz\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003eorg.quartz-scheduler\u003c/groupId\u003e \u003cartifactId\u003equartz\u003c/artifactId\u003e \u003cversion\u003e2.3.0\u003c/version\u003e \u003c/dependency\u003e 创建 MyJob 类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package icu.intelli.quartz; import org.quartz.Job; import org.quartz.JobExecutionContext; import org.quartz.JobExecutionException; import java.util.Date; /** * 定义任务类 */ public class MyJob implements Job { /** * 任务被触发时，所执行的方法 * * @param context * @throws JobExecutionException */ public void execute(JobExecutionContext context) throws JobExecutionException { System.out.println(\"execute...\" + new Date()); } } 测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package icu.intelli.quartz; import org.quartz.*; import org.quartz.impl.StdSchedulerFactory; public class QuartzMain { public static void main(String[] args) throws SchedulerException { // 1. 创建 Job 对象，做什么事 JobDetail jobDetail = JobBuilder.newJob(MyJob.class).build(); // 2. 创建 Trigger 对象，在什么时候做 // 简单的 trigger 触发时间，通过 quartz 提供的一些方法，来完成简单的重复调用 // Trigger trigger = TriggerBuilder.newTrigger() // .withSchedule(SimpleScheduleBuilder.repeatSecondlyForever()) // .build(); // cron Trigger：按照 cron 的表达式来给定触发时间 Trigger trigger = TriggerBuilder.newTrigger() .withSchedule(CronScheduleBuilder.cronSchedule(\"0/2 * * * * ?\")) .build(); // 3. 创建 Scheduler 对象，在什么时间做什么事 Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler(); scheduler.scheduleJob(jobDetail, trigger); // 4. 启动 scheduler.start(); } } SpringBoot 整合 Quartz SpringBoot 版本 1.5.x\n引入依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u003cdependency\u003e \u003cgroupId\u003eorg.quartz-scheduler\u003c/groupId\u003e \u003cartifactId\u003equartz\u003c/artifactId\u003e \u003cversion\u003e2.3.0\u003c/version\u003e \u003cexclusions\u003e \u003cexclusion\u003e \u003cartifactId\u003eslf4j-api\u003c/artifactId\u003e \u003cgroupId\u003eorg.slf4j\u003c/groupId\u003e \u003c/exclusion\u003e \u003c/exclusions\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-context-support\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-tx\u003c/artifactId\u003e \u003c/dependency\u003e 创建 QuartzConfig 配置类，使用到的是简单 Trigger\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 package icu.intelli.config; import icu.intelli.quartz.MyJob; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.scheduling.quartz.JobDetailFactoryBean; import org.springframework.scheduling.quartz.SchedulerFactoryBean; import org.springframework.scheduling.quartz.SimpleTriggerFactoryBean; /** * Quartz 的配置类 */ @Configuration public class QuartzConfig { /** * 1. 创建 Job 对象 */ @Bean public JobDetailFactoryBean jobDetailFactoryBean() { JobDetailFactoryBean jobDetailFactoryBean = new JobDetailFactoryBean(); // 关联我们自己的 Job 类 jobDetailFactoryBean.setJobClass(MyJob.class); return jobDetailFactoryBean; } /** * 2. 创建 Trigger 对象 * \u003cp\u003e * 简单的 Trigger */ @Bean public SimpleTriggerFactoryBean simpleTriggerFactoryBean(JobDetailFactoryBean jobDetailFactoryBean) { SimpleTriggerFactoryBean simpleTriggerFactoryBean = new SimpleTriggerFactoryBean(); // 关联 JobDetail 对象 simpleTriggerFactoryBean.setJobDetail(jobDetailFactoryBean.getObject()); // 该参数表示一个执行的毫秒数 simpleTriggerFactoryBean.setRepeatInterval(2000); // 该参数设置重复次数 simpleTriggerFactoryBean.setRepeatCount(5); return simpleTriggerFactoryBean; } /** * 3. 创建 Scheduler 对象 */ @Bean public SchedulerFactoryBean schedulerFactoryBean(SimpleTriggerFactoryBean simpleTriggerFactoryBean) { SchedulerFactoryBean schedulerFactoryBean = new SchedulerFactoryBean(); // 关联 Trigger 对象 schedulerFactoryBean.setTriggers(simpleTriggerFactoryBean.getObject()); return schedulerFactoryBean; } } 修改启动类，添加 @EnableScheduling，启动即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package icu.intelli; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.scheduling.annotation.EnableScheduling; /** * SpringBoot 整合 Quartz 的案例 * \u003cp\u003e * 添加 @EnableScheduling 启动 Quartz */ @SpringBootApplication @EnableScheduling public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } 使用 CronTrigger\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 package icu.intelli.config; import icu.intelli.quartz.MyJob; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.scheduling.quartz.CronTriggerFactoryBean; import org.springframework.scheduling.quartz.JobDetailFactoryBean; import org.springframework.scheduling.quartz.SchedulerFactoryBean; /** * Quartz 的配置类 */ @Configuration public class QuartzConfig { /** * 1. 创建 Job 对象 */ @Bean public JobDetailFactoryBean jobDetailFactoryBean() { JobDetailFactoryBean jobDetailFactoryBean = new JobDetailFactoryBean(); // 关联我们自己的 Job 类 jobDetailFactoryBean.setJobClass(MyJob.class); return jobDetailFactoryBean; } /** * 2. 创建 Trigger 对象 * \u003cp\u003e * Cron Trigger */ @Bean public CronTriggerFactoryBean cronTriggerFactoryBean(JobDetailFactoryBean jobDetailFactoryBean) { CronTriggerFactoryBean cronTriggerFactoryBean = new CronTriggerFactoryBean(); // 关联 JobDetail cronTriggerFactoryBean.setJobDetail(jobDetailFactoryBean.getObject()); // 设置 Cron 表达式 cronTriggerFactoryBean.setCronExpression(\"0/2 * * * * ?\"); return cronTriggerFactoryBean; } /** * 3. 创建 Scheduler 对象 */ @Bean public SchedulerFactoryBean schedulerFactoryBean(CronTriggerFactoryBean cronTriggerFactoryBean) { SchedulerFactoryBean schedulerFactoryBean = new SchedulerFactoryBean(); // 关联 Trigger 对象 schedulerFactoryBean.setTriggers(cronTriggerFactoryBean.getObject()); return schedulerFactoryBean; } } 在 Job 类中注入 Service MyJob 类实现了 Job 类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package icu.intelli.quartz; import icu.intelli.service.UserService; import org.quartz.Job; import org.quartz.JobExecutionContext; import org.quartz.JobExecutionException; import org.springframework.beans.factory.annotation.Autowired; import java.util.Date; public class MyJob implements Job { @Autowired private UserService userService; @Override public void execute(JobExecutionContext context) throws JobExecutionException { System.out.println(\"execute...\" + new Date()); userService.addUser(); } } UserService\n1 2 3 4 5 6 7 8 9 10 package icu.intelli.service; import org.springframework.stereotype.Service; @Service public class UserService { public void addUser() { System.out.println(\"addUser...\"); } } QuartzConfig\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 package icu.intelli.config; import icu.intelli.quartz.MyJob; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.scheduling.quartz.CronTriggerFactoryBean; import org.springframework.scheduling.quartz.JobDetailFactoryBean; import org.springframework.scheduling.quartz.SchedulerFactoryBean; @Configuration public class QuartzConfig { @Bean public JobDetailFactoryBean jobDetailFactoryBean() { JobDetailFactoryBean jobDetailFactoryBean = new JobDetailFactoryBean(); jobDetailFactoryBean.setJobClass(MyJob.class); return jobDetailFactoryBean; } @Bean public CronTriggerFactoryBean cronTriggerFactoryBean(JobDetailFactoryBean jobDetailFactoryBean) { CronTriggerFactoryBean cronTriggerFactoryBean = new CronTriggerFactoryBean(); cronTriggerFactoryBean.setJobDetail(jobDetailFactoryBean.getObject()); cronTriggerFactoryBean.setCronExpression(\"0/2 * * * * ?\"); return cronTriggerFactoryBean; } @Bean public SchedulerFactoryBean schedulerFactoryBean(CronTriggerFactoryBean cronTriggerFactoryBean) { SchedulerFactoryBean schedulerFactoryBean = new SchedulerFactoryBean(); schedulerFactoryBean.setTriggers(cronTriggerFactoryBean.getObject()); return schedulerFactoryBean; } } Application\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package icu.intelli; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.scheduling.annotation.EnableScheduling; @SpringBootApplication @EnableScheduling public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } 此时会出现 NullPointerException，userService 为 null，是因为 jobDetailFactoryBean 在实例化 MyJob 时，实际上是使用 AdaptableJobFactory 类的 createJobInstance 方法，改方法使用了反射机制创建对象，并没有将 MyJob 对象放到 IOC 容器中，Spring 要求被注入对象和注入对象都在 IOC 容器中，所以 UserService 没有注入到 MyJob 中\n1 2 3 4 5 6 7 8 @Configuration public class QuartzConfig { @Bean public JobDetailFactoryBean jobDetailFactoryBean() { JobDetailFactoryBean jobDetailFactoryBean = new JobDetailFactoryBean(); jobDetailFactoryBean.setJobClass(MyJob.class); return jobDetailFactoryBean; } 解决方法：\n创建 MyAdaptableJobFactory\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package icu.intelli.config; import org.quartz.spi.TriggerFiredBundle; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.config.AutowireCapableBeanFactory; import org.springframework.scheduling.quartz.AdaptableJobFactory; import org.springframework.stereotype.Component; /** * @Component 实例化该类 */ @Component(\"myAdaptableJobFactory\") public class MyAdaptableJobFactory extends AdaptableJobFactory { /** * AutowireCapableBeanFactory：可以将一个对象添加到 Spring 的 IOC 容器中，并且完成该对象的注入 */ @Autowired private AutowireCapableBeanFactory autowireCapableBeanFactory; /** * 该方法需要将实例化的对象手动添加到 Spring 的 IOC 容器中，并完成对象的注入 * * @param bundle * @return * @throws Exception */ @Override protected Object createJobInstance(TriggerFiredBundle bundle) throws Exception { Object obj = super.createJobInstance(bundle); // 将 obj 对象添加到 Spring 的 IOC 容器中，并完成注入 autowireCapableBeanFactory.autowireBean(obj); return obj; } } 修改 QuartzConfig，使用自定义的 MyAdaptableJobFactory\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 package icu.intelli.config; import icu.intelli.quartz.MyJob; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.scheduling.quartz.CronTriggerFactoryBean; import org.springframework.scheduling.quartz.JobDetailFactoryBean; import org.springframework.scheduling.quartz.SchedulerFactoryBean; @Configuration public class QuartzConfig { @Bean public JobDetailFactoryBean jobDetailFactoryBean() { JobDetailFactoryBean jobDetailFactoryBean = new JobDetailFactoryBean(); jobDetailFactoryBean.setJobClass(MyJob.class); return jobDetailFactoryBean; } @Bean public CronTriggerFactoryBean cronTriggerFactoryBean(JobDetailFactoryBean jobDetailFactoryBean) { CronTriggerFactoryBean cronTriggerFactoryBean = new CronTriggerFactoryBean(); cronTriggerFactoryBean.setJobDetail(jobDetailFactoryBean.getObject()); cronTriggerFactoryBean.setCronExpression(\"0/2 * * * * ?\"); return cronTriggerFactoryBean; } @Bean public SchedulerFactoryBean schedulerFactoryBean(CronTriggerFactoryBean cronTriggerFactoryBean, MyAdaptableJobFactory myAdaptableJobFactory) { SchedulerFactoryBean schedulerFactoryBean = new SchedulerFactoryBean(); schedulerFactoryBean.setTriggers(cronTriggerFactoryBean.getObject()); // 重新设置 JobFactory 使用自定义的 Factory schedulerFactoryBean.setJobFactory(myAdaptableJobFactory); return schedulerFactoryBean; } } ","description":"","tags":["Spring Boot","Java"],"title":"Spring Boot 定时任务","uri":"/posts/java/springboot%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97/spring-boot-scheduled/"},{"categories":null,"content":"后台运行 jar 包 nohup 介绍 run a command immune to hangups, with output to a non-tty\n运行命令不被挂起，并输出到非 tty\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 sage: nohup COMMAND [ARG]... or: nohup OPTION 运行命令，忽略挂起信号 Run COMMAND, ignoring hangup signals. --help display this help and exit --version output version information and exit 如果基本输入是终端，请从/dev/null 重定向它 If standard input is a terminal, redirect it from /dev/null. 如果标准输出是终端，将输出追加到'nohup.out'文件(如果可能), 否则追加到'$HOME/nohup.out' If standard output is a terminal, append output to 'nohup.out' if possible, '$HOME/nohup.out' otherwise. 如果基本错误输出是终端，请将它重定向到标准输出 If standard error is a terminal, redirect it to standard output. 将标准输出到 FILE, 使用'nohup COMMAND \u003e FILE' To save output to FILE, use 'nohup COMMAND \u003e FILE'. 将标准输出重定向到 nohup.out，此时并不会后台运行程序\n1 nohup COMMAND 将标准输出重定向到指定文件，此时并不会后台运行程序\n1 nohup COMMAND \u003e xxx.log nohup 不会自动将命令后台运行，你必须在命令行尾添加一个 \u0026 来明确指定后台运行该命令\n后台运行命令，并将标准输出重定向默认的 nohup.out\n1 nohup COMMAND \u0026 后台运行命令，并将标准输出重定向到指定文件\n1 nohup COMMAND \u003e xxx.log \u0026 后台运行命令，并将标准错误重定向到标准输出，再将标准输出重定向到指定文件\n1 nohup COMMAND \u003e xxx.file 2\u003e\u00261 \u0026 0：standard input 1：standard output 2：standard error 2\u003e\u00261 是将标准错误（2）重定向到标准输出（\u00261），标准输出（\u00261）再被重定向输入到 xxx.file 文件中。\n如果标准错误输出是终端，它通常会重定向到和标准输出相同的文件描述符。然而，如果标准输出被关闭，标准错误终端会代替上面的 nohup.out 或 $HOME/nohup.out，标准输出会输出到标准错误终端。\n常用后台运行 jar 命令 1 nohup java -jar xxx.jar \u003e xxx.log 2\u003e\u00261 \u0026 ","description":"","tags":["Java","Linux"],"title":"后台运行 jar 包","uri":"/posts/java/run-jar-backend/"},{"categories":null,"content":"PathUtils 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 import java.io.File; public class PathUtils { private static final String FILE_SEPARATOR = File.separator; private PathUtils() { } /** * 文件路径中的分隔副全部转换为 Unix 风格：/ * \u003cp\u003e * 例如：C:\\\\temp\\ -\u003e C://temp/ * * @param path * @return */ public static String toUnixSeparator(String path) { return path.replace(\"\\\\\", \"/\"); } /** * 文件路径中的分隔符全部转换为 Windows 风格：\\ * \u003cp\u003e * 例如：C://temp/ -\u003e C:\\\\temp\\ * * @param path * @return */ public static String toWindowsSeparator(String path) { return path.replace(\"/\", \"\\\\\"); } /** * 将文件路径中的分隔符转换为当前系统的分隔符 * 例如：Windows : C://temp// -\u003e C:\\\\temp\\\\ * Unix : C:\\\\temp\\\\ -\u003e C://temp// * * @param path * @return */ public static String toSystemSeparator(String path) { return isUnix() ? toUnixSeparator(path) : toWindowsSeparator(path); } /** * 将文件路径中的分隔符转换为 Unix 风格并以一个/结尾 * \u003cp\u003e * 例如：C:\\\\temp\\\\ -\u003e C://temp/ * C:\\\\temp -\u003e C://temp/ * * @param path * @return */ public static String endWithSingleUnixSeparator(String path) { return endWithoutUnixSeparator(path) + \"/\"; } /** * 将文件路径中的分隔符转换为 Windows 风格并以一个\\结尾 * \u003cp\u003e * 例如：C:/temp -\u003e C:\\temp\\ * C://temp// -\u003e C:\\\\temp\\ * * @param path * @return */ public static String endWithSingleWindowsSeparator(String path) { return endWithoutWindowsSeparator(path) + \"\\\\\"; } /** * 将文件路径中的分隔符转换为当前系统的分隔符，并且结尾包含一个分隔符 * 例如：Windows： * C://temp -\u003e C:\\\\temp\\ * C://temp/ -\u003e C:\\\\temp\\ * C：//temp// -\u003e C:\\\\temp\\ * Unix : * C:\\\\temp -\u003e C://temp/ * C:\\\\temp\\ -\u003e C://temp/ * C：\\\\temp\\\\ -\u003e C://temp/ * * @param path * @return */ public static String endWithSingleSystemSeparator(String path) { return isUnix() ? endWithSingleUnixSeparator(p-ath) : endWithoutWindowsSeparator(path); } /** * 将文件路径中的分隔符转换为 Unix 风格，并且结尾没有/ * 例如：C:\\\\temp\\ -\u003e C://temp * C:\\\\temp\\\\ -\u003e C://temp * * @param path * @return */ public static String endWithoutUnixSeparator(String path) { return toUnixSeparator(path).replaceAll(\"^(.*?)/+$\", \"$1\"); } /** * 将文件路径中的分隔符转换为 Windows 风格，并且结尾没有\\ * 例如：C://temp/ -\u003e C:\\\\temp * C://temp// -\u003e C:\\\\temp * * @param path * @return */ public static String endWithoutWindowsSeparator(String path) { return toWindowsSeparator(path).replaceAll(\"^(.*?)\\\\\\\\+$\", \"$1\"); } /** * 将文件路径中的分隔符转换为当前系统的分隔符，并且结尾没有分隔符 * 例如：Windows： * C://temp -\u003e C:\\\\temp * C://temp/ -\u003e C:\\\\temp * C：//temp// -\u003e C:\\\\temp * Unix : * C:\\\\temp -\u003e C://temp * C:\\\\temp\\ -\u003e C://temp * C：\\\\temp\\\\ -\u003e C://temp * * @param path * @return */ public static String endWithoutSystemSeparator(String path) { return isUnix() ? endWithoutUnixSeparator(path) : endWithoutWindowsSeparator(path); } /** * 将文件路径中的分隔符转换为 Unix 的分隔符，相邻的多个分隔符只保留一个，并且结尾包含一个分隔符 * \u003cp\u003e * 例如:C:\\\\temp -\u003e C:/temp/ * C:\\\\temp\\ -\u003e C:/temp/ * C:\\\\temp\\\\ -\u003e C:/temp/ * C:\\/\\temp\\/\\ -\u003e C:/temp/ * * @param path * @return */ public static String removeDuplicateEndWithUnixSeparator(String path) { return endWithSingleUnixSeparator(path) .replaceAll(\"[/\\\\\\\\]+[/\\\\\\\\]+\", \"/\"); } /** * 将文件路径中的分隔符转换为 Windows 的分隔符，相邻的多个分隔符只保留一个，并且结尾包含一个分隔符 * \u003cp\u003e * 例如:C://temp -\u003e C:\\temp\\ * C://temp/ -\u003e C:\\temp\\ * C://temp// -\u003e C:\\temp\\ * C:/\\/temp/\\/ -\u003e C:\\temp\\ * * @param path * @return */ public static String removeDuplicateEndWithWindowsSeparator(String path) { return endWithSingleWindowsSeparator(path) .replaceAll(\"[/\\\\\\\\]+[/\\\\\\\\]+\", \"\\\\\\\\\"); } /** * 将文件路径中的分隔符转换为系统分隔符，相邻的多个分隔符只保留一个，并且结尾包含一个分隔符 * \u003cp\u003e * 例如: * \u003cp\u003e * Unix： * C:\\\\temp -\u003e C:/temp/ * * C:\\\\temp\\ -\u003e C:/temp/ * * C:\\\\temp\\\\ -\u003e C:/temp/ * * C:\\/\\temp\\/\\ -\u003e C:/temp/ * Windows： * C://temp -\u003e C:\\temp\\ * C://temp/ -\u003e C:\\temp\\ * C://temp// -\u003e C:\\temp\\ * C:/\\/temp/\\/ -\u003e C:\\temp\\ * * @param path * @return */ public static String removeDuplicateEndWithSystemSeparator(String path) { return isUnix() ? removeDuplicateEndWithUnixSeparator(path) : removeDuplicateEndWithWindowsSeparator(path); } /** * 将文件路径中的分隔符转换为 Unix 的分隔符，相邻的多个分隔符只保留一个，并且结尾没有分隔符 * \u003cp\u003e * 例如:C:\\\\temp -\u003e C:/temp * C:\\\\temp\\ -\u003e C:/temp * C:\\\\temp\\\\ -\u003e C:/temp * C:\\/\\temp\\/\\ -\u003e C:/temp * * @param path * @return */ public static String removeDuplicateEndWithoutUnixSeparator(String path) { return endWithoutUnixSeparator(path) .replaceAll(\"[/\\\\\\\\]+[/\\\\\\\\]+\", \"/\"); } /** * 将文件路径中的分隔符转换为 Windows 的分隔符，相邻的多个分隔符只保留一个，并且结尾没有分隔符 * \u003cp\u003e * 例如:C://temp -\u003e C:\\temp * C://temp/-\u003e C:\\temp * C://temp// -\u003e C:\\temp * C:/\\/temp/\\/ -\u003e C:\\temp * * @param path * @return */ public static String removeDuplicateEndWithoutWindowsSeparator(String path) { return endWithoutWindowsSeparator(path) .replaceAll(\"[/\\\\\\\\]+[/\\\\\\\\]+\", \"\\\\\\\\\"); } /** * 将文件路径中的分隔符转换为系统分隔符，相邻的多个分隔符只保留一个，并且结尾没有分隔符 * \u003cp\u003e * 例如: * \u003cp\u003e * Unix: * C:\\\\temp -\u003e C:/temp * C:\\\\temp\\ -\u003e C:/temp * C:\\\\temp\\\\ -\u003e C:/temp * C:\\/\\temp\\/\\ -\u003e C:/temp * Windows: * C://temp -\u003e C:\\temp * C://temp/-\u003e C:\\temp * C://temp// -\u003e C:\\temp * C:/\\/temp/\\/ -\u003e C:\\temp * * @param path * @return */ public static String removeDuplicateEndWithoutSystemSeparator(String path) { return isUnix() ? removeDuplicateEndWithoutUnixSeparator(path) : removeDuplicateEndWithoutWindowsSeparator(path); } /** * 清除路径中的盘符 * \u003cp\u003e * 例如： * Z:/temp/file -\u003e /temp/file * * @param path * @return */ public static String removeDiskChar(String path) { return path.substring(path.indexOf(\":\") + 1); } /** * 清除路径中指定前缀 * \u003cp\u003e * 例如： * path = Z:/temp/file * prePath = Z:/temp * return /file * * @param path * @param prePath * @return */ public static String removePrePath(String path, String prePath) { return path.substring(path.indexOf(prePath) + 1); } /** * 系统分隔符号为/返回 true * * @return */ private static boolean isUnix() { return FILE_SEPARATOR.equals(\"/\"); } /** * 分隔符号为\\返回 true * * @return */ private static boolean isWindows() { return FILE_SEPARATOR.equals(\"\\\\\"); } } ","description":"","tags":["Java"],"title":"PathUtil","uri":"/posts/java/path-util/"},{"categories":null,"content":"Linux 基本命令 简单命令 关机：halt，poweroff\n重启：reboot\n-f：强制，不调用shutdown -p：切断电源 关机或重启： shutdown\n1 shutdown [OPTION]... [TIME] [MESSAGE] OPTION： -r：reboot -h：halt -c：cancel TIME：无指定，默认相当于 +1（CentOS7） now：立刻，相当于 +0 +m：相对时间表示法，几分钟之后 hh:mm：绝对时间表示，指明具体时间 用户登陆信息查看命令\nwhoami：显示当前登陆的有效用户 who：系统的那个前所有的登陆会话 w：系统的当前所有的登陆会话及所做的操作 nano：文本编辑\n高级命令 screen 命令 远程协助字符界面\n创建新 screen 会话 1 screen -S [SESSION] 加入 screen 会话 1 screen -x [SESSION] 退出并关闭 screen 会话 1 exit 剥离当前 screen 会话 1 Ctrl+a，Ctrl+d 显示所有已经打开的 screen 会话 1 screen -ls 恢复某 screen 会话 1 screen -r [SESSION] echo 命令 功能：显示字符\n语法：echo [-neE] [字符串]\n说明：echo 会将输入的字符串送往标准输出。输出的字符串间以空白字符隔开，并在最后加上换行号\n选项：\n-E （默认） 不支持\\解释功能 -n 不自动换行 -e 启用\\字符的解释功能 显示变量\necho \"$VAR_NAME\" 变量会替换，弱引用 echo '$VAR_NAME' 变量不会替换，强引用 启用命令选项 -e，若字符串中出现以下字符，则特别加以处理，而不会将它当成一般文字输出。\n\\\\a 发出警告声 \\\\b 退格键 \\\\c 最后不加上换行符号 \\\\n 换行且光标移至行首 \\\\r 回车，即光标移至行首，但不换行 \\\\t 插入 tab \\\\ 插入 \\ 字符 \\\\0nnn 插入 nnn（八进制）所代表的 ASCII 字符 \\\\xHH 插入 HH（十六进制）所代表的 ASCII 数字 ''，``，\"\" 的区别：\n''：原封不动显示\n``或$()：可以识别命令和变量\n\"\" 或 ${}：可以识别变量，不能识别命令\n1 2 3 4 5 6 [root@localhost ~]# echo \"echo $PATH\" echo /usr/share/Modules/bin:/usr/local/bin:/usr/local/sbin:/usr/bin:/usr/sbin:/root/bin [root@localhost ~]# echo 'echo $PATH' echo $PATH [root@localhost ~]# echo `echo $PATH` /usr/share/Modules/bin:/usr/local/bin:/usr/local/sbin:/usr/bin:/usr/sbin:/root/bin 命令行扩展，被括起来的集合：\n命令行扩展：$() 或 ``\n把一个命令的输出打印给另一个命令的参数\n1 2 echo \"This system's name is $(hostname)\" echo \"i am `whoami`\" 括号扩展：{}\n打印重复字符串的简化形式\n1 2 3 4 5 echo file{1,3,5} rm -rf file{1,3,5} echo {1..10} echo {a..z} echo {000..20..2} history 命令 语法：\nhistory [-c] [-d offset] [n] history -anrw [filename] history -ps arg [arg...] 选项：\n-c：清空命令历史\n-d offset：删除历史中指定的第 offset 个命令\nn：显示最近的 n 条历史\n-a：追加本次会话新执行的命令历史列表至历史文件\n-r：读历史文件附加到历史列表\n-w：保存历史列表到指定的历史文件\n-n：读历史文件中未读过的行到历史列表\n-p：展开历史参数成多行，但不保存到历史列表中\n1 history -p `hostname` `lscpu` 会执行 hostname 和 lscpu，并将执行结果变成多行，并且不存入到 history 列表\n-s：展开历史参数成一行，附加在历史列表后\n1 history -s `rm -rf /*` 不会执行 rm -rf /*，但会将其保存到 history 中\n命令行历史\n保存你输入的命令历史。可以用它来重复执行命令\n登陆 shell 时，会读取命令历史文件中记录下的命令 ~/.bash_history\n登陆进 shell 后新执行的命令只会记录在缓存中；这些命令会在用户退出时追加到命令历史文件中。\n重复前一个命令有 4 种方法\n使用上方向键，并回车执行 按 !! 并回车执行 输入 !-1 并回车执行 按 Ctrlp 并回车执行 !:0 执行前一条命令，但会去除参数\nCtrl+n 显示当前记录中的下一条命令，但不执行，相当于下方向键\nCtrl+j 执行当前命令\n!n 执行 history 命令输出中，对应序号 n 的命令\n!-n 执行 history 历史中倒数第 n 个命令\n!string 重复前一个以 string 开头的命令\n!?string 重复前一个包含 string 的命令\n!string:p 仅打印命令历史，而不执行\n!$:p 打印输出 !$（上一条命令的最后一个参数）的内容\n!*:p 打印输出 !*（上一条命令的所有参数）的内容\n^string 删除上一条命令中的第一个 string\n^string1^string2 将上一条命令中的第一个 string1 替换为 stirng2\n!:gs/string1/string2 将上一条命令中所有的 string1 都替换为 string2\n使用 Up（向上）和 Down（向下）键来上下浏览从前输入的命令\nCtrl+r 在命令历史中搜索命令\n1 (reverse-i-search)`': Ctrl+g 从搜索命令中退出\n要重新调用前一个命令中最后一个参数\n!$ esc.（点击 esc 后松开，然后点击。键） Alt+. （按住 Alt 键的同时点击。键） 调用历史参数\ncommand !^ 利用上一个命令的第一个参数做 cmd 的参数 command !$ 利用上一个命令的最后一个参数做 cmd 的参数 command !* 利用上一个命令的全部参数做 cmd 的参数 command !:n 利用上一个命令的第 n 个参数做 cmd 的参数 command !n:^ 调用第 n 条命令的第一个参数 command !n:$ 调用第 n 条命令的最后一个参数 command !n:m 调用第 n 条命令的第 m 个参数 command !n:* 调用第 n 条命令的所有参数 command !string:^ 从命令历史中搜索以 string 开头的命令，并获取它的第一个参数 command !string:$ 从命令历史中搜索以 string 开头的命令，并获取它的最后一个参数 command !string:n 从命令历史中搜索以 stirng 开头的命令，并获取它的第 n 个参数 command !string:* 从命令历史中搜索以 stirng 开头的命令，并获取它的所有参数 命令历史相关环境变量\nHISTSIZE：内存中命令历史记录的条数 HISTFILE：指定历史文件，默认为 ~/.bash_history HISTFILESIZE：命令历史文件记录历史的条数 HISTTIMEFORMAT=\"%F %T \" 显示时间 HISTIGNORE=\"str1:str2*:...\" 不将 str1 命令，str2 开头的命令记录到历史列表 控制命令历史的记录方式： 环境变量：HISTCONTROL ignoredups 默认，忽略重复的命令，连续且相同为“重复” ignorespace 忽略所有以空白开头的命令 ignoreboth 相当于 ignoredups 和 ignorespace 组合 erasedups 删除重复命令 export 变量名=\"值\" 存放在 /etc/profile 或 ~/.bash_profile 字符集和编码 hexdump -C file 查看文件的 16 进制\n**ASCII 码：**计算机内部，所有信息最终都是一个二进制值。上世纪 60 年代，美国制定了一套字符编码，对英语字符与二进制位之间的关系，做了统一规定。ASCII 码一共规定了 128 个字符的编码，占用了一个字节的后面 7 位，最前面的一位统一规定为 0。可通过 man ascii 查看\n**Unicode：**用于表示世界上所有语言中的所有字符。每一个符号都给予一个独一无二的编码数字，Unicode 是一个很大的集合，现在的规模可以容纳 100 多万个符号。Unicode 仅仅只是一个字符集，规定了每个字符对应的二进制代码，至于这个二进制代码如何存储则没有规定。\nUnicode 编码方案：\nUTF-8 变长，1 到 4 个字节 UTF-16 变长，2 或 4 个字节 UTF-32 固定长度，4 个字节 **UTF-8：**是目前互联网上使用最广泛的一种 Unicode 编码方式，可变长存储。使用 1-4 个字节表示一个字符，根据字符的不同变换长度。编码规则如下：\n对于单个字节的字符，第一位设为 0，后面的 7 位对应着个字符的 Unicode 码。因此，对于英文中的 0-127 号字符，与 ASCII 码完全相同。这意味着 ASCII 码的文档可用 UTF-8 编码打开 对于需要使用 N 个字节来表示的字符（N\u003e1），第一个字节的前 N 位都设为 1，第 N+1 位设为 0，剩余的 N-1 个字节的前两位都设为 10，剩下的二进制位则使用这个字符的 Unicode 码来填充 编码查询和转换：\nhttps://javawind.net/tools/native2ascii.jsp https://tool.oschina.net/encode http://www.chi2ko.com/tool/CJK.htm iconv 查看系统支持的所有编码表\niconv -f gb2312 in.txt -o out.txt 将 gb2312 格式的 in.txt 转换为 Unicode 文件格式\nlocalectl list-locales或cat /etc/locale.conf 查看所有支持的语言和编码表\nlocalectl set-locale LANG=zh_CN.utf8或vim /etc/locale.conf 设置系统使用中文\ntab 键 命令补全：\n内部命令：\n外部命令：bash 根据 PATH 环境变量定义的路径，自左而右在每个路径搜寻以给定命令名命名的文件，第一次找到的命令即为要执行的命令\n用户给定的字符串只有一条唯一对应的命令，直接补全，否则，再次 Tab 会给出列表\n路径补全：\n把用户给出的字符串当做路径开头，并在其指定上级目录下搜索以指定的字符串开头的文件名\n如果唯一：直接补全 否则：再次 Tab 给出列表 获取帮助 获取帮助的能力决定了技术能力\n多层次的帮助\nwhatis command --help man and info /usr/share/doc/ Red Hat documentation 其他网站和搜索 whatis\n显示命令的简短描述 使用了 whatis 的数据库，刚安装后不可立即使用，需要使用 makewhatis 或 mandb 制作数据库 使用示例：whatis cal 或 man -f cal 命令帮助\n内部命令：help COMMAND 或 man bash 外部命令： COMMAND --help 或 COMMAND -h 使用手册（manual）：man COMMAND 信息页：info COMMAND 程序自身的帮助文档：README、INSTALL、ChangeLog 程序官方文档：官方站点 Documentation 发行版的官方文档 Google --help 和 -h 选项\n显示用法总结和参数列表 使用的大多数，但并非所有 示例： date --help Usage: date [OPTION]... [+FORMAT] or: date [-u|--utc|--universal] [MMDDhhmm[[CC]YY][.ss]] [] 表示可选项 CAPS 或\u003c\u003e 表示变化的数据 ... 表示一个列表 x|y|z 表示 x 或 y 或 z -abc -a -b -c {} 表示分组 man 命令\n可以看外部命令的帮助，配置文件格式语法，游戏说明等，将这些分类放到了不同的章节中 手册页存放在 /usr/share/man 几乎每个命令都有 man 的“页面” man 页面分组为不同的“章节” 统称为 Linux 手册 man 命令的配置文件：/etc/man.config 或 man_db.conf MANPATH /PATH/TO/SOMEWHERE：指明 man 文件搜索位置 ``man -M /PATH/TO/SOMEWHERE COMMAND`：到指定位置下搜索 COMMAND 命令的手册页并显示 中文 man 需要安装包 man-pages-zh-CN man 章节\n1：用户命令 2：系统调用 3：C 库调用 4：设备文件及特殊文件 5：配置文件格式 6：游戏 7：杂项 8：管理类的命令 9：Linux 内核 API man 帮助段落说明\n帮助手册中的段落说明\nNAME 名称及简要说明 SYNOPSIS 用法格式说明 [] 可选内容 \u003c\u003e 必选内容 a|b 二选一 {} 分组 ... 同一内容可出现多次 DESCRIPTION 详细说明 OPTIONS 选项说明 EXAMPLES 示例 FILES 相关文件 AUTHOR 作者 COPYRIGHT 版本信息 REPORTING BUGS bug 信息 SEE ALSO 其他帮助参考 man 帮助\n查看 man 手册页 man [章节] keyword 列出所有帮助 man -a keyword 搜索 man 手册 man -k keyword 从 whatis 数据库中查询所有包含 keyword 的信息 相当于 whatis man -f keyword 打印 man 帮助文档的路径 man -w [章节] keyword man 命令\nman 命令的操作方法：使用 less 命令实现\nspace，Ctrl+v，Ctrl+f，Ctrl+F：下一屏 b，Ctrl+b：上一屏 d，Ctrl+d：下半屏 u，Ctrl+u：上半屏 Enter，Ctrl+N，e，Ctrl+E，j，Ctrl+J：下一行 y，Ctrl+Y，Ctrl+P，k，Ctrl+K：上一行 q：退出 #：跳至第#行 1G：回到文件首部 G：翻至文件尾部 man 搜索\n/KEYWORD\n以 KEYWORD 指定的字符串为关键字，从当前位置向文件尾部搜索；不区分大小写 n：下一个 N：上一个 ?KEYWORD\n以 KEYWORD 指定的字符串为关键字，从当前位置向文件首部搜索；不区分大小写 n：跟搜索命令同方向，下一个 N：跟搜索命令反方向，上一个 info\nman 常用于命令参考，GNU 工具 info 适合通用文档参考 没有参数，列出所有的页面 info 页面的结构就像一个网站 每一页分为“节点” 链接节点之前* info [命令] 导航 info 页面\n方向键，PageUp，PageDown 导航 Tab 移动到下一个链接 b 显示主题目录 Home 显示主题首部 Enter 进入选定连接 n/p/u/l 进入下/前/上一层/最后一个链接 s 文字 文本搜索 q 退出 info 通过本地文档获取帮助\nSystem -\u003e help（CentOS6）\nApplications -\u003e documentation -\u003e help（CentOS7）\n提供的官方使用指南和发行注记 /usr/share/doc 目录\n多数安装了的软件包的子目录，包括了这些软件的相关原理说明 常见文档：README INSTALL CHANGES 不适合其他地方的文档的位置 配置文件范例 HTML/PDF/PS 格式的文档 授权书详情 sosreport\n网站和搜索\nhttp://www.tldp.org http://www.slideshare.net http://www.googe.com Openstack filetype:pdf rhca site:redhat.com/docs bash 的快捷键 Ctrl + l 清屏，相当于 clear 命令 Ctrl + o 执行当前命令，并重新显示本命令 Ctrl + s 阻止屏幕输出，锁定 Ctrl + q 允许屏幕输出 Ctrl + c 终止命令 Ctrl + z 挂起命令 Ctrl + a 光标移动命令行首，相当于 Home Ctrl + e 光标移动到命令行尾，相当于 End Ctrl + f 光标向右移动一个字符 Ctrl + b 光标向左移动一个字符 Alt + f 光标向右移动一个单词尾 Alt + b 光标向左移动一个单词首 Ctrl + x 光标在命令行首和光标之间移动 Ctrl + u 从光标处删除至命令行首 Ctrl + k 从光标处删除至命令行尾 Alt + r 删除当前整行 Ctrl + w 从光标处向左删除至单词首 Alt + d 从光标处向右删除至单词尾 Ctrl + d 删除光标处的一个字符 Ctrl + h 删除光标前的一个字符 Ctrl + y 将删除的字符粘贴至光标后 Alt + c 从光标处开始向右更改为首字母大写的单词 Alt + u 从光标处开始，将右边一个单词更改为大写 Alt + l 从光标处开始，将右边一个单词更改为大写 Ctrl + t 交换光标处和之前的字符位置 Alt + t 交换光标处和之前的单词位置 Alt + n 提示输入指定字符后，重复显示该字符 N 次\n","description":"","tags":["Linux"],"title":"Linux 基本命令","uri":"/posts/linux/%E9%98%BF%E9%87%8C%E4%BA%91linux%E8%BF%90%E7%BB%B4%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/%E9%98%B6%E6%AE%B5%E4%B8%80-linux%E5%85%A5%E9%97%A8/linux-basic-command/"},{"categories":null,"content":"Maven 使用 Profile Profile 简介 在开发过程中，我们的软件会面对不同的运行环境，比如开发环境、测试环境、生产环境，而我们的软件在不同的环境中，有的配置可能会不一样，比如数据源配置、日志文件配置、以及一些软件运行过程中的基本配置，那每次我们将软件部署到不同的环境时，都需要修改相应的配置文件，这样来回修改，很容易出错，而且浪费劳动力。\nmaven 提供了一种方便的解决这种问题的方案，就是 profile 功能。\nprofile 可以让我们定义一系列的配置信息，然后指定其激活条件。这样我们就可以定义多个 profile，然后每个 profile 对应不同的激活条件和配置信息，从而达到不同环境使用不同配置信息的效果。\nprofile 定义的位置 针对于特定项目的 profile 配置我们可以定义在该项目的 pom.xml 中。 针对于特定用户的 profile 配置，我们可以在用户的 settings.xml 文件中定义 profile。该文件在用户家目录下的“.m2”目录下。 全局的 profile 配置。全局的 profile 是定义在 Maven 安装目录下的“conf/settings.xml”文件中的。 pom.xml 方式的使用 在项目的 pom.xml 的 project 标签下添加\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u003cprofiles\u003e \u003c!-- 开发环境 --\u003e \u003cprofile\u003e \u003c!-- 设置 profile 的 id, 可自定义配置 --\u003e \u003cid\u003edev\u003c/id\u003e \u003cactivation\u003e \u003c!-- 默认选中 --\u003e \u003cactiveByDefault\u003etrue\u003c/activeByDefault\u003e \u003c/activation\u003e \u003c/profile\u003e \u003c!-- 测试环境 --\u003e \u003cprofile\u003e \u003cid\u003etest\u003c/id\u003e \u003c/profile\u003e \u003c!-- 生产环境 --\u003e \u003cprofile\u003e \u003cid\u003eprod\u003c/id\u003e \u003c/profile\u003e \u003c/profiles\u003e 该代码添加了三个 profile 选项，默认使用 dev 环境。\n从 IDEA 中可以看到:\nprofile 中的标签 在每个 \u003cprofile\u003e 标签中可以添加以下标签\n在 \u003cproject\u003e 标签中可以添加以下标签\n两者做对比，会发现有部分重复的标签，这些标签都可以定义在 \u003cprofile\u003e 标签中，根据不同的运行环境，使得某些属性生效。\nProfile 的用处 结合 SpringBoot 的 profile 功能优化配置方式 SpringBoot 配置文件的目录结构 在 resources 目录下创建了 3 个文件夹 dev、prod、test，并在每个文件夹中创建对应的 application.properties 和 application-{profile}.properties 文件，在每个 application.properties 中都包含 spring.profiles.active={profile}\n在 pom.xml 中添加 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-maven-plugin\u003c/artifactId\u003e \u003cexecutions\u003e \u003cexecution\u003e \u003cgoals\u003e \u003cgoal\u003erepackage\u003c/goal\u003e \u003c/goals\u003e \u003c/execution\u003e \u003c/executions\u003e \u003cconfiguration\u003e \u003cexecutable\u003etrue\u003c/executable\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003cresources\u003e \u003cresource\u003e \u003cdirectory\u003esrc/main/resources/\u003c/directory\u003e \u003c!-- 打包时先排除掉三个文件夹 --\u003e \u003cexcludes\u003e \u003cexclude\u003edev/*\u003c/exclude\u003e \u003cexclude\u003eprod/*\u003c/exclude\u003e \u003cexclude\u003etest/*\u003c/exclude\u003e \u003c/excludes\u003e \u003cincludes\u003e \u003c!-- 如果有其他定义通用文件，需要包含进来 --\u003e \u003c!--\u003cinclude\u003emessages/*\u003c/include\u003e--\u003e \u003c/includes\u003e \u003c/resource\u003e \u003cresource\u003e \u003c!-- 这里是关键! 根据不同的环境，把对应文件夹里的配置文件打包 --\u003e \u003cdirectory\u003esrc/main/resources/${profiles.active}\u003c/directory\u003e \u003c/resource\u003e \u003c/resources\u003e \u003c/build\u003e \u003cprofiles\u003e \u003c!-- 开发环境 --\u003e \u003cprofile\u003e \u003cid\u003edev\u003c/id\u003e \u003cactivation\u003e \u003c!-- 默认选中 --\u003e \u003cactiveByDefault\u003etrue\u003c/activeByDefault\u003e \u003c/activation\u003e \u003cproperties\u003e \u003c!-- 添加了一个自定义的属性，用来根据不同的环境使用不同文件夹中的配置文件 --\u003e \u003cprofiles.active\u003edev\u003c/profiles.active\u003e \u003c/properties\u003e \u003c/profile\u003e \u003c!-- 测试环境 --\u003e \u003cprofile\u003e \u003cid\u003etest\u003c/id\u003e \u003cproperties\u003e \u003cprofiles.active\u003etest\u003c/profiles.active\u003e \u003c/properties\u003e \u003c/profile\u003e \u003c!-- 生产环境 --\u003e \u003cprofile\u003e \u003cid\u003eprod\u003c/id\u003e \u003cproperties\u003e \u003cprofiles.active\u003eprod\u003c/profiles.active\u003e \u003c/properties\u003e \u003c/profile\u003e \u003c/profiles\u003e 此时，根据不同的运行环境，maven 会将对应的配置文件打到包中，不需要对配置文件进行任何修改。\n打包 选中 prod，执行 package，可见打包了 prod 文件夹下的 application.properties 和 application-prod.properties 配置文件。\n参考文档 maven（三）最详细的 profile 的使用 maven profile 动态选择配置文件 ","description":"","tags":["Maven","Java"],"title":"maven 使用 profile","uri":"/posts/java/maven-profile/"},{"categories":null,"content":"用户，组和权限 本章内容 解释 Linux 的安全模型 解释用户帐号和组群帐号的目的 用户和组管理命令 理解并设置文件权限 默认权限 特殊权限 ACL 介绍安全 3A 资源分派：\nAuthentication：认证 Authorization：授权 Accounting|Audition：审计 用户 user 令牌 token，identity Linux 用户：Username/UID 管理员：root，0 普通用户：1-60000 自动分配 系统用户：1-499，1-999（CentOS7）\n对守护进程获取资源进行权限分配\n登录用户：500+，1000+（CentOS7）\n交互式登录\n组 group Linux 组：Groupname/GID\n管理员组：root，0\n普通组：\n系统组：1-499，1-999（CentOS7） 普通组：500+，1000+（CentOS7） 在 Linux 中用户名和组名可以同名，用户 ID 和组 ID 也可以相同\n一个用户可以属于多个组，一个组也可以包含多个用户\n属于多个组的帐号，获得的权限是多个组权限的累加\nWindows 查看用户组：net localgroup Windows 查看用户帐号：net user 在 Windows 中用户名和组名不能同名\n安全上下文 Linux 安全上下文\n运行中的程序：进程（process） 以进程发起者的身份运行： root：/bin/cat mage：/bin/cat 进程所能够访问资源的权限取决于进程的运行者的身份\n组的类别 Linux 组的类别\n用户的主要组（primary group） 用户必须属于一个且只有一个主组 组名同用户名，且仅包含一个用户，私有组 用户的附加组（supplementary group） 一个用户可以属于零个或多个辅助组 当创建新用户时，会自动创建一个与用户名同名的组，作为该用户的主要组\nWindows 中创建新用户时，会默认将用户添加到 users 组中，不会创建新组\n使用 id 用户名 查看该用户的 uid，gid，groups\n用户和组的配置文件 Linux 用户和组的配置文件\n/etc/passwd：用户及其属性信息（名称，UID，主组 ID 等）\n1 2 3 4 5 6 7 8 root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin ... wang:x:1000:1000::/home/wang:/bin/bash 格式： username:password:UID:GID:GECOS:directory:shell 用户名：密码：用户 ID:主组 ID:用户描述：家目录: 修改用户描述可以使用 chfn 用户名，使用 finger 用户名 查看，使用 chfn -f '' -o '' -p '' -h '' 用户名 清空用户描述\n使用 usermod 可以修改用户的各种属性，例如家目录等\n如果 shell 为 nologin，说明该用户不能登录，使用 chsh /sbin/nologin 用户名 修改用户 shell 为 /sbin/nologin\n可以使用 getent passwd [用户名 1] [用户名 2] [用户名...] 来查看所有或指定用户名的信息，类似于 cat /etc/passwd\n可通过修改该文件中的 UID 来更改用户的权限，如果没有 UID 为 0 的用户，系统启动时会卡住，可通过如下方式解决\n在如下页面 根据提示输入 e，在 linux16 的后方添加 init=/bin/bash 按 Ctrl+x 启动 此时可以进入命令行模式\n使用 mount -o rw.remount / 将根目录重新挂载为可读可写模式\n修改 /etc/passwd 文件，Ctrl+x 保存，reboot 重启即可\n/etc/group：组及其属性信息\n1 2 3 4 5 6 7 root:x:0: bin:x:1: ... wang:x:1000: 格式: 组名称：组密码：组 ID:组成员 管理员将指定用户添加到指定组中 groupmems -a 用户名 -g 组名 管理员将指定用户从指定组中删除 groupmems -d 用户名 -g 组名\n普通用户使用 newgrp 组名 将本用户添加到指定组，并临时将指定组作为该用户的主组，此时需要使用到组密码\n管理员使用 gpasswd 组名 给指定组添加密码\n管理员将某个用户添加到指定组后，该用户如果正在使用，则需要重新登录才能显示已在该组中，因为用户是在登录时获取令牌的。\n清空指定组的口令 gpasswd -r 组名\n/etc/shadow：用户密码及其相关属性\n1 2 3 4 5 6 7 8 9 root:$6$5bHCOKlltInipu7D$NmY1mZI3MAGIAznrPa6yqmzLVuTWr2od0PSDWCg4zGtdFd4xJEYeypkv2JtLBbnquig1b1RC9Lk5hetNP5N1r/::0:99999:7::: 格式: login name:encrypted password:date of last password change:minimum password age:maximum password age:password warning period:password inactivity period:account expiration date:reserved field 用户名：加密后的密码：最后一次修改密码距离 1970/01/01 的天数：密码在过几天可以被变更：密码再过几天必须被变更：密码过期前几天系统提醒用户：密码过期几天后帐号被锁定：帐号有效期：预留字段 加密后的密码：$6$5bHCOKlltInipu7D$NmY1mZI3MAGIAznrPa6yqmzLVuTWr2od0PSDWCg4zGtdFd4xJEYeypkv2JtLBbnquig1b1RC9Lk5hetNP5N1r/ 其中$6 代表使用 sha512 的加密算法加密，$1 代表使用 md5 加密算法加密 可以使用 grub-md5-crypt 来获取使用 md5 加密后的字符串\ngetent shadow [用户名 1] [用户名 2] [用户名...] 来查看指定用户的口令信息\nWindows 使用 net accounts 可以查看密码有效期等信息\n使用 chage 用户名 来修改用户口令的信息，直接编辑文件不安全，使用 chage -d0 用户名，使得该用户下次登录必须立即更改口令\n/etc/gshadow：组密码及其相关属性\n1 2 3 4 5 6 7 root::: bin::: ... wang:!:: 格式： 组名：加密后的组密码：当前组的管理员：组成员 使用 pwunconv 可以将口令（密码）放回到 /etc/passwd 中，pwconv 将口令还原到 /etc/shadow 中。\n! 代表禁用/锁定，相当于没有密码\n可以使用 getent 来查看 passwd，shadow，group，gshadow 中的内容。\n密码加密 当前使用的加密算法信息保存在 /etc/login.defs 文件中\n加密机制 加密：明文 --\u003e 密文 解密：密文 --\u003e 明文 单向加密：哈希算法，原文不同，密文必不同 相同算法定长输出，获得密文不可逆推出原始数据 雪崩效应：初始条件的微小改变，引起结果的巨大改变 md5：message digest，128bit sha1：secure hash algorithm，160bit sha224：224bit sha256：256bit sha384：384bit sha512：512bit 更改加密算法： 1 authconfig --passalgo=sha256 --update 只会对以后添加的用户生效，对之前的用户不产生影响。 密码的复杂性策略 使用数字，大写字母，小写字母及特殊字符中至少 3 种 足够长 使用随机密码 定期更换，不要使用最近曾经使用过得密码 使用 openssl rand -base64 12 生成随机密码\n文件操作 使用工具来对用户和组进行修改\nvipw 和 vigr\nvipw：相当于 vi /etc/pwsswd vigr：相当于 vi /etc/group pwck 和 grpck\npwck：passwd checked 检查 /etc/passwd 的文件格式是否正确 grpck：group checked 检查 /etc/group 文件格式是否正确 用户和组的管理命令 用户管理命令 /ect/login.defs 文件中存储着新建用户的默认配置信息等。\nuseradd 默认值设定在 /etc/default/useradd 文件中\n# useradd defaults file GROUP=100 # 默认组 ID HOME=/home # 默认家目录 INACTIVE=-1 # 如果口令过期，是否锁定帐号 EXPIRE= # 锁定有效期 SHELL=/bin/bash # 默认 shell 类型 SKEL=/etc/skel # 用户家目录的模板文件夹 CREATE_MAIL_SPOOL=yes # 显示默认设置 useradd -D 修改默认配置 useradd -D -s SHELL useradd -D -b BASE_DIR useradd -D -g GROUP 创建新用户 useradd [OPTIONS] 用户名\n-u UID：指定 UID -o：配合 -u 选项，忽略 UID 唯一性检查，UID 相同，权限相同 -d HOME_DIR：指定家目录，会自动创建 -r：创建系统用户（CentOS7 中 UID 小于 1000），不会创建家目录 -s SHELL：指定 shell 类型，系统用户建议设置为 /sbin/nologin -c \"COMMENT\"：添加描述 -g GID：指定主组，不创建同名组 -G GROUP1[,GROUP2,...]：指定附加组 -N：将 users 设置为新用户的主组 -m：创建家目录，用于系统用户 -M：不创建家目录，用于非系统用户 将 shell 类型设置为 /sbin/nologin，该用户不可登录也不能通过 su 用户名 切换，如果只指定 -r 选项，不指定 -s 为 /sbin/nologin，则可以通过 su 命令切换到该用户。\ngroups 用户名 查看用户所属的所有组，第一个为主组\n练习\n创建用户 gentoo，附加组为 bin 和 root，默认 shell 为 /bin/csh，注释信息为 \"Gentoo Distribution\"\n1 useradd -G bin,root -s /bin/csh -c \"Gentoo Distribution\" gentoo 创建下面的用户，组和组成员关系\n名字为 webs 的组\n1 groupadd webs 用户 nginx 使用 webs 作为附属组\n1 useradd -G webs nginx 用户 varnish，也使用 webs 作为附属组\n1 useradd -G webs varnish 用户 mysql，不可交互登录系统，且不是 webs 的成员，nginx，varnish，mysql 密码都是 123456\n1 2 3 4 useradd -s /sbin/nologin mysql echo 123456 | passwd --stdin nginx echo 123456 | passwd --stdin varnish echo 123456 | passwd --stdin mysql 新建用户的相关文件和命令\n/etc/default/useradd /etc/skel/* /etc/login.defs newusers 与 passwd 格式相同的文件：批量创建用户 chpasswd：批量修改用户口令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # chpasswd user1:password1 user2:password2 或 # echo user1:password1 | chpasswd 或 在文本文件（例如：file）中存储如下格式的内容 user1:password1 user2:password2 # cat file | chpasswd usermod 修改用户属性 usermod [OPTION] 用户名\n-u UID：新 UID -g GID：新 GID -G GROUP1[,GROUP2,...]：新附加组，原来的附加组将会被覆盖；若保留原有，则需要同时使用 -a 选项 -s SHELL：新的默认 SHELL -c \"COMMENT\"：新的注释信息 -d HOME：新家目录不会自动创建；若要创建新家目录并移动原家数据，同时使用 -m 选项 -l login_name：修改用户登录名 -L：锁定指定用户，在 /etc/shadow 密码栏增加! -U：解锁指定用户，将 /etc/shadow 密码栏的!拿掉 -e YYYY-MM-DD：指明用户帐号过期日期 -f INACTIVE：设定非活动期限 清空附加组\n1 2 3 usermod -G \"\" 用户名 或 usermod -G 用户主组 用户名 密码处的 !! 代表锁定，redhat5 版本之前可以使用 usermod -U 将用户密码解锁，如果用户密码为空，则不使用密码即可登录系统。\nuserdel 删除用户 userdel [OPTION]... 用户名\n-r：删除用户相关文件\n1 2 3 例如： 家目录：/home/用户名 邮箱目录：/var/spool/mail/用户名 组帐号维护命令 groupadd 创建组：groupadd [OPTION]... group_name\n-g GID：指明 GID 号; [GID_MIN,GID_MAX]\n-r：创建系统组\nCentOS6：GID\u003c500\nCentOS7：GID\u003c1000\ngroupmod 组属性修改：groupmod [OPTION]... group\n-n group_name：新名字 -g GID：新的 GID groupdel 删除组：groupdel GROUP\n主组不能被删除\n查看用户相关的 ID 信息 id [OPTION]... [USER]\n-u：显示 UID -g：显示 GID -G：显示用户所属的组的 ID -n：显示名称，需配合 ugG 使用 切换用户或以其他用户身份执行命令 su：switch user\n命令： 1 su [OPTIONS...] [-] [user [agrs...]] 切换用户的方式 su UserName：非登录式切换，即不会读取目标用户的配置文件，不改变当前工作目录 su - UserName：登录式切换，会读取目标用户的配置文件，切换至家目录，完全切换 root su 至其他用户无须密码；非 root 用户切换时需要密码 换个身份执行命令 1 su [-] UserName -c 'COMMAND' 选项：-l --login 1 su -l UserName 相当于 su - UserName 设置密码 修改指定用户的密码：passwd [OPTION] UserName\n-d：删除指定用户密码 -l：锁定指定用户 -u：解锁指定用户 -e：强制用户下次登录修改密码 -f：强制操作 -n mindays：指定最短使用期限 -x maxdays：指定最大使用期限 -w warndays：提前多少天开始警告 -i inactivedays：非活动期限 --stdin：从标准输入接收用户密码 1 echo \"PASSWORD\" | passwd --stdin USERNAME 修改用户密码策略 命令：chage [OPTION]... 用户名\n-d LAST_DAY -E --expiredate EXPIRE_DATE -I --inactive INACTIVE -m --mindays MIN_DAYS -M --maxdays MAX_DAYS -W --warndays WARN_DAYS -l 显示密码策略 示例：\n1 2 3 chage -d 0 tom 下次登录强制重设密码 chage -m 0 -M 42 -W 14 -l 7 tom chage -E 2016-09-10 tom 用户相关的其他命令 chfn 指定个人信息 chsh 指定 shell finger 查看个人信息 更改组密码 组密码：gpasswd [OPTION] GROUP\n-a user：将 user 添加到指定组中 -d user：从指定组中移除用户 user -A user1,user2,... 设置有管理权限的用户列表 临时切换主组：newgrp 组名\n如果用户本不属于此组，则需要组密码\n更改和查看组成员 groupmems [OPTIONS] [ACIONS]\nOPTIONS： -g, --group groupname：更改为指定组（只有 root） ACTIONS： -a, --add username：指定用户加入组 -d, --delete username：从组中删除用户 -p, --purge：从组中清除所有成员 -l, --list：显示组成员列表 显示用户所属组列表：groups [OPTION]... [USERNAME]...\n文件属性 文件属性操作 设置文件的所有者：\n格式： 1 2 chown [OPTION]... [OWNER][:[GROUP]] FILE... chown [OPTION]... --reference=RFILE FILE... 选项： -R：递归 示例： 1 2 3 chown wang xxx.txt 将 xxx.txt 的所有者设置为 wang 用户 chown wang:root xxx.txt 将 xxx.txt 的所有者设置为wang用户，所属组设置为 root chown --reference=/etc/passwd xxx.txt 将 xxx.txt 的所有者和所属组修改为与 /etc/passwd 一样 设置文件的所属组信息：\n格式： 1 2 chgrp [OPTION]... GROUP FILE... chgrp [OPTION]... --reference=RFILE FILE... 选项： -R：递归 示例： 1 2 chgrp wang xxx.txt 将 xxx.txt 的所属组设置为 wang chgrp --reference=/etc/passwd xxx.txt 将 xxx.txt 的所属组修改为与 /etc/passwd 一样 文件权限 文件权限 文件的权限主要针对三类对象进行定义 owner：所有者，u group：所属组，g other：其他，o 每个文件针对每类访问者都定义了三种权限 r：Readable，可读 w：Writable，可写 x：eXcutable，可执行 文件的权限 r：read，读，可使用文件查看类工具获取其内容 w：write，写，可修改其内容 x：excute，可执行，可以把此文件提请内核启动为一个进程 目录的权限 r：read，读，可是使用 ls 查看此目录中文件列表 w：write，写，可以对目录下的文件进行增删（必须同时有 x 权限） x：excute，可执行，可以使用 ls -l 查看此目录中文件元数据（须配合 r），可以 cd 进入此目录 X：只给目录 x 权限，不给文件 x 权限 八进制数字 字母表示 二进制数字 八进制数字 --- 000 0 --x 001 1 -w- 010 2 -wx 011 3 r-- 100 4 r-x 101 5 rw- 110 6 rwx 111 7 示例：\n1 2 3 640 : rw-r----- 755 : rwxr-xr-x 777 : rwxrwxrwx 修改文件权限 文件权限（rwx|X）\n此处的 X 表示，只对目录和包含执行权限的文件赋予可执行（x）权限\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [root@localhost ~]# ll data total 0 -rw-r--r--. 1 root root 0 Feb 6 22:04 aaa -rwxr--r--. 1 root root 0 Feb 6 22:04 bbb drwxr-xr-x. 2 root root 6 Feb 6 22:04 ccc drw-r--r--. 2 root root 6 Feb 6 22:04 ddd [root@localhost ~]# chmod -R a=rwX data [root@localhost ~]# ll data total 0 -rw-rw-rw-. 1 root root 0 Feb 6 22:04 aaa -rwxrwxrwx. 1 root root 0 Feb 6 22:04 bbb drwxrwxrwx. 2 root root 6 Feb 6 22:04 ccc drwxrwxrwx. 2 root root 6 Feb 6 22:04 ddd aaa 文件不包含 x 权限，所以执行命令后依旧没有 x 权限 bbb 文件在包含可执行权限，所以执行命令后包含可执行权限 ccc 和 ddd 是目录，所以执行命令后，均包含可执行权限 命令格式：\n语法：chmod [OPTION]... MODE[,MODE]... FILE...\n选项：\n-R：递归修改权限 MODE：\n修改一类用户的所有权限 1 2 3 4 5 u=：所有者 g=：所属组用户 o=：其他用户 a=：所有用户 ug=：所有者和所属组 修改一类用户某位或某些位权限 1 2 3 4 5 u+ u-：为所有者增加或删除某个或某些权限 g+ g-：为所属组用户增加或删除某个或某些权限 o+ o-：为其他用户增加或删除某个或某些权限 a+ a-：为所有用户增加或删除某个或某些权限 + -：为所有用户增加或删除某个或某些权限 chmod [OPTION]... OCTAL-MODE FILE...\n使用数字的方式修改文件的权限 chmod [OPTION]... --reference=RFILE FILE...\n参考 RFILE 文件的权限，将 FILE 的权限修改为同 RFILE 一样 对文件进行读/写/执行操作时，权限的匹配顺序是 所有者权限 -\u003e 所属组权限 -\u003e 其他用户权限，一旦匹配成功，则不像下一级进行匹配\n1 2 3 4 5 6 7 8 -----w-rw-. 1 wang duan 0 Feb 6 22:04 aaa wang 用户对 aaa 文件不能读/写/执行 属于duan组的用户只能对aaa进行写 其他用户可以对该文件进行读写 duan用户属于duan组，则duan用户只能对aaa进行写操作 wang用户可以使用chmod修改该文件的权限 可以只有写权限，没有读权限，通过 echo xxx \u003e\u003e file 向 file 中追加 xxx\n如果要删除文件，必须对文件所在目录有写权限\nroot 用户没有读写权限也可以读写，root 用户没有执行权限也不能执行\n默认权限设置 新建文件的最大权限为 666，为了防止新建的文件带有可执行权限，新建文件夹的最大权限为 777\numask + 默认权限 = 最大权限\n底层计算方法\n1 2 3 4 5 6 7 8 9 10 umask 为123，创建文件，计算文件的默认权限 文件的最大权限 666： 110110110 umask 为 321： 101010001 ----------- 666-321=234，真实结果为：010100110 -\u003e 246 由上，默认权限为246 umask 为 1 的位会遮掩原来的值，变为为 0，umask 为 0的位，结果不变。 umask 值 可以用来保存新建文件或目录时的默认权限\n新建 FILE 权限：666-umask\n如果所得结果某位存在执行（奇数）权限，则将其权限 +1\n新建 DIR 权限：777-umask\n非特权用户 umask 默认是 002\nroot 的 umask 默认是 022\n查看 umask：umask\n设置 umask：umask [-p] [-S] [mode]\n1 2 3 示例： umask 002 umask u=rw g=r o= 模式方式显示：umask -S\n使用字母的方式，显示新建文件夹的默认权限\n输出可被调用：umask -p\n输出：umask 0102\n可将其直接重定向到配置文件中：umask -p \u003e\u003e ~/.bashrc\n全局配置文件：/etc/bashrc\n1 2 3 4 5 if [ $UID -gt 199 ] \u0026\u0026 [ \"`/usr/bin/id -gn`\" = \"`/usr/bin/id -un`\" ]; then umask 002 else umask 022 fi 用户配置文件：~/.bashrc\n权限相关练习 当用户 docker 对 /testdir 目录无执行权限时，意味着无法做哪些操作\n无法cd，如果有读权限可以使用ll查看文件\n当用户 mongodb 对 /testdir 目录无读取权限时，意味着无法做哪些操作\n当用户 redis 对 /testdir 目录无写权限时，该目录下的只读文件 file1 是否可以修改和删除\n当用户 zabbix 对 /testdir 目录有写和执行权限时，该目录下的只读文件 file1 是否可修改和删除\n复制 /etc/fstab 文件到 /var/tmp 下，设置文件所有者为 tomcat 读写权限，所属组为 apps 组有读写权限，其他人无权限\n无删除了用户 git 的家目录，请重新创建并恢复该家目录及相应权限属性\n程序运行说明\n安全上下文\n前提：进程有属主和属组; 文件有属主和属组\n任何一个可执行程序文件能不能启动为进程，取决于发起者对程序文件是否拥有执行权限 启动为进程后，其进程的属主为发起者，进程的属组为发起者所属的组 进程访问文件时的权限，取决于进程的发起者 进程的发起者，同文件的属主：则应用文件属主权限 进程的发起者，属于文件属组：则应用文件属组权限 应用文件“其他”权限 Linux文件系统上的特殊权限 三种特殊权限 SUID：一个二进制程序包含 SUID，则任何用户执行时都会继承该二进制程序所有者的身份，获得它的权限 作用目标：\n仅二进制程序 位置：user，占据属主的执行权限位\ns：属主拥有x权限 S：属主没有x权限 场景：普通用户无法修改 /etc/shadow文件，却可以使用 passwd 命令修改自己的密码，对 /etc/shadow 文件造成修改。\n原因：因为 passwd 程序包含 SUID 权限\n1 2 [root@localhost ~]# ll /usr/bin/passwd -rwsr-xr-x. 1 root root 27856 Aug 9 09:39 /usr/bin/passwd 注意所属用户的执行权限 x 变为了 s，代表具有 SUID 权限。带有 SUID 权限的程序，任何用户在执行时，都会继承该二进制程序所有者的身份，passwd 程序的所有者为 root，对 /etc/passwd 可以读写，因此其他用户可以使用 passwd 程序对 passwd 文件进行修改。\n添加和删除 SUID 权限\n1 2 3 4 5 6 添加SUID权限 chmod u+s /bin/cat chmod 4755 /bin/cat # 4 代表添加 suid 权限 删除SUID权限 chmod u-s /bin/cat chmod 755 /bin/cat 其他说明\n1 2 3 4 5 6 7 8 9 10 11 12 [root@localhost ~]# ll /bin/cat -rwxr-xr-x. 1 root root 54080 Aug 20 14:25 /bin/cat # 为 cat 程序添加 SUID 权限 [root@localhost ~]# chmod u+s /bin/cat [root@localhost ~]# ll /bin/cat -rwsr-xr-x. 1 root root 54080 Aug 20 14:25 /bin/cat # 删除cat程序的可执行x权限 [root@localhost ~]# chmod u-x /bin/cat # 会发现 s 变为了 S，此时 root 用户不具备可执行权限 [root@localhost ~]# ll /bin/cat -rwSr-xr-x. 1 root root 54080 Aug 20 14:25 /bin/cat 而 root 用户依旧可以使用 cat 命令查看 /etc/passwd，是因为 root 用户在 root 组中，root 组具备 cat 程序的执行权限 SGID： 位置：group，占据属组的执行权限位\ns：group拥有x权限 S：group没有x权限 作用目标：\n二进制程序\n一个二进制程序包含 SGID，则任何用户执行时都会继承该二进制程序所属组的身份，获得所属组权限\n文件夹\n默认情况下，用户创建文件时，其属组为此用户所属的主组，一旦某目录设定了 SGID 权限，则对此目录有写权限的用户在此目录中创建的文件所属的组为此目录的所属组\n使用场景：通常用于创建一个协作目录\nwang 用户和 duan 用户在做同一个项目，项目文件均放在 web 目录下，两用户均需要对 web 目录下的文件进行修改，此时可以创建一个 web 组，将 wang 和 duan 均加入该组，修改 web 目录数据 web 组，对其设置 SGID，此时，wang 和 duan创建的文件默认所属组均会变为 web，则两用户均可以通过组权限对对方的文件进行修改。\n添加和删除 SUID 权限\n1 2 3 4 5 6 添加SGID权限 chmod g+s /bin/cat chmod 2755 /bin/cat # 2 代表添加 sgid 权限 删除SGID权限 chmod g-s /bin/cat chmod 755 /bin/cat chmod 6755 /bin/cat，6 代表添加 SUID 和 SGID 权限。\nSticky：对目录具有写权限的用户，通常可以删除该目录中的任何文件，无论该文件的权限或拥有权。在目录设置 Sticky 位，只有文件的所有者或root 可以删除该文件。Sticky 设置在文件上无意义 作用目标：\n仅文件夹 位置：other，占据 other 的执行权限位\nt：other 拥有 x 权限 T：other 没有 x 权限 示例：\n1 2 [root@localhost data]# ll -d /tmp drwxrwxrwt. 8 root root 211 Feb 7 11:16 /tmp 添加和删除 Sticky 权限\n1 2 3 4 5 6 添加 Sticky 权限 chmod o+t ~/data # t 代表 Sticky 权限 chmod 1777 ~/data # 1 代表 Sticky 权限 删除 Sticky 权限 chmod o-t ~/data chmod 777 ~/data 特殊权限数字法 SUID SGID STICKY 八进制和 0 0 0 0 0 0 1 1 0 1 0 2 0 1 1 3 1 0 0 4 1 0 1 5 1 1 0 6 1 1 1 7 示例 :\nchmod 4777 /tmp/a.txt 设定文件特定属性 该属性属于扩展属性，存储在元数据中\nchattr +i filename : 不能删除，改名，更改\nchattr +a filename : 只能追加内容\nlsattr filename : 显示特定属性\n1 2 [root@localhost webdir]# lsattr wang1 ----i----------- wang1 chattr -i filename : 删除i属性\nchattr -a filename : 删除a属性\n该操作对 root 帐号也会生效\n访问控制列表 因为普通的权限设置只能对所属者，所属组，其他用户进行权限设置，无法细粒度的进行权限控制，例如对 tom 用户设置特定不同于 other 用户的权限，这是做不到的，所以引入了访问控制列表技术。\n访问控制列表 : ACL，Access Control List，实现灵活的权限管理\n除了文件的所有者，所属组和其他人，可以对更多的用户设置权限\nCentOS7 默认创建的 xfs 和 ext4 文件系统具有 ACL 功能\n1 2 查看文件系统格式 df -T CentOS7 之前版本，默认手工创建的 ext4 文件系统无 ACL 功能，需手动地添加\n1 2 tune2fs -o acl /dev/sdb1 mount -o acl /dev/sdb1 /mnt/test 查看分区是否支持 ACL 权限\n1 2 tune2fs -l /dev/sda1 # 只对 ext 系列生效 查看文件是否包含 ACL 权限\n1 2 [root@localhost data]# ll f1 -rw-r--r--+ 1 root root 0 Feb 7 22:40 f1 + 号代表该文件包含 ACL 权限\nACL 相关命令\n查看 ACL 权限信息（get file access control list）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Usage: getfacl [-aceEsRLPtpndvh] file ... -a, --access display the file access control list only -d, --default display the default access control list only -c, --omit-header do not display the comment header -e, --all-effective print all effective rights -E, --no-effective print no effective rights -s, --skip-base skip files that only have the base entries -R, --recursive recurse into subdirectories -L, --logical logical walk, follow symbolic links -P, --physical physical walk, do not follow symbolic links -t, --tabular use tabular output format -n, --numeric print numeric user/group identifiers -p, --absolute-names don't strip leading '/' in pathnames -v, --version print version and exit -h, --help this help text 设置 ACL 权限（set file access control list）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Usage: setfacl [-bkndRLP] { -m|-M|-x|-X ... } file ... -m, --modify=acl modify the current ACL(s) of file(s) -M, --modify-file=file read ACL entries to modify from file -x, --remove=acl remove entries from the ACL(s) of file(s) -X, --remove-file=file read ACL entries to remove from file -b, --remove-all remove all extended ACL entries -k, --remove-default remove the default ACL --set=acl set the ACL of file(s), replacing the current ACL --set-file=file read ACL entries to set from file --mask do recalculate the effective rights mask -n, --no-mask don't recalculate the effective rights mask -d, --default operations apply to the default ACL -R, --recursive recurse into subdirectories -L, --logical logical walk, follow symbolic links -P, --physical physical walk, do not follow symbolic links --restore=file restore ACLs (inverse of `getfacl -R') --test test mode (ACLs are not modified) -v, --version print version and exit -h, --help this help text base ACL 不能删除\ngetfacl file1 | setfacl --set-file=- file2 : 赋值 file1 的 ACL 权限给 file2\nACL 权限显示说明\n1 2 3 4 5 6 7 8 9 10 [root@localhost data]# getfacl f1 # file: f1 文件名 # owner: root 属主 # group: root 属组 user::rw- 属主权限 user:wang:rwx wang用户的权限 group::r-- 属组权限 group:duan:rw- duan组的权限 mask::r-- 对应ll时，显示的组权限 other::r-- 其他用户的权限 ACL 生效顺序 : 所有者，自定义用户，自定义组，其他人\n当一个用户属于多个自定义组，会具有多个自定义组的权限\n为多用户或者组的文件和目录赋予访问权限 rwx\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 mount -o acl /directory # 查看 file|directory 的 ACL 权限 getfacl file|directory # 给 file|directory 添加 wang 用户的 rwx 权限 setfacl -m u:wang:rwx file|directory # 给 directory 递归添加 sales 组的 rwX 权限 setfacl -Rm g:sales:rwX directory # 使用 file.acl 为 file|directory 赋予批量权限 setfacl -M file.acl file|directory # 给 file|directory 添加 salesgroup 组的 rw 权限 setfacl -m g:salesgroup:rw file|directory # d，default: 设置以后在 directory 中新建的文件/目录都具有 u:wang:rx 的 acl 权限 setfacl -m d:u:wang:rx directory # 删除 file|directory 对 wang 用户的 ACL 权限 setfacl -x u:wang file|directory # 对 directory 批量删除 file.acl 文件中记录的 ACL 权限 setfacl -X file.acl directory ACL 文件上的 group 权限是 mask 值（自定义用户，自定义组，拥有组的最大权限），而非传统的组权限\n如果使用了 ACL 权限，则会将 ll file 显示的传统属组权限修改为 ACL 权限中的 mask 值，此时使用 chmod g=rw file 修改的是 ACL 权限中的 mask 值，也可以通过 setfacl -m mask::rw file 来修改 ACL 权限中的 mask 值。\nmask 值代表了所有 ACL 权限的最高权限，即，如果 mask::r，那么所有 ACL 权限都只能读，不能写和执行，效果如下方两处 #effective:r--\n1 2 3 4 5 6 7 8 9 10 11 [root@localhost data]# setfacl -m mask::r f1 [root@localhost data]# getfacl f1 # file: f1 # owner: root # group: root user::rw- user:wang:rwx\t#effective:r-- group::rw-\t#effective:r-- group:duan:rw-\t#effective:r-- mask::r-- other::r-- mask 只影响除所有者和 other 之外的人和组的最大权限，mask需要与用户的权限进行逻辑与运算后，才能变成有限的权限（Effective Permission） 用户或组的设置必须存在于mask权限设定范围内才会生效\n--set 选项会把原有的 ACL 项都删除，用新的替代，需要注意的是一定要包含 UGO 的设置，不能像 -m 一样只是添加 ACL 就可以\n1 2 示例 : setfacl --set u::rw,u:wang:rw,g::r,o::- file1 备份和恢复 ACL\n主要的文件操作命令 cp 和 mv 都支持 ACL，知识 cp 命令需要加上 -p 参数。但是 tar 等常见的备份工具是不会保留目录和文件的 ACL 信息。\n1 2 3 4 5 6 7 8 9 10 # 递归 /tmp/dir1 目录，将 ACL 信息保存到 acl.txt 文件中 getfacl -R /tmp/dir1 \u003e acl.txt # 递归还原 /tmp/dir1 目录的 ACL 信息 setfacl -R -b /tmp/dir1 # 递归 /tmp/dir1 目录，恢复 acl.txt 中的 ACL 信息 setfacl -R --set-file=acl.txt /tmp/dir1 # 还原 acl.txt 中记录的 ACL 信息 setfacl --restore acl.txt # getfacl -R /tmp/dir1 ","description":"","tags":["Linux"],"title":"用户，组和权限","uri":"/posts/linux/%E9%98%BF%E9%87%8C%E4%BA%91linux%E8%BF%90%E7%BB%B4%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/%E9%98%B6%E6%AE%B5%E4%B8%80-linux%E5%85%A5%E9%97%A8/linux-user-group-permission/"},{"categories":null,"content":"阿里云 Linux 运维学习路线目录 阶段一: Linux 入门 计算机基础 Linux 系统安装与基本操作 Linux 基本命令 文件管理 用户，组和权限 Linux 文本处理\u0026正则表达式\u0026VIM 阶段二：网络基础 计算机网络基础 进阶-TCP/IP 协议及 OSI 七层模型 高级-网络管理与配置实战 阶段三: Linux 服务器运维 Linux 服务器运维基本操作 ","description":"","tags":["Linux"],"title":"阿里云 Linux 运维学习路线目录","uri":"/posts/linux/%E9%98%BF%E9%87%8C%E4%BA%91linux%E8%BF%90%E7%BB%B4%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/linux-learn-route-table/"},{"categories":null,"content":"计算机基础 计算机系统由硬件（Hardware）系统和软件（Software）系统两大部分组成\n计算机硬件 计算机（Computer）：俗称电脑，是一种能接收和存储信息，并按照存储在其内部的程序对海量数据进行自动，高速的处理，然后把处理结果输出的现代化智能电子设备\n发展历史 第一代计算机（1946-1957）：电子管时代 第二代计算机（1958-1964）：晶体管时代 第三代计算机（1965-1970）：集成电路时代 第四代计算机（1971 以后）：大规模集成电路时代 世界上第一台计算机 ENIAC 1946 年，世界上第一台计算机 ENIAC（electronic numerical integerator and calculator）在美国宾州大学诞生，是美国奥伯丁武器试验场为了满足计算弹道需要而研制成的。使用了 17468 只电子管，占地 179 平方米，重达 30 吨，耗电 174 千瓦，耗资 40 多万美元。每秒可进行 5000 次加法或减法运算，\n冯诺依曼体系 1946 年数学家冯诺依曼提出，计算机硬件由运算器，控制器，存储器，输入设备和输出设备五大部分组成\n主存储器：运行内存，所有被计算机处理的数据都需要放在主存储器 辅助存储器：硬盘，用来持久化存储数据 运算器：进行加减乘除与或非运算 控制器：协调（指挥）各种设备间通讯\n进制 Linux 中自带 bc 计算器\n1 2 3 4 5 6 7 8 9 10 11 12 # 进入计算器 $ bc # 输出 2 进制，o（output） obase=2 12 1100 # 退出计算器 quit # 设置输入二进制 ibase=2 1100 12 摩尔定律 由英特尔（Intel）创始人之一戈登摩尔于 1965 年提出：\n当价格不变时，集成电路上可容纳的元器件数目，约每隔 18-24 个月便会增加一倍，性能也将提升一倍，\n按规模分类计算机 超级计算机排行\n巨型计算机：应用于国防尖端技术和现代科学计算机中。巨型计算机的运算速度可达每秒百万亿次以上，“天河一号”为我国首台千万亿次级的计算机， 大型计算机：具有较高的运算速度，每秒可以执行几千万条指令，而且有较大的存储空间。往往用与科学计算，数据处理或作为网络服务器使用，如 IBM z13 mainframe 小型计算机：规模较小，结构简单，运行环境要求较低，一般应用于工业自动控制，测量仪器，医疗设备中的数据采集等方面， 微型计算机：中央处理器（CPU）采用微处理芯片，体积小巧轻便，官方用于商业，服务业，工厂的自动控制，办公自动化以及大众化的信息处理 服务器 服务器 Server 是计算机的一种，是网络中客户端计算机提供各种服务的高性能的计算机，服务器在网络操作系统的控制下，将与其连接的硬盘，磁带，打印机及昂贵的专用通讯设备提供给网络上的客户站点共享，也能为网络用户提供集中计算，信息发布及数据管理等服务\n阿里提出的去 IOE：IBM（小型机）, Oracle（数据库）, EMC（存储）\n服务器按应用功能可分为： Web 服务器：apache、nginx 数据库服务器：mysql、oracle 文件服务器：NFS、SAMBA、FTP 中间件应用服务器：Tomcat 日志服务器：RSYSLOG 监控服务器：ZABBIX 程序版本控制服务器：GIT、SVN 虚拟机服务器：KVM、Docker、K8S 邮件服务器：SendMail 打印服务器： 域控制服务器：Domain Controller（DC） 多媒体服务器： 通讯服务器： ERP 服务器等 按外形分类： 塔式 Tower 服务器 刀片式 Blade 服务器 机架式 Rack 服务器 服务器硬件组成 服务器配置示例 CPU: 家用 I 系列，服务器 Xeon 至强系列\n服务器硬件 CPU CPU 是 Central Processing Unit 的缩写，即中央处理器。由控制器和运算器组成，是整个计算机系统中最重要的部分\n服务器 CPU 公司\nIntel\nXeon 智强 Itanium 安腾 AMD\nAlthlon MP IBM\nPower CPU 性能指标\nlinux 使用lscpu查看 cpu 信息\n-主频：主频是 CPU 的始终频率（CPU Clock Speed），是 CPU 运算时的工作的频率（1 秒内发生的同步脉冲数）的简称。单位是 Hz，一般来说，主频越高，CPU 的速度越快，由于内部结构不同，并非所有的时钟频率相同的 CPU 的性能都一样\n外频：系统总线的工作频率，CPU 与外部（主板芯片组）交换数据，指令的工作时钟频率 倍频：倍频指 CPU 外频与主频相差的倍数 三者关系是：主频 = 外频 × 倍频 高速缓存（cache）：高速交换的存储器，CPU 缓存分为一级，二级，三级缓存，即 L1、L2、L3，可将内存中的部分数据缓存到 cache 中，当 CPU 用到这部分数据时，可从 cache 中快速读取，不用去读取内存中的数据（CPU 的速度比内存快得多） 内存总线速度（Memory-Bus Speed）：一般等于 CPU 的外频，指 CPU 与二级缓存（L2）和内存之间的通信速度 地址总线宽度：决定了 CPU 可以访问的物理地址空间，32 位/64 位处理器， CPU 类型\nx86 x64（CISC） ARM（Acorn RISC Machine） m6800，m68k（moto） Power（IBM） Powerpc（apple，ibm，moto） Ultrasparc（Sun） Alpha（HP） 安腾（compaq） 服务器按 CPU 分类\n非 x86 服务器：\n使用 RISC（精简指令集）或 EPIC（并行指令代码）处理器，并且主要采用 UNIX 和其他专用操作系统的服务器，指令系统相对简单，他只要求硬件执行很有限且最常用的那部分指令，CPU 主要有 Compaq 的 Alpha，HP 的 PA_RISC，IBM 的 Power PC，MIPS 的 MIPS 和 SUN 的 Sparc，Intel 研发的 EPIC 安腾处理器等。这种服务器价格昂贵，体系封闭，但是稳定性好，性能强，主要用在金融，电信等大型企业的核心系统，\nx86 服务器：\n又称 CISC（复杂指令集）架构服务器，即通常所讲的 PC 服务器，他是基于 PC 机体系结构，使用 Intel 或其他兼容 x86 指令集的处理器芯片的服务器。目前主要为 intl 的 Xeon E3、E5、E7 系列，价格相对便宜，兼容性好，稳定性较差，安全性不算太高，\n主板（mainboard） 主板（mainboard），系统板（systemboard）或母板（motherboard），安装在机箱内，是计算机最基本的也是最后总要的部件之一\n主板一般为矩形电路板，上面安装了组成计算机的主要电路系统，一般有 BIOS 芯片，I/O 控制芯片，键盘和面板控制开关接口，指示灯插接件，扩展插槽，主板及插卡的直流电源供电接插件等元件\n内存和外存 内存：是介于 CPU 和外部存储之间，是 CPU 对外部存储中程序与数据进行高速运算时存放程序指令，数据和中间结果的临时场所，它的物理实质就是一组具备数据输入输出和数据存储功能的高速集成电路\n内存是 CPU 能直接寻址的存储空间，由半导体器件制成。内存的特点是存取速度快\n外存：硬盘，U 盘，软盘，光盘\n内存和外存的区别：\n内存断电后数据丢失 外存断电后数据可以保存 容量：即该内存的存储容量，单位一般为“MB”或“GB”\n内存带宽：\n内存带宽是指内存与北桥芯片之间的数据传输率\n单通道内存节制器一般都是 64-bit 的，8 个二进制位相当于一字节，换算成字节是 64/8=8，再乘以内存的运行频率，如果是 DDR 内存就要再乘以 2\n计算公式：\n内存带宽 = 内存总线频率 × 数据总线位数/8\n示例：DDR 内存带宽计算\nDDR2 667, 运行频率为 333MHz, 带宽为 333×2×64/8=5400MB/s=5.4GB/s DDR2 800, 运行频率为 600MHz, 带宽为 400×2×64/8=6400MB/s=6.4GB/s 保证内存中数据不丢失的技术：\n在线备用内存技术\n当主内存或者是扩展内存中的内存出现多位错误或者物理内存故障时，服务器仍继续运行 由备用内存接替出现故障内存的工作 备用的内存区域必须比其他区域的内存容量大或相同 内存镜像\n镜像为系统在出现多位错或内存物理故障时提供数据保护功能，以保证呢个系统仍能正常运行 数据同时写入两个镜像的内存区域 从一个区域进行数据的读取 硬盘 机械硬盘 结构 存储介质（Medis）：盘片\n盘片的基板是金属或玻璃材质制成，为达到高密度高稳定的质量，基板要求表面光滑平整，不可有任何瑕疵，\n读与写（Read Write Head）：磁头\n磁头是硬盘读取数据的关键部件，它的主要作用就是将存储在硬盘盘片上的磁信息转化为电信号向外传输\n马达（Spindle Motor\u0026Voice Coil Motor）：\n马达上装有一至多片盘片，以 7200、10000、15000RPM 等定速旋转，为保持其平衡不可抖动，所以其质量要求严谨，不产生高温噪音\n基本参数 容量：\n容量是硬盘最主要的参数。单位有 MB、GB、TB\n转速：\n转速是指硬盘盘片每分钟转动的圈数，单位为 RPM，现在硬盘转速已经达到 10000rpm，15000rpm\n传输速率\n传输速率（Data Transfer Rate），指硬盘速写数据的速度，单位为兆字节每秒（MB/s）\n缓存\n硬盘缓存的目的是为了解决系统前后级读写速度不匹配的问题，以提高硬盘的读写速度\n接口类型 IDE 接口：硬盘接口规范，采用 ATA 技术规范 SCSI 接口：应用于小型机上的高速数据传输技术 SATA 接口：Serial ATA，提高传输速率，支持热插拔 SAS 接口：Serial Attached SCSI，兼容 SATA 目前主流的硬盘接口为 SATA（家用）和 SAS（服务器用）接口\n服务器的性能短板 木桶效应，如果 CPU 每秒处理 1000 个服务请求的能力，各种总线的负载能力达到 500 个，但网卡只能接受 200 个请求，而硬盘只能承担 150 个的话，那么这台服务器的处理能力只能是 150 个请求/秒，有 85%的处理器计算能力浪费了，\n在计算机系统中，硬盘的读写速率已经成为影像系统性能进一步提高的瓶颈，因此可使用固态硬盘提升，\n固态硬盘（SSD） SSD（Solid State Disk）：泛指使用 NAND Flash 组成的固态硬盘。其特别之处在于没有机械结构，以区块写入和抹除的方式作读写的功能，因此在读写的效率上，非常依赖于读写技术上的设计，SSD 读写存取速度快，性能稳定，防震性高，发热低，耐低温，电耗低，无噪音。因为没有机械部分，所以长时间使用出现故障几率也比较小。缺点：价格高，容量小，在普通硬盘前毫无性价比优势\n阵列卡（Raid） 用来实现 RAID 的建立和重建，检测和修复多位错误，错误磁盘自动检测等功能，RAID 芯片使 CPU 的资源得以释放\nRAID 卡作用：\n阵列卡把若干硬盘驱动器按照一定要求组成一个整体，由阵列控制器管理的系统， 阵列卡用来提高磁盘子系统的性能及可靠性 阵列卡参数：\n支持的 RAID 级别 阵列卡缓存 电池保护 电源和风扇 支持服务器的电力负载 支持冗余，防止电源故障 故障预警和防止 故障之前的预防性维护 保证服务器持续运行 电源子系统包括 智能电源和风扇 冗余电源和风扇 显卡 服务器都在主板上集成了显卡，但是显存容量不高，一般为 16M 或 32M，\nGPU：Graphic Processing Unit，即“图形处理器”\n网卡 服务器都在主板上集成了网卡，传输速率为 1Gbps，即千兆网卡，特殊应用需要高端网卡，如光纤网卡，Infiniband 网卡等，传输速率能达到 10Gbps，20Gbps，即万兆网卡，\n1Gbps：1Gbit/second, 1Gbit/8 = 512MB, 512MB/s 热插拔技术 称为热交换技术（Hot Swap），允许在不关机的状态下更换故障热插拔设备\n常见的热插拔设备：硬盘，电源，PCI 设备，风扇等\n热插拔技术与 RAID 技术配合起来，可以使服务器在不关机的状态下恢复故障硬盘上的数据，同时并不影响网络用户对数据的使用，\n机柜 机柜式服务器-服务器放置在机柜中\n通常使用的是 42U（约 2 米高）机柜（1U=44.45mm）\n外观尺寸一般为款 600深 1000高 2000(mm)\n大部分网络设备（交换机，路由器等）深 600mm 即可\n机柜配件\n存储基础知识 用于存放数据信息的设备和介质，是计算机系统的外部存储，数据可安全存放，长期驻留\n传统存储：\n磁盘阵列：\n存储网络类型：\nDAS：直接连接存储（Direct Attached Storage）\nNAS：网络连接存储（Network Attached Storage）\n通过局域网在多个文件服务器之间实现了互联，基于文件的协议（NFS，SMB/CIFS 等），实现文件共享。只对文件有使用能力，\n集中管理数据，从而释放带宽，提高性能 可提供跨平台文件共享功能 可靠性较差，适用于局域网络或较小的网络 SAN：存储区域网络（Storage Area Networks）\n利用高速的光纤网络链接服务器与存储设备，基于 SCSI，IP，ATM 等多种高级协议，实现存储共享。对文件有管理能力，\n服务器跟存储装置两者各司其职 利用光纤信道来传输数据，以达到一个服务器与存储装置之间多对多的高效能，高稳定度的存储环境 实施复杂，管理成本高 区别：\n\\ DAS NAS SAN 传输类型 SCSI，FC IP IP，FC，SAS 数据类型 数据块 文件 数据块 典型应用 任何 文件服务器 数据库应用 优点 磁盘与服务器分离，便于统一管理 不占用应用服务器资源 广泛支持操作系统扩展较容易即插即用，安装简单方便 高扩展性高可用性数据集中，易管理 缺点 连接距离短数据分散，共享困难存储空间利用率不高扩展性有限 不适合存储量大的块级应用数据备份及恢复占用网络带宽 相比 NAS 成本较高安装和升级比 NAS 复杂 计算机软件 操作系统 OS：Operating System，通用目的的软件程序，包含如下功能\n硬件驱动 进程管理 内存管理 网络管理 安全管理 文件管理 OS 分类\n服务器 OS：RHEL，CentOS，Windows Server，AIX 桌面 OS：Windows 10，Windows 7，Mac OS，Fedora 移动设备 OS：Andriod，IOS，YunOS 开发接口标准 ABI：Application Binary Interface\nABI 描述了应用程序与 OS 之间的底层接口，允许编译好的目标代码在使用兼容 ABI 的系统中无需改动就能运行\nAPI：Application Binary Interface\nAPI 定义了源代码和库之间的接口，因此同样的源代码可以在支持这个 API 的任何系统中编译\nPOSIX：Portable Operating System Interface\nIEEE 在操作系统上定义的一系列 API 标准 POSIX 兼容的程序可以在其他 POSIX 操作系统编译执行\n运行程序格式：\nWindows：EXE，dll（dynamic link library），.lib Linux：ELF，.so（shared object），.a Library function 和 system call 函数库和系统调用\n用户的应用程序包含函数库（Library），函数库通过系统调用（system call）来操作内核（Kernel），内核通过硬件驱动（Device Dirver）从硬件（Hardware）中获取数据\n单核 CPU 同一时间只能做一件事，所以，同一时间只能在一个空间中工作，当运行程序时，CPU 在用户空间和内核空间之间切换工作，称为上下文切换，保留在上一空间正在处理的数据状态，\n用户空间和内核空间 用户空间（User Space）：\n用户程序的运行空间。为了安全，他们是隔离的，即使用户的程序崩溃，内核也不受影响，\n只能执行简单的运算，不能直接调用系统资源，必须通过系统接口（system call），才能向内核发出指令\n内核空间（Kernel Space）：\n是 Linux 内核的运行空间\n可以执行任意命令，调用系统的一切资源\n示例：\nstr = \"www.baidu.com\" //用户空间 x = x + 10 // 用户空间 file.write(str) // 切换到内核空间 y = x + 200 // 切换回用户空间\n说明：第一行和第二行都是简单的赋值运算，在 User space 执行。第三行需要写入文件，就要切换到 Kernel space，因为用户不能直接写文件，必须通过内核安排。第四行又是赋值运算，就切换回 User space，\n编程语言 低级语言\n机器语言：0 和 1 汇编语言：和机器语言一一对应，与硬件相关的特有代码，驱动程序开发\n中级语言：C\n系统级应用，驱动程序\n高级语言：java，python，go，php，Objective-C，C#\n应用级程序开发\nC：hello.c\n# include \u003cstdio.h\u003e int main(void) { printf(\"Hello, world\\n\"); } Java：hello.java\nclass Hello{ public static void main(String[] agrs){ System.out.println(\"Hello Java\"); } } Perl：hello.pl\n#!/usr/bin/perl print \"hello perl\\n\" Python hello.py\n#!/usr/bin/python print 'Hello Python' 将中级语言和高级语言编译为低级语言（0 与 1），才能被计算机执行，\n服务器三大操作系统 Windows Linux GNU/Linux\nUnix 1969 年 Ken Thompson\nSystem：Bell Lab\nAIX（IBM） Solaris（SUN） HP-UX（HP） BSD：（BSRG）Berkeley System Distribution\nNetBSD OpenBSD FreeBSD 兼容分时系统 只有一台主机，配置多个键盘和显示器，给多个用户用，\n主机同一时刻只能处理一个用户的请求，\n为进一步强化大型主机功能，让主机的资源可以提供更多的是使用着来利用，在 1964 年，贝尔实验室，麻省理工学院及奇艺公司共同发起了 Multic（多路信息计算系统）计划，目的是让大型主机可以同时支持 300 个以上的终端机连线使用。不过到了 1969 年前后，由于计划进度缓慢，资金短缺，所以计划虽然继续研究，但贝尔实验室退出了，\n1966 年加州大学伯克利分校毕业的 Ken Thompson 加入了贝尔实验室。参与了 Multics 系统的研发，并基于该系统开发了'star travel'游戏。当贝尔实验室退出该项目后，意味着 Ken 将没有机器可以再玩这个游戏。所以 Ken 找到了一台老式的 PDP-7，并在这台机器上重写了他的游戏。利用 PDP-7 上的汇编语言，花费一个月时间完成了操作系统的内核。一周一个内核，一个文件系统，一个编译器和一个编译程序，该操作系统内核就是 unix 的起源，\nGNU 由于 UNIX 开始收费，相应的软件也开始收费，所以 GNU 诞生了，提供开源免费的，运行在 Unix 上的应用软件，\nGNU（GNU is Not Unix）\n1984 年由 Richard Stallman 发起并创建 目标是编写大量兼容于 Unix 系统的自由软件 官方网站：http://www.gnu.org GPL：（GNU General Public License）\n自由软件基金会：Free Software Foundation 允许用户任意复制，传递，修改及再发布 基于自由软件修改再次发布的软件，仍需遵循 GPL LGPL（Lesser General Public License）\nLGPL 相对于 GPL 较为宽松，允许不公开全部源代码 GNU 操作系统：Hurd Hird of Unix-Replacing Daemons\n官网：http://www.gnu.org/home.html\nLinux 起源 1991 年 10 月 5 日，Torvalds 在 comp.os.minix 新闻组上发布消息，宣布他自行编写的完全自由免费的内核诞生（Freeminix-like kernel sources for 386-AT）-FREAX，英文含义是怪诞的，怪物，异想天开\n类 Unix 内核，在 GPL 下发布\n官网：www.kernel.org\nLinux 操作系统包含：\n完整的类 Unix 操作系统 Linux 内核 + GNU 工具 Linux 发行版 slackware：SUSE Linux Enterprise Server（SLES） OpenSuse 桌面\ndebian：ubuntu，mint\nredhat：RHEL：RedHat Enterprise Linux，每 18 个月发行一个新版本\nCentOS：兼容 RHEL 的格式 中标麒麟：中标软件 Fedora：每 6 个月发行一个新版本 ArchLinux：轻量简洁\nGentoo：极致性能\nLFS：Linux From sratch 自定制 Linux，需要深入理解 Linux 可以去看官网文档\nAndroid：kernel+busybox（工具集）+java 虚拟机\nLinux 分支参考网站：\nhttp://www.futurist.se/gldt/ http://www.mindpin.com/d3js-demo/linux/ Linux 内核 1 2 3 4 $ uname -r 3.10.0-1062.1.2.el7.x86_64 $ cat /etc/redhat-release CentOS Linux release 7.7.1908 (Core) 开源许可证 GPL 最严格，MIT 最宽松\nLinux 哲学思想 一切都是一个文件（包括硬件） 小型，单一用途的程序 链接程序，共同完成复杂的任务 避免令人困惑的用户界面 配置数据存储在文本中 ","description":"","tags":["Linux"],"title":"计算机基础","uri":"/posts/linux/%E9%98%BF%E9%87%8C%E4%BA%91linux%E8%BF%90%E7%BB%B4%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/%E9%98%B6%E6%AE%B5%E4%B8%80-linux%E5%85%A5%E9%97%A8/linux-computer-basics/"},{"categories":null,"content":"Fedora 恢复 Home 目录 Fedora 误删了 home 目录下的文件夹，重建后，不显示图标，垃圾箱失效等问题。\n修改 ~/.config/user-dirs.dirs\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # This file is written by xdg-user-dirs-update # If you want to change or add directories, just edit the line you're # interested in. All local changes will be retained on the next run. # Format is XDG_xxx_DIR=\"$HOME/yyy\", where yyy is a shell-escaped # homedir-relative path, or XDG_xxx_DIR=\"/yyy\", where /yyy is an # absolute path. No other format is supported. # XDG_DESKTOP_DIR=\"$HOME/Desktop\" XDG_DOWNLOAD_DIR=\"$HOME/Downloads\" XDG_TEMPLATES_DIR=\"$HOME/Templates\" XDG_PUBLICSHARE_DIR=\"$HOME/Public\" XDG_DOCUMENTS_DIR=\"$HOME/Documents\" XDG_MUSIC_DIR=\"$HOME/Music\" XDG_PICTURES_DIR=\"$HOME/Pictures\" XDG_VIDEOS_DIR=\"$HOME/Videos\" 运行\n1 xdg-user-dirs-update 如果隐藏文件也被删除了，家目录的模板文件夹在 /etc/skel 目录下，可以将其中的所有文件复制到家目录下，具体位置可查看 /etc/default/useradd 文件中的 SKEL 属性\n1 2 3 cp -r /etc/skel /home/用户名 chown -R 用户名.主组 /home/用户名 chmod 700 /home/用户名 ","description":"","tags":["Linux","Fedora"],"title":"Fedora 恢复 Home 目录","uri":"/posts/linux/fedora/fedora-restore-home-file/"},{"categories":null,"content":"Linux 设置欢迎语 配置文件 设置登陆后的欢迎语句修改 /etc/motd\n设置登陆前的欢迎语句修改 /etc/issue\n示例 // I am not sure why this works but it fixes the problem. // 虽然我不知道为什么这样管用，但它却是修复了问题 // drunk, fix later // 有点晕了，以后再修改 \u003c!-- Here be dragons --\u003e \u003c!-- 前方高能 --\u003e // This code sucks, you know it and I know it. // Move on and call me an idiot later. // 你我都知道这代码很烂 // 先不要骂我 2B 了，请先继续往下看 /** * .,:,,, .::,,,::. * .::::,,;;, .,;;:,,....:i: * :i,.::::,;i:. ....,,:::::::::,.... .;i:,. ......;i. * :;..:::;::::i;,,:::;:,,,,,,,,,,..,.,,:::iri:. .,:irsr:,.;i. * ;;..,::::;;;;ri,,,. ..,,:;s1s1ssrr;,.;r, * :;. ,::;ii;:, . ................... .;iirri;;;,,;i, * ,i. .;ri:. ... ............................ .,,:;:,,,;i: * :s,.;r:... ....................................... .::;::s; * ,1r::. .............,,,.,,:,,........................,;iir; * ,s;........... ..::.,;:,,. ...............,;1s * :i,..,. .,:,,::,. .......... .......;1, * ir,....:rrssr;:, ,,.,::. .r5S9989398G95hr;. ....,.:s, * ;r,..,s9855513XHAG3i .,,,,,,,. ,S931,.,,.;s;s\u0026BHHA8s.,..,..:r: * :r;..rGGh, :SAG;;G@BS:.,,,,,,,,,.r83: hHH1sXMBHHHM3..,,,,.ir. * ,si,.1GS, sBMAAX\u0026MBMB5,,,,,,:,,.:\u00268 3@HXHBMBHBBH#X,.,,,,,,rr * ;1:,,SH: .A@\u0026\u0026B#\u00268H#BS,,,,,,,,,.,5XS, 3@MHABM\u002659M#As..,,,,:,is, * .rr,,,;9\u00261 hBHHBB\u00268AMGr,,,,,,,,,,,:h\u0026\u00269s; r9\u0026BMHBHMB9: . .,,,,;ri. * :1:....:5\u0026XSi;r8BMBHHA9r:,......,,,,:ii19GG88899XHHH\u0026GSr. ...,:rs. * ;s. .:sS8G8GG889hi. ....,,:;:,.:irssrriii:,. ...,,i1, * ;1, ..,....,,isssi;, .,,. ....,.i1, * ;h: i9HHBMBBHAX9: . ...,,,rs, * ,1i.. :A#MBBBBMHB##s ....,,,;si. * .r1,.. ,..;3BMBBBHBB#Bh. .. ....,,,,,i1; * :h;.. .,..;,1XBMMMMBXs,.,, .. :: ,. ....,,,,,,ss. * ih: .. .;;;, ;;:s58A3i,.. ,. ,.:,,. ...,,,,,:,s1, * .s1,.... .,;sh, ,iSAXs;. ,. ,,.i85 ...,,,,,,:i1; * .rh: ... rXG9XBBM#M#MHAX3hss13\u0026\u0026HHXr .....,,,,,,,ih; * .s5: ..... i598X\u0026\u0026A\u0026AAAAAA\u0026XG851r: ........,,,,:,,sh; * . ihr, ... . .. ........,,,,,;11:. * ,s1i. ... ..,,,..,,,.,,.,,.,.. ........,,.,,.;s5i. * .:s1r,...................... ..............;shs, * . .:shr:. .... ..............,ishs. * .,issr;,... ...........................,is1s;. * .,is1si;:,....................,:;ir1sr;, * ..:isssssrrii;::::::;;iirsssssr;:.. * .,::iiirsssssssssrri;;:. */ /** * ii. ;9ABH, * SA391, .r9GG35\u0026G * \u0026#ii13Gh; i3X31i;:,rB1 * iMs,:,i5895, .5G91:,:;:s1:8A * 33::::,,;5G5, ,58Si,,:::,sHX;iH1 * Sr.,:;rs13BBX35hh11511h5Shhh5S3GAXS:.,,::,,1AG3i,GG * .G51S511sr;;iiiishS8G89Shsrrsh59S;.,,,,,..5A85Si,h8 * :SB9s:,............................,,,.,,,SASh53h,1G. * .r18S;..,,,,,,,,,,,,,,,,,,,,,,,,,,,,,....,,.1H315199,rX, * ;S89s,..,,,,,,,,,,,,,,,,,,,,,,,....,,.......,,,;r1ShS8,;Xi * i55s:.........,,,,,,,,,,,,,,,,.,,,......,.....,,....r9\u00265.:X1 * 59;.....,. .,,,,,,,,,,,... .............,..:1;.:\u0026s * s8,..;53S5S3s. .,,,,,,,.,.. i15S5h1:.........,,,..,,:99 * 93.:39s:rSGB@A; ..,,,,..... .SG3hhh9G\u0026BGi..,,,,,,,,,,,,.,83 * G5.G8 9#@@@@@X. .,,,,,,..... iA9,.S\u0026B###@@Mr...,,,,,,,,..,.;Xh * Gs.X8 S@@@@@@@B:..,,,,,,,,,,. rA1 ,A@@@@@@@@@H:........,,,,,,.iX: * ;9. ,8A#@@@@@@#5,.,,,,,,,,,... 9A. 8@@@@@@@@@@M; ....,,,,,,,,S8 * X3 iS8XAHH8s.,,,,,,,,,,...,..58hH@@@@@@@@@Hs ...,,,,,,,:Gs * r8, ,,,...,,,,,,,,,,..... ,h8XABMMHX3r. .,,,,,,,.rX: * :9, . .:,..,:;;;::,.,,,,,.. .,,. ..,,,,,,.59 * .Si ,:.i8HBMMMMMB\u00265,.... . .,,,,,.sMr * SS :: h@@@@@@@@@@#; . ... . ..,,,,iM5 * 91 . ;:.,1\u0026@@@@@@MXs. . .,,:,:\u0026S * hS .... .:;,,,i3MMS1;..,..... . . ... ..,:,.99 * ,8; ..... .,:,..,8Ms:;,,,... .,::.83 * s\u0026: .... .sS553B@@HX3s;,. .,;13h. .:::\u00261 * SXr . ...;s3G99XA\u0026X88Shss11155hi. ,;:h\u0026, * iH8: . .. ,;iiii;,::,,,,,. .;irHA * ,8X5; . ....... ,;iihS8Gi * 1831, .,;irrrrrs\u0026@ * ;5A8r. .:;iiiiirrss1H * :X@H3s....... .,:;iii;iiiiirsrh * r#h:;,...,,.. .,,:;;;;;:::,... .:;;;;;;iiiirrss1 * ,M8 ..,....,.....,,::::::,,... . .,;;;iiiiiirss11h * 8B;.,,,,,,,.,..... . .. .:;;;;iirrsss111h * i@5,:::,,,,,,,,.... . . .:::;;;;;irrrss111111 * 9Bi,:,,,,...... ..r91;;;;;iirrsss1ss1111 */ /** * .,, .,:;;iiiiiiiii;;:,,. .,, * rGB##HS,.;iirrrrriiiiiiiiiirrrrri;,s\u0026##MAS, * r5s;:r3AH5iiiii;;;;;;;;;;;;;;;;iiirXHGSsiih1, * .;i;;s91;;;;;;::::::::::::;;;;iS5;;;ii: * :rsriii;;r::::::::::::::::::::::;;,;;iiirsi, * .,iri;;::::;;;;;;::,,,,,,,,,,,,,..,,;;;;;;;;iiri,,. * ,9BM\u0026, .,:;;:,,,,,,,,,,,hXA8: ..,,,. * ,;\u0026@@#r:;;;;;::::,,. ,r,,,,,,,,,,iA@@@s,,:::;;;::,,. .;. * :ih1iii;;;;;::::;;;;;;;:,,,,,,,,,,;i55r;;;;;;;;;iiirrrr,.. * .ir;;iiiiiiiiii;;;;::::::,,,,,,,:::::,,:;;;iiiiiiiiiiiiri * iriiiiiiiiiiiiiiii;;;::::::::::::::::;;;iiiiiiiiiiiiiiiir; * ,riii;;;;;;;;;;;;;:::::::::::::::::::::::;;;;;;;;;;;;;;iiir. * iri;;;::::,,,,,,,,,,:::::::::::::::::::::::::,::,,::::;;iir: * .rii;;::::,,,,,,,,,,,,:::::::::::::::::,,,,,,,,,,,,,::::;;iri * ,rii;;;::,,,,,,,,,,,,,:::::::::::,:::::,,,,,,,,,,,,,:::;;;iir. * ,rii;;i::,,,,,,,,,,,,,:::::::::::::::::,,,,,,,,,,,,,,::i;;iir. * ,rii;;r::,,,,,,,,,,,,,:,:::::,:,:::::::,,,,,,,,,,,,,::;r;;iir. * .rii;;rr,:,,,,,,,,,,,,,,:::::::::::::::,,,,,,,,,,,,,:,si;;iri * ;rii;:1i,,,,,,,,,,,,,,,,,,:::::::::,,,,,,,,,,,,,,,:,ss:;iir: * .rii;;;5r,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sh:;;iri * ;rii;:;51,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.:hh:;;iir, * irii;::hSr,.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.,sSs:;;iir: * irii;;:iSSs:.,,,,,,,,,,,,,,,,,,,,,,,,,,,..:135;:;;iir: * ;rii;;:,r535r:...,,,,,,,,,,,,,,,,,,..,;sS35i,;;iirr: * :rrii;;:,;1S3Shs;:,............,:is533Ss:,;;;iiri, * .;rrii;;;:,;rhS393S55hh11hh5S3393Shr:,:;;;iirr: * .;rriii;;;::,:;is1h555555h1si;:,::;;;iirri:. * .:irrrii;;;;;:::,,,,,,,,:::;;;;iiirrr;, * .:irrrriiiiii;;;;;;;;iiiiiirrrr;,. * .,:;iirrrrrrrrrrrrrrrrri;:. * ..,:::;;;;:::,,. */ /** * ┌───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┐ * │Esc│ │ F1│ F2│ F3│ F4│ │ F5│ F6│ F7│ F8│ │ F9│F10│F11│F12│ │P/S│S L│P/B│ ┌┐ ┌┐ ┌┐ * └───┘ └───┴───┴───┴───┘ └───┴───┴───┴───┘ └───┴───┴───┴───┘ └───┴───┴───┘ └┘ └┘ └┘ * ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───────┐ ┌───┬───┬───┐ ┌───┬───┬───┬───┐ * │~ `│! 1│@ 2│# 3│$ 4│% 5│^ 6│\u0026 7│* 8│( 9│) 0│_ -│+ =│ BacSp │ │Ins│Hom│PUp│ │N L│ / │ * │ - │ * ├───┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─────┤ ├───┼───┼───┤ ├───┼───┼───┼───┤ * │ Tab │ Q │ W │ E │ R │ T │ Y │ U │ I │ O │ P │{ [│} ]│ | \\ │ │Del│End│PDn│ │ 7 │ 8 │ 9 │ │ * ├─────┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴─────┤ └───┴───┴───┘ ├───┼───┼───┤ + │ * │ Caps │ A │ S │ D │ F │ G │ H │ J │ K │ L │: ;│\" '│ Enter │ │ 4 │ 5 │ 6 │ │ * ├──────┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴────────┤ ┌───┐ ├───┼───┼───┼───┤ * │ Shift │ Z │ X │ C │ V │ B │ N │ M │\u003c ,│\u003e .│? /│ Shift │ │ ↑ │ │ 1 │ 2 │ 3 │ │ * ├─────┬──┴─┬─┴──┬┴───┴───┴───┴───┴───┴──┬┴───┼───┴┬────┬────┤ ┌───┼───┼───┐ ├───┴───┼───┤ E││ * │ Ctrl│ │Alt │ Space │ Alt│ │ │Ctrl│ │ ← │ ↓ │ → │ │ 0 │ . │←─┘│ * └─────┴────┴────┴───────────────────────┴────┴────┴────┴────┘ └───┴───┴───┘ └───────┴───┴───┘ */ /** * ┌─────────────────────────────────────────────────────────────┐ * │┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┐│ * ││Esc│!1 │@2 │#3 │$4 │%5 │^6 │\u00267 │*8 │(9 │)0 │_- │+= │|\\ │`~ ││ * │├───┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴───┤│ * ││ Tab │ Q │ W │ E │ R │ T │ Y │ U │ I │ O │ P │{[ │}] │ BS ││ * │├─────┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴─────┤│ * ││ Ctrl │ A │ S │ D │ F │ G │ H │ J │ K │ L │: ;│\" '│ Enter ││ * │├──────┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴────┬───┤│ * ││ Shift │ Z │ X │ C │ V │ B │ N │ M │\u003c ,│\u003e .│? /│Shift │Fn ││ * │└─────┬──┴┬──┴──┬┴───┴───┴───┴───┴───┴──┬┴───┴┬──┴┬─────┴───┘│ * │ │Fn │ Alt │ Space │ Alt │Win│ HHKB │ * │ └───┴─────┴───────────────────────┴─────┴───┘ │ * └─────────────────────────────────────────────────────────────┘ * * Happy Hacking auto coding */ /** * _ooOoo_ * o8888888o * 88\" . \"88 * (| -_- |) * O\\ = /O * ____/`---'\\____ * . ' \\\\| |// `. * / \\\\||| : |||// \\ * / _||||| -:- |||||- \\ * | | \\\\\\ - /// | | * | \\_| ''\\---/'' | | * \\ .-\\__ `-` ___/-. / * ___`. .' /--.--\\ `. . __ * .\"\" '\u003c `.___\\_\u003c|\u003e_/___.' \u003e'\"\". * | | : `- \\`.;`\\ _ /`;.`/ - ` : | | * \\ \\ `-. \\_ __\\ /__ _/ .-` / / * ======`-.____`-.___\\_____/___.-`____.-'====== * `=---=' * * ............................................. * 佛祖保佑 永无 BUG */ /** * 佛曰: * 写字楼里写字间，写字间里程序员； * 程序人员写程序，又拿程序换酒钱。 * 酒醒只在网上坐，酒醉还来网下眠； * 酒醉酒醒日复日，网上网下年复年。 * 但愿老死电脑间，不愿鞠躬老板前； * 奔驰宝马贵者趣，公交自行程序员。 * 别人笑我忒疯癫，我笑自己命太贱； * 不见满街漂亮妹，哪个归得程序员？ */ /** * _ooOoo_ * o8888888o * 88\" . \"88 * (| -_- |) * O\\ = /O * ___/`---'\\____ * . ' \\\\| |// `. * / \\\\||| : |||// \\ * / _||||| -:- |||||- \\ * | | \\\\\\ - /// | | * | \\_| ''\\---/'' | | * \\ .-\\__ `-` ___/-. / * ___`. .' /--.--\\ `. . __ * .\"\" '\u003c `.___\\_\u003c|\u003e_/___.' \u003e'\"\". * | | : `- \\`.;`\\ _ /`;.`/ - ` : | | * \\ \\ `-. \\_ __\\ /__ _/ .-` / / * ======`-.____`-.___\\_____/___.-`____.-'====== * `=---=' * ............................................. * 佛曰：bug 泛滥，我已瘫痪！ */ /** * .::::. * .::::::::. * ::::::::::: FUCK YOU * ..:::::::::::' * '::::::::::::' * .:::::::::: * '::::::::::::::.. * ..::::::::::::. * ``:::::::::::::::: * ::::``:::::::::' .:::. * ::::' ':::::' .::::::::. * .::::' :::: .:::::::'::::. * .:::' ::::: .:::::::::' ':::::. * .::' :::::.:::::::::' ':::::. * .::' ::::::::::::::' ``::::. * ...::: ::::::::::::' ``::. * ```` ':. ':::::::::' ::::.. * '.:::::' ':'````.. */ /** * ┏┓　┏┓ * ┏┛┻━━━┛┻┓ * ┃　┃ * ┃　━　┃ * ┃　＞　＜　┃ * ┃　┃ * ┃...　⌒　...　┃ * ┃　┃ * ┗━┓　┏━┛ * ┃　┃　* ┃　┃ * ┃　┃ * ┃　┃ 神兽保佑 * ┃　┃ 代码无 bug　* ┃　┃ * ┃　┗━━━┓ * ┃　┣┓ * ┃　┏┛ * ┗┓┓┏━┳┓┏┛ * ┃┫┫　┃┫┫ * ┗┻┛　┗┻┛ */ /** *　┏┓　┏┓+ + *　┏┛┻━━━┛┻┓ + + *　┃　┃ *　┃　━　┃ ++ + + + * ████━████ ┃+ *　┃　┃ + *　┃　┻　┃ *　┃　┃ + + *　┗━┓　┏━┛ *　┃　┃　*　┃　┃ + + + + *　┃　┃ *　┃　┃ + 神兽保佑 *　┃　┃ 代码无 bug　*　┃　┃　+　*　┃　┗━━━┓ + + *　┃ ┣┓ *　┃ ┏┛ *　┗┓┓┏━┳┓┏┛ + + + + *　┃┫┫　┃┫┫ *　┗┻┛　┗┻┛+ + + + */ /** * ━━━━━━神兽出没━━━━━━ * ┏┓　┏┓ * ┏┛┻━━━┛┻┓ * ┃　┃ * ┃　━　┃ * ┃　┳┛　┗┳　┃ * ┃　┃ * ┃　┻　┃ * ┃　┃ * ┗━┓　┏━┛ * ┃　┃ 神兽保佑 * ┃　┃ 代码无 bug　* ┃　┗━━━┓ * ┃　┣┓ * ┃　┏┛ * ┗┓┓┏━┳┓┏┛ * ┃┫┫　┃┫┫ * ┗┻┛　┗┻┛ * ━━━━━━感觉萌萌哒━━━━━━ */ /** _ * _._ _..._ .-', _.._(`)) * '-. ` ' /-._.-' ',/ * ) \\ '. * / _ _ | \\ * | a a / | * \\ .-. ; * '-('' ).-' ,' ; * '-; | .' * \\ \\ / * | 7 .__ _.-\\ \\ * | | | ``/ /` / * /,_| | /,_/ / * /,_/ '`-' */ /** ************************************************************** * * * .=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-. * * | ______ | * * | .-\" \"-. | * * | / \\ | * * | _ | | _ | * * | ( \\ |, .-. .-. ,| / ) | * * | \u003e \"=._ | )(__/ \\__)( | _.=\" \u003c | * * | (_/\"=._\"=._ |/ /\\ \\| _.=\"_.=\"\\_) | * * | \"=._\"(_ ^^ _)\"_.=\" | * * | \"=\\__|IIIIII|__/=\" | * * | _.=\"| \\IIIIII/ |\"=._ | * * | _ _.=\"_.=\"\\ /\"=._\"=._ _ | * * | ( \\_.=\"_.=\" `--------` \"=._\"=._/ ) | * * | \u003e _.=\" \"=._ \u003c | * * | (_/ \\_) | * * | | * * '-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=' * * * * LASCIATE OGNI SPERANZA, VOI CH'ENTRATE * ************************************************************** */ /** * ,s555SB@@\u0026 * :9H####@@@@@Xi * 1@@@@@@@@@@@@@@8 * ,8@@@@@@@@@B@@@@@@8 * :B@@@@X3hi8Bs;B@@@@@Ah, * ,8i r@@@B: 1S ,M@@@@@@#8; * 1AB35.i: X@@8 . SGhr ,A@@@@@@@@S * 1@h31MX8 18Hhh3i .i3r ,A@@@@@@@@@5 * ;@\u0026i,58r5 rGSS: :B@@@@@@@@@@A * 1#i . 9i hX. .: .5@@@@@@@@@@@1 * sG1, ,G53s. 9#Xi;hS5 3B@@@@@@@B1 * .h8h.,A@@@MXSs, #@H1: 3ssSSX@1 * s ,@@@@@@@@@@@@Xhi, r#@@X1s9M8 .GA981 * ,. rS8H#@@@@@@@@@@#HG51;. .h31i;9@r .8@@@@BS;i; * .19AXXXAB@@@@@@@@@@@@@@#MHXG893hrX#XGGXM@@@@@@@@@@MS * s@@MM@@@hsX#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\u0026, * :GB@#3G@@Brs ,1GM@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@B, * .hM@@@#@@#MX 51 r;iSGAM@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@8 * :3B@@@@@@@@@@@\u00269@h :Gs .;sSXH@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@: * s\u0026HA#@@@@@@@@@@@@@@M89A;.8S. ,r3@@@@@@@@@@@@@@@@@@@@@@@@@@@r * ,13B@@@@@@@@@@@@@@@@@@@5 5B3 ;. ;@@@@@@@@@@@@@@@@@@@@@@@@@@@i * 5#@@#\u0026@@@@@@@@@@@@@@@@@@9 .39: ;@@@@@@@@@@@@@@@@@@@@@@@@@@@; * 9@@@X:MM@@@@@@@@@@@@@@@#; ;31. H@@@@@@@@@@@@@@@@@@@@@@@@@@: * SH#@B9.rM@@@@@@@@@@@@@B :. 3@@@@@@@@@@@@@@@@@@@@@@@@@@5 * ,:. 9@@@@@@@@@@@#HB5 .M@@@@@@@@@@@@@@@@@@@@@@@@@B * ,ssirhSM@\u00261;i19911i,. s@@@@@@@@@@@@@@@@@@@@@@@@@@S * ,,,rHAri1h1rh\u0026@#353Sh: 8@@@@@@@@@@@@@@@@@@@@@@@@@#: * .A3hH@#5S553\u0026@@#h i:i9S #@@@@@@@@@@@@@@@@@@@@@@@@@A. * * * 又看源码，看你妹妹呀！ */ /** *_______________#########_______________________ *______________############_____________________ *______________#############____________________ *_____________##__###########___________________ *____________###__######_#####__________________ *____________###_#######___####_________________ *___________###__##########_####________________ *__________####__###########_####_______________ *________#####___###########__#####_____________ *_______######___###_########___#####___________ *_______#####___###___########___######_________ *______######___###__###########___######_______ *_____######___####_##############__######______ *____#######__#####################_#######_____ *____#######__##############################____ *___#######__######_#################_#######___ *___#######__######_######_#########___######___ *___#######____##__######___######_____######___ *___#######________######____#####_____#####____ *____######________#####_____#####_____####_____ *_____#####________####______#####_____###______ *______#####______;###________###______#________ *________##_______####________####______________ */ /** * ,%%%%%%%%, * ,%%/\\%%%%/\\%% * ,%%%\\c \"\" J/%%% * %. %%%%/ o o \\%%% * `%%. %%%% _ |%%% * `%% `%%%%(__Y__)%%' * // ;%%%%`\\-/%%%' * (( / `%%%%%%%' * \\\\ .' | * \\\\ / \\ | | * \\\\/ ) | | * \\ /_ | |__ * (___________))))))) 攻城湿 * * _ _ * __ _(_)_ _(_) __ _ _ __ * \\ \\ / / \\ \\ / / |/ _` |'_ \\ * \\ V /| |\\ V /| | (_| | | | | * \\_/ |_| \\_/ |_|\\__,_|_| |_| */ /** https://oldboyedu.com/ *　１１１　１　*　１１１　１１１１１１１１１１１１　１１１　*　１１　１１１１１１１１１１１１　１１１１１　*　１１　１１１　１１　１１１１１１１　*　１１１１　１　１１１１１１１１１１１　１１１　１１１１　*　１１１１１１　１１１１１１１１１１１　１１１１　１１１１１　*　１１１１１１　１１　１１１１　１１１１１１　*　１１　１１１１１１１１　１１　１１１１１１１１１１１１１１１１１１　*　１１　１１１１１１１１１１１　１１１１１１１１１１１１１１１１１１１　*　１１１１１１１１１　１１　１１　１１　１１　*　１１１１１１１１１１１１１１１１１１　１１　*　１１１１　１１１１１１１１１１１１　１１１１１１１１１１１１１１　*　１１１１　１１　１１　１１１１１１１１１１１１１１　*　１１　１１　１１　１１　１１１　１１　１１　１１１　*　１１　１１　１１　１１　１１　１１１　１１　１１１　*　１１　１１１　１１　１１　１１　１１１　１１　１１１　*　１１１１　１１１　１１１１１１１１１　１１　１１１　１１　１１１１１１１　*　１１１１１１　１１１１１１１１１１　１１１１１１１１１１１１１１１１１　*　１１　１１１　１１１　１１１１１１１１１１１１１１１１１　*/ /** * https://www.oldboyedu.com/ * _____ _____ _____ _____ * /\\ \\ /\\ \\ /\\ \\ /\\ \\ * /::\\____\\ /::\\ \\ /::\\ \\ /::\\ \\ * /:::/ / \\:::\\ \\ /::::\\ \\ /::::\\ \\ * /:::/ / \\:::\\ \\ /::::::\\ \\ /::::::\\ \\ * /:::/ / \\:::\\ \\ /:::/\\:::\\ \\ /:::/\\:::\\ \\ * /:::/____/ \\:::\\ \\ /:::/__\\:::\\ \\ /:::/__\\:::\\ \\ * /::::\\ \\ /::::\\ \\ /::::\\ \\:::\\ \\ /::::\\ \\:::\\ \\ * /::::::\\ \\ _____ ____ /::::::\\ \\ /::::::\\ \\:::\\ \\ /::::::\\ \\:::\\ \\ * /:::/\\:::\\ \\ /\\ \\ /\\ \\ /:::/\\:::\\ \\ /:::/\\:::\\ \\:::\\____\\ /:::/\\:::\\ \\:::\\ \\ * /:::/ \\:::\\ /::\\____\\/::\\ \\/:::/ \\:::\\____\\/:::/ \\:::\\ \\:::| |/:::/__\\:::\\ \\:::\\____\\ * \\::/ \\:::\\ /:::/ /\\:::\\ /:::/ \\::/ /\\::/ |::::\\ /:::|____|\\:::\\ \\:::\\ \\::/ / * \\/____/ \\:::\\/:::/ / \\:::\\/:::/ / \\/____/ \\/____|:::::\\/:::/ / \\:::\\ \\:::\\ \\/____/ * \\::::::/ / \\::::::/ / |:::::::::/ / \\:::\\ \\:::\\ \\ * \\::::/ / \\::::/____/ |::|\\::::/ / \\:::\\ \\:::\\____\\ * /:::/ / \\:::\\ \\ |::| \\::/____/ \\:::\\ \\::/ / * /:::/ / \\:::\\ \\ |::| ~| \\:::\\ \\/____/ * /:::/ / \\:::\\ \\ |::| | \\:::\\ \\ * /:::/ / \\:::\\____\\ \\::| | \\:::\\____\\ * \\::/ / \\::/ / \\:| | \\::/ / * \\/____/ \\/____/ \\|___| \\/____/ */ /** * http://www.oldboyedu.com/ * _.._ ,------------. * ,' `. ( We want you! ) * / __) __` \\ `-,----------' * ( (`-`(-') ) _.-' * /) \\ = / ( * /' |--' . \\ * ( ,---| `-.)__` * )( `-.,--' _`-. * '/,' ( Uu\", * (_ , `/,-' ) * `.__, : `-'/ /`--' * | `--' | * ` `-._ / * \\ ( * /\\ . \\. freebuf * / |` \\ ,-\\ * / \\| .) / \\ * ( ,'|\\ ,' : * | \\,`.`--\"/ } * `,' \\ |,' / * / \"-._ `-/ | * \"-. \"-.,'| ; * / _/[\"---'\"\"] * : / |\"- ' * ' | / * ` | */ /** * https://campus.alibaba.com/ * `:::::::::::, * `::;:::::::;:::::::, ` * `::;;:::::::@@@@;:::::::` * ,:::::::::::::@ #@':::::` * :::::::::::::::'@@ @;:::: * ::::::::::::'@@@@'``` .+:::` * ::::::::::;@@@#. ,:::, * .::::::::+@#@` :::: * :::::::+@@' :::: * `:::::'@@: `:::. * ,::::@@: ` :::: * ;::::::@ .:::; * :;:::::;@` ` :::; * :::::::::@` @ ;:::: * :::::::::#` @` ,:::: * :::::::::@` +@ @ .::::` * .::::::'@@` `@@' @ ::::, * :::::::++@@@@@@@@@@. ::::; * ;:::::::+, `..` ::::: * ,::::::::', ::::: * :::::::::+, :::::` * :::::::::+@. ,::::.` `, * ::::::;;@+ .::;:: `; * :::::::@@ `:::;: `::`` * ::::::#@ ;:::: .::` * :::::;@ :::::` .;::` * :::::@ `:;::: `::::; * :::::# :::::. `,;::::: * :::::: ` ::::::,.,::::::::::. * ,::::::` .:: ::::::::::::::::;` * ;::::::::,````.,:::::, ::::::::::::::. * :::::::::::::::::: ` `::::::::::` * `::::::::::::, .:::. * `..` */ /** * http://www.oldboyedu.com/ * .--, .--, * ( ( \\.---./ ) ) * '.__/o o\\__.' * {= ^ =} * \u003e - \u003c * / \\ * // \\\\ * //| . |\\\\ * \"'\\ /'\"_.-~^`'-. * \\ _ /--' ` * ___)( )(___ * (((__) (__))) 高山仰止，景行行止。虽不能至，心向往之。 */ /** * 頂頂頂頂頂頂頂頂頂　頂頂頂頂頂頂頂頂頂 * 頂頂頂頂頂頂頂　頂頂　* 頂頂　頂頂頂頂頂頂頂頂頂頂頂 * 頂頂　頂頂頂頂頂頂頂頂頂頂頂 * 頂頂　頂頂　頂頂 * 頂頂　頂頂　頂頂頂　頂頂 * 頂頂　頂頂　頂頂頂　頂頂 * 頂頂　頂頂　頂頂頂　頂頂 * 頂頂　頂頂　頂頂頂　頂頂 * 頂頂　頂頂頂　* 頂頂　頂頂　頂頂　頂頂 * 頂頂頂頂　頂頂頂頂頂　頂頂頂頂頂 * 頂頂頂頂　頂頂頂頂　頂頂頂頂 */ 转码工具 在线图片转 ASCII http://picascii.com/# 在线图片和文字转 ASCII https://www.ascii-art-generator.org/ 在线图片和文字转 ASCII https://www.degraeve.com/img2txt.php ","description":"","tags":["Linux"],"title":"Linux 设置欢迎语","uri":"/posts/linux/%E9%98%BF%E9%87%8C%E4%BA%91linux%E8%BF%90%E7%BB%B4%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/%E9%98%B6%E6%AE%B5%E4%B8%80-linux%E5%85%A5%E9%97%A8/linux-welcome-message/"},{"categories":null,"content":"Java 静态导入 import static 是 JDK1.5 中的新特性。该功能是向当前类导入指定类中的静态方法，使得在当前类中可以直接通过方法名调用这些静态方法，而不用使用 类名。方法名() 的格式调用。例如：import static java.lang.Math.*;。也可以导入指定的方法：import static java.lang.Math.abs;\n这种方法建议在有很多重复调用的时候使用，如果仅有一到两次调用，不如直接写来的方便\n1 import static java.lang.Math.*; 参考文档 import static 和 import 的区别\n","description":"","tags":["Java"],"title":"Java 静态导入","uri":"/posts/java/java-static-import/"},{"categories":null,"content":"Linux 设置 k380 锁定 fn 按键 使用如下 github 开源项目：k380-function-keys-conf\nMake function keys default on Logitech k380 bluetooth keyboard. Instructions\nFirst install gcc. On Ubuntu run:\n1 sudo apt install gcc Download installation files https://github.com/jergusg/k380-function-keys-conf/releases/ (Source code).\nConnect your K380 keyboard via bluetooth to your computer.\nRun build.sh\n1 ./build.sh To switch keyboard's upper keys to F-keys run:\n1 sudo ./k380_conf -d /dev/hidrawX -f on Where X is number of your keyboard hidraw interface. Possibly 0, 1, 2, 3. Switch keys to F-keys automatically\nFollow instructions your received when you built k380_conf:\n1 sudo cp /your-build-path/80-k380.rules /etc/udev/rules.d/ \u0026\u0026 sudo udevadm control --reload Now, when you reconnect your keyboard it will be automatically switched to F-keys mode.\n","description":"","tags":["Linux"],"title":"Linux 设置 k380 锁定 fn 按键","uri":"/posts/linux/linux-k380-fn/"},{"categories":null,"content":"IDEA 远程调试 启动远程调试 Tomcat 启动远程调试 Windows 修改 catalina.bat\n在 set local 上方添加\n1 2 3 4 5 SET CATALINA_OPTS=-server -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=5005 # 设置 dos 窗口的 Title SET TITLE=CustomerTitle set local Linux 修改 catalina.sh, 添加\n1 CATALINA_OPTS=\"-server -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=5005\" jar 包方式启动远程调试 使用如下命令运行 jar\n1 java -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5005 -jar /jar/path/xxx.jar Docker 容器环境启动 jar 包远程调试 IDEA连接远程调试 参考文档 Tomcat 开启远程 Debug 调试\n","description":"","tags":["IDEA","Java"],"title":"IDEA 远程调试","uri":"/posts/java/idea-remove-debug/"},{"categories":null,"content":"使用 Docker 搭建 VPN 未测试\nhttp://medium.com/@gurayy/set-up-a-vpn-server-with-docker-in-5-minutes-a66184882c45\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 git clone https://github.com/kylemanna/docker-openvpn.git cd docker-openvpn docker build -t myownupn . cd .. mkdir vpn-data docker run -v $PWD/vpn-data:/etc/openvpn --rm myownvpn ovpn_genconfig -u udp://IP_ADDRESS:3000 docker run -v $PWD/vpn-data:/etc/openvpn --rm -it myownvpn ovpn_initpki docker run -v $PWD/vpn-data:/etc/openvpn -d -p 3000:1194/udp --cap-add=NET_ADMIN myownvpn docker run -v $PWD/vpn-data:/etc/openvpn --rm -it myownvpn easyrsa build-client-full user1 nopass docker run -v $PWD/vpn-data:/etc/openvpn --rm myownvpn ovpn_getclient user1 \u003e user1.ovpn ","description":"","tags":["Docker","VPN"],"title":"使用 Docker 搭建 VPN","uri":"/posts/docker/docker-build-vpn/"},{"categories":null,"content":"CentOS7 挂载 exFAT 格式的 U 盘 安装依赖包 1 $ yum install http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-5.el7.nux.noarch.rpm -y 1 $ yum install exfat-utils fuse-exfat -y 查看所有分区 1 2 3 4 5 6 7 8 9 10 11 $ fdisk -l Disk /dev/sdb: 62.1 GB, 62109253632 bytes, 121307136 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x3c3fff2d Device Boot Start End Blocks Id System /dev/sdb1 * 63 121307135 60653536+ 7 HPFS/NTFS/exFAT 挂载分区 将 /dev/sdb1 挂载到 /mnt 下\n1 $ mount /dev/sdb1 /mnt 卸载分区 1 umount /dev/sdb1 ","description":"","tags":["Linux","CentOS"],"title":"CentOS7 挂载 exFAT 格式的 U 盘","uri":"/posts/linux/centos/centos7-mount-exfat/"},{"categories":null,"content":"项目管理工具 Maven 快速入门 简介 服务于基于 Java 平台的项目构建，依赖管理和项目信息管理。\n项目构建：编译，运行单元测试，生成文档，打包和部署等就是构建。\n推荐书籍：《Maven 实战》 许晓斌\nPOM ：project object model\nMaven 优势 跨平台 服务于构建，它是一个异常强大的构建工具，能自动化构建过程，从清理，编译，测试到生成报告，再到打包和部署。 标准化，能够标准化构建过程。在 Maven 之前，十个项目可能有十种构建方式，有了 maven 后所有项目的构建命令都是简单一致的，这极大地避免了不必要的学习成本，而且有利于促进项目团队的的标准化。 封装构建过程，我们一直在不停地寻找避免重复的方法。Maven 最大化清除了构建的重复，抽象了够贱的生命周期，并且为绝大部分的构建任务提供已实现的插件，我们不需要定义过程。 依赖管理，在这个开源的年代里，几乎任何 java 应用都会借用一些第三方的开源类库，这些类库都可以通过依赖的方式引入到项目中来。随着依赖的增多，版本不一致，版本冲突，依赖臃肿等问题都会接踵而至。手工解决这些问题是十分枯燥的，Maven 提供了一个优秀的解决方案，它通过一个坐标系统准确的定位每一个组件，让他们变得有秩序，因此我们可以借助它有序的管理依赖，轻松的解决繁杂的依赖问题。Maven 为 Java 提供了一个免费的中央仓库，在其中可以知道任何流行的开源类库。 项目规范化：maven 对于项目目录结构，测试用例命名方式等都有既定的规则，只要遵循了这些成熟的规则，用户在项目间切换的时候就免去了额外的学习成本，可以说是 约定优于配置。 手动构建一个 maven 项目 创建一个 pom.xml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003c!--GAV 用来确定项目的唯一坐标--\u003e \u003c!--groupId：组织名称，通常使用公司域名倒叙--\u003e \u003c!--artifactId：项目名称--\u003e \u003c!--version：版本--\u003e \u003cgroupId\u003ecom.example\u003c/groupId\u003e \u003cartifactId\u003eproject-name\u003c/artifactId\u003e \u003cversion\u003eV0.1\u003c/version\u003e \u003c!-- 引入依赖 --\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003ejunit\u003c/groupId\u003e \u003cartifactId\u003ejunit\u003c/artifactId\u003e \u003cversion\u003e4.11\u003c/version\u003e \u003c!-- 设置只在测试时使用，不会被打包到发布的 war/jar 包中 --\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/project\u003e 创建一套目录结构 目录 目的 ${basedir} 存放 pom.xml 和所有的子目录 ${basedir}/src/main/java 项目的 java 源代码 ${basedir}/src/main/resources 项目的资源，例如 property 文件 ${basedir}/src/test/java 项目的测试类，比如说 JUnit 代码 ${basedir}/src/test/resources 测试使用的资源 1 2 mkdir -p maven-demo/src/main/java maven-demo/src/resources mkdir -p maven-demo/src/test/java maven-demo/src/test/resources Hello Maven 在 maven-demo/src/main/java 目录下创建 HelloMaven.java\n1 2 3 4 5 6 public class HelloMaven { public static void main(String[] agrs){ System.out.println(\"Hello Maven!!\"); } } ","description":"","tags":["Maven","Java"],"title":"项目管理工具 Maven 快速入门","uri":"/posts/java/getting-start-with-maven/"},{"categories":null,"content":"Linux 创建桌面启动图标 使用 vim 命令在 Desktop 目录下创建 app-name.desktop 文件，app-name 自定义\n可参考 QQ 的桌面图标进行编写\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [Desktop Entry] Version=2.0.0-b1 Encoding=UTF-8 Name=腾讯 QQ Comment=腾讯 QQ Exec=/usr/share/tencent-qq/qq Icon=/usr/share/tencent-qq/qq.png Terminal=false Type=Application Categories=Application;Network;Tencent Software; StartupNotify=true Name[zh_CN]=腾讯 QQ GenericName[zh_CN]= Comment[zh_CN]=腾讯 QQ ","description":"","tags":["Linux"],"title":"Linux 创建桌面启动图标","uri":"/posts/linux/linux-desktop-icon/"},{"categories":null,"content":"Maven 仓库 官方文档：Introduction to Repositories\nmaven 允许通过修改 settings.xml 配置文件，以及项目中的 pom.xml 文件来改变项目所用仓库位置\nmaven 仓库分类\n本地仓库：用户本机上的仓库，用于缓存从远程仓库下载的和以及本地未发布的依赖包\n远程仓库：除了本地仓库以外的都称为远程仓库。只有项目引用了本地仓库不存在的依赖包，才会从远程仓库进行下载。（对于 SNAPSHOT 版本的依赖包，只要远程仓库有了更新，就会从远程仓库进行下载，详情参考 Maven 的 SNAPSHOT 和 RELEASE 的区别）\n中央仓库：maven 官方提供的仓库，maven 默认从该仓库下载依赖包 第三方仓库：由第三方组织提供的仓库，可以获取第三方提供的依赖包。镜像仓库也是其中的一种。 镜像仓库：通常是给中央仓库搭建的镜像，用来加快下载速度 私服：个人或公司自己搭建的，在组织内部提供服务的仓库 maven 项目对依赖包的搜索顺序，由先到后\n本地仓库：setting.xml 中通过 \u003clocalRepository\u003e 设置的 settings.xml 中的 \u003cmirror\u003e settings.xml 中的 \u003cprofile\u003e\u003crepository\u003e pom.xml 中的 \u003cprofile\u003e\u003crepository\u003e pom.xml 中的 \u003crepositories\u003e 中央仓库：maven 官方提供的仓库 maven 的配置文件\nsettings.xml：maven 应用级别的配置文件\n${user.home}/.m2/setting.xml：用户级别的配置文件，仅对当前用户生效 ${MAVEN_HOME}/conf/setting.xml：全局配置文件，对所有用户生效 如果两者都进行了配置，以用户级别的配置为准\npom.xml：maven 项目级别的配置文件，仅对当前项目生效。子 pom 会继承其父 pom 的配置。\n本地仓库 本地仓库默认是在 ${user.home}/.m2/repository，可通过修改 settings.xml 来进行修改\n1 \u003clocalRepository\u003e/path/to/local/repository\u003c/localRepository\u003e 远程仓库 pom.xml 中的 \u003crepositories\u003e 只配置 public 库\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u003cproject\u003e ... \u003crepositories\u003e \u003crepository\u003e \u003c!-- 通常 public 库是将 release、snapshot、maven center 三个库组合到一起向外提供服务的 --\u003e \u003cid\u003eintelli-public\u003c/id\u003e \u003cname\u003eintelli internal public repository\u003c/name\u003e \u003curl\u003ehttp://intelli.icu:8090/repository/maven-public/\u003c/url\u003e \u003creleases\u003e \u003c!-- 是否允许通过该仓库下载 release 版本的依赖 --\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003enever\u003c/updatePolicy\u003e \u003c/releases\u003e \u003csnapshots\u003e \u003c!-- 是否允许通过该仓库下载 snapshot 版本的依赖 --\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003ealways\u003c/updatePolicy\u003e \u003c/snapshots\u003e \u003c/repository\u003e \u003c/repositories\u003e ... \u003c/project\u003e updatePolicy 说明：依赖包的更新频率。通常 release 版本选择 never，snapshot 版本选择 always。详情可参考 Maven 的 SNAPSHOT 和 RELEASE 的区别\nalways：每次构建都进行更新 daily：每天第一次构建进行更新 interval:X：隔 X 分钟更新一次 never：从不更新。（除非本地仓库不包含所需依赖） 将 release 和 snapshot 分开配置\n除了上方的配置方式，还可以将 release，snapshot，maven center 三个库分开配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 \u003cproject\u003e ... \u003crepositories\u003e \u003c!-- 正式版本库 --\u003e \u003crepository\u003e \u003cid\u003eintelli-release\u003c/id\u003e \u003cname\u003eintelli internal release repository\u003c/name\u003e \u003curl\u003ehttp://intelli.icu:8090/repository/maven-releases/\u003c/url\u003e \u003creleases\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003enever\u003c/updatePolicy\u003e \u003c/releases\u003e \u003csnapshots\u003e \u003cenabled\u003efalse\u003c/enabled\u003e \u003c/snapshots\u003e \u003c/repository\u003e \u003c!-- 快照版本库 --\u003e \u003crepository\u003e \u003cid\u003eintelli-snapshot\u003c/id\u003e \u003cname\u003eintelli internal snapshot repository\u003c/name\u003e \u003curl\u003ehttp://intelli.icu:8090/repository/maven-snapshots/\u003c/url\u003e \u003creleases\u003e \u003cenabled\u003efalse\u003c/enabled\u003e \u003c/releases\u003e \u003csnapshots\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003ealways\u003c/updatePolicy\u003e \u003c/snapshots\u003e \u003c/repository\u003e \u003c/repositories\u003e ... \u003c/project\u003e pom.xml 中的 \u003cprofile\u003e\u003crepositories\u003e 这种方式与直接使用 \u003crepositories\u003e 对比，好处是可以通过 maven 的 profile 功能，在不同的环境使用不同的库。\u003crepositories\u003e 内部的配置二者相同。maven profile 参考 Maven 使用 Profile\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 \u003cproject\u003e ... \u003cprofiles\u003e \u003c!-- 开发环境 --\u003e \u003cprofile\u003e \u003cid\u003edev\u003c/id\u003e \u003cactivation\u003e \u003c!-- 默认激活该环境 --\u003e \u003cactiveByDefault\u003etrue\u003c/activeByDefault\u003e \u003c/activation\u003e \u003crepositories\u003e \u003crepository\u003e \u003cid\u003eintelli-public-dev\u003c/id\u003e \u003cname\u003eintelli internal public repository for dev environment\u003c/name\u003e \u003curl\u003ehttp://intelli.icu:8090/repository/maven-public-dev/\u003c/url\u003e \u003creleases\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003enever\u003c/updatePolicy\u003e \u003c/releases\u003e \u003csnapshots\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003ealways\u003c/updatePolicy\u003e \u003c/snapshots\u003e \u003c/repository\u003e \u003c/repositories\u003e \u003c/profile\u003e \u003c!-- 生产环境 --\u003e \u003cprofile\u003e \u003cid\u003eprod\u003c/id\u003e \u003crepositories\u003e \u003crepository\u003e \u003cid\u003eintelli-public-prod\u003c/id\u003e \u003cname\u003eintelli internal public repository for prod environment\u003c/name\u003e \u003curl\u003ehttp://intelli.icu:8090/repository/maven-public-prod/\u003c/url\u003e \u003creleases\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003enever\u003c/updatePolicy\u003e \u003c/releases\u003e \u003csnapshots\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003ealways\u003c/updatePolicy\u003e \u003c/snapshots\u003e \u003c/repository\u003e \u003c/repositories\u003e \u003c/profile\u003e \u003c/profiles\u003e ... \u003c/project\u003e settings.xml 中的 \u003cprofile\u003e\u003crepository\u003e 在 settings.xml 中配置 repository，与在 pom.xml 中最重要的区别就是激活环境的方式不同，其他都相同。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 \u003csettings\u003e ... \u003cprofiles\u003e \u003c!-- 开发环境 --\u003e \u003cprofile\u003e \u003cid\u003edev\u003c/id\u003e \u003crepositories\u003e \u003crepository\u003e \u003cid\u003eintelli-public-dev\u003c/id\u003e \u003cname\u003eintelli internal public repository for dev environment\u003c/name\u003e \u003curl\u003ehttp://intelli.icu:8090/repository/maven-public-dev/\u003c/url\u003e \u003creleases\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003enever\u003c/updatePolicy\u003e \u003c/releases\u003e \u003csnapshots\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003ealways\u003c/updatePolicy\u003e \u003c/snapshots\u003e \u003c/repository\u003e \u003c/repositories\u003e \u003c/profile\u003e \u003c!-- 生产环境 --\u003e \u003cprofile\u003e \u003cid\u003eprod\u003c/id\u003e \u003crepositories\u003e \u003crepository\u003e \u003cid\u003eintelli-public-prod\u003c/id\u003e \u003cname\u003eintelli internal public repository for prod environment\u003c/name\u003e \u003curl\u003ehttp://intelli.icu:8090/repository/maven-public-prod/\u003c/url\u003e \u003creleases\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003enever\u003c/updatePolicy\u003e \u003c/releases\u003e \u003csnapshots\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003cupdatePolicy\u003ealways\u003c/updatePolicy\u003e \u003c/snapshots\u003e \u003c/repository\u003e \u003c/repositories\u003e \u003c/profile\u003e \u003c/profiles\u003e \u003c!-- 激活方式和在 pom.xml 中有明显区别，其他都一样 --\u003e \u003cactiveProfiles\u003e \u003c!-- 需要激活的 profile 的 id --\u003e \u003cactiveProfile\u003eprod\u003c/activeProfile\u003e \u003c/activeProfiles\u003e ... \u003c/settings\u003e settings.xml 中的 \u003cmirror\u003e 由于网络或访问流量过大等问题，造成访问远程仓库很慢，因此将远程仓库镜像到多个地方，提升访问速度\n配置中央仓库的镜像 其中 id、url 和 mirrirOf 都是唯一的。url 是镜像仓库的地址，mirrorOf 说明对哪个仓库进行的镜像，下方的 central 表示是 maven 中央仓库的镜像。\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u003csettings\u003e ... \u003cmirrors\u003e \u003c!-- 阿里云 maven 中央仓库的镜像 --\u003e \u003cmirror\u003e \u003cid\u003ealimaven\u003c/id\u003e \u003cname\u003ealiyun maven\u003c/name\u003e \u003curl\u003ehttps://maven.aliyun.com/repository/central/\u003c/url\u003e \u003cmirrorOf\u003ecentral\u003c/mirrorOf\u003e \u003c/mirror\u003e \u003c/mirrors\u003e ... \u003c/settings\u003e 配置私服镜像 如果公司提供了私服，可以强制让 maven 只通过私服提供的服务下载依赖。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u003csettings\u003e ... \u003cmirrors\u003e \u003c!-- 私服提供的镜像 --\u003e \u003cmirror\u003e \u003cid\u003eorganization-name\u003c/id\u003e \u003cname\u003einternal nexus repository\u003c/name\u003e \u003curl\u003ehttp://nexus.intelli.icu:8090/repository/maven-public/\u003c/url\u003e \u003c!-- 所有依赖都从该镜像下载 --\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003c/mirror\u003e \u003c/mirrors\u003e ... \u003c/settings\u003e 如果使用到了 SNAPSHOT 版本，还需要添加如下配置，否则会出现查找不到 SNAPSHOT 版本 jar 包的问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 \u003csettings\u003e ... \u003cprofiles\u003e \u003cprofile\u003e \u003cid\u003epublic\u003c/id\u003e \u003c!-- 让中央仓库直接对 SNAPSHOTS 进行引导 --\u003e \u003c!-- 通过上方的 mirror 向私服发送所有的请求 --\u003e \u003crepositories\u003e \u003crepository\u003e \u003cid\u003ecentral\u003c/id\u003e \u003curl\u003ehttp://central\u003c/url\u003e \u003creleases\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003c/releases\u003e \u003csnapshots\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003c/snapshots\u003e \u003c/repository\u003e \u003c/repositories\u003e \u003cpluginRepositories\u003e \u003cpluginRepository\u003e \u003cid\u003ecentral\u003c/id\u003e \u003curl\u003ehttp://central\u003c/url\u003e \u003creleases\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003c/releases\u003e \u003csnapshots\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003c/snapshots\u003e \u003c/pluginRepository\u003e \u003c/pluginRepositories\u003e \u003c/profile\u003e \u003c/profiles\u003e \u003cactiveProfiles\u003e \u003c!-- 在任何时候都激活这个 profile --\u003e \u003cactiveProfile\u003epublic\u003c/activeProfile\u003e \u003c/activeProfiles\u003e \u003c/settings\u003e 参考 Nexus：MavenRepositories-ConfiguringApacheMaven\n分发依赖包到远程仓库 将依赖包发布到远程仓库是在项目各自的 pom.xml 中的 distributionManagement 部分进行配置。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u003cproject\u003e ... \u003cdistributionManagement\u003e \u003crepository\u003e \u003cid\u003eintelli-releases\u003c/id\u003e \u003cname\u003eintelli internal releases repository\u003c/name\u003e \u003curl\u003ehttp://intelli.icu:8090/repository/maven-releases/\u003c/url\u003e \u003c/repository\u003e \u003csnapshotRepository\u003e \u003cid\u003eintelli-snapshots\u003c/id\u003e \u003cname\u003eintelli internal snapshots repository\u003c/name\u003e \u003curl\u003ehttp://intelli.icu:8090/repository/maven-snapshots/\u003c/url\u003e \u003c/snapshotRepository\u003e \u003c/distributionManagement\u003e ... \u003c/project\u003e 配置密码 如果远程仓库设置了需要密码才能访问，需要在 settings.xml 中添加对应仓库的访问密码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u003csettings\u003e ... \u003cservers\u003e \u003c!-- 每个 server 对应一个仓库 --\u003e \u003cserver\u003e \u003c!-- id 需要和 repository/snapshotRepository 的 id 相同 --\u003e \u003cid\u003eintelli-public\u003c/id\u003e \u003c!-- 用户名 --\u003e \u003cusername\u003eadmin\u003c/username\u003e \u003c!-- 密码 --\u003e \u003cpassword\u003epassword\u003c/password\u003e \u003c/server\u003e \u003c/servers\u003e ... \u003c/settings\u003e Maven 密码加密：Password Encryption\n","description":"","tags":["Maven","Java"],"title":"Maven 仓库","uri":"/posts/java/maven-repository/"},{"categories":null,"content":"Windows 远程连接图形化 Linux 方式一：使用 xrdp 首先，需要 CentOS 已安装图像化界面（GNOME）并启动 1 2 3 4 5 # 安装 GNOME yum groupinstall \"GNOME Desktop\" \"Graphical Administration Tools\" # 启动 startx 安装 xrdp 1 yum install xrdp -y 启动 xrdp 服务 1 2 3 4 systemctl start xrdp # 设置为开机自启 systemctl enable xrdp 安装完成后，使用 Windows10 自带的远程连接即可 方式二：使用 vnc 下载 vncViewer 客户端 将 vncViewer 安装到非受控机器\nhttps://www.realvnc.com/en/connect/download/viewer/\n启动 linux 上的 vnc 服务 输入受控机器 IP 即可连接 参考文档 通过 windows 远程访问 linux 桌面的方法（简单） Linux 和 Windows 间的远程桌面访问 ","description":"","tags":["Linux"],"title":"Windows 远程连接图形化 Linux","uri":"/posts/linux/windows-remote-connect-graphical-linux/"},{"categories":null,"content":"下载安装 Synergy 下载 通过该网站下载即可\nhttps://sourceforge.net/projects/synergy-stable-builds/\n我下载的是 v1.8.8-stable.tar.gz\nSynergy 需要设置一个服务端，可以设置多个客户端，可将最常用的电脑设置为服务端。\n本教程以 Windows10 系统的电脑作为服务端，CentOS7 系统的电脑作为客户端。\nWindows 服务端安装 找到对应版本，傻瓜式安装。\n设置为服务端 选中 Server，将该电脑设置为服务端\n设置屏幕名称 依次点击编辑→设置\n弹出如下设置框，自定义一个屏幕名称，稍后会用到\n设置服务端 点击设置服务端···\n弹出如下窗口，设置服务器的屏幕名\n按下图操作，添加客户端屏幕\n启动服务端 CentOS7 客户端安装 设置为客户端 前提需要安装 GNOME 图形界面，并启动\n1 2 3 4 # 安装图形界面 yum groupinstall \"GNOME Desktop\" \"Graphical Administration Tools\" -y # 启动 startx 安装 Synergy\n1 yum install synergy-v1.8.8-stable-Linux-x86_64.rpm -y 打开 Synergy，选择作为 Client\n设置客户端屏幕名 该客户端屏幕名需与服务端设置的对应屏幕名相同\n设置为客户端，并设置服务端 IP Windows 上使用 cmd 命令 ipconfig 查看网卡信息\n以此作为服务端 IP，并选中 Client\n此处屏幕名可能不会立即改变，关闭后重启就会变成自己设置的了。\n启动客户端 ","description":"","tags":["Synergy","Computer"],"title":"下载安装 Synergy","uri":"/posts/computer/synergy-download/"},{"categories":null,"content":"SpringBoot JPA 日志打印 SQL 语句和参数 Springboot JPA 日志打印 SQL 语句和传入的参数\n在 application.properties 中添加\n1 2 3 4 logging.level.org.hibernate.SQL=debug logging.level.org.hibernate.engine.QueryParameters=debug logging.level.org.hibernate.engine.query.HQLQueryPlan=debug logging.level.org.hibernate.type.descriptor.sql.BasicBinder=trace 参考文档 Springboot JPA 日志打印 SQL 语句和传入的参数 初阶篇\n","description":"","tags":["Spring Boot","Spring Data JPA","Java"],"title":"SpringBoot JPA 日志打印 SQL 语句和参数","uri":"/posts/java/spring-boot-jpa-print-sql/"},{"categories":null,"content":"Annotation 注解 Annotation 是从 JDK1.5 之后提出的一个新的开发技术结构，利用 Annotation 可以有效的减少程序配置的代码，可以利用 Annotation 进行一些结构化的定义. Annotation 是以一种注解的形式实现的程序开发。\n如果要想清楚 Annotation 的产生意义，必须了解下程序开发结构的历史，从历史来讲\n程序开发共分为三个过程 过程一 在程序定义的时候，将所有可能使用到的资源全部定义在程序代码之中\n此方法如果数据库 IP 改变后，需要修改原代码\n过程二 引入配置文件，在配置文件中定义全部要使用的服务器资源\n在配置项不多的情况下，此类配置非常好用，十分简单。但是如果所有的项目都使用这种方式开发，可能出现配置文件暴多\n所有的操作都需要通过配置文件完成，这样对于开发的难度提升了\n过程三 将配置信息重新写回到程序里，利用一些特殊的标记与程序代码分离。\n如果全部都使用注解开发，难度太高了，配置文件也有好处也有缺点，所以现在使用注解加配置文件的形式开发。\nJava 中的内置注解 基本注解 @Override（覆盖） 检查该方法是否是重写方法。如果如果发现其父类，或者是引用的接口中并没有该方法时，会报编译错误\n1 2 3 4 5 6 7 8 package java.lang; /** * @since 1.5 */ @Target(ElementType.METHOD) @Retention(RetentionPolicy.SOURCE) public @interface Override { } 在进行覆盖时，发生如下状况，在编译时不会产生任何的错误信息\n虽然明确继承一个父类并进行方法的覆盖，但是忘记写 extends 关键字 在进行方法覆盖时单词写错了 可通过 @Override 标记在方法上，明确表示该方法是覆盖的方法，可以在编译过程中将 bug 暴露出来，保证覆盖的准确性\n示例\n1 2 3 4 5 6 7 8 9 10 class Base { void method() { } } class Sub extends Base { @Override void method() { } } @Deprecated（过期操作） 标记过时方法。如果使用该注解标记的方法，会报编译警告\n1 2 3 4 5 6 7 8 9 package java.lang; /** * @since 1.5 */ @Documented @Retention(RetentionPolicy.RUNTIME) @Target(value={CONSTRUCTOR, FIELD, LOCAL_VARIABLE, METHOD, PACKAGE, PARAMETER, TYPE}) public @interface Deprecated { } 所谓的过期操作指的是在一些软件项目的迭代过程中，可能有某个类或方法由于在最初设计时考虑不周，导致新版本的应用会有不适应的地方（老版本不影响），这个时候又不能直接删除这些操作，给一个过渡的时间，于是可以采用过期的声明，目的告诉新的用户不要使用这些操作。\n例如\n1 2 3 4 5 6 7 8 public class Date implements java.io.Serializable, Cloneable, Comparable\u003cDate\u003e { @Deprecated public Date(int year, int month, int date, int hrs, int min) { this(year, month, date, hrs, min, 0); } } @SuppressWarnings（压制警告） 指示编译器去忽略该注解中声明的警告\n1 2 3 4 5 6 7 8 9 package java.lang; /** * @since 1.5 */ @Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE, MODULE}) @Retention(RetentionPolicy.SOURCE) public @interface SuppressWarnings { String[] value(); } 可取值 说明 all to suppress all warnings（抑制所有警告） boxing to suppress warnings relative to boxing/unboxing operations（要抑制与箱/非装箱操作相关的警告） cast to suppress warnings relative to cast operations（为了抑制与强制转换操作相关的警告） dep-ann to suppress warnings relative to deprecated annotation（要抑制相对于弃用注释的警告） deprecation to suppress warnings relative to deprecation（要抑制相对于弃用的警告） fallthrough to suppress warnings relative to missing breaks in switch statements（在 switch 语句中，抑制与缺失中断相关的警告） finally to suppress warnings relative to finally block that don’t return（为了抑制警告，相对于最终阻止不返回的警告） hiding to suppress warnings relative to locals that hide variable（为了抑制本地隐藏变量的警告） incomplete-switch to suppress warnings relative to missing entries in a switch statement (enum case)（为了在 switch 语句（enum 案例）中抑制相对于缺失条目的警告） nls to suppress warnings relative to non-nls string literals（要抑制相对于非 nls 字符串字面量的警告） null to suppress warnings relative to null analysis（为了抑制与 null 分析相关的警告） rawtypes to suppress warnings relative to un-specific types when using generics on class params（在类 params 上使用泛型时，要抑制相对于非特异性类型的警告） restriction to suppress warnings relative to usage of discouraged or forbidden references（禁止使用警告或禁止引用的警告） serial to suppress warnings relative to missing serialVersionUID field for a serializable class（为了一个可串行化的类，为了抑制相对于缺失的 serialVersionUID 字段的警告） static-access to suppress warnings relative to incorrect static access（抑制与不正确的静态访问相关的警告） synthetic-access to suppress warnings relative to unoptimized access from inner classes（相对于内部类的未优化访问，来抑制警告） unchecked to suppress warnings relative to unchecked operations（相对于不受约束的操作，抑制警告） unqualified-field-access to suppress warnings relative to field access unqualified（为了抑制与现场访问相关的警告） unused to suppress warnings relative to unused code（抑制没有使用过代码的警告） 例如\n1 2 3 4 5 class Base { @SuppressWarnings({\"unused\"}) void method() { } } 元注解 注解在其他注解类上的注解，称为元注解\n@Retention 指明标识了该注解的注解的生命周期。默认值为 RetentionPolicy.CLASS。\n1 2 3 4 5 6 7 8 9 10 11 package java.lang.annotation; /** * @since 1.5 */ @Documented @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.ANNOTATION_TYPE) public @interface Retention { RetentionPolicy value(); } 可取值 说明 RetentionPolicy.SOURCE 标识了该注解的注解仅存在于编译器处理期间，编译结束后的 .class 文件中是没有该注解信息的 RetentionPolicy.CLASS 标识了该注解的注解会被记录在编译生成的 .class 文件中，但在虚拟机运行时失效 RetentionPolicy.RUNTIME 标识了该注解的注解会被记录在编译生成的 .class 文件中，在虚拟机运行时依旧存在，所以可以通过反射来进行读取 RetentionPolicy\n1 2 3 4 5 6 7 8 9 10 package java.lang.annotation; /** * @since 1.5 */ public enum RetentionPolicy { SOURCE, CLASS, RUNTIME } @Documented 指明标注了该注解的注解能够包含到 Javadoc 中去\n1 2 3 4 5 6 7 8 9 package java.lang.annotation; /** * @since 1.5 */ @Documented @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.ANNOTATION_TYPE) public @interface Documented { } @Target 指明标注了该注解的注解可以标注在那些地方，例如类，属性，方法等。\n1 2 3 4 5 6 7 8 9 10 package java.lang.annotation; /** * @since 1.5 */ @Documented @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.ANNOTATION_TYPE) public @interface Target { ElementType[] value(); } 可选值 说明 ElementType.TYPE 可标注在类，接口（包含注解类），枚举 ElementType.FIELD 可标注在字段上（包含枚举常量） ElementType.METHOD 可标注在方法上 ElementType.PARAMETER 可标注在形式参数上 ElementType.CONSTRUCTOR 可标注在构造方法上 ElementType.LOCAL_VARIABLE 可标注在局部变量上 ElementType.ANNOTATION_TYPE 可标注在注解类上 ElementType.PACKAGE 可标注在包上 ElementType.TYPE_PARAMETER since1.8，可标注在任意声明类型的地方。// TODO 不懂 ElementType.TYPE_USE since 1.8，可标注在任何使用类型的地方。例如 new，强制类型转换，implements 子句和 throws 子句。 ElementType.MODULE since9，声明模块。// TODO 不了解 ElementType\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package java.lang.annotation; /** * @since 1.5 */ public enum ElementType { TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE, ANNOTATION_TYPE, PACKAGE, TYPE_PARAMETER, TYPE_USE, MODULE } @Inherited 指明标注了该注解的注解具有继承性。例如 MyAnnotation 被标注了 @Inherited，现在一个类 Base 使用了 MyAnnotation，则它的子类 Sub 也具有 MyAnnotation 注解。\n1 2 3 4 5 6 7 8 9 10 package java.lang.annotation; /** * @since 1.5 */ @Documented @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.ANNOTATION_TYPE) public @interface Inherited { } @Repeatable 指明标注了该注解的注解，可以在其可标注的地方标注多次。\n1 2 3 4 5 6 7 8 9 10 package java.lang.annotation; /** * @since 1.8 */ @Documented @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.ANNOTATION_TYPE) public @interface Repeatable { Class\u003c? extends Annotation\u003e value(); } 例如\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) @Documented @Repeatable(MyAnnos.class) public @interface MyAnno { String[] value() default {}; } @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) @Documented public @interface MyAnnos { MyAnno[] value(); } JDK1.7 后新增非元注解 @SafeVarargs 忽略任何使用参数为泛型变量的方法或构造函数调用产生的警告\n1 2 3 4 5 6 7 8 package java.lang; /** * @since 1.7 */ @Documented @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.CONSTRUCTOR, ElementType.METHOD}) public @interface SafeVarargs {} @FunctionalInterface 标识一个匿名函数或函数式接口\n1 2 3 4 5 6 7 8 9 10 11 package java.lang; import java.lang.annotation.*; /** * @since 1.8 */ @Documented @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) public @interface FunctionalInterface {} 自定义注解 Java 中使用 @interface 声明一个类为注解\n1 2 public @interface MyAnno { } 可在其类上方标注之前介绍的元注解\n1 2 3 4 5 6 @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) @Documented public @interface MyAnno { } 可在其内部指定方法\n1 2 3 4 5 6 7 8 9 10 @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) @Documented public @interface MyAnno { // 指定注解中有一个属性 name, 没有默认值，所以在使用该注解的时候，必须给出值 String name(); // 指定注解中有一个属性 value, 默认值为 false, 在使用该注解时如果不指定，则使用默认值 boolean value() default false; } 示例\n添加自定义注解\n1 2 3 4 @MyAnno(name = \"base\") public class Base{ } 使用 Annotation 之后最大特点是可以结合反射，通过反射获取注解中的值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) @Documented public @interface MyAnno { String name(); boolean value() default false; } @MyAnno(name = \"base\") public class Base { public static void main(String[] args) { Class\u003cBase\u003e clazz = Base.class; MyAnno anno = clazz.getAnnotation(MyAnno.class); System.out.println(anno.name() + \" \" + anno.value()); } } 输出结果 base false ","description":"","tags":["Annotation","Java"],"title":"Annotation 注解","uri":"/posts/java/annotation/"},{"categories":null,"content":"Spring Boot 自定义 starters Spring Boot 基础系列目录\n介绍 starter：场景启动器\n这个场景需要使用到的依赖是什么\n如何编写自动配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 指定这个类是一个配置类 @Configuration // 在指定条件成立的条件下，自动配置类生效 @ConditionalOnXXX // 指定自动配置类的顺序 @AutoConfigureAfter // 给容器中添加组件 @Bean // 注解在相关的 xxxProperties 类上来绑定相关的配置 @ConfigurationProperties // 让 xxxProperties 生效并加入到容器中 @EnableConfigurationProperties 自动配置类要能加载 将需要启动就加载的自动配置类，配置在 /META-INF/spring.factories 中 org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\ org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\ org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration 模式\n启动器只用来做依赖导入，专门来写一个自动配置模块，启动器依赖于自动配置模块，别人只需要引入启动器(starter)即可\n启动器模块是一个空 JAR 文件，仅提供辅助性依赖管理，这些依赖可能用于自动装配或者其他类库 命名规约 官方命名空间 前缀：spring-boot-starter- 模式：spring-boot-start-模块名 举例：spring-boot-starter-web，spring-boot-starter-actuator 自定义命名空间 后缀：-spring-boot-starter 模式：模块-spring-boot-starter 举例：mybatis-spring-boot-starter 编写 starter 创建一个空工程 IDEA：File → New → Project → Empty Project\nProject name：intelli-spring-boot-starter\n创建一个 Maven 工程 IDEA：File → New → Project → Spring Initializr\nGroup：icu.intelli Artifact：intelli-spring-boot-starter-autoconfigurer Packaging：Jar Package：icu.intelli.starter 什么模块都不需要选择\n添加依赖关系 在 intelli-spring-boot-starter 项目的 pom 文件中添加\n1 2 3 4 5 6 7 8 \u003cdependencies\u003e \u003c!-- 引入自动配置模块 --\u003e \u003cdependency\u003e \u003cgroupId\u003eicu.intelli.starter\u003c/groupId\u003e \u003cartifactId\u003eintelli-spring-boot-starter-autoconfigurer\u003c/artifactId\u003e \u003cversion\u003e0.0.1-SNAPSHOT\u003c/version\u003e \u003c/dependency\u003e \u003cdependencies\u003e 此时，当我们使用我们自定义的 starter 时，会自动将该 starter 的自动配置包导入到工程中，从而该自动配置生效\n修改 intelli-sprig-boot-starter-autoconfigurer 清理多余的目录结构，保留如下即可\n修改 pom.xml，保留如下属性和依赖即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cparent\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-parent\u003c/artifactId\u003e \u003cversion\u003e1.5.10.RELEASE\u003c/version\u003e \u003crelativePath/\u003e \u003c!-- lookup parent from repository --\u003e \u003c/parent\u003e \u003cgroupId\u003eicu.intelli.starter\u003c/groupId\u003e \u003cartifactId\u003eintelli-spring-boot-starter-autoconfigurer\u003c/artifactId\u003e \u003cversion\u003e0.0.1-SNAPSHOT\u003c/version\u003e \u003cname\u003eintelli-spring-boot-starter-autoconfigurer\u003c/name\u003e \u003cdescription\u003eDemo project for Spring Boot\u003c/description\u003e \u003cproperties\u003e \u003cjava.version\u003e1.8\u003c/java.version\u003e \u003c/properties\u003e \u003cdependencies\u003e \u003c!--引入 spring-boot-starter；所有 starter 的基本配置--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter\u003c/artifactId\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/project\u003e 添加自定义 starter 的自动配置代码 添加 HelloService 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class HelloService { HelloProperties helloProperties; public HelloProperties getHelloProperties() { return helloProperties; } public void setHelloProperties(HelloProperties helloProperties) { this.helloProperties = helloProperties; } public String sayHelloCcue(String name) { return helloProperties.getPrefix() + \"-\" + name + helloProperties.getSuffix(); } } 添加 HelloProperties 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // 绑定配置文件中以 intelli.hello 开头的配置 @ConfigurationProperties(prefix = \"intelli.hello\") public class HelloProperties { private String prefix; private String suffix; public String getPrefix() { return prefix; } public void setPrefix(String prefix) { this.prefix = prefix; } public String getSuffix() { return suffix; } public void setSuffix(String suffix) { this.suffix = suffix; } } 添加 HelloServiceAutoConfiguration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Configuration // web 应用才生效 @ConditionalOnWebApplication @EnableConfigurationProperties(HelloProperties.class) public class HelloServiceAutoConfiguration { @Autowired HelloProperties helloProperties; @Bean public HelloService helloService() { HelloService service = new HelloService(); service.setHelloProperties(helloProperties); return service; } } 添加 /META-INF/spring.factories 1 2 org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ icu.intelli.starter.HelloServiceAutoConfiguration 测试 将 intelli-spring-boot-starter-autoconfigurer 和 intelli-spring-boot-starter 依次 install 到 Maven 仓库\n创建新项目测试自定义的 starter：File → New → Project → Spring Initializr\nGroup：icu.intelli Artifact：spring-boot-08-starter-test Packaging：Jar Package：icu.intelli 选中 Web 模块\nProject name：spring-boot-08-starter-test\n引入自定义的 starter\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003eicu.intelli.starter\u003c/groupId\u003e \u003cartifactId\u003eintelli-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/dependency\u003e 创建 Controller\n1 2 3 4 5 6 7 8 9 10 11 @RestController public class HelloController { @Autowired HelloService helloService; @GetMapping(\"/hello\") public String hello() { return helloService.sayHelloCcue(\"haha\"); } } 编辑配置文件\n1 2 intelli.hello.prefix=INTELLI intelli.hello.suffix=HELLO WORLD 访问 http://localhost:8080/hello，返回\nINTELLI-hahaHELLO WORLD ","description":"","tags":["Spring Boot","Java"],"title":"Spring Boot 自定义 starters","uri":"/posts/java/springboot%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97/spring-boot-customize-starters/"},{"categories":null,"content":"https://blog.csdn.net/zt15732625878/article/details/86493096\n","description":"","tags":["Keepalived"],"title":"keepalived 指定配置文件位置","uri":"/posts/keepalived/keepalived-config/"},{"categories":null,"content":"Keepalived+Nginx 高可用 简介 keepalived 介绍 官方说明\nKeepalived 是 C 语言编写的路由软件。该项目的主要目标是为 Linux 系统（和基于 Linux 的基础结构的系统）的负载均衡和高可用提供简单和健壮的设施。负载均衡框架依赖知名并被广泛应用的 Linux Virtual Server(IPVS) 核心模块，提供第 4 层的负载均衡。Keepalived 实现了一组检查器，根据服务器的健康状态，自适应维护和管理负载均衡服务池。另一方面，通过 VRRP 协议实现高可用。VRRP 是路由故障转移的根本。另外，Keepalived 实现了一组搭载了 VRRP 的有限状态机，提供低级别和高速的协议交互。为了提供快速的网络故障发现能力，Keepalived 实现了 BFD 协议。VRRP 状态转换可以根据 BFD 的提示加快状态转换。Keepalived 框架可以独立使用也可以多个一起使用，以提供弹性基础架构。\n双机高可用的两种方法 Nginx+keepalived 双机 主从 模式：即前端使用两台服务器，一台主服务器和一台热备服务器，正常情况下，主服务器绑定一个公网虚拟 IP，提供负载均衡服务，热备服务器处于空闲状态；当主服务器发生故障时，热备服务器接管主服务器的公网虚拟 IP，提供负载均衡服务；但是热备服务器在主机器不出现故障的时候，永远处于浪费状态，对于服务器不多的网站，该方案不经济实惠。\nNginx+keepalived 双机 主主 模式： 即前端使用两台负载均衡服务器，互为主备，且都处于活动状态，同时各自绑定一个公网虚拟 IP，提供负载均衡服务；当其中一台发生故障时，另一台接管发生故障服务器的公网虚拟 IP（这时由非故障机器一台负担所有的请求）。这种方案，经济实惠，非常适合于当前架构环境。\n架构及说明 Nginx+Keepalived 双机 主从模式 设备 IP 说明 master 主机 192.168.64.129 master 机器，CentOS7.6_X64 backup 主机 192.168.64.130 backup 机器，CentOS7.6_X64 VIP 192.168.64.128 虚拟 IP（飘移 IP） VIP 是一个对外提供访问的虚拟 IP，可自定义，不需要提供真实机器\nKeepalived 及 Nginx安装 安装依赖\n此处防止出错，将官方展示的依赖包全部安装\n1 yum install -y make autoconf automake openssl-devel libnl3-devel ipset-devel iptables-devel file-devel net-snmp-devel glib2-devel json-c-devel pcre2-devel libnftnl-devel libmnl-devel python-sphinx epel-release python-sphinx_rtd_theme latexmk texlive texlive-titlesec texlive-framed texlive-threeparttable texlive-wrapfig texlive-multirow 下载源码压缩包\n1 2 wget https://www.keepalived.org/software/keepalived-2.0.19.tar.gz wget https://nginx.org/download/nginx-1.9.9.tar.gz 安装 Keepalived\nKeepalived 官方安装说明\nkeepalived 默认安装位置 /usr/local/keepalived\n1 2 3 4 5 $ tar -zxvf keepalived-2.0.19.tar.gz $ cd keepalived-2.0.19 $ ./configure $ make $ make install 安装 Nginx\nNginx 官方安装说明\nNginx 默认安装位置 /usr/local/nginx\n1 2 3 4 5 $ tar -zxvf nginx-1.9.9.tar.gz $ cd nginx-1.9.9 $ ./configure $ make $ make install 配置 Nginx Nginx 默认配置文件位置：/usr/local/nginx/conf/nginx.conf\n以下仅提供最基本的测试配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # 需指定运行 nginx 的用户，默认是 nobody user root; # 指定工作进程的数量 worker_processes 1; events { worker_connections 1024; } http { # 定义 upstream 实现负载均衡，可省略 #upstream upstream-name { #server xx.xx.xx.xx:8000; #server xx.xx.xx.xx:port; #} server { # 指定 nginx 监听主机的 80 端口 listen 80; # 拦截 /test 开头的请求，例如：http://localhost:80/test/test.json location /test { # 示例请求会返回主机的 /root/test 目录查找 test.json 文件 root /root; } # 拦截所有请求，将请求路由到 upstream 中定义的服务器上 #location / { #proxy_pass http://upstream-name; # 反向代理不改变请求头的信息 #proxy_set_header Host $http_host; #} } } 在 /root 目录下创建 /test/test.json 文件，内容可以为各自主机的地址，用于测试主机 keepalived 关闭后，VIP 是否会飘移到备用主机。\n1 2 3 4 5 6 7 8 9 129 机器的 test.json { \"message\" : \"This Is Master-129\" } 130 备用机器的 test.json { \"message\" : \"This Is Backup-130\" } nginx 启动命令默认在如下位置， 启动 nginx\n1 /usr/local/nginx/sbin/nginx 此时访问 http://192.168.64.129:80/test/test.json 会返回 {\"message\" : \"This Is Master-129}\"，访问 http://192.168.64.130:80/test/test.json 会返回 {\"message\" : \"This Is Backup-130\"}\n配置 Keepalived keepalived 默认的配置文件放在 /usr/local/etc/keepalived/keepalived.conf，需要将配置文件放在 /etc/keepalived/keepalived.conf 才可以成功启动/关闭 keepalived 服务，可将如下的配置文件直接放在 /etc/keepalived 目录下\nmaster-129 主机的配置\n由于未部署 sendmail，已将相关配置注释，如需部署可参考 linux下sendmail邮件系统安装操作记录\n! Configuration File for keepalived #全局定义 global_defs { #notification_email { #指定keepalived在发生事件时（比如切换）发送通知邮件的邮箱 # xiaochong@then.com #设置报警邮件地址，可以设置多个，每行一个。 需开启本机的sendmail服务 #} #notification_email_from xiaochong@then.com #keepalived在发生诸如切换操作时需要发送email通知地址 #smtp_server 127.0.0.1 #指定发送email的smtp服务器 #smtp_connect_timeout 30 #设置连接smtp server的超时时间 router_id HAmaster-129 #运行keepalived的机器的一个标识，通常可设为hostname。故障发生时，发邮件时显示在邮件主题中的信息。 } vrrp_script chk_http_port { #检测nginx服务是否在运行。有很多方式，比如进程，用脚本检测等等 script \"/root/software/chk_nginx.sh\" #这里通过脚本监测 interval 2 #脚本执行间隔，每2s检测一次 weight -5 #脚本结果导致的优先级变更，检测失败（脚本返回非0）则优先级 -5 fall 2 #检测连续2次失败才算确定是真失败。会用weight减少优先级（1-255之间） rise 1 #检测1次成功就算成功。但不修改优先级 } vrrp_instance VI_1 { #keepalived在同一virtual_router_id中priority（0-255）最大的会成为master，也就是接管VIP，当priority最大的主机发生故障后次priority将会接管 state MASTER #指定keepalived的角色，MASTER表示此主机是主服务器，BACKUP表示此主机是备用服务器。注意这里的state指定instance（Initial）的初始状态，就是说在配置好后，这台服务器的初始状态就是这里指定的，但这里指定的不算，还是得要通过竞选通过优先级来确定。如果这里设置为MASTER，但如若他的优先级不及另外一台，那么这台在发送通告时，会发送自己的优先级，另外一台发现优先级不如自己的高，那么他会就回抢占为MASTER interface ens33 #指定HA监测网络的接口。实例绑定的网卡，因为在配置虚拟IP的时候必须是在已有的网卡上添加的 mcast_src_ip 192.168.64.129 # 发送多播数据包时的源IP地址，这里注意了，这里实际上就是在哪个地址上发送VRRP通告，这个非常重要，一定要选择稳定的网卡端口来发送，这里相当于heartbeat的心跳端口，如果没有设置那么就用默认的绑定的网卡的IP，也就是interface指定的IP地址 virtual_router_id 51 #虚拟路由标识，这个标识是一个数字，同一个vrrp实例使用唯一的标识。即同一vrrp_instance下，MASTER和BACKUP必须是一致的 priority 101 #定义优先级，数字越大，优先级越高，在同一个vrrp_instance下，MASTER的优先级必须大于BACKUP的优先级 advert_int 1 #设定MASTER与BACKUP负载均衡器之间同步检查的时间间隔，单位是秒 authentication { #设置验证类型和密码。主从必须一样 auth_type PASS #设置vrrp验证类型，主要有PASS和AH两种 auth_pass 1111 #设置vrrp验证密码，在同一个vrrp_instance下，MASTER与BACKUP必须使用相同的密码才能正常通信 } virtual_ipaddress { #VRRP HA 虚拟地址 如果有多个VIP，继续换行填写 192.168.64.128 } track_script { #执行监控的服务。注意这个设置不能紧挨着写在vrrp_script配置块的后面（实验中碰过的坑），否则nginx监控失效!! chk_http_port #引用VRRP脚本，即在 vrrp_script 部分指定的名字。定期运行它们来改变优先级，并最终引发主备切换。 } } backup-130 备用主机的配置\n! Configuration File for keepalived global_defs { #notification_email { #\txiaochong@then.com #\t10997173638883@qq.com #} #notification_email_from xiaochong@then.com #smtp_server 127.0.0.1 #smtp_connect_timeout 30 router_id HAbackup-130 } vrrp_script chk_http_port { script \"/root/software/chk_nginx.sh\" interval 2 weight -5 fall 2 rise 1 } vrrp_instance VI_1 { state BACKUP interface ens33 mcast_src_ip 192.168.64.130 virtual_router_id 51 priority 99 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.64.128 } track_script { chk_http_port } } 测试 经过前面的配置，如果 master 主服务器的 keepalived 停止服务，backup 备用服务器会自动接管 VIP 对外服务；一旦 master 主服务器的 keepalived 恢复，会重新接管 VIP。\n分别启动主备服务器上的 keepalived 和 nginx\n1 2 systemctl start keepalived /nginx/path/sbin/nginx -c /nginx/path/conf/nginx.conf 使用 ip addr 命令，查看 master 主服务器的网卡信息，发现 ens33 中包含 VIP 的信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [root@localhost keepalived]# ip addr 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:0d:99:c1 brd ff:ff:ff:ff:ff:ff inet 192.168.64.129/24 brd 192.168.64.255 scope global noprefixroute dynamic ens33 valid_lft 1738sec preferred_lft 1738sec inet 192.168.64.128/32 scope global ens33 valid_lft forever preferred_lft forever inet6 fe80::ec49:90d1:6713:bc21/64 scope link noprefixroute valid_lft forever preferred_lft forever 使用 ip addr 命令，查看 backup 备用服务器的网卡信息，ens33 网卡中不包含 VIP 的信息\n1 2 3 4 5 6 7 8 9 10 11 12 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:e2:e8:ec brd ff:ff:ff:ff:ff:ff inet 192.168.64.130/24 brd 192.168.64.255 scope global noprefixroute dynamic ens33 valid_lft 1654sec preferred_lft 1654sec inet6 fe80::a458:734d:1f98:9472/64 scope link noprefixroute valid_lft forever preferred_lft forever 测试访问 http://192.168.64.128:80/test/test.json，返回\n1 2 3 { \"message\" : \"This Is Master-129.\" } 请求被主服务器 master 处理\n关闭 master 主服务器的 keepalived 服务，使用 ip addr 再次查看，已不存在 VIP\n1 2 3 4 5 6 7 8 9 10 11 12 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:0d:99:c1 brd ff:ff:ff:ff:ff:ff inet 192.168.64.129/24 brd 192.168.64.255 scope global noprefixroute dynamic ens33 valid_lft 1521sec preferred_lft 1521sec inet6 fe80::ec49:90d1:6713:bc21/64 scope link noprefixroute valid_lft forever preferred_lft forever 使用 ip addr 查看 backup 备用服务器，VIP 已经飘移到该服务器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:e2:e8:ec brd ff:ff:ff:ff:ff:ff inet 192.168.64.130/24 brd 192.168.64.255 scope global noprefixroute dynamic ens33 valid_lft 1463sec preferred_lft 1463sec inet 192.168.64.128/32 scope global ens33 valid_lft forever preferred_lft forever inet6 fe80::a458:734d:1f98:9472/64 scope link noprefixroute valid_lft forever preferred_lft forever 测试访问 http://192.168.64.128:80/test/test.json，返回\n1 2 3 { \"message\" : \"This Is Backup-130.\" } 请求已被备用服务器backup接管\n使用 keepalived 监控 Nginx 状态 以上已完成基本的 keepalived+nginx 的配置和测试，为保证系统稳定性，我们需要当 Nginx 服务停止后，Keepalived 可以自动启动 Nginx 服务，如果启动失败，则将 keepalived 也停止，将请求交由其他备用服务器处理.\nkeepalived 支持配置监控脚本，可以通过脚本监控 Nginx 服务的状态.\n监控 Nginx 状态的三种方式\n最简单的做法是监控 Nginx 进程 更靠谱的做法是检查 Nginx 端口 最靠谱的方法是检查多个 url 能否获取到页面 keepalived 配置文件的 vrrp_script chk_http_port 中的 script 一般有两种写法，分别对应监控进程和监控端口，当前使用的配置方式是监控端口的方式，可以直接查看监控端口的方式\n监控进程的方式 keepalived 通过脚本执行的返回结果，改变 vrrp_instance 的优先级（priority），然后继续发送通告消息，backup 比较优先级再决定是否抢占 IP。\n1 2 3 4 5 需要安装 psmisc 软件包，并将配置文件中的 script \"/root/software/chk_nginx.sh\" 修改为 script \"killall -0 nginx\" 如果 nginx 进程存在返回 0，否则返回 1 优先级的改变策略\n如果脚本执行结果为 0，并且 weight 配置的值大于 0，则优先级相应的增加 如果脚本执行结果非 0，并且 weight 配置的值小于 0，则优先级相应的减少 其他情况，原本配置的优先级不变，即配置文件中 priority 对应的值。 优先级的范围在 [1, 254]，不会一直升高或减小，可以编写多个检测脚本并为每个检测脚本设置不同的 weight（在配置中列出就行）\n在 master 节点的 vrrp_instance 中 配置 nopreempt，当它异常恢复后，即使它 priority 更高也不会抢占，这样可以避免正常情况下做无谓的切换。\n监控端口的方式 手动在脚本里面检测是否有异常情况，如果有直接关闭 keepalived 进程，backup 机器接收不到 advertisement 则会抢占 IP。\n脚本文件 chk_nginx.sh 如下，需要修改启动 nginx 和停止 keepalived 的代码\n1 2 3 4 5 6 7 8 9 10 11 counter=$(ps -C nginx --no-heading|wc -l) echo \"current nginx : $counter\" if [ \"${counter}\" = \"0\" ]; then /nginx/path/sbin/nginx -c /nginx/path/conf/nginx.conf sleep 2 counter=$(ps -C nginx --no-heading|wc -l) echo \"after start nginx : $counter\" if [ \"${counter}\" = \"0\" ]; then systemctl stop keepalived fi fi 修改脚本文件权限\n1 $ chmod 755 chk_nginx.sh 该脚本检查 nginx 服务是否存在（counter\u003e0），如果不存在（counter=0）启动之，并在 2 秒后重新检查，如果启动失败，则停止 keepalived 服务，此时备用服务器将抢占 VIP。\n检测keepalived是否会启动nginx 关闭 nginx，会发现最多 2s 后，nginx 就会重新启动\n双机 双主模式 只需修改配置文件即可，增加新的 VIP：192.168.64.127，192.168.64.128 是 129 机器上主虚拟 VIP，192.168.64.127 是 130 机器上主虚拟 VIP\n129 的 keepalived 配置文件，在最后一行添加\nvrrp_instance VI_2 { state BACKUP interface ens33 virtual_router_id 52 priority 90 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.139.127 } } 130 的 keepalived 配置文件，在最后一行添加\nvrrp_instance VI_2 { state MASTER interface ens33 virtual_router_id 52 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.139.127 } } 参考文档 Nginx+keepalived 高可用双机热备（主从模式/双主模式）\n","description":"","tags":["Keepalived","Nginx"],"title":"Keepalived+Nginx 高可用","uri":"/posts/keepalived/keepalived-with-nginx-hign-availability/"},{"categories":null,"content":"Disable SerializationFeature.FAIL_ON_EMPTY_BEANS 错误提示 com.fasterxml.jackson.databind.exc.InvalidDefinitionException: No serializer found for class org.hibernate.proxy.pojo.bytebuddy.ByteBuddyInterceptor and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) (through reference chain: icu.intelli.springboot.entity.User$HibernateProxy$sPsvljjm[\"hibernateLazyInitializer\"])\n出错原因 使用 SpringBoot 2.2.2 整合 JPA 时，调用 userRepository.getOne(id) 方法时，出的错\n解决办法 方法一 在实体类上添加如下注解\n1 @JsonIgnoreProperties(value = {\"handler\",\"hibernateLazyInitializer\",\"fieldHandler\"}) 方法二 注册一个 objectMapper 覆盖掉默认的，这样就不用在每个类上面使用 @JsonIgnoreProperties\n1 2 3 4 5 6 @Bean public ObjectMapper objectMapper() { return new ObjectMapper().disable(SerializationFeature.FAIL_ON_EMPTY_BEANS); } // ObjectMapper 为 com.fasterxml.jackson.databind.ObjectMapper; 方法三 不使用 SpringBoot 默认的 jackson 进行对象 json 化，手动使用其他 json 框架如 fastJson 进行 json 化然后返回\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e \u003cartifactId\u003efastjson\u003c/artifactId\u003e \u003cversion\u003e1.2.47\u003c/version\u003e \u003c/dependency\u003e 参考文档 Disable SerializationFeature.FAIL_ON_EMPTY_BEANS\n","description":"","tags":["Exception","Java"],"title":"Disable SerializationFeature.FAIL_ON_EMPTY_BEANS","uri":"/posts/java/disable-serialization-feature-fail-on-empty-beans/"},{"categories":null,"content":"Spring Boot 启动配置原理 Spring Boot 基础系列目录\nSpringBoot 1.5.9 版本\n几个重要的事件回调机制 配置在 META-INF/spring.factories\nApplicationContextInitializer SpringApplicationRunListener 只需要放在 IOC 容器中的\nApplicationRunner CommandLineRunner 启动流程 创建 SpringApplication 对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 initialize(sources) private void initialize(Object[] sources) { // 保存主配置类 if (sources != null \u0026\u0026 sources.length \u003e 0) { this.sources.addAll(Arrays.asList(sources)); } // 判断当前应用是否是 web 应用 this.webEnvironment = deduceWebEnvironment(); // 从类路径下找到 META-INF/spring.factories 配置的所有 ApplicationContestInitializer 并保存起来 setInitializers((Collection) getSpringFactoriesInstances( ApplicationContextInitializer.class)); // 从类路径下找到 META-INF/spring.factories 配置的所有 ApplicationListener 并保存起来 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); // 从多个配置类中找到有 main 方法的主配置类 this.mainApplicationClass = deduceMainApplicationClass(); } 运行 run 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 public ConfigurableApplicationContext run(String... args) { // 开始和停止的监听 StopWatch stopWatch = new StopWatch(); stopWatch.start(); // 空的 IOC 容器 ConfigurableApplicationContext context = null; FailureAnalyzers analyzers = null; // 与做 awt 应用相关的 configureHeadlessProperty(); // 获取 SpringApplicationRunListener；从类路径下 META-INF/spring.factories 中获取所有的监听器 SpringApplicationRunListeners listeners = getRunListeners(args); // 回调所有的 SpringApplicationRunListener 的 starting 方法 listeners.starting(); try { // 封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); // 准备环境 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); // 创建环境完成后回调 SpringApplicationRunListener 的 environmentPrepared(environment); 表示环境准备完成 Banner printedBanner = printBanner(environment); // 创建 ApplicationContext，决定创建 Web 的 IOC 还是普通的 IOC context = createApplicationContext(); analyzers = new FailureAnalyzers(context); // 准备上下文环境，将 environment 保存到 ioc 中，而且 applyInitializers(context) // applyInitializers：回调之前保存的所有 ApplicationContestInitializer 的所有 initialize 方法 // 回调所有 ApplicationListener 的 contextPrepared(context) 方法 prepareContext(context, environment, listeners, applicationArguments, printedBanner); // prepareContext 运行完成以后回调所有 ApplicationListener 的 contextLoaded() 方法 // 刷新容器：ioc 容器初始化的过程，如果是 web 应用还会创建嵌入式的 Tomcat // 扫描，创建，加载所有组件的地方(配置类，组件，自动配置等均在这添加到容器) refreshContext(context); // 从 ioc 容器中获取所有的 ApplicationRunner 和 CommandLineRunner 进行回调 // ApplicationRunner 先回调，CommandLineRunner 再回调 afterRefresh(context, applicationArguments); // 所有的 SpringApplicationRunListener 回调 finished 方法 listeners.finished(context, null); stopWatch.stop(); if (this.logStartupInfo) { new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); } // 整个 SpringBoot 应用启动完成后返回启动的 IOC 容器 return context; } catch (Throwable ex) { handleRunFailure(context, listeners, analyzers, ex); throw new IllegalStateException(ex); } } 总结\nrun() 准备环境 执行 ApplicationContextInitializer.initialize() 监听器 SpringApplicationRunListener 回调 contextPrepared 加载主配置类定义信息 监听器 SpringApplicationRunListener 回调 contextLoaded 刷新启动 IOC 容器 扫描加载所有容器中的组件 包括从/META-INF/spring.factories 中获取所有的 EnableAutoConfiguration 组件 回调容器中所有的 ApplicationRunner，CommandLineRunner 的 run 方法 监听器 SpringApplicationRunListener 回调 finished 事件监听机制 1. 创建实现 ApplicationContextInitializer 接口的类\n1 2 3 4 5 6 public class HelloApplicationContextInitialier implements ApplicationContextInitializer\u003cConfigurableApplicationContext\u003e { @Override public void initialize(ConfigurableApplicationContext applicationContext) { System.out.println(\"HelloApplicationContextInitialier...initialize...\" + applicationContext); } } 2. 创建实现 SpringApplicationRunListener 接口的类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public class HelloSpringApplicationRunListener implements SpringApplicationRunListener { @Override public void starting() { System.out.println(\"HelloSpringApplicationRunListener...strting...\"); } @Override public void environmentPrepared(ConfigurableEnvironment environment) { Object o = environment.getSystemProperties().get(\"os.name\"); System.out.println(\"HelloSpringApplicationRunListener...environmentPrepared...\" + o); } @Override public void contextPrepared(ConfigurableApplicationContext context) { System.out.println(\"HelloSpringApplicationRunListener...contextPrepared...\"); } @Override public void contextLoaded(ConfigurableApplicationContext context) { System.out.println(\"HelloSpringApplicationRunListener...contextLoaded...\"); } @Override public void finished(ConfigurableApplicationContext context, Throwable exception) { System.out.println(\"HelloSpringApplicationRunListener...finished...\"); } } 3. 创建实现 ApplicationRunner 接口的类，并将其添加到容器中\n1 2 3 4 5 6 7 @Component public class HelloApplicationRunner implements ApplicationRunner { @Override public void run(ApplicationArguments args) throws Exception { System.out.println(\"ApplicationArguments...run...\"); } } 4. 创建实现 CommandLineRunner 接口的类，并将其添加到容器中\n1 2 3 4 5 6 7 @Component public class HelloCommandLineRunner implements CommandLineRunner { @Override public void run(String... args) throws Exception { System.out.println(\"HelloCommandLineRunner...run...\"); } } 5. 在根目录下创建 /META-INFO/spring.factories，配置自定义的 SpringApplicationRunListener 和 ApplicationContextInitializer\n1 2 3 4 5 org.springframework.boot.SpringApplicationRunListener=\\ icu.intelli.listener.HelloSpringApplicationRunListener org.springframework.context.ApplicationContextInitializer=\\ icu.intelli.listener.HelloApplicationContextInitialier 6. 启动 SpringBoot 应用会报错\nException in thread \"main\" java.lang.IllegalArgumentException: Cannot instantiate interface org.springframework.boot.SpringApplicationRunListener : icu.intelli.listener.HelloSpringApplicationRunListener xxxxxxxxx Caused by: java.lang.NoSuchMethodException: icu.intelli.listener.HelloSpringApplicationRunListener.\u003cinit\u003e(org.springframework.boot.SpringApplication, [Ljava.lang.String;) xxxxxxxxx 需要在 HelloSpringApplicationRunListener 中添加一个有参的构造，可以参照 SpringApplicationRunListener 接口的其他实现类\n7. 在 HelloSpringApplicationRunListener 中添加有参构造\n1 public HelloSpringApplicationRunListener(SpringApplication application, String[] args) {} 8. 重新启动 SpringBoot 应用\n","description":"","tags":["Spring Boot","Java"],"title":"Spring Boot 启动配置原理","uri":"/posts/java/springboot%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97/spring-boot-startup-principle/"},{"categories":null,"content":"Spring Boot 与数据访问 Spring Boot 基础系列目录\n简介 对于数据访问层，无论是 SQL 还是 NOSQL，SpringBoot 默认采用整合 Spring Data 的方式进行统一处理，添加大量自动配置，屏蔽了很多设置。引入各种 xxxTemplate，xxxRepository 来简化我们对数据访问层的操作。对我们来说只需要进行简单的设置即可。我们将在数据访问章节测试使用 SQL 相关，NOSQL 在缓存、消息、检索等章节测试\nJDBC MyBatis JPA spring-boot-starter-data-xxx\n整合基本 JDBC 与数据源 JDBC pom.xml\n1 2 3 4 5 6 7 8 9 10 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-jdbc\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003emysql\u003c/groupId\u003e \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e \u003cscope\u003eruntime\u003c/scope\u003e \u003c/dependency\u003e application.yml\n1 2 3 4 5 6 spring: datasource: username: root password: Root1234 url: jdbc:mysql://39.105.30.251:3306/jdbc driver-class-name: com.mysql.jdbc.Driver Controller\n1 2 3 4 5 6 7 8 9 10 11 12 13 @Controller public class HelloController { @Autowired JdbcTemplate jdbcTemplate; @ResponseBody @GetMapping(\"/query\") public Map\u003cString, Object\u003e map(){ List\u003cMap\u003cString, Object\u003e\u003e list = jdbcTemplate.queryForList(\"select * from department\"); return list.get(0); } } 1.x 版本默认使用 org.apache.tomcat.jdbc.pool.DataSource 数据源，2.x 版本默认使用 com.zaxxer.hikari.HikariDataSource 数据源\n数据源的相关配置都在 DataSourceProperties 类中\n1.x 自动配置原理\norg.springframework.boot.autoconfigure.jdbc\n参考 DataSourceConfiguration，根据配置创建数据源，默认使用 Tomcat 连接池，可以使用 spring.datasource.type 指定自定义的数据源类型\nSpringBoot 默认可以支持\n1 org.apache.tomcat.jdbc.pool.DataSource, HikariDataSource, BasicDataSource 自定义数据源类型\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /** * Generic DataSource configuration. */ @Configuration(proxyBeanMethods = false) @ConditionalOnMissingBean(DataSource.class) @ConditionalOnProperty(name = \"spring.datasource.type\") static class Generic { @Bean DataSource dataSource(DataSourceProperties properties) { // 使用 DataSourceBuilder 创建数据源，利用反射创建相应 type 的数据源，并且绑定相关属性 return properties.initializeDataSourceBuilder().build(); } } DataSourceInitializer：ApplicationListener\n作用 runSchemaScripts() 运行建表语句; runDataScripts() 运行插入数据的 sql 语句; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 默认只需要将文件命名为 schema-*.sql(建表), data-*.sql(插入数据) # 默认规则：schema.sql, schema-all.sql # 可以使用 spring: datasource: username: root password: Root1234 url: jdbc:mysql://39.105.30.251:3306/jdbc driver-class-name: com.mysql.jdbc.Driver schema: - classpath: department.sql # 指定配 sql 的位置 # SpringBoot2.x 版本需要添加 spring: datasource: initialization-mode: always 操作数据库：自动配置了 jdbcTemplate 操作数据库\n使用 druid 使用 http://localhost:8080/druid 登录 druid 控制台\n方式一：使用 com.alibaba.druid 环境\nSpringBoot 1.5.9 druid 1.1.8\n引入 druid 数据源\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e \u003cartifactId\u003edruid\u003c/artifactId\u003e \u003cversion\u003e1.1.8\u003c/version\u003e \u003c/dependency\u003e 配置 druid 数据源\napplication.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 spring: datasource: username: root password: 123456 url: jdbc:mysql://192.168.15.22:3306/jdbc driver-class-name: com.mysql.jdbc.Driver type: com.alibaba.druid.pool.DruidDataSource initialSize: 5 minIdle: 5 maxActive: 20 maxWait: 60000 timeBetweenEvictionRunsMillis: 60000 minEvictableIdleTimeMillis: 300000 validationQuery: SELECT 1 FROM DUAL testWhileIdle: true testOnBorrow: false testOnReturn: false poolPreparedStatements: true # 配置监控统计拦截的 filters，去掉后监控界面 sql 无法统计，'wall' 用于防火墙 filters: stat,wall,log4j maxPoolPreparedStatementPerConnectionSize: 20 useGlobalDataSourceStat: true connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500 此时，配置是不生效的 需要添加配置类\nDruidConfig.java\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 @Configuration public class DruidConfig { @ConfigurationProperties(prefix = \"spring.datasource\") @Bean public DataSource druid(){ return new DruidDataSource(); } //配置 Druid 的监控 //1、配置一个管理后台的 Servlet @Bean public ServletRegistrationBean statViewServlet(){ ServletRegistrationBean bean = new ServletRegistrationBean(new StatViewServlet(), \"/druid/*\"); Map\u003cString,String\u003e initParams = new HashMap\u003c\u003e(); initParams.put(\"loginUsername\",\"admin\"); initParams.put(\"loginPassword\",\"123456\"); // 默认就是允许所有访问 initParams.put(\"allow\",\"\"); initParams.put(\"deny\",\"192.168.15.21\"); bean.setInitParameters(initParams); return bean; } //2、配置一个 web 监控的 filter @Bean public FilterRegistrationBean webStatFilter(){ FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); Map\u003cString,String\u003e initParams = new HashMap\u003c\u003e(); initParams.put(\"exclusions\",\"*.js,*.css,/druid/*\"); bean.setInitParameters(initParams); bean.setUrlPatterns(Arrays.asList(\"/*\")); return bean; } } 方式二：使用 druid-spring-boot-starter SpringBoot 2.2.2 druid-spring-boot-starter 1.1.10\n添加依赖\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e \u003cartifactId\u003edruid-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e1.1.10\u003c/version\u003e \u003c/dependency\u003e 配置 application.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 spring: application: name: springboot-test-exam1 datasource: # 使用阿里的 Druid 连接池 type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver # 填写你数据库的 url、登录名、密码和数据库名 url: jdbc:mysql://localhost:3306/databaseName?useSSL=false\u0026characterEncoding=utf8 username: root password: root druid: # 连接池的配置信息 # 初始化大小，最小，最大 initial-size: 5 min-idle: 5 maxActive: 20 # 配置获取连接等待超时的时间 maxWait: 60000 # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 timeBetweenEvictionRunsMillis: 60000 # 配置一个连接在池中最小生存的时间，单位是毫秒 minEvictableIdleTimeMillis: 300000 validationQuery: SELECT 1 testWhileIdle: true testOnBorrow: false testOnReturn: false # 打开 PSCache，并且指定每个连接上 PSCache 的大小 poolPreparedStatements: true maxPoolPreparedStatementPerConnectionSize: 20 # 配置监控统计拦截的 filters，去掉后监控界面 sql 无法统计，'wall' 用于防火墙 filters: stat,wall,slf4j # 通过 connectProperties 属性来打开 mergeSql 功能；慢 SQL 记录 connectionProperties: druid.stat.mergeSql\\=true;druid.stat.slowSqlMillis\\=5000 # 配置 DruidStatFilter web-stat-filter: enabled: true url-pattern: \"/*\" exclusions: \"*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*\" # 配置 DruidStatViewServlet stat-view-servlet: url-pattern: \"/druid/*\" # IP 白名单(没有配置或者为空，则允许所有访问) allow: 127.0.0.1,192.168.163.1 # IP 黑名单 (存在共同时，deny 优先于 allow) deny: 192.168.1.73 # 禁用 HTML 页面上的“Reset All”功能 reset-enable: false # 登录名 login-username: admin # 登录密码 login-password: 123456 更多版本查看，见 Maven 仓库\n更多参数说明，见 官方文档\n整合 MyBatis 添加 mybatis 依赖\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003eorg.mybatis.spring.boot\u003c/groupId\u003e \u003cartifactId\u003emybatis-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e2.1.1\u003c/version\u003e \u003c/dependency\u003e 配置 druid 数据源及配置文件\n详情参照 [使用 druid](#使用 druid)\n建立数据表\n1 2 3 4 5 6 7 spring: datasource: schema: - classpath:sql/department.sql - classpath:sql/employee.sql # SpringBoot2.x 版本需要添加下面配置 initialization-mode: always 创建 java bean 略\nMybatis 注解版 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 指定这是一个操作数据库的 mapper @Mapper public interface DepartmentMapper { @Select(\"SELECT * FROM department WHERE id=#{id}\") Department getDeptById(Integer id); @Delete(\"DELETE FROM department WHERE id=#{id}\") int deleteDeptById(Integer id); // 插入后返回主键 @Options(useGeneratedKeys = true, keyProperty = \"id\") @Insert(\"INSERT INTO department(departmentName) VALUES(#{departmentName})\") int insertDept(Department department); @Update(\"UPDATE department SET departmentName=#{departmentName} WHERE id=#{id}\") int updateDept(Department department); } 自定义 MyBatis 的配置规则，给容器中添加一个 ConfigurationCustomizer\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Configuration public class MyBatisConfig { @Bean public ConfigurationCustomizer configurationCustomizer() { return new ConfigurationCustomizer() { @Override public void customize(Configuration configuration) { // 自动将数据库中 dept_name 映射为 bean 中的 deptName configuration.setMapUnderscoreToCamelCase(true); } }; } } 使用 @MapperScan 扫描指定包下的所有 Mapper，就不用在每个 xxxMapper 接口上标注 @Mapper 注解了\n1 2 3 4 5 6 7 8 9 // 标注在 SpringBoot 主程序上 @MapperScan(value = \"icu.intelli.springboot.mapper\") @SpringBootApplication public class Application { // 或者 MyBatis 的自定义配置类上 @MapperScan(value = \"icu.intelli.springboot.mapper\") @org.springframework.context.annotation.Configuration public class MyBatisConfig { Mybatis 配置文件版 mapper.java\n1 2 3 4 5 6 7 // 无论是注解还是配置文件方式，都要使用 @Mapper 或者 @MapperScan 将接口扫描装配到容器中 public interface EmployeeMapper { Employee getEmpById(Integer id); void insertEmp(Employee employee); } mapper.xml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"\u003e \u003cmapper namespace=\"icu.intelli.springboot.mapper.EmployeeMapper\"\u003e \u003cselect id=\"getEmpById\" resultType=\"icu.intelli.springboot.bean.Employee\"\u003e SELECT * FROM employee WHERE id = #{id} \u003c/select\u003e \u003cinsert id=\"insertEmp\"\u003e INSERT INTO employee( lastName, email, gender, d_id ) Values( #{lastName}, #{email}, #{gender}, #{dId} ) \u003c/insert\u003e \u003c/mapper\u003e mybatis-config.xml\n1 2 3 4 5 6 7 8 9 10 \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"\u003e \u003cconfiguration\u003e \u003csettings\u003e \u003c!-- 开启驼峰转换 --\u003e \u003csetting name=\"mapUnderscoreToCamelCase\" value=\"true\"/\u003e \u003c/settings\u003e \u003c/configuration\u003e application.yml\n1 2 3 mybatis: config-location: classpath:mybatis/mybatis-config.xml mapper-locations: classpath:mybatis/mapper/*.xml 整合 JPA Spring Data 简介 SpringData 项目的目的是为了简化构建基于 Spring 框架应用的数据访问技术，包括非关系数据库，Map-Reduce 框架，云数据服务等等，另外也包含对关系数据库的访问支持.\nSpring Data 包含多个子项目\nSpring Data 的结构\nSpring Data 特点\nSpringData 为我们提供使用统一的 API 来对数据访问层进行操作；这主要是 Spring Data Commons 项目来实现的。Spring Data Commons 让我们在使用关系型或者非关系型数据库访问技术时基于 Spring 提供的统一标准，标准包含了 CRUD(创建、获取、更新、删除)、查询、排序和分页的相关操作.\n统一的 Repository 接口\nRepository\u003cT, ID extends Serializable\u003e：统一接口 RevisionRepository\u003cT, ID extends Serializable, N extends Number \u0026 Comparable\u003cN\u003e\u003e：基于乐观锁机制 CrudRepository\u003cT, ID extends Serializable\u003e：基于 CRUD 操作 PagingAndSortingRepository\u003cT, ID extends Serializable\u003e：基于 CRUD 及分页 提供数据访问模板类 xxxTemplate 如：MongoTemplate、RedisTemplate 等\nJPA(Java Persistence API)与 Spring Data\nJpaRepository 基本功能\n编写接口继承 JPARepository 既有 crud 及分页等基本功能\n定义符合规范的方法命名\n在接口中只需要声明符合规范的方法，即拥有对应的功能\n@Query 自定义查询，定制查询 SQL\nSpecification 查询(Spring Data JPA 支持 JPA2.0 的 Criteria 查询)\n整合 JPA JPA 也是基于 ORM(Object Relational Mapping)思想的\n编写一个实体类(bean)和数据表进行映射，并且配置好映射关系\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 使用 JPA 注解配置映射关系 // 告诉 JPA 这是一个实体类(和数据表映射的类) @Entity // 指定和哪个数据表对应，如果省略，默认表名就是类名小写 user @Table(name = \"tbl_user\") public class User { // 这是一个主键 @Id // 自增主键 @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer id; // 这是和数据表对应的一个列 @Column(name = \"last_name\", length = 50) private String lastName; // 可以省略，默认列名就是属性名 @Column private String email; 编写一个 Dao 接口来操作实体类对应的数据表(Repository)\n1 2 3 4 // 继承 JpaRepository 来完成对数据库的操作 // JpaRepository\u003cT, ID\u003e：T 为对应的实体类型, ID 为实体类的主键类型 public interface UserRepository extends JpaRepository\u003cUser, Integer\u003e { } 基本的配置\n1 2 3 4 5 6 7 spring: jpa: hibernate: # 更新或者创建数据表结构 ddl-auto: update # 控制台显示 SQL show-sql: true ","description":"","tags":["Spring Boot","Java"],"title":"Spring Boot 与数据访问","uri":"/posts/java/springboot%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97/spring-boot-data-access/"},{"categories":null,"content":"Spring Boot 与 Docker Spring Boot 基础系列目录\n简介 Docker 是一个开源的应用容器引擎\nDocker 支持将软件编译成一个镜像，然后在镜像中对各种软件做好配置，将镜像发布出去，其他使用者可以直接使用这个镜像。\n运行中的这个镜像称为容器，容器启动时非常快速的。\nDocker 核心概念 Docker 主机（Host）: 安装了 Docker 程序的机器（Docker 是直接安装在操作系统上的）\nDocker 客户端（Client）: 连接 Docker 主机进行操作\nDocker 仓库（Registry）: 用来保存各种打包好的软件镜像\nDocker 镜像（Images）: 软件打包好的镜像，放在仓库中\nDocker 容器（Container）: 镜像启动后的实例称为一个容器，是独立运行的一个或一组应用\n使用 Docker 的步骤 :\n安装 Docker 去 Docker 仓库找到这个软件对应的镜像 直接使用 docker 运行这个镜像，这个镜像就会生成一个容器 对容器的启动停止就是对软件的启动停止 安装 Docker 安装虚拟机 安装 VirtualBox 或 VMWare\n导入 linux 虚拟机文件\n启动 linux 虚拟机\n使用客户端连接 linux 虚拟机\n设置虚拟网络 桥接网络 → 选好网卡 → 接入网线\n设置好网络后使用命令重启虚拟机网络\n1 systemctl restart network 查看 Linux 的 IP 地址\n1 ifconfig 使用客户端连接\n在 Linux 上安装 Docker 查看 CentOS 版本:\n1 uname -a Docker 要求 CentOS 系统的内核版本高于 3.10\n升级软件包及内核（选做）\n1 yum update 安装 Docker\n1 yum install docker 启动 Docker\n1 systemctl start docker 设置 Docker 开机自启\n1 systemctl enable docker 停止 Docker\n1 systemctl stop docker 常用操作 镜像操作 操作 命令 说明 检索 docker search 关键字 我们经常去 docker hub 上检索镜像的详细信息，如镜像的 TAG 拉取 docker pull 镜像名:tag :tag 是可选的，tag 表示标签，多为软件的版本，默认是 latest 列表 docker images 查看所有本地镜像 删除 docker rmi image-id 删除指定的本地镜像 容器操作 操作 命令 说明 运行 docker run --name container-name -d image-name --name: 自定义容器名\n-d: 后台运行\nimage-name: 指定镜像模板 列表 docker ps 查看运行中的容器 加上 -a 可以查看所有容器 停止 docker stop container-name/container-id 停止指定名称或 id 的容器 启动 docker start container-name/container-id 启动指定名称或 id 的容器 删除 docker rm container-id 删除指定 id 的容器 端口映射 -p 6379:6379 eg.docker run -d -p 6379:6379 --name myredisdocker.io/redis -p: 主机端口映射到容器内部的端口 主机端口:docker 内部端口 容器日志 docker logs container-name/container-id 更多命令 官方文档 软件镜像 → 运行镜像 → 产生容器（正在运行的软件）\n步骤\n搜索镜像\n1 docker search tomcat 拉取镜像\n1 docker pull tomcat 根据镜像启动容器\n1 docker run --name mytomcat -d tomcat:latest 查看运行中的容器\n1 docker ps 停止运行中的容器\n1 docker stop 容器 id 查看所有的容器\n1 docker ps -a 启动容器\n1 docker start 容器 id 删除容器\n1 2 docker stop 容器 id docker rm 容器 id 启动一个做了端口映射的 tomcat\n1 docker run -d -p 8888:8080 tomcat 为了演示简单关闭了 Linux 防火墙\n1 2 systemctl status firewalld systemctl stop firewalld 查看容器日志\n1 docker logs 容器 id 安装 MySQL 拉取镜像\n1 docker pull mysql 错误的启动\n1 2 3 4 5 6 7 8 9 docker run --name msql01 -d mysql 错误日志 [root@iZ2ze7jsh4toa7ztb73ei2Z ~]# docker logs 364d3b95d995 2019-12-18 02:58:39+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 8.0.18-1debian9 started. 2019-12-18 02:58:40+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql' 2019-12-18 02:58:40+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 8.0.18-1debian9 started. 2019-12-18 02:58:40+00:00 [ERROR] [Entrypoint]: Database is uninitialized and password option is not specified You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD 必须指定以上三个参数中的一个\n正确的启动\n1 docker run --name mysql1 -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql 几个其他的高级操作\n1 2 3 4 5 6 7 8 指定配置文件 docker run --name container-name -v /my/custom:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=my-secret-pwd -d mysql:tag 把主机的/my/custom 文件夹挂载到 mysql docker 容器的/etc/mysql/conf.d 文件夹里面 改 mysql 的配置文件就只需要把 mysql 配置文件放在主机的/conf/custom 下即可 不用 cnf 文件配置 mysql docker run --name container-name -e MYSQL_ROOT_PASSWORD=my-secret-pwd -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci 使用--mysql-propertie-key=mysql-properties-val 指定 mysql 的一些参数 剩余安装: redis rabbitmq elasticsearch\n","description":"","tags":["Spring Boot","Java"],"title":"Spring Boot 与 Docker","uri":"/posts/java/springboot%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97/spring-boot-docker/"},{"categories":null,"content":"Spring Boot 与 Web 开发 Spring Boot 基础系列目录\n简介 使用 SpringBoot\n创建 SpringBoot 应用，选中需要的模块 SpringBoot 已经默认将这些场景配置好了，只需要在配置文件中指定少量配置就可以运行起来 自己编写业务代码 自动配置原理?\n这个场景 SpringBoot 帮我们配置了什么? 能不能修改? 能修改哪些配置? 能不能扩展? ……\nxxxAutoConfiguration：帮我们给容器中自动配置组件 xxxProperties：配置类来封装配置文件的内容 SpringBoot 对静态资源的映射规则 SpringBoot 跟 Web 相关的配置都在 WebMvcAutoConfiguration 里\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @ConfigurationProperties(prefix = \"spring.resources\", ignoreUnknownFields = false) public class ResourceProperties { // 可以设置和资源有关的参数，缓存时间等 @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { if (!this.resourceProperties.isAddMappings()) { logger.debug(\"Default resource handling disabled\"); return; } Duration cachePeriod = this.resourceProperties.getCache().getPeriod(); CacheControl cacheControl = this.resourceProperties.getCache().getCachecontrol().toHttpCacheControl(); if (!registry.hasMappingForPattern(\"/webjars/**\")) { customizeResourceHandlerRegistration(registry.addResourceHandler(\"/webjars/**\") .addResourceLocations(\"classpath:/META-INF/resources/webjars/\") .setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl)); } String staticPathPattern = this.mvcProperties.getStaticPathPattern(); if (!registry.hasMappingForPattern(staticPathPattern)) { customizeResourceHandlerRegistration(registry.addResourceHandler(staticPathPattern) .addResourceLocations(getResourceLocations(this.resourceProperties.getStaticLocations())) .setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl)); } } // 配置欢迎页映射 @Bean public WelcomePageHandlerMapping welcomePageHandlerMapping(ApplicationContext applicationContext, FormattingConversionService mvcConversionService, ResourceUrlProvider mvcResourceUrlProvider) { WelcomePageHandlerMapping welcomePageHandlerMapping = new WelcomePageHandlerMapping( new TemplateAvailabilityProviders(applicationContext), applicationContext, getWelcomePage(), this.mvcProperties.getStaticPathPattern()); welcomePageHandlerMapping.setInterceptors(getInterceptors(mvcConversionService, mvcResourceUrlProvider)); return welcomePageHandlerMapping; } 所有 /webjars/**，都去 /META-INF/resources/webjars/ 找资源;\nwebjars：以 jar 包的方式引入静态资源\nwebjars 官网: 可以将常用的前端框架以 Maven 依赖的方式引入到项目中 测试访问：http://localhost:8080/webjars/jquery/3.4.1/jquery.js\n1 2 3 4 5 6 7 \u003c!-- 引入 jquery-webjars --\u003e \u003c!-- 在访问时只需要写 webjars 下面的资源名称即可 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.webjars\u003c/groupId\u003e \u003cartifactId\u003ejquery\u003c/artifactId\u003e \u003cversion\u003e3.4.1\u003c/version\u003e \u003c/dependency\u003e /**， 访问当前项目的任何资源，静态资源的文件夹\n\"classpath:/META-INF/resources/\", \"classpath:/resources/\", \"classpath:/static/\", \"classpath:/public/\", \"/\"\nlocalhost:8080/abc → 去静态资源文件夹里面找 abc\n欢迎页：静态资源文件夹下的所有 index.html 页面；被\"/**\"映射\nlocalhost:8080/ → 找 index.html 页面\n所有的 **/favicon.ico 都是在静态资源文件夹下找\n可以通过 spring.resources.static-locations 属性自定义静态文件夹数组，会使默认配置失效\n模板引擎 JSP、Velocity、Freemarker、Thymeleaf\nSpringBoot 推荐的 Thymeleaf;\n语法简单，功能更强大。\n引入 Thymeleaf 1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-thymeleaf\u003c/artifactId\u003e \u003c/dependency\u003e 如果 thymeleaf 版本过低，使用下列方式替换\n1 2 3 4 5 \u003cproperties\u003e \u003cthymeleaf.version\u003e3.0.2.RELEASE\u003c/thymeleaf.version\u003e \u003c!-- 布局功能的支持程序 thymeleaf3 主程序使用 layout2 以上版本 --\u003e \u003cthymeleaf-layout-dialect.version\u003e2.1.1\u003c/thymeleaf-layout-dialect.version\u003e \u003c/properties\u003e Thymeleaf 使用\u0026语法 1 2 3 4 5 6 7 8 @ConfigurationProperties(prefix = \"spring.thymeleaf\") public class ThymeleafProperties { private static final Charset DEFAULT_ENCODING = StandardCharsets.UTF_8; public static final String DEFAULT_PREFIX = \"classpath:/templates/\"; public static final String DEFAULT_SUFFIX = \".html\"; 只需要把 html 页面存放在 classpath:/templates/，thymeleaf 就能自动渲染;\n使用\n导入 thymeleaf 的名称空间\n1 \u003chtml xmlns:th=\"http://www.thymeleaf.org\"\u003e 使用 thymeleaf 语法\n1 2 \u003c!-- th:text 将 div 里面的文本内容设置为 ${hello} --\u003e \u003cdiv th:text=\"${hello}\"\u003e这是显示欢迎信息\u003c/div\u003e Thymeleaf 语法规则 th:text：改变当前元素里面的文本内容\nth：任意 html 属性；替换原生属性的值 表达式 官方文档\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 Simple expressions:（表达式语法） Variable Expressions: ${...}：获取变量值，OGNL 1. 获取对象的属性，调用方法 2. 使用内置的基本对象 #ctx: the context object. #vars: the context variables. #locale: the context locale. #request: (only in Web Contexts) the HttpServletRequest object. #response: (only in Web Contexts) the HttpServletResponse object. #session: (only in Web Contexts) the HttpSession object. #servletContext: (only in Web Contexts) the ServletContext object. 3. 内置的一些工具对象 #execInfo: information about the template being processed. #messages: methods for obtaining externalized messages inside variables expressions, in the same way as they would be obtained using #{…} syntax. #uris: methods for escaping parts of URLs/URIs #conversions: methods for executing the configured conversion service (if any). #dates: methods for java.util.Date objects: formatting, component extraction, etc. #calendars: analogous to #dates, but for java.util.Calendar objects. #numbers: methods for formatting numeric objects. #strings: methods for String objects: contains, startsWith, prepending/appending, etc. #objects: methods for objects in general. #bools: methods for boolean evaluation. #arrays: methods for arrays. #lists: methods for lists. #sets: methods for sets. #maps: methods for maps. #aggregates: methods for creating aggregates on arrays or collections. #ids: methods for dealing with id attributes that might be repeated (for example, as a result of an iteration). Selection Variable Expressions: *{...}：选择表达式，和 ${...} 在功能上是相同的 补充：配合 th:object=\"${session.user}\"来使用 \u003cdiv th:object=\"${session.user}\"\u003e \u003cp\u003eName: \u003cspan th:text=\"*{firstName}\"\u003eSebastian\u003c/span\u003e.\u003c/p\u003e \u003cp\u003eSurname: \u003cspan th:text=\"*{lastName}\"\u003ePepper\u003c/span\u003e.\u003c/p\u003e \u003cp\u003eNationality: \u003cspan th:text=\"*{nationality}\"\u003eSaturn\u003c/span\u003e.\u003c/p\u003e \u003c/div\u003e Message Expressions: #{...}：获取国际化内容 Link URL Expressions: @{...}：定义 URL @{/order/process(execId=${execId},execType='FAST')} Fragment Expressions: ~{...}：片段引用的表达式 \u003cdiv th:insert=\"~{commons :: main}\"\u003e...\u003c/div\u003e Literals（字面量） Text literals: 'one text', 'Another one!',… Number literals: 0, 34, 3.0, 12.3,… Boolean literals: true, false Null literal: null Literal tokens: one, sometext, main,… Text operations（文本操作）: String concatenation: + Literal substitutions: |The name is ${name}| Arithmetic operations（数学运算）: Binary operators: +, -, *, /, % Minus sign (unary operator): - Boolean operations（布尔运算）: Binary operators: and, or Boolean negation (unary operator): !, not Comparisons and equality（比较运算）: Comparators: \u003e, \u003c, \u003e=, \u003c= (gt, lt, ge, le) Equality operators: ==, != (eq, ne) Conditional operators（条件运算）: If-then: (if) ? (then) If-then-else: (if) ? (then) : (else) Default: (value) ?: (defaultvalue) Special tokens（特殊操作）: No-Operation: _ SpringMVC 自动配置 Developing Web Applications\nSpring MVC auto-configuration Spring Boot 自动配置好了 SpringMVC\n以下是 SpringBoot 对 SpringMVC 的默认配置：\nInclusion of ContentNegotiatingViewResolver and BeanNameViewResolver beans.\n自动配置了 ViewResolver（视图解析器：根据方法的返回值得到试图对象（View），视图对象决定如何渲染（转发或重定向）） ContentNegotiatingViewResolver：用来组合所有视图解析器的; 如何定制：我们可以自己给容器中添加一个视图解析器；ContentNegotiatingViewResolver 会自动的将其组合起来，使其生效 Static index.html support. 静态首页访问\nSupport for serving static resources, including support for WebJars (covered later in this document)).静态资源文件夹路径，webjars\nCustom Favicon support (covered later in this document). 设置 favicon.ico\nAutomatic registration of Converter, GenericConverter, and Formatter beans.\nConverter：转换器，public String hello(String user)：类型转换使用\nFormatter：格式化器，2019-12-14 → Date\n1 2 3 4 5 6 7 @Bean @Override public FormattingConversionService mvcConversionService() { WebConversionService conversionService = new WebConversionService(this.mvcProperties.getDateFormat()); addFormatters(conversionService); return conversionService; } 自己添加的格式化器和转换器，只需要将其添加到容器中即可\nSupport for HttpMessageConverters (covered later in this document).\nHttpMessageConverters：消息转换器，用来转换 Http 请求和响应的；User → json HttpMessageConverters 是从容器中确定的，获取容器中所有的 HttpMessageConverters. 自己给容器中添加 HttpMessageConverter，只需要将自己的组件注册到容器中(@Bean，@Component） Automatic registration of MessageCodesResolver (covered later in this document). 定义错误代码生成规则\nAutomatic use of a ConfigurableWebBindingInitializer bean (covered later in this document).\n我们可以配置一个 ConfigurableWebBindingInitializer 来替换默认的（需要添加到容器）\n用来初始化 WebDataBinder\n请求数据 === JavaBean\norg.springframework.boot.autoconfigure.web：web 的所有自动配置场景\n扩展 SpringMVC If you want to keep Spring Boot MVC features and you want to add additional MVC configuration (interceptors, formatters, view controllers, and other features), you can add your own @Configuration class of type WebMvcConfigurer but without @EnableWebMvc. If you wish to provide custom instances of RequestMappingHandlerMapping, RequestMappingHandlerAdapter, or ExceptionHandlerExceptionResolver, you can declare a WebMvcRegistrationsAdapter instance to provide such components.\n1 2 3 4 5 6 7 \u003cmvc:view-controller path=\"/hello\" view-name=\"success\" /\u003e \u003cmvc:interceptors\u003e \u003cmvc:interceptor\u003e \u003cmvc:mapping path=\"/hello\"/\u003e \u003cbean\u003e\u003c/bean\u003e \u003c/mvc:interceptor\u003e \u003c/mvc:interceptors\u003e 编写一个配置类（标注@Configuration），是 WebMvcConfigurer（boot1.x 版本是 WebMvcConfigurerAdapter）类型，不能标注@EnableWebMvc\n既保留了所有的自动配置，也能用我们的扩展配置\n1 2 3 4 5 6 7 8 9 10 // 使用 WebMvcConfigurer 可以来扩展 SpringMVC 的功能 @Configuration public class MyMvcConfig implements WebMvcConfigurer { @Override public void addViewControllers(ViewControllerRegistry registry) { // 浏览器发送 /intelli 请求，也来到 success 页面 registry.addViewController(\"/intelli\").setViewName(\"success\"); } } 原理\nWebMvcAutoConfiguration 在做其他自动配置时，会导入 @Import(EnableWebMvcConfiguration.class) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @Configuration(proxyBeanMethods = false) public static class EnableWebMvcConfiguration extends DelegatingWebMvcConfiguration implements ResourceLoaderAware { @Configuration(proxyBeanMethods = false) public class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport { private final WebMvcConfigurerComposite configurers = new WebMvcConfigurerComposite(); // 从容器中获取所有的 WebMvcConfigurer @Autowired(required = false) public void setConfigurers(List\u003cWebMvcConfigurer\u003e configurers) { if (!CollectionUtils.isEmpty(configurers)) { this.configurers.addWebMvcConfigurers(configurers); } // 一个参考实现，将所有的 WebMvcConfigurer 相关的配置都来一起调用 /* @Override public void addViewControllers(ViewControllerRegistry registry) { for (WebMvcConfigurer delegate : this.delegates) { delegate.addViewControllers(registry); } } */ } 容器中所有的 WebMvcConfigurer 都会一起起作用 我们的配置类也会被调用 效果：SpringMvc 的配置和我们的扩展配置都会起作用\n全面接管 SpringMVC If you want to take complete control of Spring MVC, you can add your own @Configuration annotated with @EnableWebMvc.\n效果： SpringBoot 对 SpringMVC 的自动配置不需要了，所有都是我们自己配，所有的 SpringMVC 的自动配置都失效\n在我们自己的配置类中添加 @EnableWebMvc 即可。\n1 2 3 4 // 禁用 SpringMVC 的自动配置，全都由我们自己来配置 @EnableWebMvc @Configuration public class MyMvcConfig implements WebMvcConfigurer { 原理\n为什么加上 @EnableWebMvc 自动配置就失效了?\n1 2 3 @Import(DelegatingWebMvcConfiguration.class) public @interface EnableWebMvc { } 1 2 @Configuration(proxyBeanMethods = false) public class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport { 1 2 3 4 5 6 7 8 9 10 @Configuration(proxyBeanMethods = false) @ConditionalOnWebApplication(type = Type.SERVLET) @ConditionalOnClass({ Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class }) // 容器中没有这个组件的时候，这个配置类才生效 @ConditionalOnMissingBean(WebMvcConfigurationSupport.class) @AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10) @AutoConfigureAfter({ DispatcherServletAutoConfiguration.class, TaskExecutionAutoConfiguration.class, ValidationAutoConfiguration.class }) public class WebMvcAutoConfiguration { @EnableWebMvc 将 WebMvcConfigurationSupport 组件导入进来了; 导入的 WebMvcConfigurationSupport 只是 SpringMVC 最基本的功能。 如何修改 SpringBoot 的默认配置 SpringBoot 自动配置的模式：\nSpringBoot 在自动配置很多组件的时候，先看容器中有没有用户自己配置的（@Bean，@Component），如果有就用用户配置的，如果没有，才自动配置；如果有些组件可以有多个（eg.ViewResolver），将用户配置的和自己默认的组合起来。 在 SpringBoot 中会有非常多的 xxxConfigurer，帮助我们进行扩展配置 在 SpringBoot 中会有很多的 xxx.Customizer 帮助我们进行定制配置 Restful CRUD 默认访问首页 1 2 3 4 5 6 7 8 @Configuration public class MyMvcConfiguarer implements WebMvcConfigurer { @Override public void addViewControllers(ViewControllerRegistry registry) { registry.addViewController(\"/\").setViewName(\"login\"); registry.addViewController(\"/index.html\").setViewName(\"login\"); } } 国际化 编写国际化配置文件 使用 ResourceBundleMessageSource 管理国际化资源文件 在页面使用 fmt:message 取出国际化内容 详细说明\n编写国际化配置文件，抽取页面需要显示的国际化消息\nSpring Boot 自动配置好了管理国际化资源文件的组件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 @Configuration(proxyBeanMethods = false) @ConditionalOnMissingBean(name = AbstractApplicationContext.MESSAGE_SOURCE_BEAN_NAME, search = SearchStrategy.CURRENT) @AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE) @Conditional(ResourceBundleCondition.class) @EnableConfigurationProperties public class MessageSourceAutoConfiguration { private static final Resource[] NO_RESOURCES = {}; @Bean @ConfigurationProperties(prefix = \"spring.messages\") public MessageSourceProperties messageSourceProperties() { return new MessageSourceProperties(); } @Bean public MessageSource messageSource(MessageSourceProperties properties) { ResourceBundleMessageSource messageSource = new ResourceBundleMessagimgeSource(); if (StringUtils.hasText(properties.getBasename())) { // 设置国际化资源文件的基础名（去掉语言国家代码的） messageSource.setBasenames(StringUtils .commaDelimitedListToStringArray(StringUtils.trimAllWhitespace(properties.getBasename()))); } if (properties.getEncoding() != null) { messageSource.setDefaultEncoding(properties.getEncoding().name()); }/** * 可以在连接上携带区域信息 */ public class MyLocaleResolver implements LocaleResolver { @Override public Locale resolveLocale(HttpServletRequest request) { String l = reqimguest.getParameter(\"l\"); Locale locale = Locale.getDefault(); if (!StringUtils.isEmpty(l)) { String[] split = l.split(\"_\"); locale = new Locale(split[0], split[1]); } return locale; } @Override public void setLocale(HttpServletRequest request, HttpServletResponse response, Locale locale) { } } // MyMvcConfigurer 中将自定义的组件添加到容器中 @Bean public LocaleResolver localeResolver(){ return new MyLocaleResolver(); } messageSource.setFallbackToSystemLocale(properties.isFallbackToSystemLocale()); Duration cacheDuration = properties.getCacheDuration(); if (cacheDuration != null) { messageSource.setCacheMillis(cacheDuration.toMillis()); } messageSource.setAlwaysUseMessageFormat(properties.isAlwaysUseMessageFormat()); messageSource.setUseCodeAsDefaultMessage(properties.isUseCodeAsDefaultMessage()); return messageSource; } public class MessageSourceProperties { // 我们的配置文件可以直接放在类路径下叫 messages.properties private String basename = \"messages\"; 在 application.properties 中配置 spring.messages.basename=i18n/login，即可指定国家化配置文件的位置 i18n/login 从跟路径下查找基础名为 login 的国际化配置文件\n去页面获取国际化的值\nthemeleaf 使用 #{...} 获取国际化值\n1 \u003clabel class=\"sr-only\" th:text=\"#{login.username}\"\u003eUsername\u003c/label\u003e 1 2 \u003c!-- 行内表达式 --\u003e \u003cinput type=\"checkbox\" value=\"remember-me\"/\u003e [[#{login.remember}]] 效果：根据浏览器语言设置的信息，切换国际化\nSpringMVC 国际化原理\n国际化 Locale（区域信息对象）：LocaleResolver（获取区域信息对象）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @Bean @ConditionalOnMissingBean @ConditionalOnProperty(prefix = \"spring.mvc\", name = \"locale\") public LocaleResolver localeResolver() { if (this.mvcProperties.getLocaleResolver() == WebMvcProperties.LocaleResolver.FIXED) { return new FixedLocaleResolver(this.mvcProperties.getLocale()); } AcceptHeaderLocaleResolver localeResolver = new AcceptHeaderLocaleResolver(); localeResolver.setDefaultLocale(this.mvcProperties.getLocale()); return localeResolver; } @Override public Locale resolveLocale(HttpServletRequest request) { Locale defaultLocale = getDefaultLocale(); if (defaultLocale != null \u0026\u0026 request.getHeader(\"Accept-Language\") == null) { return defaultLocale; } Locale requestLocale = request.getLocale(); List\u003cLocale\u003e supportedLocales = getSupportedLocales(); if (supportedLocales.isEmpty() || supportedLocales.contains(requestLocale)) { return requestLocale; } Locale supportedLocale = findSupportedLocale(request, supportedLocales); if (supportedLocale != null) { return supportedLocale; } return (defaultLocale != null ? defaultLocale : requestLocale); } SpringBoot 默认配置的是根据请求头中带来的区域信息获取 Locale 进行国际化\n切换国际化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 /** * 可以在连接上携带区域信息 */ public class MyLocaleResolver implements LocaleResolver { @Override public Locale resolveLocale(HttpServletRequest request) { String l = request.getParameter(\"l\"); Locale locale = Locale.getDefault(); if (!StringUtils.isEmpty(l)) { String[] split = l.split(\"_\"); locale = new Locale(split[0], split[1]); } return locale; } @Override public void setLocale(HttpServletRequest request, HttpServletResponse response, Locale locale) { } } // MyMvcConfigurer 中将自定义的组件添加到容器中 @Bean public LocaleResolver localeResolver(){ return new MyLocaleResolver(); } 登录 开发期间模板引擎页面修改后，要实时生效：\n禁用模板引擎的缓存\n1 2 # 禁用模板引擎缓存 spring.thymeleaf.cache=false 页面修改完成以后，idea 使用 Ctrl+F9，重新编译\n登录错误消息的显示\n1 2 \u003c!-- 判断 --\u003e \u003cp style=\"color: red\" th:text=\"${msg}\" th:if=\"${not #strings.isEmpty(msg)}\"\u003e\u003c/p\u003e 登录成功，防止表单重复提交，可以重定向到主页\n1 2 3 4 5 // 在自定义的视图解析器中添加 registry.addViewController(\"/main.html\").setViewName(\"dashboard\"); // 登录成功，将请求重定向到 main.html 再经过解析器返回 dashboard.html 页面 return \"redirect:/main.html\"; 拦截器进行登录验证 创建登录拦截器类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * 登录检查 */ public class LoginHandlerInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { Object user = request.getSession().getAttribute(\"loginUser\"); if (user == null) { // 未登录，返回登录页面 request.getRequestDispatcher(\"/index.html\").forward(request, response); request.setAttribute(\"msg\", \"没有权限，请先登录.\"); return false; } else { // 已登录，放行请求 return true; } } } 注册拦截器\n设置拦截所有请求，放心登录相关请求\n1 2 3 4 5 6 7 8 9 10 11 @Configuration public class MyMvcConfigurer implements WebMvcConfigurer { // 注册拦截器 @Override public void addInterceptors(InterceptorRegistry registry) { // 静态资源：*.css、*.js // SpringBoot 已经做好了静态资源映射 registry.addInterceptor(new LoginHandlerInterceptor()).addPathPatterns(\"/**\") .excludePathPatterns(\"/index.html\", \"/\", \"/user/login\"); } } CRUD 员工列表 实验要求\nRestfulCRUD：CRUD 要满足 Rest 风格 URI：/资源名称/资源标识 HTTP 请求方式区分对资源的 CRUD 操作\n- 普通 CRUD（uri 来区分操作） RestfulCRUD 查询 getEmp emp---GET 添加 addEmp?xxx emp---POST 修改 updateEmp?id=x\u0026xxx=xx emp/(id)---PUT 删除 deleteEmp?id=x emp/(id)---DELETE 实验的请求架构：\n- 请求 URI 请求方式 查询所有员工 emps GET 查询某个员工 emp/(id) GET 来到添加页面 emp GET 添加员工 emp POST 来到修改页面（查出员工进行信息回显） emp/(id) GET 修改员工 emp PUT 删除员工 emp/(id) DELETE 员工列表\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 1. 抽取公共片段 \u003cdiv th:fragment=\"copy\"\u003e \u0026copy; 2011 The Good Thymes Virtual Grocery \u003c/div\u003e 2. 引入公共片段 \u003cdiv th:insert=\"~{footer :: copy}\"\u003e\u003c/div\u003e \u003cdiv th:insert=\"footer :: copy\"\u003e\u003c/div\u003e ~{templatename::selector}：模板名::选择器 ~{templatename::fragmentname}：模板名::片段名 3. 默认效果 insert 的功能片段在 div 标签中 如果使用 th:insert 等属性进行引入，可以不用写~{}; 行内写法可以加上：[[~{}]], [(~{})] 三种引入公共片段的 th 属性：\nth:insert 将公共片段整个插入到声明引入元素中\nth:replace 将声明引入的元素替换为公共片段\nth:include 将被引入的片段的内容包含进这个标签中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u003cfooter th:fragment=\"copy\"\u003e \u0026copy; 2011 The Good Thymes Virtual Grocery \u003c/footer\u003e \u003c!-- 引入方式 --\u003e \u003cdiv th:insert=\"footer :: copy\"\u003e\u003c/div\u003e \u003cdiv th:replace=\"footer :: copy\"\u003e\u003c/div\u003e \u003cdiv th:include=\"footer :: copy\"\u003e\u003c/div\u003e \u003c!-- 效果 --\u003e \u003cdiv\u003e \u003cfooter\u003e \u0026copy; 2011 The Good Thymes Virtual Grocery \u003c/footer\u003e \u003c/div\u003e \u003cfooter\u003e \u0026copy; 2011 The Good Thymes Virtual Grocery \u003c/footer\u003e \u003cdiv\u003e \u0026copy; 2011 The Good Thymes Virtual Grocery \u003c/div\u003e CRUD 员工添加 最常遇到的问题是，提交的数据格式不对：特别是生日\n2019-12-12; 2019/12/12; 2019.12.12;\n日期格式化：SpringMVC 将页面提交的值需要转换为指定的类型;\n默认是按照 2019-12-12 类型进行格式化\n通过 application.properties 修改默认时间格式\n1 spring.mvc.date-format= CRUD 员工修改 form 表单只支持 POST 和 GET 请求，此时需要使用 PUT 请求方式:\nSpringMVC 中配置 HiddenHttpMethodFilter，将请求转成我们指定的方式 页面创建一个 post 表单 创建一个 input 项，name=\"_method\"；值就是我们指定的请求方式 CRUD 员工删除 使用 DELETE 请求方式，参考员工修改\n使用 @PathVariable(\"id\") 获取 uri 中的变量值\nthymeleaf 设置自定义属性\n1 \u003cform action=\"xxx\" th:attr=\"key1=val1, key2=val2\" 错误处理机制 SpringBoot 默认的错误处理机制 默认效果：\n如果是浏览器，返回一个默认的错误页面 浏览器发送请求的请求头：\n如果是其他客户端，默认相应一个 json 数据 客户端发送请求的请求头：\n原理：\n可以参照 ErrorMvcAutoConfiguration，错误处理的自动配置\n给容器中添加了如下组件\nDefaultErrorAttributes：\n1 2 3 4 5 6 7 8 9 // 帮我们在页面共享信息 public Map\u003cString, Object\u003e getErrorAttributes(WebRequest webRequest, boolean includeStackTrace) { Map\u003cString, Object\u003e errorAttributes = new LinkedHashMap(); errorAttributes.put(\"timestamp\", new Date()); this.addStatus(errorAttributes, webRequest); this.addErrorDetails(errorAttributes, webRequest, includeStackTrace); this.addPath(errorAttributes, webRequest); return errorAttributes; } BasicErrorController：处理默认的 /error 请求\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 @Controller @RequestMapping(\"${server.error.path:${error.path:/error}}\") public class BasicErrorController extends AbstractErrorController { @RequestMapping(produces = MediaType.TEXT_HTML_VALUE) // 产生 html 类型的数据，浏览器发出的请求，来这个方法处理 public ModelAndView errorHtml(HttpServletRequest request, HttpServletResponse response) { HttpStatus status = getStatus(request); Map\u003cString, Object\u003e model = Collections .unmodifiableMap(getErrorAttributes(request, isIncludeStackTrace(request, MediaType.TEXT_HTML))); response.setStatus(status.value()); // 去哪个页面作为错误页面，包含页面地址和页面内容 ModelAndView modelAndView = resolveErrorView(request, response, status, model); return (modelAndView != null) ? modelAndView : new ModelAndView(\"error\", model); } @RequestMapping // 产生 json 数据，其他客户端的请求，来到这里处理 public ResponseEntity\u003cMap\u003cString, Object\u003e\u003e error(HttpServletRequest request) { HttpStatus status = getStatus(request); if (status == HttpStatus.NO_CONTENT) { return new ResponseEntity\u003c\u003e(status); } Map\u003cString, Object\u003e body = getErrorAttributes(request, isIncludeStackTrace(request, MediaType.ALL)); return new ResponseEntity\u003c\u003e(body, status); } ErrorPageCustomizer\n1 2 3 // 系统出现错误以后来到 error 请求进行处理，相当于 SSM 在 web.xml 注册的错误页面规则 @Value(\"${error.path:/error}\") private String path = \"/error\"; DefaultErrorViewResolver\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Override public ModelAndView resolveErrorView(HttpServletRequest request, HttpStatus status, Map\u003cString, Object\u003e model) { ModelAndView modelAndView = resolve(String.valueOf(status.value()), model); if (modelAndView == null \u0026\u0026 SERIES_VIEWS.containsKey(status.series())) { modelAndView = resolve(SERIES_VIEWS.get(status.series()), model); } return modelAndView; } private ModelAndView resolve(String viewName, Map\u003cString, Object\u003e model) { //默认 SpringBoot 可以找到一个页面：error/404 String errorViewName = \"error/\" + viewName; // 模板引擎可以解析这个页面地址就用模板引擎解析 TemplateAvailabilityProvider provider = this.templateAvailabilityProviders.getProvider(errorViewName, this.applicationContext); if (provider != null) { // 模板引擎可用的情况下返回 errorViewName 指定的视图地址 return new ModelAndView(errorViewName, model); } // 模板引擎不可用，就在静态资源文件夹下找 errorViewName 对应的页面：error/404.html return resolveResource(errorViewName, model); } 步骤： 一旦系统出现 4xx 或者 5xx 之类的错误, ErrorPageCustomizer 就会生效（定制错误的响应规则）；就会来到 /error 请求；就会被 BasicErrorController 处理;\n响应页面：去哪个页面是由 DefaultErrorViewResolver 解析得到的\n1 2 3 4 5 6 7 8 9 10 11 protected ModelAndView resolveErrorView(HttpServletRequest request, HttpServletResponse response, HttpStatus status, Map\u003cString, Object\u003e model) { // 所有的 ErrorViewResolver 得到 ModelAndView for (ErrorViewResolver resolver : this.errorViewResolvers) { ModelAndView modelAndView = resolver.resolveErrorView(request, status, model); if (modelAndView != null) { return modelAndView; } } return null; } 如何定制错误响应 如何定制错误的页面\n有模板引擎的情况下：error/ 状态码，将错误页面命名为 错误状态码.html, 放在模板引擎文件夹里面的 error 文件夹下，发生此状态码的错误，就会来到对应的页面;\n可以使用 4xx 和 5xx 作为错误页面的文件名来匹配这种类型的所有错误，精确优先（优先寻找精确地 状态码.html）\n页面能获取的信息：\ntimestamp：时间戳 status：状态码 error：错误提示 exception：异常对象 message：异常消息 errors：jsr303 数据校验的错误都在这 没有模板引擎（或模板引擎不能按上述找到这个错误页面），从静态资源文件夹下找\n以上都没有错误页面，默认来到 SpringBoot 默认的错误提示页面\n如何定制错误的 json 数据\n自定义异常处理\u0026返回定制 json 数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 自定义异常需要添加 @ControllerAdvice public class MyExceptionHandler { // 浏览器和客户端返回的都是 json @ResponseBody // 产生 MyException 时，使用该方法 @ExceptionHandler(MyException.class) public Map\u003cString, Object\u003e handleException(Exception e) { Map\u003cString, Object\u003e map = new HashMap\u003c\u003e(); map.put(\"code\", \"user.myexception\"); map.put(\"message\", e.getMessage()); return map; } } 转发到 /error 进行自适应相应效果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @ControllerAdvice public class MyExceptionHandler { @ExceptionHandler(MyException.class) public String handleException(Exception e, HttpServletRequest request) { Map\u003cString, Object\u003e map = new HashMap\u003c\u003e(); // 传入我们自己的错误状态码，否则就不会进入定制错误页面的解析流程 /** Integer status = (Integer)this.getAttribute(requestAttributes, \"javax.servlet.error.status_code\"); */ request.setAttribute(\"javax.servlet.error.status_code\", \"400\"); map.put(\"code\", \"user.myexception\"); map.put(\"message\", e.getMessage()); // 转发到 /error, 让 BasicErrorController 自适应处理 return \"forward:/error\"; } } 将我们的定制数据携带出去\n出现错误以后，会来到 /error 请求，会被 BasicErrorController 处理，响应出去的可以获取的数据是由 getErrorAttributes 得到的（是 AbstractErrorController 规定的方法）\n完全来编写一个 ErrorController 的实现类（或者编写 AbstractErrorController 的子类） 页面上能用的数据，或者是 json 返回能用的数据，是从 errorAttributes.getErrorAttributes 得到的 容器中的 DefaultErrorAttributes 默认进行数据处理的，可以写一个 DefaultErrorAttributes 的子类，覆盖他的 getErrorAttribute 方法，可以通过 requestAttributes.getAttribute() 获取到自定义异常中使用 request.setAttributes() 设置的值 最终的效果： 响应是自适应的，可以通过定制 ErrorAttribute 改变需要定制的内容\n配置嵌入式 Servlet 容器 SpringBoot 默认用的是嵌入式 Servlet 容器（Tomcat）;\n如何定制和修改 Servlet 容器的相关配置 修改和 server 有关的配置（ServerProperties）\n1 2 3 4 5 6 7 server.port=8080 server.servlet.context-path=/crud # 通用的 servlet 容器设置 server.xxx # Tomcat 的设置 server.tomcat.xxx 编写一个 EmbeddedServletContainerCustomizer：嵌入式的 Servlet 容器的定制器，springboot2.x 使用 WebServerFactoryCustomizer，来修改 Servlet 的配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // SpringBoot 1.x @Bean public EmbeddedServletContainerCustomizer embeddedServletContainerCustomizer(){ return new EmbeddedServletContainerCustomizer(){ // 定制嵌入式的 Servlet 容器相关规则 @Override public void customize(ConfigurableEmbeddedServletContainer container) { container.setPort(8083); } } } // SpringBoot2.x @Bean public WebServerFactoryCustomizer\u003cConfigurableWebServerFactory\u003e webServerFactoryCustomizer() { return new WebServerFactoryCustomizer\u003cConfigurableWebServerFactory\u003e() { @Override public void customize(ConfigurableWebServerFactory factory) { factory.setPort(8081); } }; } 注册 Servlet 三大组件（Servlet，Filter，Listener） 由于 SpringBoot 默认是以 jar 包的方式启动嵌入式的 Servlet 容器来启动 SpringBoot 的 web 应用，没有 web.xml 文件.\n所以要注册三大组件用以下方式：\nServlet：\n1 2 3 4 @Bean public ServletRegistrationBean myServlet() { return new ServletRegistrationBean\u003c\u003e(new MyServlet(), \"/myServlet\"); } Filter：\n1 2 3 4 5 6 7 @Bean public FilterRegistrationBean myFilter() { FilterRegistrationBean\u003cFilter\u003e filterFilterRegistrationBean = new FilterRegistrationBean\u003c\u003e(); filterFilterRegistrationBean.setFilter(new MyFilter()); filterFilterRegistrationBean.setUrlPatterns(Arrays.asList(\"/hello\", \"/myServlet\")); return filterFilterRegistrationBean; } Listener：\n1 2 3 4 @Bean public ServletListenerRegistrationBean myListener(){ return new ServletListenerRegistrationBean(new MyListener()); } SpringBoot 帮我们自动配置 SpringMVC 的时候，自动注册了 SpringMVC 的前端控制器（DispatcherServlet），通过 DispatcherServletAutoConfiguration 类\n默认拦截 / 所有请求，包括静态资源，但是不拦截 jsp 请求\n/* 会拦截 jsp\n可通过 server.servletPath（springboot2.x 使用 spring.mvc.servlet.path）来修改 SpringMVC 前端控制器默认拦截的请求路径\n使用其他 Servlet 容器 SpringBoot 1.5.9 默认支持：\nSpringBoot2.2.2 默认支持：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c!-- 排除 tomcat servlet 容器 --\u003e \u003cexclusions\u003e \u003cexclusion\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-tomcat\u003c/artifactId\u003e \u003c/exclusion\u003e \u003c/exclusions\u003e \u003c/dependency\u003e \u003c!--引入其他的 Servlet 容器--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-jetty\u003c/artifactId\u003e \u003c/dependency\u003e 嵌入式 Servlet 容器自动配置原理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // SpringBoot 1.5.9 @AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE) @Configuration @ConditionalOnWebApplication @Import(BeanPostProcessorsRegistrar.class) // Spring 注解版，给容器中导入一些组件 // 导入了 EmbeddedServletContainerCustomizerBeanPostProcessor // 后置处理器：bean 初始化前后（创建完对象，还没属性赋值）执行初始化工作 public class EmbeddedServletContainerAutoConfiguration { @Configuration // 当前是否引入了 Tomcat 依赖 @ConditionalOnClass({ Servlet.class, Tomcat.class }) // 判断当前容器中没有用户自己定义的 EmbeddedServletContainerFactory（嵌入式的容器工厂，作用：创建嵌入式的 Servlet 容器） @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedTomcat { @Bean public TomcatEmbeddedServletContainerFactory tomcatEmbeddedServletContainerFactory() { return new TomcatEmbeddedServletContainerFactory(); } } // SpringBoot 2.2.2 @Configuration(proxyBeanMethods = false) @AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE) @ConditionalOnClass(ServletRequest.class) @ConditionalOnWebApplication(type = Type.SERVLET) @EnableConfigurationProperties(ServerProperties.class) @Import({ ServletWebServerFactoryAutoConfiguration.BeanPostProcessorsRegistrar.class, ServletWebServerFactoryConfiguration.EmbeddedTomcat.class, ServletWebServerFactoryConfiguration.EmbeddedJetty.class, ServletWebServerFactoryConfiguration.EmbeddedUndertow.class }) public class ServletWebServerFactoryAutoConfiguration { @Bean @ConditionalOnClass(name = \"org.apache.catalina.startup.Tomcat\") public TomcatServletWebServerFactoryCustomizer tomcatServletWebServerFactoryCustomizer( ServerProperties serverProperties) { return new TomcatServletWebServerFactoryCustomizer(serverProperties); } EmbeddedServletContainerFactory（嵌入式 Servlet 容器工厂）\n1 2 3 4 5 6 7 public interface EmbeddedServletContainerFactory { // 嵌入式的 Servlet 容器 EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers); } EmbeddedServletContainer：嵌入式的 Servlet 容器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 /** * Nested configuration if Tomcat is being used. */ @Configuration @ConditionalOnClass({ Servlet.class, Tomcat.class }) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedTomcat { @Bean public TomcatEmbeddedServletContainerFactory tomcatEmbeddedServletContainerFactory() { return new TomcatEmbeddedServletContainerFactory(); } } /** * Nested configuration if Jetty is being used. */ @Configuration @ConditionalOnClass({ Servlet.class, Server.class, Loader.class, WebAppContext.class }) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedJetty { @Bean public JettyEmbeddedServletContainerFactory jettyEmbeddedServletContainerFactory() { return new JettyEmbeddedServletContainerFactory(); } } /** * Nested configuration if Undertow is being used. */ @Configuration @ConditionalOnClass({ Servlet.class, Undertow.class, SslClientAuthMode.class }) @ConditionalOnMissingBean(value = EmbeddedServletContainerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedUndertow { @Bean public UndertowEmbeddedServletContainerFactory undertowEmbeddedServletContainerFactory() { return new UndertowEmbeddedServletContainerFactory(); } } 以 TomcatEmbeddedServletContainerFactory 为例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Override public EmbeddedServletContainer getEmbeddedServletContainer( ServletContextInitializer... initializers) { // 创建一个 Tomcat Tomcat tomcat = new Tomcat(); // 配置 tomcat 的基本环节 File baseDir = (this.baseDirectory != null ? this.baseDirectory : createTempDir(\"tomcat\")); tomcat.setBaseDir(baseDir.getAbsolutePath()); Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); configureEngine(tomcat.getEngine()); for (Connector additionalConnector : this.additionalTomcatConnectors) { tomcat.getService().addConnector(additionalConnector); } prepareContext(tomcat.getHost(), initializers); // 将配置好的 tomcat 传入进去，返回一个 EmbeddedServletContainer，并且启动 Tomcat 服务器 return getTomcatEmbeddedServletContainer(tomcat); } 我们对嵌入式容器的配置修改是怎么生效的\n1 ServerProperties, EmbeddedServletContainerCustomizer（2.x 版本不一样） EmbeddedServletContainerCustomizer：定制器帮我们修改了 Servlet 容器的配置\n怎么修改的?\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 // EmbeddedServletContainerCustomizerBeanPostProcessor // 初始化之前 @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { // 如果当前初始化的是一个 ConfigurableEmbeddedServletContainer 类型的组件 if (bean instanceof ConfigurableEmbeddedServletContainer) { postProcessBeforeInitialization((ConfigurableEmbeddedServletContainer) bean); } return bean; } private void postProcessBeforeInitialization( ConfigurableEmbeddedServletContainer bean) { // 获取所有的定制器，调用每一个定制器的 customize 方法给 Servlet 容器进行属性赋值 for (EmbeddedServletContainerCustomizer customizer : getCustomizers()) { customizer.customize(bean); } } private Collection\u003cEmbeddedServletContainerCustomizer\u003e getCustomizers() { if (this.customizers == null) { // Look up does not include the parent context this.customizers = new ArrayList\u003cEmbeddedServletContainerCustomizer\u003e( this.beanFactory // 从容器中获取到所有这个类型的组件：EmbeddedServletContainerCustomizer // 定制 Servlet 容器，给容器中可以添加一个 EmbeddedServletContainerCustomizer 类型的组件 .getBeansOfType(EmbeddedServletContainerCustomizer.class, false, false) .values()); Collections.sort(this.customizers, AnnotationAwareOrderComparator.INSTANCE); this.customizers = Collections.unmodifiableList(this.customizers); } return this.customizers; } // serverProperties 也是定制器（2.x 版本不同） 总流程：\nSpringBoot 根据导入的依赖情况，给容器中添加相应的嵌入式容器工厂：EmbeddedServletContainerFactory\n容器中某个组件要创建组件就毁惊动后置处理器：EmbeddedServletContainerCustomizerBeanPostProcessor\n只要是嵌入式的 Servlet 容器工厂，后置处理器就工作\n后置处理器从容器中获取所有的 EmbeddedServletContainerCustomizer，调用定制器的定制方法\n嵌入式 Servlet 容器启动原理 什么时候创建嵌入式的 Servlet 容器工厂? 什么时候获取嵌入式的 Servlet 容器并启动 Tomcat?\n获取嵌入式的 Servlet 容器工厂\nSpringBoot 应用启动运行 run 方法\nrefreshContext(context)：SpringBoot 刷新 IOC 容器，创建并初始化容器，创建容器中的每个组件，如果是 web 应用创建 AnnotationConfigEmbeddedWebApplicationContext（2.x 是 AnnotationConfigServletWebServerApplicationContext），否则 AnnotationConfigApplicationContext（2.x 还有一种 REACTIVE 对应的 AnnotationConfigReactiveWebServerApplicationContext）\nrefresh(context)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 public void refresh() throws BeansException, IllegalStateException { synchronized (this.startupShutdownMonitor) { // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try { // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); } onRefresh()：web 的 ioc 容器重写了 onRefresh 方法\nwebioc 容器会创建嵌入式的 Servlet 容器：createembeddedServletContainer() （2.x 是 createWebServer）\n获取嵌入式的 Servlet 容器工厂 EmbeddedServletContainerFactory containerFactory = getEmbeddedServletContainerFactory();（2.x 是 ServletWebServerFactory factory = getWebServerFactory();）\n从 IOC 容器中获取 EmbeddedServletContainerFactory 组件，TomcatEmbeddedServletContainerFactory 创建对象，后置处理器就获取所有的定制器来先定制 Servlet 容器的相关配置\n使用容器工厂获取嵌入式的 Servlet 容器：this.embeddedServletContainer = containerFactory.getEmbeddedServletContainer(getSelfInitializer());\n嵌入式的 Servlet 容器创建对象并启动.\n先启动嵌入式的 Servlet 容器，再将 IOC 容器中剩下没有创建出的对象获取出来\nIOC 容器启动创建嵌入式的 Servlet 容器\n使用外置的 Servlet 容器 嵌入式 Servlet 容器：应用打成可执行的 jar\n优点：简单，便携 缺点：默认不支持 JSP，优化定制比较复杂（解决方法见：配置嵌入式 Servlet 容器）; 外置的 Servlet 容器：外面安装 Tomcat---把应用打成 war 包\n1 2 3 # 可指定 SpringMVC 视图解析器的前后缀 spring.mvc.view.prefix=/WEB-INF/ spring.mvc.view.suffix=.jsp 步骤\n其实就是将 SpringBoot 工程修改为了 Maven Web 工程，然后添加了一个 SpringBootServletInitializer 的子类，在外置 tomcat 启动后，自动启动 SpringBoot 工程.\n必须创建一个 war 项目：jar 项目可以修改 pom.xml 中的\u003cpackaging\u003ewar\u003c/packaging\u003e\n1 2 3 4 \u003cgroupId\u003eicu.intelli\u003c/groupId\u003e \u003cartifactId\u003espring-boot-jpa-demo\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003cpackaging\u003ewar\u003c/packaging\u003e 创建好目录结构：\nIDEA 可通过 Project Structure 快速创建，手动创建的也需要进入 Project Structure 将 web 根目录和 web.xml 设置好 ​\t​\t将嵌入式的 tomcat 指定为 provided\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-tomcat\u003c/artifactId\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e 必须编写一个 SpringBootServletInitializer 的子类，并调用 configure 方法\n1 2 3 4 5 6 7 8 9 public class ServletInitializer extends SpringBootServletInitializer { @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) { // 需要传入 SpingBoot 应用的主程序 return application.sources(Application.class); } } IDEA 通过 Edit Configurations... 添加 tomcat 容器，并将当前项目设置进去\n启动外置 tomcat 就可以使用（此处直接运行 Application.java 使用的还是嵌入式的 tomcat）\n原理 jar 包：执行 SpringBoot 主类的 main 方法，启动 IOC 容器，创建嵌入式 Servlet 容器;\nwar 包：启动服务器，服务器来启动 SpringBoot 应用（SpringBootServletInitializer），然后启动 IOC 容器\nservlet 3.0：8.2.4 Shared libraries 65.79/ runtimes pluggability\n规则\n服务器启动（Web 应用启动）会创建当前 web 应用里面每一个 jar 包里面的 ServletContainerInitializer 实例; ServletContainerInitializer 的实现放在 jar 包的 META-INFO/service 文件夹下，里面必须有一个名为 javax.servlet.ServletContainerInitializer 的文件，内容就是 ServletContainerInitializer 的实现类的全类名 还可以使用 @HandlerTypes，在应用启动的时候加载我们感兴趣的类 流程\n启动 Tomcat\norg/springframework/spring-web/5.2.2.RELEASE/spring-web-5.2.2.RELEASE.jar!/META-INF/services/javax.servlet.ServletContainerInitializer\nSpringBoot 的 web 模块里有这个文件：javax.servlet.ServletContainerInitializer\nSpringServletContainerInitializer 将 @HandlesTypes(WebApplicationInitializer.class) 标注的所有这个类型的类传入到 onStartup 方法的 Set\u003cClass\u003c?\u003e\u003e, 为这些 WebApplicationInitializer 类型的类创建实例\n每一个 WebApplicationInitializer 都调用自己的 onStartup 方法\n相当于我们的 SpringBootServletInitialize 的类会被创建对象，并执行 onStartup 方法 SpringBootServletInitialize 实例执行 onStartup 的时候会 createRootApplicationContext，创建容器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 protected WebApplicationContext createRootApplicationContext(ServletContext servletContext) { SpringApplicationBuilder builder = createSpringApplicationBuilder(); builder.main(getClass()); ApplicationContext parent = getExistingRootWebApplicationContext(servletContext); if (parent != null) { this.logger.info(\"Root context already created (using as parent).\"); servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, null); builder.initializers(new ParentContextApplicationContextInitializer(parent)); } builder.initializers(new ServletContextApplicationContextInitializer(servletContext)); builder.contextClass(AnnotationConfigServletWebServerApplicationContext.class); // 调用 configure 方法，子类重写了这个方法，将 SpringBoot 的主程序类传入了进来 builder = configure(builder); builder.listeners(new WebEnvironmentPropertySourceInitializer(servletContext)); // 使用 builder 创建一个 Spring 应用 SpringApplication application = builder.build(); if (application.getAllSources().isEmpty() \u0026\u0026 MergedAnnotations.from(getClass(), SearchStrategy.TYPE_HIERARCHY).isPresent(Configuration.class)) { application.addPrimarySources(Collections.singleton(getClass())); } Assert.state(!application.getAllSources().isEmpty(), \"No SpringApplication sources have been defined. Either override the \" + \"configure method or add an @Configuration annotation\"); // Ensure error pages are registered if (this.registerErrorPageFilter) { application.addPrimarySources(Collections.singleton(ErrorPageFilterConfiguration.class)); } // 启动 SpringBoot 应用 return run(application); } Spring 的应用就启动了，并且创建 IOC 容器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 public ConfigurableApplicationContext run(String... args) { StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection\u003cSpringBootExceptionReporter\u003e exceptionReporters = new ArrayList\u003c\u003e(); configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try { ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] { ConfigurableApplicationContext.class }, context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) { new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); } listeners.started(context); callRunners(context, applicationArguments); } catch (Throwable ex) { handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); } try { listeners.running(context); } catch (Throwable ex) { handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); } return context; } ","description":"","tags":["Spring Boot","Java"],"title":"Spring Boot 与 Web 开发","uri":"/posts/java/springboot%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97/spring-boot-web/"},{"categories":null,"content":"Spring Boot 配置文件 Spring Boot 基础系列目录\n配置文件 Spring Boot 使用一个全局的配置文件，配置文件名是固定的\napplication.properties application.yml 配置文件的作用：修改 SpringBoot 自动配置的默认值；\nYAML（YAML Ain't Markup Language）\nYAML A Markup Language：是一种标记语言 YAML isn't Markup Language：不是标记语言 标记语言\n以前的配置文件，大多都是用 xxx.xml 文件 YAML：以数据为中心，比 json、xml 等更适合做配置文件 1 2 3 4 5 6 7 8 9 # YAML 配置例子 server: port: 8081 # 注意：`port:` 与 `8081` 之间必须有一个空格 # XML 配置的例子 #\u003cserver\u003e # \u003cport\u003e8081\u003c/port\u003e #\u003c/server\u003e YAML 语法 基本语法 k:(空格)v：表示一对键值对（空格必须有）\n以空格的缩进来控制层级关系；只要是左对齐的一列数据，都是同一层级的\n1 2 3 server: port: 8081 path: /hello 属性和值都是大小写敏感的\n值的写法 字面量: 普通的值（数字、字符串、布尔） k: v ：字面量直接来写，字符串默认不用加上单双引号\n\"\"（双引号）：不会转义字符串里面的特殊字符，特殊字符会作为本身想表示的意思\n1 2 # 输出：zhangsan 换行 lisi name: \"zhangsan \\n lisi\" ''（单引号）：会转义特殊字符，特殊字符最终只是一个普通的字符串数据\n1 2 # 输出：zhangsan \\n lisi name: 'zhangsan \\n lisi' 对象（属性和值），Map（键值对） k: v：在下一行来写对象的属性和值的关系，注意缩进\n1 2 3 4 # 对象还是 k: v 的方式 friends: lastName: zhangsan age: 20 行内写法\n1 friends: {lastName: zhangsan,age: 10} 数组（List、Set） 用 - 值表示数组中的一个元素\n1 2 3 4 pets: - cat - dog - pig 行内写法\n1 pets: {cat,dog,pig} SpringBoot 对配置文件的读取 配置文件值注入 配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 person: lastName: zhangsan age: 20 boss: false birth: 2019/11/27 email: 12345@qq.com maps: {k1: v1, k2: 12} lists: - lisi - zhaoliu dog: name: 小狗 age: 2 javaBean\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * 将配置文件中配置的每一个属性的值，映射到这个组件中 * @ConfigurationProperties 告诉 SpringBoot 将本类中的所有属性和配置文件中相关的配置进行绑定 * prefix = \"person\"：和配置文件中哪个下面的所有属性进行一一映射 * * 只有这个组件是容器中的组件，才能使用容器提供的 @ConfigurationProperties 功能 */ @Component @ConfigurationProperties(prefix = \"person\") public class Person { private String lastName; private Integer age; private Boolean boss; private Date birth; private String email; private Map\u003cString, String\u003e maps; private List\u003cObject\u003e lists; private Dog dog; 我们可以导入配置文件处理器，以后编写配置就有提示了\n1 2 3 4 5 6 \u003c!--导入配置文件处理器，配置文件进行绑定就会有提示--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-configuration-processor\u003c/artifactId\u003e \u003coptional\u003etrue\u003c/optional\u003e \u003c/dependency\u003e lastName: 张三 和 last-name: 张三 是一样的\nproperties 配置乱码问题\n@Value 获取值和 @ConfigurationProperties 获取值比较 角度 @ConfigurationProperties @Value 功能 批量注入配置文件中的属性 需要一个个指定 松散绑定（松散语法） 支持 不支持 SpEL 不支持 支持 JSR303 数据校验 支持 不支持 复杂类型封装 支持 不支持 配置文件无论选用 yml 还是 properties 他们都能获取到值\n如果，只是在某个业务逻辑中需要获取一下某个属性的值，用 @Value\n如果，专门编写了一个 JavaBean 来和配置文件进行映射，我们就直接使用 @ConfigurationProperties\n配置文件注入值数据校验 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Component @ConfigurationProperties(prefix = \"person\") @Validated public class Person { /** * 等价于使用 xml 的配置： * \u003cbean class=\"Person\" * \u003cproperty name=\"lastName\" value=\"字面量/${key}/#{SpEL}\"\u003e\u003c/property\u003e * ${key} 可以从环境变量，配置文件中获取值 */ @Value(\"${person.lastName}\") private String lastName; @Value(\"#{11 * 2}\") private Integer age; @Value(\"true\") private Boolean boss; // email 必须为邮箱格式 @Email private String email; @PropertySource 和 @ImportResource @ConfigurationProperties 注解默认从全局配置文件中获取值\n@PropertySource：加载指定的配置文件\n1 2 3 4 @Component @ConfigurationProperties(prefix = \"person\") @PropertySource(value = {\"classpath:person.properties\"}) public class Person { @ImportResource：导入 Spring 的配置文件，让配置文件里面的内容生效\nSpring Boot 里面如果没有默认的配置文件（application.yml/application.properties），那我们自己编写的配置文件也不能被自动识别。想要加载 Spring 的配置，可以在配置类上使用 @ImportResource\n1 2 3 4 // 导入 Spring 的配置文件让其生效 @ImportResource(value = {\"classpath:beans.xml\"}) // 导入 Spring Boot 的配置文件让其生效 @ImportResource(value = {\"classpath:beans.properties\"}) SpringBoot 推荐使用全注解的方式给容器中添加组件\n原始 xml 方式\n1 2 3 4 5 6 7 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"\u003e \u003cbean id=\"helloService\" class=\"icu.intelli.springboot.bean.HelloService\"\u003e\u003c/bean\u003e \u003c/beans\u003e 配置类方式\n配置类就相当于 Spring 配置文件\n使用 @Bean 给容器中添加组件\n1 2 3 4 5 6 7 8 9 10 11 12 13 /** * @Configuration 指明当前类是一个配置类，就是来替代之前的 Spring 配置文件 */ @Configuration public class MyAppConfig { // 将方法的返回值添加到容器中，容器中这个组件默认的 id 就是方法名 @Bean public HelloService helloService(){ System.out.println(\"配置类给容器中添加组件了……\"); return new HelloService(); } } 配置文件占位符 随机数\n1 2 $(random.value), $(random.int), $(random.long) $(random.int(10)), $(random.int[1024, 65536]) 占位符获取之前配置的值，如果没有可以使用:设置默认值\n1 2 3 4 5 6 7 8 9 10 person.last-name=张三${random.uuid} person.age=${random.int} person.birth=2017/12/15 person.boss=false person.maps.k1=v1 person.maps.k2=v2 person.lists=a,b,c # 如果配置了 person.hello，则使用配置的值，否则使用默认值：hello person.dog.name=${person.hello:hello}_dog person.dog.age=15 Profile Profile 是 Spring 对不同环境提供不同配置功能的支持，可以通过激活，指定参数等方式快速切换环境\n在 application.yml 中，可以使用 --- 来分割不同环境的配置，同时使用 spring.profiles 指定环境名称。然后通过 spring.profiles.active 激活指定的环境。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 app: # 公共配置 name: spring boot test server: port: 8081 spring: profiles: ## 指定激活哪个环境 active: dev # 可以使用 --- 对同一个配置文件进行分块 --- server: port: 8083 spring: ## dev 环境 profiles: dev --- server: port: 8084 spring: ## prod 环境 profiles: prod 多 Profile 文件 在同一个配置文件中编写多个环境的配置会很乱，所以可以将不同环境的配置写到不同的配置文件中。按照 application-{profile}.properties/yml 格式来创建不同环境的配置文件。\n激活指定 profile 在配置文件中指定 spring.profiles.active=dev\n命令行\n1 java -jar spring-boot-02-config-0.0.1-SNAPSHOT.jar --spring.profiles.active=dev 虚拟机参数\n1 -Dspring.profiles.active=dev 在 IDEA 中配置参数 在一个 yml 中引入其它 yml SpringBoot 只支持加载 application-{profile}.yml 格式的 yml 文件，如果需要加载多个 yml，可使用如下方式\n1 2 3 4 spring: profiles: include: login,datasource,dubbo 配置文件加载位置 SpringBoot 启动时会扫描以下位置的 application.properties/yml 文件作为 SpringBoot 的默认配置文件\nsrc:./config/ src:./ classpath:/config/ classpath:/ 以上是按照优先级从高到低的顺序，所有位置的文件都会被加载，高优先级配置会覆盖低优先级配置，所有配置形成互补配置\n我们还可以通过配置 spring.config.location 来手动指定配置文件。在启动项目的时候手动指定自定义的配置文件，指定的配置文件和默认加载的这些配置文件会共同起作用，形成互补配置，此时指定的配置文件优先级最高\n外部配置加载顺序 Spring Boot 支持多种外部配置方式，如下常用配置优先级从高到低，高优先级的配置会覆盖低优先级配置，所有配置形成互补配置\n命令行参数\n1 java -jar spring-boot-xx-SNAPSHOT.jar --server.port=8082 此时则使用 8082 端口，多个参数按空格分开；格式：--配置项=值\n来自 java:comp/env 的 JNDI 属性\njava 系统属性\n操作系统环境变量\nRandomValuePropertySource 配置的 random.* 属性值\njar 包外部的 application-{profile}.properties 或 application.yml（带 spring.profile）配置文件\njar 包内部的 application-{profile}.properties 或 application.yml（带 spring.profile）配置文件\njar 包外部的 application.properties 或 application.yml（不带 spring.profile）配置文件\njar 包外部的 application.properties 或 application.yml（不带 spring.profile）配置文件\n@Configuration 注解类上的 @PropertySource\n通过 SpringApplication.setDefaultProperties 指定的默认属性\n6-9 由 jar 包外向 jar 包内进行寻找，优先加载带 profile 的，再加载不带 profile 的。更多配置详见 官方文档\n自动配置原理 配置文件中可以配置哪些属性，参照 官方 Common Application properties\nSpringBoot 在启动时加载主配置类，开启了自动配置功能 @EnableAutoConfiguration\n@EnableAutoConfiguration 作用\n利用 AutoConfigurationImportSelector 给容器中导入一些组件\n可以查看 selectImports() 方法的内容\nList\u003cString\u003e configurations = getCandidateConfigurations(annotationMetadata, attributes); 获取候选的配置\n1 2 3 4 // 扫描所有jar包类路径（META-INF）下的spring.factories文件 // 把扫描到的这些文件的内容包装成Properties对象 // 从properties中获取到EnableAutoConfiguration.class类（类名）对应的值，然后添加在容器中 SpringFactoriesLoader.loadFactoryNames() 将类路径下 META-INF/spring.factories 里面配置的所有 EnableAutoConfiguration 的值加入到容器中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 # Auto Configure org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\\ org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\\ org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\ org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\\ org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\\ org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\ org.springframework.boot.autoconfigure.cloud.CloudServiceConnectorsAutoConfiguration,\\ org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\\ org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\\ org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\\ org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\\ org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.elasticsearch.ReactiveElasticsearchRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.elasticsearch.ReactiveRestClientAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.jdbc.JdbcRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.mongo.MongoReactiveDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.mongo.MongoReactiveRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.redis.RedisReactiveAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\\ org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\\ org.springframework.boot.autoconfigure.elasticsearch.jest.JestAutoConfiguration,\\ org.springframework.boot.autoconfigure.elasticsearch.rest.RestClientAutoConfiguration,\\ org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\\ org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\\ org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\\ org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\\ org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\\ org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\\ org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\\ org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration,\\ org.springframework.boot.autoconfigure.http.codec.CodecsAutoConfiguration,\\ org.springframework.boot.autoconfigure.influx.InfluxDbAutoConfiguration,\\ org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\\ org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\\ org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\\ org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\\ org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\\ org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\\ org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\\ org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\\ org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\\ org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\\ org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\\ org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\\ org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\\ org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\\ org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\\ org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\\ org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration,\\ org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\\ org.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\\ org.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\\ org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\\ org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\\ org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\\ org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\\ org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\\ org.springframework.boot.autoconfigure.mongo.MongoReactiveAutoConfiguration,\\ org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\\ org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\\ org.springframework.boot.autoconfigure.quartz.QuartzAutoConfiguration,\\ org.springframework.boot.autoconfigure.rsocket.RSocketMessagingAutoConfiguration,\\ org.springframework.boot.autoconfigure.rsocket.RSocketRequesterAutoConfiguration,\\ org.springframework.boot.autoconfigure.rsocket.RSocketServerAutoConfiguration,\\ org.springframework.boot.autoconfigure.rsocket.RSocketStrategiesAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.servlet.UserDetailsServiceAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.servlet.SecurityFilterAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.reactive.ReactiveSecurityAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.reactive.ReactiveUserDetailsServiceAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.rsocket.RSocketSecurityAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.saml2.Saml2RelyingPartyAutoConfiguration,\\ org.springframework.boot.autoconfigure.sendgrid.SendGridAutoConfiguration,\\ org.springframework.boot.autoconfigure.session.SessionAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.oauth2.client.servlet.OAuth2ClientAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.oauth2.client.reactive.ReactiveOAuth2ClientAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.oauth2.resource.servlet.OAuth2ResourceServerAutoConfiguration,\\ org.springframework.boot.autoconfigure.security.oauth2.resource.reactive.ReactiveOAuth2ResourceServerAutoConfiguration,\\ org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration,\\ org.springframework.boot.autoconfigure.task.TaskExecutionAutoConfiguration,\\ org.springframework.boot.autoconfigure.task.TaskSchedulingAutoConfiguration,\\ org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration,\\ org.springframework.boot.autoconfigure.transaction.TransactionAutoConfiguration,\\ org.springframework.boot.autoconfigure.transaction.jta.JtaAutoConfiguration,\\ org.springframework.boot.autoconfigure.validation.ValidationAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.client.RestTemplateAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.embedded.EmbeddedWebServerFactoryCustomizerAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.HttpHandlerAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.ReactiveWebServerFactoryAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.WebFluxAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.error.ErrorWebFluxAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.function.client.ClientHttpConnectorAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.reactive.function.client.WebClientAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.DispatcherServletAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.error.ErrorMvcAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.HttpEncodingAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.MultipartAutoConfiguration,\\ org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration,\\ org.springframework.boot.autoconfigure.websocket.reactive.WebSocketReactiveAutoConfiguration,\\ org.springframework.boot.autoconfigure.websocket.servlet.WebSocketServletAutoConfiguration,\\ org.springframework.boot.autoconfigure.websocket.servlet.WebSocketMessagingAutoConfiguration,\\ org.springframework.boot.autoconfigure.webservices.WebServicesAutoConfiguration,\\ org.springframework.boot.autoconfigure.webservices.client.WebServiceTemplateAutoConfiguration 每一个 xxxAutoConfiguration 类都是容器中的一个组件，都加入到容器中；用它们来做自动配置\n对每一个自动配置类进行自动配置\n以 HttpEncodingAutoConfiguration 为例，解释自动配置原理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @Configuration(proxyBeanMethods = false) // 表示这是一个配置类，以前编写的配置文件一样，也可以给容器中添加组件 @EnableConfigurationProperties(HttpProperties.class) // 启动指定类的ConfigurationProperties功能，将配置文件中对应的值和HttpProperties绑定起来，并把HttpProperties加入到IOC容器中 @ConditionalOnWebApplication(type = ConditionalOnWebApplication.Type.SERVLET)// spring底层@Conditional注解，根据不同的条件，如果满足指定的条件，整个配置类里面的配置就会生效；判断当前应用是否是SERVLET应用，如果是，当前配置类生效 @ConditionalOnClass(CharacterEncodingFilter.class) // 判断当前项目有无CharacterEncodingFilter类；SpringMVC中解决乱码的过滤器 @ConditionalOnProperty(prefix = \"spring.http.encoding\", value = \"enabled\", matchIfMissing = true) // 判断配置文件中是否存在某个配置spring.http.encoding.enabled；如果不存在，判断也是成立的. public class HttpEncodingAutoConfiguration { // 已经和SpringBoot的配置文件映射了 private final HttpProperties.Encoding properties; // 只有一个有参构造器的情况下，参数的值就会从容器中拿 public HttpEncodingAutoConfiguration(HttpProperties properties) { this.properties = properties.getEncoding(); } @Bean // 给容器中添加一个组件，这个组件的某些值需要从properties中获取 @ConditionalOnMissingBean public CharacterEncodingFilter characterEncodingFilter() { CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter(); filter.setEncoding(this.properties.getCharset().name()); filter.setForceRequestEncoding(this.properties.shouldForce(Type.REQUEST)); filter.setForceResponseEncoding(this.properties.shouldForce(Type.RESPONSE)); return filter; } 根据当前不同的条件判断这个配置类是否生效。一旦这个配置类生效：这个配置类就会给容器中添加各种组件，这些组件的属性是从对应的 properties 类中获取的，而这些类中的每一个属性又是和配置文件绑定的\n所有在配置文件中能配置的属性都是在 xxxProperties 类中封装着，配置文件能配置什么就可以参照某个功能对应的这个属性类\n1 2 @ConfigurationProperties(prefix = \"spring.http\") // 从配置文件中获取指定的值和bean的属性进行绑定 public class HttpProperties { SpringBoot 的精髓 SpringBoot 启动时会加载大量的自动配置类 我们看我们需要的功能有没有 SpringBoot 默认写好的配置类 再看这个配置类中到底配置来了哪些组件（只要有需要用的组件，就不需要再来配置了） 给容器中自动配置类添加组件的时候，会从 properties 类中获取某些属性。我们就可以在配置文件中指定这些属性的值 细节 SpringBoot 对 Spring 提供的 @Conditional 注解进行了扩展。只有 @Conditional 指定的条件成立，才给容器中添加组件，配置类里的内容才生效。\n@Conditional 扩展注解 作用 @ConditionalOnJava 系统 Java 版本是否符合要求 @ConditionalOnBean 容器中存在指定的 Bean @ConditionalMissingBean 容器中不存在指定的 Bean @ConditionalOnExpression 满足 SpEL 表达式指定 @ConditionalOnClass 系统中有指定类 @ConditionalMissingClass 系统中没有指定类 @ConditionalOnSingleCandidate 容器中只有一个指定的 Bean，或者这个 Bean 是首选 Bean @ConditionalOnProperty 系统中指定的属性是否有指定的值 @ConditionalOnWebApplication 当前是 web 环境 @ConditionalOnNotWebApplication 当前不是 web 环境 @ConditionalOnJndi JNDI 存在指定项 详细说明可参考：Condition Annotations\n自动配置类必须在一定的条件下才能生效，我们怎么知道哪些自动配置类生效了？\n可以通过在配置文件中配置 debug=true，将自动配置报告打印到控制台，这样我们就可以很方便的知道哪些自动配置类生效。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ============================ CONDITIONS EVALUATION REPORT ============================ Positive matches: ----------------- AopAutoConfiguration matched: - @ConditionalOnProperty (spring.aop.auto=true) matched (OnPropertyCondition) ...... Negative matches: ----------------- ActiveMQAutoConfiguration: Did not match: - @ConditionalOnClass did not find required class 'javax.jms.ConnectionFactory' (OnClassCondition) ...... ","description":"","tags":["Spring Boot","Java"],"title":"Spring Boot 配置文件","uri":"/posts/java/springboot%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97/spring-boot-configuration-file/"},{"categories":null,"content":"Spring Boot 入门 Spring Boot 基础系列目录\nSpring Boot 简介 简化 Spring 应用开发的一个框架；整个 Spring 技术栈的一个大整合；J2EE 开发的一站式解决方案\n微服务 2014 年，martin fowler\n微服务：架构风格\n一个应用应该是一组小型服务；可以通过 HTTP 的方式进行互通\n单体应用：ALL IN ONE\n微服务：每一个功能元素最终都是一个可独立替换和独立升级的一个单元\n详细参照微服务文档\n环境要求 Maven 设置 给 Maven 的 settings.xml 配置文件的 profiles 标签添加，设置 Maven 编译时使用的 JDK 版本\n1 2 3 4 5 6 7 8 9 10 11 12 \u003cprofile\u003e \u003cid\u003ejdk-1.8\u003c/id\u003e \u003cactivation\u003e \u003cactiveByDefault\u003etrue\u003c/activeByDefault\u003e \u003cjdk\u003e1.8\u003c/jdk\u003e \u003c/activation\u003e \u003cproperties\u003e \u003cmaven.compiler.source\u003e1.8\u003c/maven.compiler.source\u003e \u003cmaven.compiler.target\u003e1.8\u003c/maven.compiler.target\u003e \u003cmaven.compiler.compilerVersion\u003e1.8\u003c/maven.compiler.compilerVersion\u003e \u003c/properties\u003e \u003c/profile\u003e Spring Boot HelloWorld 一个功能：浏览器发送一个 hello 请求，服务器接收请求并处理，响应 Hello World 字符串\n创建一个 Maven 工程 创建 Maven 工程，packing 设置为 jar\n导入 Spring Boot 相关依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u003c!-- Inherit defaults from Spring Boot --\u003e \u003cparent\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-parent\u003c/artifactId\u003e \u003cversion\u003e2.2.1.RELEASE\u003c/version\u003e \u003c/parent\u003e \u003c!-- Add typical dependencies for a web application --\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e \u003c/dependencies\u003e 编写一个主程序：启动一个 Spring Boot 应用 1 2 3 4 5 6 7 8 9 10 11 /** * @SpringBootApplication 来标注一个主程序类，说明这是一个 Spring Boot 应用 */ @SpringBootApplication public class HelloWorldMainApplication { public static void main(String[] args) { // Spring 应用启动起来 SpringApplication.run(HelloWorldMainApplication.class, args); } } 编写相关的 Controller、Service 1 2 3 4 5 6 7 8 9 10 @Controller public class HelloController { @ResponseBody @RequestMapping(\"/hello\") public String hello(){ return \"Hello World!\"; } } 运行主程序测试 简化部署 导入 Spring Boot 的 Maven 插件后，使用 Maven 的 package 命令即可将应用打成 jar\n1 2 3 4 5 6 7 8 9 \u003c!-- Package as an executable jar --\u003e \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-maven-plugin\u003c/artifactId\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e 使用 java -jar xxx.jar 直接运行\nHello World 探究 POM 文件 父项目 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u003cparent\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-parent\u003c/artifactId\u003e \u003cversion\u003e2.2.1.RELEASE\u003c/version\u003e \u003c/parent\u003e \u003c!-- spring-boot-starter-parent 的父项目是 --\u003e \u003cparent\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-dependencies\u003c/artifactId\u003e \u003cversion\u003e2.2.1.RELEASE\u003c/version\u003e \u003crelativePath\u003e../../spring-boot-dependencies\u003c/relativePath\u003e \u003c/parent\u003e \u003c!-- 它来真正管理 Spring Boot 应用里面的所有依赖版本，所以叫 Spring Boot 的版本仲裁中心 --\u003e 以后我们导入依赖，默认是不需要写版本的；（没有在 dependencies 里面管理的依赖依然需要声明版本号）\n导入的启动器（依赖） 1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e spring-boot-starter-web：spring-boot 场景启动器；该启动器导入了 web 模块正常运行所依赖的组件\nSpring Boot 将所有的功能场景都抽取出来，做成一个个的 starter（启动器），只需要在项目里面引入这些 starter，相关场景的所有依赖都会自动导入进来。要用什么功能就导入什么场景的启动器\n主程序类，主入口类 1 2 3 4 5 6 7 8 9 10 11 /** * @SpringBootApplication 来标注一个主程序类，说明这是一个 Spring Boot 应用 */ @SpringBootApplication public class HelloWorldMainApplication { public static void main(String[] args) { // Spring 应用启动起来 SpringApplication.run(HelloWorldMainApplication.class, args); } } @SpringBootApplication：标注在某个类上，说明这个类是 SpringBoot 的主配置类，Spring Boot 就应该运行这个类的 main 方法来启动 SpringBoot 应用\n1 2 3 4 5 6 7 8 9 @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) }) public @interface SpringBootApplication { @SpringBootConfiguration：标注在某个类上，表示这是一个 Spring Boot 配置类\n@Configuration：是 Spring 的注解，原始 Spring 开发中的配置文件替换为配置类，被 @Component 标注，也是一个组件 @EnableAutoConfiguration：开启自动配置功能。\n以前需要配置的东西，Spring Boot 会自动配置\n1 2 3 @AutoConfigurationPackage @Import(AutoConfigurationImportSelector.class) public @interface EnableAutoConfiguration { @AutoConfigurationPackage：自动配置包\n@Import(AutoConfigurationPackages.Registrar.class)\nSpring 的底层注解 @Import，给容器中导入一个组件；导入的组件由 AutoConfigurationPackages.Registrar.class 指定\n将主配置类（@SpringBootApplication 标注的类）的所在包及其所有子包里面的所有组件扫描到 Spring 容器。\n@Import(AutoConfigurationImportSelector.class)\n1 AutoConfigurationImportSelector：自动配置引入的选择器 将所有需要导入的组件以全类名的方式返回，这些组件就会被添加到 Spring 容器中\n会给容器中导入非常多的自动配置类（xxxAutoConfiguration）；就是给容器中导入这个场景需要的所有组件，并配置好这些组件;\n有了自动配置类，免去了手动编写配置注入功能组件等的工作\nSpringFactoriesLoader.loadFactoryNames(EnableAutoConfiguration.class, classLoader;\nSpring Boot 在启动的时候从类路径下的 META-INF/spring.factories 中获取 EnableAutoConfiguration 指定的值，将这些值作为自动配置类导入到容器中，自动配置类就生效了，帮我们进行自动配置工作；以前需要我们自己配置的东西，自动配置类都做了。\nJ2EE 的整体整合解决方案和自动配置都在 spring-boot-autoconfigure-2.x.x.RELEASE.jar;\n使用 Spring Initializer 快速创建 Spring Boot 项目 IDE 都支持使用 Spring 的项目创建向导快速创建一个 Spring Boot 项目\n选择我们需要的模块；想到会联网创建 Spring Boot 项目\n默认生成的 Spring Boot 项目：\n主程序已经生成好了，我们只需要写我们自己的逻辑 resources 文件夹中目录结构 static：保存所有的静态资源：js css images templates：保存所有的模板页面；（Spring Boot 默认 jar 包使用嵌入式的 Tomcat，默认不支持 jsp 页面）；可以使用模板引擎（freemarker，thymeleaf） application.properties：Spring Boot 应用的配置文件，可以修改一些默认配置 ","description":"","tags":["Spring Boot","Java"],"title":"Spring Boot 入门","uri":"/posts/java/springboot%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97/spring-boot-get-start/"},{"categories":null,"content":"Spring Boot 与日志 Spring Boot 基础系列目录\n日志框架介绍 市面上的日志框架：JUL、JCL、Jboss-logging、logback、log4j、log4j2、slf4j……\n日志门面（日志的抽象层） 日志实现 JCL、SLF4j、jboss-logging log4j、JUL、log4j2、Logback JCL：2014 年最后更新，jboss-logging：只有特定框架使用；log4j、logback、slf4j 是同一个人写的，logback 对 log4j 性能问题的改进，log4j2 适配的框架少；因此选择 slf4j 和 logback。\nSpringBoot：底层是 Spring 框架，Spring 框架默认使用 JCL\n**SpringBoot 选用 slf4j 和 logback **\nslf4j 的使用 如何在系统中使用 slf4j 以后开发的时候，日志记录方法的调用，不应该直接调用日志的实现，而是应调用日志的抽象；\n给系统里面导入 slf4j 的 jar 和 logback 的 jar\nslf4j 用户手册\n1 2 3 4 5 6 7 8 9 import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class HelloWorld { public static void main(String[] args) { Logger logger = LoggerFactory.getLogger(HelloWorld.class); logger.info(\"Hello World\"); } } slf4j 适配各种 log 实现框架\n每一个日志的实现框架都有自己的配置文件，使用 slf4j 后，配置文件还是用日志实现框架的\n遗留问题 A 系统（slf4j + logback）：依赖 Spring（commons-logging），Hibernate（jboss-logging），Mybatis\n统一日志记录，即使别的框架，也要一起统一使用 slf4j 进行输出\nlegacy APIs\n如何让系统中所有的日志都统一到 slf4j\n将系统中其他日志框架先排除出去； 用中间包来替换原有的日志框架； 导入 slf4j 其他的实现。 SpringBoot 日志关系 1 2 3 4 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter\u003c/artifactId\u003e \u003c/dependency\u003e SpringBoot 使用它来做日志记录\n1 2 3 4 xml\u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-logging\u003c/artifactId\u003e \u003c/dependency\u003e 总结\nspringBoot 底层也是使用 slf4j+logback 的方式进行日志记录 SpringBoot 也把其他的日志都替换成了 slf4j 引入中间替换包 如果我们要引入其他框架，一定要把这个框架的默认日志依赖移除掉 Spring 框架用的是 commons-logging 1 2 3 4 5 6 7 8 9 10 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-core\u003c/artifactId\u003e \u003cexclusions\u003e \u003cexclusion\u003e \u003cgroupId\u003ecommons-logging\u003c/groupId\u003e \u003cartifactId\u003ecommons-logging\u003c/artifactId\u003e \u003c/exclusion\u003e \u003c/exclusions\u003e \u003c/dependency\u003e SpringBoot 能自动适配所有的日志，而且底层使用 slf4j+logback 的方式记录日志，引入其他框架的时候，只需要把这个框架依赖的日志框架排除掉;\n日志使用 默认配置 SpringBoot 默认帮我们配置好了日志\n测试类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @SpringBootTest class ApplicationTests { // 记录器 Logger logger = LoggerFactory.getLogger(getClass()); @Test void contextLoads() { // 日志的级别 // 由低到高 trace\u003cdebug\u003cinfo\u003cwarn\u003cerror // 可以调整需要输出的日志级别 logger.trace(\"这是 trace 日志……\"); logger.debug(\"这是 debug 日志……\"); // SpringBoot 默认使用的是 info 级别 // 没有指定级别的就用 SpringBoot 默认规定的级别：root 级别 logger.info(\"这是 info 日志……\"); logger.warn(\"这是 warn 日志……\"); logger.error(\"这是 error 日志……\"); } } 配置文件 application.properties\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 指定某个包的日志记录级别 logging.level.icu.intelli=trace # 不指定路径在当前项目下生成 springboot.log 日志 # 可以指定完整路径 logging.file.name=D:/log/springboot.log # 在当前磁盘的根路径下创建 spring 文件夹和里面的 log 文件夹，使用 spring.log 作为默认文件 # 指定 logging.file.name 后 logging.file.path 即失效 # 1.x 版本为 logging.file 和 logging.path logging.file.path=D:/log # 在控制台输出的文件格式 logging.pattern.console=%d{yyyy-MM-dd} [%thread] %-5level %logger{50} - %msg%n # 指定文件中日志输出的格式 logging.pattern.file=%d{yyyy-MM-dd} === [%thread] === %-5level === %logger{50} === %msg%n 指定配置 官方对日志的说明\n在类路径下放上每个日志框架自己的配置文件即可；SpringBoot 就不使用默认的配置了\nLogging System Customization Logback logback-spring.xml, logback-spring.groovy, logback.xml or logback.grooy Log4j2 log4j2-spring.xml or log4j2.xml JDK（Java Util Logging） logging.properties logback.xml：直接被日志框架识别\nlogback-spring.xml：日志框架就不直接加载日志的配置项，由 SpringBoot 解析日志配置，可以使用 SpringBoot 的 profile 高级特性\n1 2 3 4 5 6 7 8 9 10 11 12 \u003cspringProfile name=\"staging\"\u003e \u003c!-- configuration to be enabled when the \"staging\" profile is active --\u003e 可以指定某段配置只在某个环境生效 \u003c/springProfile\u003e \u003cspringProfile name=\"dev | staging\"\u003e \u003c!-- configuration to be enabled when the \"dev\" or \"staging\" profiles are active --\u003e \u003c/springProfile\u003e \u003cspringProfile name=\"!production\"\u003e \u003c!-- configuration to be enabled when the \"production\" profile is not active --\u003e \u003c/springProfile\u003e 切换日志框架 可以按照 slf4j 的日志适配图，进行相关的切换\n切换为 log4j2 时，可以使用 springboot 提供的 spring-boot-start-log4j2\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003cexclusions\u003e \u003cexclusion\u003e \u003cartifactId\u003espring-boot-starter-logging\u003c/artifactId\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003c/exclusion\u003e \u003c/exclusions\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-log4j2\u003c/artifactId\u003e \u003c/dependency\u003e ","description":"","tags":["Spring Boot","Java"],"title":"Spring Boot 与日志","uri":"/posts/java/springboot%E5%9F%BA%E7%A1%80%E7%B3%BB%E5%88%97/spring-boot-log/"},{"categories":null,"content":"logback 配置文件介绍 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!-- scan：默认为 true，配置文件发生改变，会被重新加载--\u003e \u003c!-- scanPeriod：检查配置文件是否发生更改的时间间隔，默认 6000 毫秒--\u003e \u003c!-- debug：如果为 true，实时打印 logback 框架的日志信息--\u003e \u003cconfiguration scan=\"true\" scanPeriod=\"60 seconds\" debug=\"false\"\u003e \u003c!-- 定义参数常量 --\u003e \u003c!-- 日志级别 TRACE\u003cDEBUG\u003cINFO\u003cWARN\u003cERROR --\u003e \u003cproperty name=\"log.level\" value=\"DEBUG\"/\u003e \u003c!-- 最大保存时间（天） --\u003e \u003cproperty name=\"log.maxHistory\" value=\"30\"/\u003e \u003c!-- 文件输出路径 --\u003e \u003cproperty name=\"log.filePath\" value=\"D:/log\"/\u003e \u003c!-- 输出格式 --\u003e \u003cproperty name=\"log.pattern\" value=\"%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n\"/\u003e \u003c!-- 控制台设置 --\u003e \u003cappender name=\"consoleAppender\" class=\"ch.qos.logback.core.ConsoleAppender\"\u003e \u003c!-- layout 将 event 事件转为字符串 --\u003e \u003c!-- encoder 除了将 event 事件转为字节数组，还会将日志输出到文件 --\u003e \u003cencoder\u003e \u003cpattern\u003e${log.pattern}\u003c/pattern\u003e \u003c/encoder\u003e \u003c/appender\u003e \u003c!-- DEBUG --\u003e \u003cappender name=\"debugAppender\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"\u003e \u003c!-- 文件路径 --\u003e \u003cfile\u003e${log.filePath}/debug.log\u003c/file\u003e \u003crollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"\u003e \u003c!-- 文件名称 --\u003e \u003cfileNamePattern\u003e${log.filePath}/debug/debug.%d{yyyy-MM-dd}.log.gz\u003c/fileNamePattern\u003e \u003c!-- 文件最大保存历史时间 --\u003e \u003cmaxHistory\u003e${log.maxHistory}\u003c/maxHistory\u003e \u003c/rollingPolicy\u003e \u003cencoder\u003e \u003cpattern\u003e${log.pattern}\u003c/pattern\u003e \u003c/encoder\u003e \u003c!-- 仅接受 DEBUG 级别的信息 --\u003e \u003cfilter class=\"ch.qos.logback.classic.filter.LevelFilter\"\u003e \u003clevel\u003eDEBUG\u003c/level\u003e \u003conMatch\u003eACCEPT\u003c/onMatch\u003e \u003conMismatch\u003eDENY\u003c/onMismatch\u003e \u003c/filter\u003e \u003c/appender\u003e \u003c!-- INFO --\u003e \u003cappender name=\"infoAppender\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"\u003e \u003c!-- 文件路径 --\u003e \u003cfile\u003e${log.filePath}/info.log\u003c/file\u003e \u003crollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"\u003e \u003c!-- 文件名称 --\u003e \u003cfileNamePattern\u003e${log.filePath}/info/info.%d{yyyy-MM-dd}.log.gz\u003c/fileNamePattern\u003e \u003c!-- 文件最大保存历史时间 --\u003e \u003cmaxHistory\u003e${log.maxHistory}\u003c/maxHistory\u003e \u003c/rollingPolicy\u003e \u003cencoder\u003e \u003cpattern\u003e${log.pattern}\u003c/pattern\u003e \u003c/encoder\u003e \u003c!-- 仅接受 INFO 级别的信息 --\u003e \u003cfilter class=\"ch.qos.logback.classic.filter.LevelFilter\"\u003e \u003clevel\u003eINFO\u003c/level\u003e \u003conMatch\u003eACCEPT\u003c/onMatch\u003e \u003conMismatch\u003eDENY\u003c/onMismatch\u003e \u003c/filter\u003e \u003c/appender\u003e \u003c!-- ERROR --\u003e \u003cappender name=\"errorAppender\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"\u003e \u003c!-- 文件路径 --\u003e \u003cfile\u003e${log.filePath}/error.log\u003c/file\u003e \u003crollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"\u003e \u003c!-- 文件名称 --\u003e \u003cfileNamePattern\u003e${log.filePath}/error/error.%d{yyyy-MM-dd}.log.gz\u003c/fileNamePattern\u003e \u003c!-- 文件最大保存历史时间 --\u003e \u003cmaxHistory\u003e${log.maxHistory}\u003c/maxHistory\u003e \u003c/rollingPolicy\u003e \u003cencoder\u003e \u003cpattern\u003e${log.pattern}\u003c/pattern\u003e \u003c/encoder\u003e \u003c!-- 仅接受 ERROR 级别的信息 --\u003e \u003cfilter class=\"ch.qos.logback.classic.filter.LevelFilter\"\u003e \u003clevel\u003eERROR\u003c/level\u003e \u003conMatch\u003eACCEPT\u003c/onMatch\u003e \u003conMismatch\u003eDENY\u003c/onMismatch\u003e \u003c/filter\u003e \u003c/appender\u003e \u003c!-- 记录哪个包下的信息，一个类/包只能对应一个 logger --\u003e \u003c!--additivity：默认 true，按 logger 中的日志级别，将日志输出到它父级（root）的位置（console）--\u003e \u003clogger name=\"icu.intelli\" level=\"${log.level}\" additivity=\"true\"\u003e \u003cappender-ref ref=\"debugAppender\"/\u003e \u003cappender-ref ref=\"infoAppender\"/\u003e \u003cappender-ref ref=\"errorAppender\"/\u003e \u003c/logger\u003e \u003c!-- 根级别 --\u003e \u003croot level=\"info\"\u003e \u003cappender-ref ref=\"consoleAppender\"/\u003e \u003c/root\u003e \u003c/configuration\u003e ","description":"","tags":["Logback","Java"],"title":"logback 配置文件介绍","uri":"/posts/java/logback-config-file/"},{"categories":null,"content":"接口的过渡抽象类 接口不当设计 如果 IMessage 接口的 1080 个实现类中均需要添加一个完全相同的方法，此时需要在每一个实现类中添加该方法，累死。该操作是由结构设计不当造成的\n解决方法 使用接口的过渡抽象类\n创建一个抽象类实现 Imessage 接口，具体的实现类继承该抽象类，遇到上述问题时，只需再改抽象类中添加方法即可.\nJDK1.8 新特性 为了解决接口设计的缺陷，所以在接口中允许开发者定义普通方法。\n范例：观察普通方法定义\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 interface IMessage { public String message(); // 方法都具备 public public default boolean connect() { System.out.println(\"建立消息的发送通道.\"); return true; } } class IMessageImpl implements IMessage { public String message() { return \"intelli.icu\"; } } public class Test { public static void main(String[] args) { IMessage iMessage = new IMessageImpl(); if (iMessage.connect()) { System.out.println(iMessage.message()); } } } 接口中的普通方法必须追加 default 声明，但是该操作属于挽救功能，所以如果不是必须的情况，不应该作为你设计的首选。\n除了可以追加普通方法之外，接口里面也可以定义 static 方法，而 static 方法，可以使用接口直接调用\n范例：观察 static 方法定义\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public class Test { public static void main(String[] args) { IMessage iMessage = IMessage.getInstance(); if (iMessage.connect()) { System.out.println(iMessage.message()); } } } interface IMessage { public String message(); // 方法都具备 public public default boolean connect() { System.out.println(\"建立消息的发送通道.\"); return true; } // 定义接口的 static 方法 public static IMessage getInstance() { return new IMessageImpl(); } } class IMessageImpl implements IMessage { public String message() { if (this.connect()) { return \"intelli.icu\"; } return \"没有消息发送\"; } } 如果现在真的可以在接口里面定义普通方法或 static 方法，那么这个功能就已经可以取代抽象类了，但是不应该将这两个功能作为接口的主要设计原则。应该奉行：接口就是抽象方法。\n","description":"","tags":["Java"],"title":"接口的过渡抽象类","uri":"/posts/java/transition-abstract-class/"},{"categories":null,"content":"枚举 枚举的主要作用是定义有限个数对象的一种结构（多例设计），枚举就属于多例设计，并且其结构比多例设计更简单\n多例模式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class Color { private static final Color RED = new Color(\"红色\"); private static final Color GREEN = new Color(\"绿色\"); private static final Color BLUE = new Color(\"蓝色\"); private String title; private Color(String title) { this.title = title; } public static Color getInstance(String color) { switch (color) { case \"red\": return RED; case \"green\": return GREEN; case \"blue\": return BLUE; default: return null; } } public String toString() { return this.title; } } 枚举的基本定义 从 JDK1.5 之后，在程序之中提供了 enum 的关键字，利用此关键字可以实现枚举的定义\n定义一个枚举\n1 2 3 4 5 6 enum Color { // 枚举类 RED, GREEN, BLUE; //实例化对象 } // 调用方式: Color c = Color.RED; 采用多例设计模式需要编写很多程序代码，牵扯到了构造方法的私有化以及静态方法。使用枚举更简便，并且在编译时即可判断所使用的的实例化对象是否存在.\n在进行枚举处理的时候还可以利用 values() 方法获取所有的枚举对象，而多例需要使用到对象数组\n1 2 3 for(Color c: Color.values()){ sout(c); } 在 JDK1.5 追加了枚举结构之后，可以在 switch 之中进行枚举项的判断\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public class Test { public static void main(String[] args) { Color c = Color.RED; switch (c) { case RED: System.out.println(\"红色\"); break; case GREEN: System.out.println(\"绿色\"); break; case BLUE: System.out.println(\"蓝色\"); break; } } } // 枚举类 enum Color { // 实例化对象 RED, GREEN, BLUE } 多例是无法实现这种与 switch 直接连接的, 多例想要实现它，需要编写大量的 if 判断\nEnum 类 严格意义上讲，枚举并不属于一种新的结构，他的本质相当于是一个类，这个类默认会继承 Enum 类\n1 2 public abstract class Enum\u003cE extends Enum\u003cE\u003e\u003e implements Comparable\u003cE\u003e, Serializable {} 现在定义的枚举类的类型就是 Enum 中所使用的 E 类型\nEnum 类中的方法\nNo. 方法名称 类型 说明 01 protected Enum(String name, int ordinal) 构造 传入名字和序号 02 public final String name() 普通 获得对象名字 03 public final int ordinal() 普通 获得对象序号 1 2 3 4 5 6 7 8 9 10 11 12 13 public class Test { public static void main(String[] args) { for (Color c : Color.values()) { System.out.println(c.ordinal() + \" - \" + c.name()); } } } // 枚举类 enum Color { //实例化对象 RED, GREEN, BLUE } 在枚举之中，每一个对象的序号都是根据对象的定义顺序来决定的\n面试题：请解释 enum 与 Enum 的区别?\nenum：是从 JDK1.5 之后提供的一个关键字，用于定义枚举类 Enum：是一个抽象类，所有使用 enum 关键字定义的类就默认继承了此类 定义枚举结构 一直强调枚举本身就属于一种多例设计模式，那么既然是多例设计模式，那么在一个类中可以定义的内容是非常多的。例如：构造方法，普通方法，属性等，这些内容在枚举类中依旧可以直接定义，但是需要注意的是：枚举中定义的构造方法不能采用非私有化定义（public 无法使用）。\n在枚举中定义其他结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public class Test { public static void main(String[] args) { for (Color c : Color.values()) { System.out.println(c.ordinal() + \" - \" + c.name() + \" - \" + c); } } } // 枚举类 enum Color { // 枚举对象要写在首行 RED(\"红色\"), GREEN(\"绿色\"), BLUE(\"蓝色\"); // 定义属性 private String title; private Color(String title) { this.title = title; } public String toString() { return title; } } 本程序在简化程度上要远远高于多例设计模式，除了这种基本的结构之外，在枚举结构中也可以实现接口的继承\n枚举实现接口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public class Test { public static void main(String[] args) { IMessage msg = Color.RED; System.out.println(msg.getMessage()); } } // 枚举类 enum Color implements IMessage { // 枚举对象要写在首行 RED(\"红色\"), GREEN(\"绿色\"), BLUE(\"蓝色\"); // 定义属性 private String title; private Color(String title) { this.title = title; } public String toString() { return title; } @Override public String getMessage() { return this.title; } } interface IMessage { public String getMessage(); } 在枚举类中可以直接定义抽象方法，并且要求每一个枚举对象都要独立实现覆写此抽象方法\n枚举中定义抽象方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 public class Test { public static void main(String[] args) { Color c = Color.RED; System.out.println(c.getMessage()); } } // 枚举类 enum Color { // 枚举对象要写在首行 RED(\"红色\") { public String getMessage() { return this.toString(); } }, GREEN(\"绿色\") { public String getMessage() { return this.toString(); } }, BLUE(\"蓝色\") { public String getMessage() { return this.toString(); } }; // 定义属性 private String title; private Color(String title) { this.title = title; } public String toString() { return title; } // 定义抽象方法 public abstract String getMessage(); } 这个程序实际上不使用枚举也可以正常实现，追加几个判断即可，所以对于枚举，用与不用随意，能看懂就可以了。\n","description":"","tags":["Enum","Java"],"title":"枚举","uri":"/posts/java/enum/"},{"categories":null,"content":"Kong 集群部署总结 准备工作 本次使用的各个软件版本为\nCentOS 7 Windows 10 PostgreSQL：v10.11 Kong v1.4.2 npm v8.11.3 Nginx: v1.16.1 Konga v- 整体介绍 架构图 其中，Konga、Request-Nginx、AdminAPI-Nginx 和其中一个 Kong 安装在 Windows，另一个 Kong，2 个 logController 和 1 个 testController 部署在 CentOS。\nCentOS 系统 IP：10.1.100.152\nWindows 系统 IP：10.1.7.187\nKong 均使用 8000 作为调用服务的端口，使用 8001 作为访问 Admin API 端口。\nRequest-Nginx 代理客户的请求，对请求进行负载均衡，并监听 9000 端口。\nAdminAPI 在 Konga 和 Kong 集群之间传输数据，对 Konga 的请求进行负载均衡，并监听 9001 端口。\nlog-upstream 的反向代理路由只处理 /logRoute 开头的请求，test-upstream 的反向代理路由只处理 /testRoute 开头的请求。\nlogController 中方法的访问路径为 /logController/login，使用 18081 和 18082 端口\ntestController 中方法的访问路径为 /testController/test，使用 18083 端口\n部署及配置说明 kong 的配置介绍 CentOS 中的 kong.conf\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 设置任意 IP 均可以通过反向代理监听的端口 proxy_listen=0.0.0.0:8000,0.0.0.0:8443 ssl # 设置任意 IP 均可以通过 Admin API 监听的端口 admin_listen=0.0.0.0:8001,0.0.0.0:8444 ssl # 设置数据库信息，需提前创建数据库 # 数据库类型，本次使用 PostgresSQL database=postgres # 数据库 IP pg_host=127.0.0.1 # 数据库端口 pg_port=5432 # 数据库用户名 pg_user=kong # 数据库密码 pg_password=kong # 数据库名称 pg_database=kong Windows 使用了 docker 进行安装\n安装及启动命令\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 docker run -d --name kong --network=kong-net -e \"KONG_DATABASE=postgres\" -e \"KONG_PG_HOST=10.1.100.152\" -e \"KONG_PROXY_ACCESS_LOG=/dev/stdout\" -e \"KONG_ADMIN_ACCESS_LOG=/dev/stdout\" -e \"KONG_PROXY_ERROR_LOG=/dev/stderr\" -e \"KONG_ADMIN_ERROR_LOG=/dev/stderr\" -e \"KONG_PROXY_LISTEN=0.0.0.0:8000, 0.0.0.0:8443 ssl\" -e \"KONG_ADMIN_LISTEN=0.0.0.0:8001, 0.0.0.0:8444 ssl\" -p 8000:8000 -p 8443:8443 -p 8001:8001 -p 8444:8444 kong:1.4.2 如果使用 linux 的 docker 需要在上述命令中添加 --privileged=true, 给 kong 应用授权\n添加代理服务，负载均衡及路由 详解可参见 Kong 对比 Nginx 负载均衡\nlogController\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 curl -X POST http://10.1.100.152:8001/upstreams \\ --data 'name=log-upstream' curl -X POST http://10.1.100.152:8001/upstreams/log-upstream/targets \\ --data \"target=10.1.100.152:18081\" \\ --data \"weight=100\" curl -X POST http://10.1.100.152:8001/upstreams/log-upstream/targets \\ --data \"target=10.1.100.152:18082\" \\ --data \"weight=50\" curl -X POST http://10.1.100.152:8001/services/ \\ --data \"name=log-service\" \\ --data \"host=log-upstream\" # 注意此处的 paths[] 参数 # 当通过 paths 中的一个匹配到一个 Route 后，会将匹配到的前缀从发送给上游服务的请求中剔除掉 # 可通过将 strip_path 设置为 false, 取消剔除，默认值为 true, 本文不做修改 # 例如访问 http:10.1.7.187:8000/logRoute/logController/login # 到达上游服务的 url 实际可能 http:10.1.100.152:18081/logController/login curl -X POST http://10.1.100.152:8001/services/log-service/routes/ \\ --data \"hosts[]=10.1.100.152\u0026hosts[]=10.1.7.187\" \\ --data \"paths[]=/logRoute\" 添加 testController\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 curl -X POST http://10.1.100.152:8001/upstreams \\ --data 'name=test-upstream' curl -X POST http://10.1.100.152:8001/upstreams/test-upstream/targets \\ --data \"target=10.1.100.152:18083\" \\ --data \"weight=100\" curl -X POST http://10.1.100.152:8001/services/ \\ --data \"name=test-service\" \\ --data \"host=test-upstream\" curl -X POST http://10.1.100.152:8001/services/test-service/routes/ \\ --data \"hosts[]=10.1.100.152\u0026hosts[]=10.1.7.187\" \\ --data \"paths[]=/testRoute\" 此时已对真实的服务做了反向代理和负载均衡。可通过 http://10.1.7.187:8000/logRoute/logController/login，http://10.1.100.152:8000/logRoute/logController/login，http://10.1.7.187:8000/testRoute/testController/test，http://10.1.100.152:8000/testRoute/testController/test 访问真实服务，并通过 http://10.1.7.187:8001/routes，http://10.1.100.152:8001/routes 访问 Admin API 接口获取所有 routes 信息。\n对 Kong 的端口进行反向代理和负载均衡 访问端口(8000) nginx.conf\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 events { } http { upstream kong { server 10.1.100.152:8000; server 10.1.7.187:8000; } server { listen 9000; location / { # 一定要添加该条，否则会访问不同 kong 的 route proxy_set_header Host $http_host; proxy_pass http://kong; } } } 此时可通过 http://10.1.7.187:9000/logRoute/logController/login 或 http://10.1.7.187:9000/testRoute/testController/test 访问真实服务\nAdmin API 端口(8001) nginx.conf\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 events { } http { upstream kong-admin { server 10.1.7.187:8001; server 10.1.100.152:8001; } server { listen 9001; location / { allow all; proxy_pass http://kong-admin; } } } 此时可通过 http://10.1.7.187:9001/routes 访问 kong 的 Admin API，并获取所有的 route 信息。\n安装 Konga GitHub 地址\n测试环境不需要做数据库，拉下代码，直接 npm install → npm start 即可。\n生产环境需要使用到数据库，来存储账号等信息。\n具体步骤参照 GitHub 下方说明即可。\n","description":"","tags":["Kong"],"title":"Kong 集群部署总结","uri":"/posts/kong/kong-cluster-summary/"},{"categories":null,"content":"log4j 的 HelloWorld 程序 Log4J 日志简介 Log4J（log for java）是 java 主流的日志框架，提供各种类型，各种存储，各种格式，多样化的日志服务；在爬虫领域，主要用于记录爬虫的执行过程，方便排查爬虫执行错误问题。\n2015 年 8 月 5 日，宣布 Log4j 1.x 任期结束，推荐使用 Apache log4j 2\nHello World 引入依赖 1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003elog4j\u003c/groupId\u003e \u003cartifactId\u003elog4j\u003c/artifactId\u003e \u003cversion\u003e1.2.17\u003c/version\u003e \u003c/dependency\u003e 配置文件 log4j.properties\n1 2 3 4 5 6 7 8 9 10 11 12 log4j.rootLogger=DEBUG, Console, File # Console log4j.appender.Console = org.apache.log4j.ConsoleAppender log4j.appender.Console.layout = org.apache.log4j.PatternLayout log4j.appender.Console.layout.ConversionPattern = %d [%t] %-5p [%c] - %m%n # File log4j.appender.File = org.apache.log4j.FileAppender log4j.appender.File.file = D:\\\\log\\\\log log4j.appender.File.layout = org.apache.log4j.PatternLayout log4j.appender.File.layout.ConversionPattern = %d [%t] %-5p [%c] - %m%n 测试程序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class HelloWorld { // 获取一个 logger 实例 private static Logger logger = Logger.getLogger(HelloWorld.class); public static void main(String[] args) { logger.info(\"普通 info 信息\"); logger.debug(\"调试 debug 信息\"); logger.error(\"报错 error 信息\"); logger.warn(\"警告 warn 信息\"); logger.fatal(\"致命 fatal 信息\"); logger.error(\"报错信息\", new IllegalArgumentException(\"非法参数\")); } } 输出\n2019-12-12 21:52:32,920 [main] INFO [icu.intelli.HelloWorld] - 普通 info 信息 2019-12-12 21:52:32,921 [main] DEBUG [icu.intelli.HelloWorld] - 调试 debug 信息 2019-12-12 21:52:32,921 [main] ERROR [icu.intelli.HelloWorld] - 报错 error 信息 2019-12-12 21:52:32,921 [main] WARN [icu.intelli.HelloWorld] - 警告 warn 信息 2019-12-12 21:52:32,921 [main] FATAL [icu.intelli.HelloWorld] - 致命 fatal 信息 2019-12-12 21:52:32,923 [main] ERROR [icu.intelli.HelloWorld] - 报错信息 java.lang.IllegalArgumentException: 非法参数 at icu.intelli.HelloWorld.main(HelloWorld.java:17) ","description":"","tags":["Log4j","Java"],"title":"log4j 的 HelloWorld 程序","uri":"/posts/java/log4j-hello-word/"},{"categories":null,"content":"log4j 详细配置 log4j 根配置语法 1 log4j.rootLogger = [ level ], appenderName, appenderName, ... 把指定级别（level）的日志信息输出到指定的一个或多个位置（appenderName）\n日志等级 log4j 根据日志信息的重要程度，由高到低否分为 OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL，可以输出等级大于等于 level 的日志信息。例如：配置为 WARN 可以输出 FATAL、ERROR、WARN 日志信息。\nlog4j 官方建议实际开发时只是用 4 个级别，优先级从高到低分别为 ERROR、WARN、INFO、DEBUG\n如果 rootLogger 的 level 设置为 DEBUG，则所有的信息都可以输出\n输出位置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # DEBUG 为 level # Console 和 File 为 appenderName，可以自定义，只要下方配置与其对应即可 log4j.rootLogger=DEBUG, Console, File # Console log4j.appender.Console = org.apache.log4j.ConsoleAppender log4j.appender.Console.layout = org.apache.log4j.PatternLayout log4j.appender.Console.layout.ConversionPattern = %d [%t] %-5p [%c] - %m%n # File log4j.appender.File = org.apache.log4j.FileAppender log4j.appender.File.file = D:\\\\log\\\\log log4j.appender.File.layout = org.apache.log4j.PatternLayout log4j.appender.File.layout.ConversionPattern = %d [%t] %-5p [%c] - %m%n log4j 官方提供的 appender:\norg.apache.log4j.ConsoleAppender：控制台 org.apache.log4j.FileAppender：文件 org.apache.log4j.DailyRollingFileAppender：每天产生一个日志文件 org.apache.log4j.RollingFileAppender：文件大小到达指定尺寸产生一个新文件 org.apache.log4j.WriterAppender：将日志信息以流的形式发送到任意指定的地方 实际开发中使用 1，3，4\n假如日志数据量不是很大，可以使用 DailyRollingFileAppender 每天产生一个日志，方便查看； 假如日志数据量很大，可以使用 RollingFileAppender，固定尺寸的日志，超过指定大小就产生一个新文件。 示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 log4j.rootLogger=DEBUG, Console ,File ,DailyRollingFile ,RollingFile # Console log4j.appender.Console=org.apache.log4j.ConsoleAppender log4j.appender.Console.layout=org.apache.log4j.PatternLayout log4j.appender.Console.layout.ConversionPattern=%d [%t] %-5p [%c] - %m%n # File log4j.appender.File = org.apache.log4j.FileAppender log4j.appender.File.File = C://File log4j.appender.File.layout = org.apache.log4j.PatternLayout log4j.appender.File.layout.ConversionPattern =%d [%t] %-5p [%c] - %m%n # DailyRollingFile log4j.appender.DailyRollingFile = org.apache.log4j.DailyRollingFileAppender log4j.appender.DailyRollingFile.File = C://DailyRoolingFile log4j.appender.DailyRollingFile.layout = org.apache.log4j.PatternLayout log4j.appender.DailyRollingFile.layout.ConversionPattern =%d [%t] %-5p [%c] - %m%n # RollingFile log4j.appender.RollingFile = org.apache.log4j.RollingFileAppender log4j.appender.RollingFile.File = C://RoolingFile log4j.appender.RollingFile.MaxFileSize=1KB log4j.appender.RollingFile.MaxBackupIndex=3 log4j.appender.RollingFile.layout = org.apache.log4j.PatternLayout log4j.appender.RollingFile.layout.ConversionPattern =%d [%t] %-5p [%c] - %m%n log4j.appender.RollingFile.MaxFileSize：日志文件的最大尺寸\nlog4j.appender.RollingFile.MaxBackupIndex：日志文件的个数，如果超过了则覆盖\nlayout 日志信息格式 org.apache.log4j.HTMLLayout：以 HTML 表格形式布局 org.apache.log4j.SimpleLayout：包含日志信息的级别和信息的字符串 org.apache.log4j.TTCCLayout：包含日志产生的时间，线程，类别等信息 org.apache.log4j.PatternLayout：可以灵活地指定布局模式 HTMLLayout 1 2 log4j.appender.Console=org.apache.log4j.ConsoleAppender log4j.appender.Console.layout=org.apache.log4j.HTMLLayout 输出\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 \u003c!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\"\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eLog4J Log Messages\u003c/title\u003e \u003cstyle type=\"text/css\"\u003e \u003c!-- body, table {font-family: arial,sans-serif; font-size: x-small;} th {background: #336699; color: #FFFFFF; text-align: left;} --\u003e \u003c/style\u003e \u003c/head\u003e \u003cbody bgcolor=\"#FFFFFF\" topmargin=\"6\" leftmargin=\"6\"\u003e \u003chr size=\"1\" noshade\u003e Log session start time Fri Dec 13 11:00:02 GMT+08:00 2019\u003cbr\u003e \u003cbr\u003e \u003ctable cellspacing=\"0\" cellpadding=\"4\" border=\"1\" bordercolor=\"#224466\" width=\"100%\"\u003e \u003ctr\u003e \u003cth\u003eTime\u003c/th\u003e \u003cth\u003eThread\u003c/th\u003e \u003cth\u003eLevel\u003c/th\u003e \u003cth\u003eCategory\u003c/th\u003e \u003cth\u003eMessage\u003c/th\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003e0\u003c/td\u003e \u003ctd title=\"main thread\"\u003emain\u003c/td\u003e \u003ctd title=\"Level\"\u003eINFO\u003c/td\u003e \u003ctd title=\"icu.intelli.HelloWorld category\"\u003eicu.intelli.HelloWorld\u003c/td\u003e \u003ctd title=\"Message\"\u003e普通 info 信息\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003e2\u003c/td\u003e \u003ctd title=\"main thread\"\u003emain\u003c/td\u003e \u003ctd title=\"Level\"\u003e\u003cfont color=\"#339933\"\u003eDEBUG\u003c/font\u003e\u003c/td\u003e \u003ctd title=\"icu.intelli.HelloWorld category\"\u003eicu.intelli.HelloWorld\u003c/td\u003e \u003ctd title=\"Message\"\u003e调试 debug 信息\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003e2\u003c/td\u003e \u003ctd title=\"main thread\"\u003emain\u003c/td\u003e \u003ctd title=\"Level\"\u003e\u003cfont color=\"#993300\"\u003e\u003cstrong\u003eWARN\u003c/strong\u003e\u003c/font\u003e\u003c/td\u003e \u003ctd title=\"icu.intelli.HelloWorld category\"\u003eicu.intelli.HelloWorld\u003c/td\u003e \u003ctd title=\"Message\"\u003e警告 warn 信息\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003e2\u003c/td\u003e \u003ctd title=\"main thread\"\u003emain\u003c/td\u003e \u003ctd title=\"Level\"\u003e\u003cfont color=\"#993300\"\u003e\u003cstrong\u003eERROR\u003c/strong\u003e\u003c/font\u003e\u003c/td\u003e \u003ctd title=\"icu.intelli.HelloWorld category\"\u003eicu.intelli.HelloWorld\u003c/td\u003e \u003ctd title=\"Message\"\u003e报错 error 信息\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003e2\u003c/td\u003e \u003ctd title=\"main thread\"\u003emain\u003c/td\u003e \u003ctd title=\"Level\"\u003e\u003cfont color=\"#993300\"\u003e\u003cstrong\u003eFATAL\u003c/strong\u003e\u003c/font\u003e\u003c/td\u003e \u003ctd title=\"icu.intelli.HelloWorld category\"\u003eicu.intelli.HelloWorld\u003c/td\u003e \u003ctd title=\"Message\"\u003e致命 fatal 信息\u003c/td\u003e \u003c/tr\u003e SimpleLayout 输出\nINFO - 普通 info 信息 DEBUG - 调试 debug 信息 WARN - 警告 warn 信息 ERROR - 报错 error 信息 FATAL - 致命 fatal 信息 TTCCLayout 输出\n[main] INFO icu.intelli.HelloWorld - 普通 info 信息 [main] DEBUG icu.intelli.HelloWorld - 调试 debug 信息 [main] WARN icu.intelli.HelloWorld - 警告 warn 信息 [main] ERROR icu.intelli.HelloWorld - 报错 error 信息 [main] FATAL icu.intelli.HelloWorld - 致命 fatal 信息 PatternLayout 实际开发应该使用的\n配置\n1 2 3 log4j.appender.Console=org.apache.log4j.ConsoleAppender log4j.appender.Console.layout=org.apache.log4j.PatternLayout log4j.appender.Console.layout.ConversionPattern=%d [%t] %-5p [%c] - %m%n 输出\n2019-12-13 11:03:46,985 [main] INFO [icu.intelli.HelloWorld] - 普通 info 信息 2019-12-13 11:03:46,985 [main] DEBUG [icu.intelli.HelloWorld] - 调试 debug 信息 2019-12-13 11:03:46,985 [main] WARN [icu.intelli.HelloWorld] - 警告 warn 信息 2019-12-13 11:03:46,985 [main] ERROR [icu.intelli.HelloWorld] - 报错 error 信息 2019-12-13 11:03:46,985 [main] FATAL [icu.intelli.HelloWorld] - 致命 fatal 信息 ConversionPattern 配置说明 %m 输出代码中指定的消息； %M 输出打印该条日志的方法名； %p 输出日志等级，即 DEBUG，INFO，WARN，ERROR，FATAL, %-5p 表示需要输出 5 个字符，不足 5 个字符用空格填补； %r 输出自应用启动到输出该 log 信息耗费的毫秒数; %c 输出所属的类名，通常就是所在类的全名； %t 输出产生该日志事件的线程名； %n 输出一个回车换行符，Windows 平台为”\\r\\n”，Unix 平台为“\\n”； %d 输出日志时间点的日期或时间，默认格式为 ISO8601，也可以在其后指定格式，比如：%d{yyyy-MM-dd HH:mm:ss,SSS}，输出类似：2002-10-18 22:10:28,921； %l 输出日志事件的发生位置，及在代码中的行数； Threshold 属性指定输出等级 有时候我们需要把一些 ERROR 日志单独存到指定文件，这时，就需要用到 Threshold 属性\n示例\n将 Debug 以上的所有信息保存到 DebugFile，其中的 ERROR 级别以上的信息，单独再保存到 ErrorFile 一份。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 log4j.rootLogger=DEBUG, DebugFile, ErrorFile # DebugFile log4j.appender.DebugFile = org.apache.log4j.FileAppender log4j.appender.DebugFile.File = D:/log/DebugFile log4j.appender.DebugFile.layout = org.apache.log4j.PatternLayout log4j.appender.DebugFile.layout.ConversionPattern =%d [%t] %-5p [%c] - %m%n # ErrorFile log4j.appender.ErrorFile = org.apache.log4j.FileAppender log4j.appender.ErrorFile.File = D:/log/ErrorFile log4j.appender.ErrorFile.layout = org.apache.log4j.PatternLayout log4j.appender.ErrorFile.layout.ConversionPattern =%d [%t] %-5p [%c] - %m%n log4j.appender.ErrorFile.Threshold = ERROR DebugFile:\nErrorFile:\nAppend 属性指定是否追加内容 默认是 true, 追加。\n设置为覆盖之前的信息\n1 log4j.appender.File.Append = false ","description":"","tags":["Log4j","Java"],"title":"log4j 详细配置","uri":"/posts/java/log4j-configuration/"},{"categories":null,"content":"Nginx 中 proxy_set_header 的作用 参考文档：nginx 中 proxy_set_header Host $host 的作用\nginx 为了实现反向代理的需求而增加了一个 ngx_http_proxy_module 模块。其中 proxy_set_header 指令就是该模块需要读取的配置文件。在这里，所有设置的值的含义和 http 请求同中的含义完全相同，除了 Host 外还有 X-Forward-For。 Host 的含义是表明请求的主机名，因为 nginx 作为反向代理使用，而如果后端真是的服务器设置有类似防盗链或者根据 http 请求头中的 host 字段来进行路由或判断功能的话，如果反向代理层的 nginx 不重写请求头中的 host 字段，将会导致请求失败【默认反向代理服务器会向后端真实服务器发送请求，并且请求头中的 host 字段应为 proxy_pass 指令设置的服务器】。 同理，X_Forward_For 字段表示该条 http 请求是有谁发起的？如果反向代理服务器不重写该请求头的话，那么后端真实服务器在处理时会认为所有的请求都来在反向代理服务器，如果后端有防攻击策略的话，那么机器就被封掉了。因此，在配置用作反向代理的 nginx 中一般会增加两条配置，修改 http 的请求头： proxy_set_header Host $http_host; proxy_set_header X-Forward-For $remote_addr; 这里的$http_host 和$remote_addr 都是 nginx 的导出变量，可以再配置文件中直接使用。如果 Host 请求头部没有出现在请求头中，则$http_host 值为空，但是$host 值为主域名。因此，一般而言，会用$host 代替$http_host 变量，从而避免 http 请求中丢失 Host 头部的情况下 Host 不被重写的失误。\nX-Forwarded-For:简称 XFF 头，它代表客户端，也就是 HTTP 的请求端真实的 IP，只有在通过了 HTTP 代理或者负载均衡服务器时才会添加该项。它不是 RFC 中定义的标准请求头信息，在 squid 缓存代理服务器开发文档中可以找到该项的详细介绍。标准格式如下：X-Forwarded-For: client1, proxy1, proxy2。\n这一 HTTP 头一般格式如下: X-Forwarded-For: client1, proxy1, proxy2 其中的值通过一个 逗号+空格 把多个 IP 地址区分开，最左边(client1)是最原始客户端的 IP 地址，代理服务器每成功收到一个请求，就把请求来源 IP 地址添加到右边。在上面这个例子中，这个请求成功通过了三台代理服务器：proxy1, proxy2 及 proxy3。请求由 client1 发出，到达了 proxy3(proxy3 可能是请求的终点)。请求刚从 client1 中发出时，XFF 是空的，请求被发往 proxy1；通过 proxy1 的时候，client1 被添加到 XFF 中，之后请求被发往 proxy2;通过 proxy2 的时候，proxy1 被添加到 XFF 中，之后请求被发往 proxy3；通过 proxy3 时，proxy2 被添加到 XFF 中，之后请求的的去向不明，如果 proxy3 不是请求终点，请求会被继续转发。 鉴于伪造这一字段非常容易，应该谨慎使用 X-Forwarded-For 字段。正常情况下 XFF 中最后一个 IP 地址是最后一个代理服务器的 IP 地址，这通常是一个比较可靠的信息来源。\n","description":"","tags":["Nginx"],"title":"Nginx 中 proxy_set_header 的作用","uri":"/posts/nginx/nginx-proxy-set-header/"},{"categories":null,"content":"konga\n官方推荐使用 node v8.11.3，使用 v12+ 会遇到解决不了的问题\n如果缺少 python/VCBuild.exe，以管理员身份执行如下代码\n1 npm install --global --production windows-build-tools ","description":"","tags":["Kong"],"title":"Kong 的图形化管理页面 konga","uri":"/posts/kong/kong-konga/"},{"categories":null,"content":"Kong 对比 Nginx 负载均衡 介绍和准备环境 由于 Kong 是基于 Openresty 的，而 Openresty 又是对 Niginx 的二次封装，所以有很多配置与 Nginx 类似。\n举一个典型的 Nginx 负载均衡配置的例子\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 这里包含着上游服务的位置信息 upstream upstream-name { server 10.1.3.15:8080 weight=100; server 10.1.3.16:8081 weight=50 } # 这是 Nginx 的反向代理服务 server { listen 80; location /hello { proxy_pass http://upstream-name; } } nginx 监听来自本地 80 端口的请求，如果路径与 /hello 匹配，便将请求原封不动的转发到名称为 upstream-name 的 upstream，而该 upstream 配置了一个负载均衡器，可以路由到 10.1.3.15:8080 和 10.1.3.16:8081\n在 10.1.3.15:8080 和 10.1.3.16:8081 上部署两个项目，访问路径为 /hello/hi, 分别返回 “10.1.3.15:8080” 和 “10.1.3.16:8081”。\n对于 Kong 的安装和启动此处不做介绍\n对比 Kong 和 Nginx 的 upstream 和 target Kong 创建一个叫 upstream-name 的 upstream\n1 2 curl -i -X POST http://kong:8001/upstreams \\ -- data \"name=upstream-name\" 添加两个负载均衡节点，即两个真实的服务\n1 2 3 4 5 6 7 curl -i -X POST http://kong:8081/upstreams/upstreams-name/targets \\ --data \"target=10.1.3.15:8080\" \\ --data \"weight=100\" curl -i -X POST http://kong:8081/upstreams/upstreams-name/targets \\ --data \"10.1.3.16:8081\" \\ --data \"weight=50\" Nginx 1 2 3 4 upstream upstream-name { server 10.1.3.15:8080 weight=100; server 10.1.3.16:8081 weight=50 } 对比 Kong 和 Nginx 的 service 和 route Kong 配置一个 service（反向代理服务），host 对应 upstream-name\n1 2 3 curl -i -X POST http://kong:8001/services \\ --data \"name=service-name\" \\ --data \"host=upstream-name\" 为上面的 service 配置 route 信息\n1 2 3 curl -X POST http://localhost:8001/services/service-name/routes/ \\ --data \"hosts[]=route's IP or domain\" \\ --data \"path[]=/hello\" 请求路径以 /hello 开头的请求都会被路由到对应的代理服务进行处理，该代理服务使用负载均衡算法选择并调用一个真实服务。\nNginx 1 2 3 location /hello { proxy_pass http://upstream-name; } 测试 Kong 负载均衡 1 curl http://route's IP or domain:8000/hello/hi 2/3 概率返回 10.1.3.15:8080，1/3 概率返回 10.1.3.16:8081。\n遇到的问题 通过上述方式访问，我遇到过返回 404 的问题，通过对真实服务添加 Filter 调试发现, 使用浏览器访问 http://route's IP or domain:8000/hello/hi，后台真实访问的是 http://route's IP or domain:8000/hi，缺少了 /hello 路径，具体原因暂未探讨，请注意，使用的 kong 版本为 1.4.0。\n参考文档 初识 Kong 之负载均衡\n","description":"","tags":["Kong","Nginx"],"title":"Kong 对比 Nginx 负载均衡","uri":"/posts/kong/kong-compare-nginx/"},{"categories":null,"content":"集群参考 介绍 Kong 集群允许你通过添加更多的机器来水平扩展系统，并处理更多传入请求。因为它们都使用同一个数据库，所以它们会使用相同的配置。指向同一个数据库的 Kong 节点将属于同一个集群。\n需要在 Kong 集群前添加一个负载均衡器，来在可用节点之间分配流量。\nKong 集群能够/不能够做的 拥有一个 Kong 集群并不意味着客户端的流量就会在这些 Kong 节点之间实现负载均衡。仍然需要在所有的 Kong 集群节点前添加一个负载均衡器去分配流量。否则，一个 Kong 集群中的所有节点都使用相同的配置。\n处于性能考虑, Kong 在代理请求时避免数据库的连接，并在内存中缓存数据库内容。该缓存实体包含服务，路由，消费方，插件，证书等等……因为这些值已经存储在内存中，所以需要将任意一个节点使用 Admin API 做的改变传播给其他的节点。\n本文介绍了如何使那些缓存的实体失效以及如何为您的用例配置 Kong 节点，这些配置考虑了性能和一致性。\n单节点 Kong 集群 一个单独的 Kong 节点连接到数据库（cassandra 或 PostgreSQL）创建一个单节点的 Kong 集群。任何通过该节点的 Admin API 做的改变会即时生效。例\n想象有一个 Kong 节点 A，如果我们删除以前注册的服务\n1 curl -X DELETE http://127.0.0.1:8001/services/test-service 这时，任何访问 A 节点的请求都会返回 404 Not Found，因为该节点从内部缓存中清除了它\n1 curl -i http://127.0.0.1:8000/test-service 多节点的 Kong 集群 在多个 Kong 节点的集群中，连接相同数据库的其他节点不会立即接收到 A 节点删除该服务的通知，虽然服务不在数据库了（它被 A 节点删除了），但是它还存在在 B 节点的内存中。\n所有的节点进行周期性的后台工作去同步其他节点执行的改变。这项工作的频率可以通过如下配置设置\n1 db_update_frequency (default: 5 seconds) 每隔 db_update_frequency 秒，所有正在运行的 Kong 节点会轮询数据库中的更新，并在需要时清除它们缓存中的实体。\n如果我们通过 A 节点删除了一个服务，这个改变在节点 B 轮询数据库之前对于 B 节点来说是无效的，要过 db_update_frequency 秒才生效。（小于等于）\n这个配置使得 Kong 集群最终一致。\n正在缓存什么 所有核心的实体，例如服务，路由，插件，消费者，证书都会被 Kong 缓存到内存，并根据轮询机制将它们更新为失效。\n另外, Kong 还缓存未命中的数据。例如你配置的一个服务没有 plugin，Kong 将会缓存这个信息。例\n在 A 节点，我们添加一个 Service 和一个 Route\n1 2 3 4 5 6 7 # node A $ curl -X POST http://127.0.0.1:8001/services \\ --data \"name=example-service\" \\ --data \"url=http://example.com\" $ curl -X POST http://127.0.0.1:8001/services/example-service/routes \\ --data \"paths[]=/example\" （注意，我们使用 /services/example-service/routes 作为快捷方式：也可以使用 /routes 端点代替，但是这时我们需要使用 service_id 作为参数，这个新的服务 ID 是 UUID）\n对 A 节点和 B 节点的代理端口发送请求，将会缓存该服务，并缓存没有在该服务上配置 plugin 的事实:\n1 2 3 4 5 # node A curl http://127.0.0.1:8000/example HTTP 200 OK ... 1 2 3 4 5 # node B curl http://127.0.0.2:8000/example HTTP 200 OK ... 现在我们通过 A 节点的 Admin API 添加一个插件\n1 2 3 # node A curl -X POST http://127.0.0.1:8001/services/example-service/plugins \\ --data \"name=example-plugin\" // TODO 官方文档\n","description":"","tags":["Kong"],"title":"Kong 集群参考","uri":"/posts/kong/kong-cluster-reference/"},{"categories":null,"content":"未能加载 Visual C++ 组件“VCBuild.exe” 缺少 python 环境，或缺少组件等\n安装构建工具\n1 npm install --global --production windows-build-tools ","description":"","tags":["NodeJS"],"title":"未能加载 Visual C++ 组件“VCBuild.exe”","uri":"/posts/nodejs/cannot-load-visual-cpp-vcbuild/"},{"categories":null,"content":"Kong 负载均衡 \u0026 蓝绿部署 \u0026 金丝雀发布 介绍 Kong 为提交到后端的请求提供多种负载均衡方式：一个简单的 DNS-based 方法和一个更动态的 ring-balancer 方法（允许服务不通过 DNS 服务器注册）\nDNS-based 负载均衡 A 记录（A records） 一个 A 记录包含一个或多个 IP 地址。因此，当一个主机名解析为一个 A 记录，每一个后端服务必须有他自己的 IP 地址。\n因为没有权重（weight）信息，所以，所有的入口在负载均衡时都具有相同的权重，并且这个均衡器会进行一个简单的轮询。\nSRV 记录（SRV records） SRV 记录包含它所有 IP 地址的权重和端口信息，后端服务可以通过 IP 和端口号来唯一的标识。因此，一个 IP 地址能够承载多个在不同端口上的服务实例。\n因为权重（weight）是可用的，每个入口在负载均衡时会有自己的权重，将会进行带权重的轮询。\n同样的，任何一个给定的端口信息将会覆盖 DNS 服务器中的端口信息。如果一个服务有 host=myhost.com 和 port=123 两个属性，并且 myhost.com 解析为具有 127.0.0.1:456 的 SRV 记录，则该请求会被代理为 http://127.0.0.1:456/somepath，123 端口被重写为 456。\nDNS 优先权（DNS priorities） DNS 解析器会按以下的顺序解析记录类型\n以前最后解决成功的类型 SRV 记录 A 记录 CNAME 记录 解析顺序可通过 dns_order 属性配置\nDNS 注意事项 每当 DNS 被刷新，都会生成一个列表以正确处理权重。并尝试将权重保持为彼此的倍数来保证算法的高效性。例如，权重为 17 和 31 的两个权重值，将会导致具有 527 条记录的列表，而 16 和 32（或他们的最小相对值 1 和 2）两个权重将导致仅有 3 条记录的列表，特别是有一个非常小（甚至是 0）的 TTL 值 一些域名服务器不返回所有的记录（由于 UDP 包的大小造成的），这时，一个给定的 Kong 节点只能使用域名服务器提供的少数上游服务实例。在这种情况下，上游实例池的加载可能不一致，因为域名服务器提供的信息有限，所以 Kong 节点实际上并没有发现某些实例。为了减轻这种情况，请使用其他域名服务器，或使用 IP 地址替换名称，或使用足够的 Kong 节点保证使用了所有的上游服务。 当域名返回了 3 name error，这是 kong 的有效响应。如果这是意外情况，请首先验证是否正在查询正确的名称，然后检查您的名称服务器配置。 从 DNS 记录（A 或 SRV）中初始选择 IP 地址不是随机的。因此使用 TTL 为 0 的记录时，名称服务器应将记录列表随机化。 环平衡器（Ring-balancer） 当使用 ring-balancer，后端服务的添加和删除会被 Kong 管理，这时更新 DNS 不是必须的。Kong 会作为服务注册表。可以使用一个 HTTP 请求添加/删除节点，并立即启动/停止接收流量。\n通过 upstream 和 target 条目来配置 ring-balancer\ntarget：后端服务的地址，使用 IP 地址（或域名）和端口号指定。例如：“192.168.100.12.80”。每个 target 都可以通过附加的 weight 去设置它的权重。\nupstream：能被用在路由（Route）的 host 字段中的一个虚拟主机名（virtual hostname），例如：一个上游服务的被命名为 weather.v2.service，那么带有 host=weather.v2.service 的请求均可以请求它。\n上游（Upstream） 每个 upstream 有它自己的 ring-balancer。每个 upstream 有许多的 target 连接到它，并且代理到虚拟主机名（可以使用 upstream 的 post_header 属性对其覆盖）的请求将会在 targets 之间进行负载均衡。ring-balancer 会预先定义一定数量的 slots，并根据目标权重将 slots 分配给 upstream 中的 targets。\n可以使用 HTTP 请求 Admin API 添加或移除 targets。 这种操作成本较低。更改 upstream 本身的成本较高，例如当 slots 的数量变了，需要重建负载均衡器。\n只有当 target 历史被清理时，均衡器会被完全重建。其他情况只会根据更改重建。\nring-balancer 中的位置（positions，from 1 to slots）是随机分配的。必要的随机性使得在运行时调用 ring-balancer 的成本较低。在 wheel（the positions，ring-balancer 中的位置）上进行轮询会提供在 targets 分布均匀的加权轮询，同时对 targets 的插入/删除成本较低。\n每个 target 应该有大约 100 个 slots，确保 slots 是合理分配的。例如：如果预计有 8 个 targets，这个 upstream 需要定义 slots=800，哪怕起初只有 2 个 targets。\n这里通过更多的 slots 获取更好的随机分布，如果通过之后去修改（添加/移除 targets），付出的代价更大。\n有关添加和操作 upstreams 的信息，可以查看 Admin API reference\n目标（Target） 由于 upstream 维护了一个改变历史，targets 只能被添加，不能被修改或删除。想要去改变一个 target，只需要为这个 target 添加一个新的记录，并改变他的 weight 值。会使用最后一条记录。设置 target 的 weight=0，可以有效的从均衡器中删除它。有关添加和操作 targets 的信息，可以查看 Admin API reference\n当 targets 中的不活动条目比活动条目高 10 倍时会被自动清理。清理会重建均衡器，因此它比只添加 target 记录更耗费资源。\n**target **可以使用主机名替代 IP 地址。这种情况下，主机名会被解析，解析出来的所有条目都会添加到 ring-balancer。例如：添加 api.host.com:123 和 weight=100. “api.host.com”被解析为一个 A 记录包含 2 个 IP 地址。这两个 IP 地址会作为 target 被添加，每个都具有 weight=100 属性和 123 端口。\n当它被解析为 SRV 记录，将会提取 DNS 记录中的端口和权重，并且会覆盖给定的端口 123 和权重 100。\n均衡器会遵循 DNS 记录中设置的 TTL 值，并在它过期时重新查询和更新均衡器。\n例外：当 DNS 记录的 TTL 被设置为 0 时，会将这个主机名作为单独的 target 和指定的权重一起添加进来。当这个 target 的每个代理请求后会再次查询该名称服务器。\n负载均衡算法（Balancing Algorithms） 默认情况下 ring-balancer 使用 weighted-round-robin（加权轮询）。另一种方法是基于 hash 的算法。对于 hash 的输入可以是none，consumer，ip，header，cookie。当设置为 none 时，将会使用 weighted-round-robin 算法，并禁用 hash 算法。\n有两个选项，主选项（primary）和副选项（fallback），以防止主选项失败。（例如，如果主选项设置为 consumer，但是没有 consumer 认证）\n不同的 hash 选项介绍\nnone：不使用 hash，使用 weight-round-robin 替代 consumer：使用消费者 ID（consumer id）作为 hash 的输入值。如果没有消费者 ID，该选项会把认证 ID（credential id）作为副选项 ip：把远程的 IP 地址作为 hash 的输入值。使用该选项，请查看 real_ip_header header：使用提供的 header（在 hash_on_header 或 hash_fallback_header 字段配置）作为 hash 的数据值。 cookie：提供一个 cookie 名称（hash_on_cookie 字段）和路径（hash_on_cookie_path 字段，默认/）作为 hash 的输入值。如果请求中不包含 cookie，它将由相应配置。因此如果设置 cookie 作为主选项，hash_fallback 是无效的。 hash 算法遵循consistent--hashing（或 ketama principle），确保因为改变 targets 而对均衡器进行修改时的损失最小。这会最大化 upstream 缓存的命中。\n更多信息查看 Admin API reference 中关于 upstream 的设置。\n平衡的注意事项 ring-balancer 被设计为单节点使用或集群使用。对于加权轮询算法那没有太大的区别，但是当使用基于 hash 的算法时，所有的节点都应该建立完全相同的 ring-balancer，以确保它们做相同的工作。为了做到这一点，必须使用确定的方法来创建均衡器。\n不要在均衡器中使用主机名，因为平衡器可能会缓慢的分开，因为 DNS ttl 仅是第二匹配选项，请求取决于实际的主机名称。另外，一些命名服务器不会返回所有的记录，会加剧这种问题。所以，Kong 在集群时使用 hash 算法，通过 IP 地址添加 target。\n当选用 hash 算法时，请确保输入的值具备足够的差异，可以获取一个分布均匀的散列表。Hash 使用 CRC-32 来计算。例如，你的系统有上万个用户，但每个平台仅定义了几个消费者（例如 Web，IOS 和 Android），则使用远程 IP 地址设置作为 Hash 的输入是无法满足需求的。Hash 需要输入 ip 可以提供更大的差异，使得 Hash 的输出分布更均匀。但是如果许多客户端位于同一个 NET 网关（例如：呼叫中心），则 cookie 比 ip 能提供更好的分布。\n蓝绿部署（Blue-Green Deployments） 使用 ring-balancer 可以很轻松的为服务进行 蓝绿部署。\n切换 target 的基础架构仅需要向服务发送一个 PATCH 请求，去改变他的 host 值。\n设置 “Blue” 环境，运行 version1 的地址服务：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 创建一个 upstream curl -X POST http://kong:8001/upstreams \\ --data \"name=upstreams-name\" # 添加两个 target（服务）到 upstream curl -X POST http://kong:8001/upstreams/upstreams-name/targets \\ --data \"target=192.168.34.15:80\" --data \"weight=100\" curl -X POST http://kong:8001/upstreams/upstreams-name/targets \\ --data \"target=192.168.34.16:80\" --data \"weight=50\" # 创建一个服务指向 Blue upstream curl -X POST http://kong:8001/services/ \\ --data \"name=service-name\" \\ --data \"host=upstreams-name\" \\ --data \"path=/address\" # 添加一个路由作为服务的入口点 curl -X POST http://kong:8001/services/service-name/routes/ \\ --data \"hosts[]=address.mydomain.com\" 将请求头中的 host 设置为 address.mydomain.com，该请求会被 Kong 反向代理到两个已经定义的 targets 中：2/3 的请求会发送到 http://192.168.34.15:80/address （weight=100），1/3 的请求会发送到 http://192.168.34.16:80/address （weight=50）。\n在部署 version2 之前，先设置 “Green”环境\n1 2 3 4 5 6 7 8 9 10 11 # 创建一个新的 upstream curl -X POST http://kong:8001/upstreams \\ --data \"name=upstream-name-2\" # 往 upstream 中添加这些 targets curl -X POST http://kong:8001/upstreams/upstream-name-2/targets \\ --data \"target=192.168.34.17:80\" --data \"weight=100\" curl -X POST http://kong:8001/upstreams/upstream-name-2/targets \\ --data \"target=192.168.34.18:80\" --data \"weight=100\" 激活 Blue/Green，只需要更新服务即可：\n1 2 3 # 从 Blue upstream 切换到 Green upstream，v1 箭头 v2 $ curl -X PATCH http://kong:8001/services/service-name \\ --data \"host=upstream-name-2\" 将请求头中的 host 设置为 address.mydomain.com，现在它会被 Kong 代理到新的 targets；1/2 的请求会发送到 http://192.168.34.17:80/address （weight=100），另 1/2 的请求会发送到 http://192.168.34.18:80/address （weight=100）\n像往常一样，通过 Kong 的 Admin API 做的改变是动态的，并会立即生效。不需要重新加载或重新启动，没有处理的请求会被删除。\n金丝雀发布（Canary Releases） 使用 ring-balancer，target 的权重能够被精细地调整，从而实现平滑的 金丝雀发布\n使用 2 个非常简单的 targets 示例：\n1 2 3 4 5 6 7 8 9 # 第一个 target 权重为 1000 curl -X POST http://kong:8001/upstreams/upstreams-name/targets \\ --data \"target=192.168.34.17:80\" --data \"weight=1000\" # 第二个 target 权重为 0 curl -X POST http://kong:8001/upstreams/upstreams-name/targets \\ --data \"target=192.168.34.18:80\" --data \"weight=0\" 通过多次请求，每次仅修改 target 的权重，流量将会缓慢的路由到其他 target。例如：将它设置为 10%\n1 2 3 4 5 6 7 8 9 # 修改第一个 targets 的权重为 900 $ curl -X POST http://kong:8001/upstreams/upstreams-name/targets \\ --data \"target=192.168.34.17:80\" --data \"weight=900\" # 修改第二个 targets 的权重为 100 $ curl -X POST http://kong:8001/upstreams/upstreams-name/targets \\ --data \"target=192.168.34.18:80\" --data \"weight=100\" 通过 Kong 的 Admin API 做的改变是动态的，并会立即生效。不需要重新加载或重新启动，没有处理的请求会被删除。\n参考文档 Loadbalancing reference\n","description":"","tags":["Kong"],"title":"Kong 负载均衡 \u0026 蓝绿部署 \u0026 金丝雀发布","uri":"/posts/kong/kong-lb-deploy-and-release/"},{"categories":null,"content":"bad interpreter: No such file or directory 错误提示 bash: /usr/bin/yum: /usr/bin/python: 坏的解释器：没有那个文件或目录\nbash: /usr/bin/yum: /usr/bin/python: bad interpreter: No such file or directory\n解决办法 查看 /usr/bin 目录中包含的 python 版本\n1 ll /usr/bin | grep python 查看 /usr/bin/yum 文件（yum 的配置文件）\n1 vim /usr/bin/yum 将已存在的 pythonX 修改为 python, 记得先备份一下 pythonX.\n1 2 cp python2 python2.bak mv python2 python 参考文档 安装完 python3 之后，执行 yum 出错，bash: /usr/bin/yum: /usr/bin/python: 坏的解释器：没有那个文件或目录\n","description":"","tags":["Linux"],"title":"bad interpreter: No such file or directory","uri":"/posts/linux/bad-interpreter-no-such-file-or-directory/"},{"categories":null,"content":"CentOS7 安装绿色版 MySQL57 创建用户和组 1 2 # groupadd mysql # useradd -r -g mysql -s /bin/false mysql 因为这个用户只需要有所有权，不需要登录，useradd 使用 -r -s /bin/false 选项创建一个不能登录服务主机的用户。如果 useradd 命令不支持这些，可以忽略它们。用户名和组名也可以不叫 mysql\n压缩包下载 MySQL Product Archives\n解压 1 # tar -zxvf mysql-VERSION-OS.tar.gz 文件夹介绍\n文件夹 内容 bin mysqld 服务，客户端和实用程序 docs MySQL 信息手册 man Unix 手册页 include 包含（头）文件 lib 库 share 数据库安装时的错误信息，字典和 SQL support-files 其他支持文件 可选：创建连接\n1 # ln -s full-path-to-mysql-VERSION-OS mysql 可选：添加 bin 到环境变量\n在 /etc/profile 中添加\n1 export PATH=$PATH:/usr/local/mysql/bin 初始化数据文件夹 在 mysql 文件夹中创建存储 mysql 数据的文件夹，将所有权赋给 mysql 和 mysql 组，并设置一个适当的目录权限\n1 2 3 # mkdir data # chown mysql:mysql data # chmod 750 data // TODO Post Installation Setup\n","description":"","tags":["MySQL","CentOS"],"title":"CentOS7 安装绿色版 MySQL57","uri":"/posts/database/mysql-install-in-centos7/"},{"categories":null,"content":"failed to retrieve PostgreSQL server_version_num 错误提示 Error: [PostgreSQL error] failed to retrieve PostgreSQL server_version_num: 致命错误：用户 \"kong\" Ident 认证失败\n解决方式 修改 pg_hba.conf\n# host all all 127.0.0.1/32 ident # 将 ident 修改为 trust host all all 127.0.0.1/32 trust ","description":"","tags":["PostgreSQL"],"title":"failed to retrieve PostgreSQL server_version_num","uri":"/posts/database/postgresql-ident-exception/"},{"categories":null,"content":"服务注册与发现 使用 Admin API 添加服务 使用 cUrl 命令添加服务\n1 2 3 4 curl -i -X POST \\ --url http://localhost:8001/services/ \\ --data 'name=log-service' \\ --data 'url=http://localhost:18081' 说明\n--url http://localhost:8001/services/\n向该 url 发送请求，因为 kong 装在本机，所以 IP 使用 localhost\n--data 'name=log-service'\n该次请求提交的数据，name 是指定当前的服务名称\n--data 'url=http://localhost:18081'\n该次请求提交的数据，url 是被添加服务的 url，因为测试的服务在本机，所以 IP 使用 localhost\n关于该接口的详细参数，见官方文档 Service Object\n为服务添加路由 1 2 3 4 curl -i -X POST \\ --url http://localhost:8001/services/log-service/routes \\ --data 'name=log-route' \\ --data 'hosts[]=10.1.100.152' 说明\n--url http://localhost:8001/services/log-service/routes\nurl 请求格式：/services/{service name or id}/routes，为 name=log-service 的服务添加一个路由\n--data 'name=log-route'\n设置路由名称为 log-route\n--data 'hosts[]=10.1.100.152'\n设置请求头中的 Host 为 10.1.100.152，也可以设置为 example.com 格式\n完成上述两步后，Kong 将会反向代理所有向指定主机（host[]指定的主机）发送的请求，并将这些请求路由到与其关联的上游 URL（upstream URL，第一步中通过 --data 'url=xx' 指定的 url）\n关于该接口的详细参数，见官方文档 Route Object\n通过 kong 访问服务 1 2 3 curl -i -X GET \\ --url http://10.1.100.152:8000/logController/login \\ --header 'Host:10.1.100.152' 说明\n--url http://10.1.100.152:8000/logController/login\n使用 Kong 的 IP 和端口，访问被添加服务的 /logController/login 接口\n--header 'Host:10.1.100.152'\n指定请求头中的 Host，与上一步中的 host[] 对应\n也可以使用浏览器直接访问\n1 http://10.1.100.152:8000/logController/login 参考文档 Configuring a Service\n","description":"","tags":["Kong"],"title":"服务注册与发现","uri":"/posts/kong/kong-server-registry-and-discovery/"},{"categories":null,"content":"远程连接 Kong 的 Admin API 当通过另一台机器访问 Kong 的 Admin API 时，会访问不到，这里有两种解决方法\n法一：修改 kong 的配置文件 kong.conf 修改 admin_listen 的值，添加所需端口（或直接改为 0.0.0.0）\n1 admin_listen=0.0.0.0:8001,0.0.0.0:8444 ssl 重启 kong 服务\n法二：配置环境变量 在 /etc/profile 中添加\n1 export KONG_ADMIN_LISTEN=0.0.0.0:8001,0.0.0.0:8444 ssl 执行 source 命令\n1 source /etc/profile 重启 kong 服务\n参考文档 kong 的端口简介以及如何远程连接 kong 的管理端口\n","description":"","tags":["Kong"],"title":"远程连接 Kong 的 Admin API","uri":"/posts/kong/kong-remote-admin-api/"},{"categories":null,"content":"Kong 使用 DB-less 模式 介绍 通常，Kong 必须使用一个数据库（Postgres 或 Cassandra）去保存它对各种实体的配置，例如路由，服务和插件。Kong 使用 kong.conf 文件设置数据库。\nKong 1.1 版本添加了不使用数据库的能力，将各种实体信息保存在内存中，称为 DB-less mode。当使用 DB-less 模式时，这些实体的配置会保存在第二个 YMAL 或 JSON 配置文件中，使用声明式配置。\n使用 DB-less 的好处 减少依赖：不需要去安装和管理一个数据库 适合 CI/CD 脚本的自动化：实体的配置单独保存在一个文件中，可以通过 Git 仓库等进行管理。 使得 kong 有更多的部署方式：例如，不使用数据库的 Kong 非常适合在网络服务方案中做轻量的支持 使用 DB-less 模式启动 kong DB-less 模式启动 kong，包含两种方式\n在 kong.conf 中指定 创建 kong.conf，在 kong.conf 中添加\n1 2 # 设置不使用数据库 database = off 使用创建的 kong.conf，启动 kong\n1 2 # 启动 kong $ kong start -c kong.conf 通过设置环境变量指定 1 2 3 4 5 6 # 设置环境变量 $ export KONG_DATABASE=off # 创建 kong.conf $ touch kong.conf # 启动 kong $ kong start -c kong.conf 测试查看 kong 的配置 在 Kong 启动后，访问管理页面，验证 database 被设置成了 off\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 $ http :8081/ # 返回 HTTP/1.1 200 OK Access-Control-Allow-Origin: * Connection: keep-alive Content-Length: 6342 Content-Type: application/json; charset=utf-8 Date: Wed, 27 Mar 2019 15:24:58 GMT Server: kong/1.1.0 { \"configuration:\" { ... \"database\": \"off\", ... }, ... \"version\": \"1.1.0\" } Kong 运行起来了，但是没有加载声明式配置文件。这意味着，这个节点的配置是空的。这没有任何的路由，服务或者实体\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ http :8001/routes # 返回 HTTP/1.1 200 OK Access-Control-Allow-Origin: * Connection: keep-alive Content-Length: 23 Content-Type: application/json; charset=utf-8 Date: Wed, 27 Mar 2019 15:30:02 GMT Server: kong/1.1.0 { \"data\": [], \"next\": null } 创建声明配置文件 通过如下命令，在当前目录创建一个具备结构的声明配置文件 kong.yml\n1 $ kong config -c kong.conf init 声明配置文件格式 介绍和创建 kong 的声明配置文件包含实体和他们的值，以下是一个小的，但是完整的例子，说明了多个特征\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 _format_version: \"1.1\" services: - name: my-service url: https://example.com plugins: - name: key-auth routes: - name: my-route paths: - / consumers: - username: my-user keyauth_credentials: - key: my-key _format_version: \"1.1\" 是唯一一个必须存在的元数据，指明该配置文件的语法格式版本号。\n在最上面，可以定义任意的 Kong 实体，可以是核心实体（在上例中的 services 和 consumers），也可以是自定义实体（例如：keyauth_credentials），自定义实体可以对声明配置文件的固有格式进行扩展，这也是 kong config 命令必须要有一个 kong。conf 的原因，以便用户来管理 plugins。\n实体间 one-to-one 的关系可以通过嵌套来表示，而涉及到两个以上的实体关系，必须使用其顶级实体，通过定义的主键或名字指定。例如一个插件即需要一个服务方也需要一个消费方\n1 2 3 4 5 6 7 plugins: # 该插件的名称 - name: syslog # 引用了上面的 my-user consumer: my-user # 引用了上面的 my-service service: my-service 格式检查 1 2 3 $ kong config -c kong.conf parse kong.yml parse successful 加载配置文件 加载声明配置文件包含 3 种方式\n在 kong.conf 中指定\n1 2 3 4 declarative_config = /ymlpath/kong.yml # 启动 kong $ kong start -c kong.conf 设置环境变量指定\n1 2 3 4 5 6 7 8 9 10 11 # 设置 DB-less 模式 $ export KONG_DATABASE=off # 设置 kong.yml 位置 $ export KONG_DECLARATIVE_CONFIG=kong.yml # 启动 kong $ kong start -c kong.conf# 设置 DB-less 模式 $ export KONG_DATABASE=off # 设置 kong.yml 位置 $ export KONG_DECLARATIVE_CONFIG=kong.yml # 启动 kong $ kong start -c kong.conf 在运行时修改配置：可以在一个运行中的 kong 节点通过 http 请求 /config 端点进行配置\n1 $ http :8001/config config=@kong.yml 该方式替换了之前加载进内存中的配置。\n相关配置说明 内存缓存需求 实体的配置都在 kong 的缓存中。请确保内存缓存的配置正确：可以查看 kong.conf 中的 `mem_cache_size 设置\n没有中心数据库协调 这种方式没有中心数据库，多个 kong 节点没有中央协调点以及数据的集群传输：每个节点都是完全相互独立的。\n这意味着每个独立的节点都有自己的声明配置文件。使用 /config 方式不会影响其他的节点，因为各个节点之间是没有关联的。\n只读的管理接口 当使用 DB-less 模式运行 Kong 时，只能通过声明配置的方式配置实体，通过端点对实体的 CURD 操作只有读是有效的，通常使用 GET 方式来检查实体的工作状态，如果使用 POST、PATCH、PUT 或 DELETE 方式请求端点（例如 /service 或 /plugins），将会返回 HTTP 405 Not Allowed。\n这种限制仅限于对数据库的操作。例如，允许使用 POST 方式去设置目标的健康状态，因为这是一个节点特定的内存操作。\n插件兼容性 DB-less 模式不支持所有的 Kong 插件，因为有一些插件需要中心数据库的支持来动态的创建实体，或需要动态创建实体。\n完全兼容的插件 以下的插件只从数据库中读取数据（大部分只是读取它们的初始化配置），所以 DB-less 模式是完全支持的。\naws-lambda azure-functions bot-detection correlation-id cors datadog file-log http-log tcp-log udp-log syslog ip-restriction prometheus zipkin request-transformer response-transformer request-termination kubernetes-sidecar-injector 部分兼容的插件 认证插件是能够使用的，只要使用静态证书，并且设置为声明配置的一部分。所有的认证插件\nacl basic-auth hmac-auth jwt key-auth kong 捆绑的限流插件为计数器提供不同的存储和协调策略: local 策略存储节点内存的计数器，按每个节点的方式应用限制；redis 策略使用外部 Redis 的 key-value 存储，来协调不同节点的计数器；cluster 策略使用 Kong 数据库作为集群范围限制的中央协调点。DB-less 模式可以使用 local 策略和 redis 策略，不能使用 cluster 策略。所有的限流插件\nrate-limiting response-ratelimiting pre-function 和 post-function 插件可以在 DB-less 模式下使用他们的无服务模式，但是如果有配置尝试写数据库将会失败。\n完全不兼容的插件 oauth2：在日常工作中，该插件需要创建和删除令牌，并且提交到数据库，这在 DB-less 模式下是不可用的。 参考文档 DB-less and Declarative Configuration\n","description":"","tags":["Kong"],"title":"Kong 使用 DB-less 模式","uri":"/posts/kong/kong-dbless/"},{"categories":null,"content":"CentOS 安装 Kong 官方文档\n安装 kong 通过官方文档可以下载 rpm 包，或者设置 yum 仓库。\n使用 rpm 包安装 1 2 $ sudo yum install epel-release $ sudo yum install kong-1.4.1.*.noarch.rpm --nogpgcheck 使用 repository 安装 1 2 3 4 5 6 7 8 $ sudo yum update -y $ sudo yum install -y wget $ wget https://bintray.com/kong/kong-rpm/rpm -O bintray-kong-kong-rpm.repo $ export major_version=`grep -oE '[0-9]+\\.[0-9]+' /etc/redhat-release | cut -d \".\" -f1` $ sed -i -e 's/baseurl.*/\u0026\\/centos\\/'$major_version''/ bintray-kong-kong-rpm.repo $ sudo mv bintray-kong-kong-rpm.repo /etc/yum.repos.d/ $ sudo yum update -y $ sudo yum install -y kong 使用源文件方式安装 官方文档\n设置配置文件 Kong 支持有数据库运行和无数据库运行。\n如果使用数据库，需要在 kong.conf 中设置数据库的信息，将所有的配置实体，比如 Kong 代理的连接和服务存放在数据库中。\n如果不使用数据库，需要使用 kong.conf 配置属性，并通过一个 kong.yml 来声明实体结构。\n使用数据库 Kong 支持使用 PostgreSQL9.5+ 和 Cassandra 3.x.x 作为他的数据存储。\n如果使用 PostgreSQL，需要提供一个数据库的用户\n1 2 CREATE USER kong; CREATE DATABASE kong OWNER kong; 然后验证配置初始化 kong 的配置到数据库\n1 $ kong migrations bootstrap [-c /path/to/kong.conf] 关于数据库的配置信息参考 官方 Configuration Reference\n不使用数据库 需要创建一个 kong.yml，在当前目录执行以下命令，创建一个带基本结构的 kong.yml，详细讲解见 使用 DB-less 模式\n1 $ kong config init 然后修改 kong.conf 文件\n1 2 3 4 # 设置不使用数据库 database = off # 指定 kong.yml 的位置 declarative_config = /path/to/kong.yml 然后验证 kong 的配置并初始化\n1 $ kong migrations bootstrap [-c /path/to/kong.conf] 启动 Kong 1 $ kong start [-c /path/to/kong.conf] 验证 当上述方式均已完成，会返回一个 Kong started 消息。\nKong 默认监听的端口\n8000：Kong 监听该端口，为了接收客户端发来的 HTTP 请求，并且将它发送到上游服务。 8443：该端口是为了接收 HTTPS 请求。这个端口和 8000 端口一样，除了他是监听 HTTPS 请求。可以通过配置文件禁用该端口。 8001：这个端口用来配置 Kong 监听的 Admin API 8444：Admin API 监听 HTTPS 请求 其他操作 停止 kong\n1 kong stop [-p /prefix/kong/is/running/at/kong-2.0.2] 重载 kong\n1 kong reload ","description":"","tags":["Kong"],"title":"CentOS 安装 Kong","uri":"/posts/kong/kong-install-in-centos/"},{"categories":null,"content":"Oracle 和 Mysql 的区别 数据库 → 数据库实例 → 表空间 → 数据文件\nOracle 数据库的体系结构 数据库：database Oracle 数据库是数据的物理存储，这就包括：数据文件 ORA 或者 DBF，控制文件，联机日志，参数文件。Oracle 数据库的概念和其他数据库不一样，这里的数据库是一个操作系统只有一个库，可以看做 Oracle 就只有一个大数据库。\n数据库实例 一个 Oracle 实例由一系列的后台进程和内存结构组成。一个数据库有 n 个实例。通常情况下，Oracle 数据库只会有一个实例 ORCL。\n数据文件（dbf） 数据文件是数据库的物理存储单位。数据库的数据是存储在表空间中的，其实是存储在某一个或多个数据文件中。而一个表空间可以由一个或多个数据文件组成，一个数据文件只能属于一个表空间。一旦数据文件被加入到某个表空间后，就不能删除这个文件。如果要删除某个数据文件，只能通过删除其所属的表空间进行删除。\n表空间 表空间是 Oracle 对物理数据库上相关数据文件（ORA 或者 DBF 文件）的逻辑映射。一个数据库在逻辑上被划分成一到若干个表空间，每个表空间包含了在逻辑上相关联的一组结构。每个数据库至少要有一个表空间（称之为 system 表空间）。\n每个表空间由同一磁盘上的一个或多个文件组成，这些文件叫数据文件（datafile）。一个数据文件只能属于一个表空间。\n用户 用户是在实例下建立的。不同的实例中可以创建相同名字的用户。表的数据是由用户放入某一个表空间的，而这个表空间会随机把这些表数据放到一个或多个数据文件中。\n由于 Oracle 的数据库不是普通的概念，Oracle 是由用户和表空间对数据进行管理和存放的。但是表不是由表空间去查询的，而是由用户去查的。因为不同用户可以在同一个表空间建立同一个名字的表，这里就需要根据用户进行区分了。\nMySQL 和 Oracle 创建项目流程对比 数据库 创建流程 MySQL 创建一个数据库，在数据库中创建表 Oracle 创建一个表空间，在表空间中创建用户，用户创建表 Oracle 是多用户的，MySQL 是多数据库的。\n","description":"","tags":["Oracle","MySQL"],"title":"Oracle 和 MySQL 区别","uri":"/posts/database/oracle-diff-mysql/"},{"categories":null,"content":"pg_hba.conf 配置文件说明 TYPE 表示主机类型，值可能为\nlocal：表示是 unix-domain 的 socket 连接 host：表示 TCP/IP 的 socket 连接 hostssl：表示 SSL 加密的 TCP/IP socket DATABASE 表示数据库名称，值可能为\nall：全部数据库 sameuser： samerole： replication： 指定数据库名称：多个数据库用逗号（,）分隔 USER 表示用户名称，值可能为\nall： 用户名：多个用户名用逗号（,）分隔 ADDRESS METHOD 参考文档 pg_hba.conf 文件说明与配置\n官方文档\n","description":"","tags":["PostgreSQL"],"title":"pg_hba.conf 文件说明","uri":"/posts/database/pghba-config/"},{"categories":null,"content":"systemctl 常用命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # 列出当前系统服务的状态 systemctl list-units # 列出服务的开机状态 systemctl list-unit-files # 查看指定服务的状态 systemctl status servicename # 关闭指定服务 systemctl stop servicename # 开启指定服务 systemctl start servicename # 从新启动服务 systemctl restart servicename # 设定指定服务开机开启 systemctl enable servicename # 设定指定服务开机关闭 systemctl disable servicename # 使指定服务从新加载配置 systemctl reload servicename # 查看指定服务的倚赖关系 systemctl list-dependencies servicename # 冻结指定服务 systemctl mask servicename # 启用服务 systemctl unmask servicename # 开机不开启图形 systemctl set-default multi-user.target # 开机启动图形 systemctl set-default graphical.target # 文本界面设定 color setterm ","description":"","tags":["Linux"],"title":"systemctl 常用命令","uri":"/posts/linux/linux-systemctl-usual-commond/"},{"categories":null,"content":"远程访问 PostgreSQL 修改 pg_hba.conf 和 postgresql.conf 文件\npg_hba.conf 文件在默认在 /var/lib/pgsql/10/data/pg_hba.conf\npostgresql.conf 文件默认在 postgresql.conf\n可以通过 find / -name filename 从 / 目录查找 filename 文件\npg_hba.conf\n# 在 ipv4 下添加 host all all 0.0.0.0/0 trust postgresql.conf\n1 listen_addresses='*' 如果不设置可能会报如下错误\ncould not connect to server: Connection refused (0x0000274D/10061)Is the server running on host\"localhost\" (127.0.0.1) and acceptingTCP/IP connections on port 5432?\n","description":"","tags":["PostgreSQL"],"title":"远程访问 PostgreSQL","uri":"/posts/database/postgresql-remote-access/"},{"categories":null,"content":"CentOS7 安装 PostgreSQL12.2 yum 命令方式 参考 官方文档\n安装成功后，使用 createdb mydb，测试创建一个数据库 mydb，可能会有以下提示\ncreatedb: could not connect to database template1: FATAL: role \"root\" does not exist 因为创建数据库必须登入数据库才行，数据库中并没有 root 这个角色，因为安装好 PostgreSQL 后，PostgreSQL 会自动创建一个 Linux 用户和一个对应的数据库角色，均叫 postgres，它是一个具备数据库超级管理员权限的角色，所以可以使用 postgres 角色去创建其他数据库角色。此处可以不创建该 root 角色，可以直接通过 postgres 角色去访问数据库.\n1 2 3 4 5 6 7 8 # 切换到系统的 postgres 用户 su - postgres # 登录到主数据库 psql postgres # 设置 postgres 角色的密码 \\password postgres # 创建一个数据库角色 root，并赋予超级管理员权限 create user root superuser; 最后一个命令创建了一个 root 角色，并给他 superuser 的权限.\n使用 \\q，exit 依次退出主数据库和 postgres 角色，使用 root 角色登录到主数据库\n1 2 3 4 5 6 7 8 # 退出主数据库 \\q # 退出 postgres 角色 exit # 使用 root 角色登录主数据库 psql postgres # 修改 root 角色密码 \\password root 登录到数据库\n1 psql -U root -d mydb -h 127.0.0.1 -p 5432 参数说明\n-U：数据库用户名 数据库名称 数据库服务器 IP 数据库服务器端口号 源文件方式 CentOS7 需要提前安装的软件包\n1 yum install -y gcc-c++ make readline-devel zlib-devel docbook-dtds docbook-style-xsl fop libxslt 官方文件仓库\n官方文档\n官方安装文档\n配置 第一步是在源目录修改 PostgreSQL 的配置文件。使用默认配置只需要执行\n1 ./configure 该脚本会查找并检查 PostgreSQL 所需的系统变量等信息，并将编译结果保存到编译目录下。默认配置会编译服务端和它的应用程序，以及所有的客户端和它的界面。所有的文件都会被安装到 /usr/local/pgsql 目录下.\n如果想自己指定编译目录，可以在源目录的外部运行 configure，这个过程也叫做 VPATH 编译.\n1 2 3 4 5 6 7 8 # 创建存放编译结果的目录 mkdir build_dir # 移动到该目录下 cd build_dir # 运行 configure 进行编译 # 此处如果报关于 readline/zlib 的错误，需要使用 yum 安装 readline/zlib 和 readline-devel/zlib-devel 包 # 如果卡在 checking for DocBook XML，需要 yum install docbook-dtds docbook-style-xsl fop libxslt -y /path/to/source/tree/configure [option go here] 可以选用以下的命令，来自定义编译和安装：\n--prefix=PREFIX：\n将所有的文件安装到 PREFIX 目录下，而不是默认的 /usr/local/pgsql 目录。实际文件会安装到相应的子目录，没有一个文件是直接安装到 PREFIX 目录下的\n--exec-prefix=EXE-PREFIX：\n将与 PostgreSQL 体系结构相关的文件安装到指定的 EXE-PREFIX 目录下，而不是 PREFIX，这利对于在主机间共享与 PostgreSQL 体系结构无关的文件。如忽略此设置，则 EXEC-PREFIX 默认与 PREFIX 相同，此时这些文件都会被安装到同一目录树下\n--bindir=DIRECTORY：\n指定可执行程序的目录。默认在 EXEC-PREFIX/bin 目录，默认是 /usr/local/pgsql/bin 目录\n--sysconfdir=DIRECTORY：\n设置各个配置文件的目录，默认是 PREFIX/etc\n--libdir=DIRECTORY：\n设置库文件和动态加载模块。默认是 EXEC-PREFIX/lib.\n更多参数详见官方说明\n编译 下列命令二选一，开始编译：\n1 2 make make all 编译成功后会显示\nAll of PostgreSQL successfully made. Ready to install.\n如果想要编译所有的可以编译的，包括文档（HTML 和手册），以及附加模块（contrib），请使用：\n1 make world 编译成功后会显示\nPostgreSQL, contrib, and documentation successfully made. Ready to install.\n回归测试 如果你想在安装之前对编译进行测试，可以在这里进行回归测试。该回归测试是用来测试 PostgreSQL 能否像开发人员预想的一样，在当前机器运行。\n1 make check 安装 输入安装命令\n1 make install 此时会将文件安装到第一步指定的目录下。此时请确保有足够的权限可以进入指定的目录。通常这一步需要具备 root 权限。或者指定目录是由当前用户创建的。\n如需安装文档（HTML 和手册页）\n1 make install-docs 如需全部安装（包含 HTML 和手册页和附加模块）\n1 make install-world 卸载：使用 mark uninstall 去卸载安装。然后，这不会把创建的目录全清理掉。\n清理：在安装之后，可以使用 make clean 将编译文件清除。这会保留由 configure 程序创建的文件，所以，如果你需要在以后重新编译，可以直接使用 mark 系列命令。如果需要重新指定安装目录，使用 make distclean。如果要在同一个源码目录下编译多个平台并要重新配置每个平台，那么必须执行该命令。（当然，可以使用不同的编译目录，使得源代码目录的结构保持不变）\n如果在编译时，发现 configure 操作失败了，或者需要对 configure 进行修改（例如系统更新），那么在重新配置和重新编译之前执行 make distclean 是很好的。否则，你对配置的改变可能不会应用到所有的地方。\n安装后的设置 设置分享库（shared libraries） 在某些系统上使用共享库，你需要告诉系统怎么找到新安装的共享库。一些不需要告诉的系统有：FreeBSD、HP-UX、Linux、NetBSD、OpenBSD 和 Solaris。\n各个系统设置共享库的搜索路径是不同的，但是最广泛地方式是设置环境变量。\n使用 Bourne shells（sh、ksh、base、zsh）\n1 2 LD_LIBRARY_PATH=/usr/local/pgsql/lib export LD_LIBRARY_PATH 使用 csh 或 tcsh\n1 setenv LD_LIBRARY_PATH /usr/local/pgsql/lib 需要将 /usr/local/pgsql/lib 替换成第一步中 --libdir 指定的位置，并将上面的命令放在 /etc/profile 或 ~/.bash_profile 中。\n环境变量 将 /usr/local/pgsql 或者第一步设置的 --bindir 目录添加到系统的 PATH。严格的说，这是不必要的，但是会让使用 PostgreSQL 更简便。\n将下面代码添加到 shell 的启动文件，例如 ~/.bash_profile（如果想对所有用户生效，放在 /etc/profile 下）\n1 2 PATH=/usr/local/pgsql/bin:$PATH export PATH 初始化 在做任何事情之前，需要初始化数据库的存储区域，称之为 database cluster（数据库群，SQL 标准术语叫 catalog cluster）。一个数据库群是由数据库服务器的单个实例管理的数据库集合。在初始化后，会创建一个叫 postgres 的数据库作为默认数据库。数据库服务本身不需要该数据库一定存在，但是许多第三方的程序假定它存在。使用如下命令初始化数据库群的目录，/usr/local/pgsql/data 可自定义。\n1 2 3 initdb -D /usr/local/pgsql/data 或 pg_ctl -D /usr/local/pgsql/data initdb 如果提示 bash: initdb: command not found...，可通过指定 initdb 的绝对路径方式执行\n1 2 例如： /usr/local/pgsql/bin/initdb -D /usr/local/pgsql/data 启动服务 数据库服务的名称叫 postgres，postgres 程序必须知道在哪里可以找到它要使用的数据。通过 -D 选项来指定 data 目录的位置。如果不使用 -D，服务将会去环境变量中查找 PGDATA，如果没有这个变量，会启动失败。\n1 2 3 postgres -D /usr/local/pgsql/data # 如果提示 command not found，使用 /usr/local/pgsql/bin/postgres -D /usr/local/pgsql/data 服务默认在前台运行，并且必须保持这样才能使用 PostgreSQL 账号登录。\n使用以下命令让服务在后台运行\n1 2 3 4 5 # 普通的 Unix shell 命令，指定了将服务的标准输出和标准错误输出保存在 logfile 中 postgres -D /usr/local/pgsql/data \u003elogfile 2\u003e\u00261 \u0026 # 使用 pgSql 提供的简单命令，-l 后指定 log 文件的位置 pg_ctl start -D /usr/local/pgsql/data -l logfile 连接 安装完成后会自动创建一个与当前 Linux 系统用户名相同的数据库角色，并具有数据库的 superuser 权限。并会创建一个默认的数据库叫 postgres，属于该角色\n连接到一个数据库 1 2 3 psql dbname # 例如，连接到默认数据库 psql postgres 设置用户密码 登录到一个数据库后，输入\n1 \\password 远程连接 例如使用 Navicat 连接\n修改 pg_hba.conf 和 postgresql.conf 文件\npg_hba.conf 文件在默认在 /var/lib/pgsql/12/data/pg_hba.conf\npostgresql.conf 文件默认在 /var/lib/pgsql/12/data/postgresql.conf\n可以通过 find / -name filename 从 / 目录查找 filename 文件。\npg_hba.conf\n1 2 # 在 ipv4 下添加 host all all 0.0.0.0/0 trust postgresql.conf\n1 listen_addresses='*' 关闭 PostgreSQL 服务\n1 /path/for/postgresql/bin/pg_ctl -D /path/for/postgresql/data stop 启动 PostgreSQL 服务\n1 /path/for/postgresql/bin/pg_ctl -D /path/for/postgresql/data -l /path/for/postgresql/logs/logfile start ","description":"","tags":["PostgreSQL","CentOS"],"title":"CentOS7 安装 PostgreSQL12.2","uri":"/posts/database/postgresql-install-in-centos/"},{"categories":null,"content":"指定 Tomcat 使用的 JDK 修改 bin 目录下的 setclasspath.sh，在上方添加\n1 2 3 4 5 6 7 export JAVA_HOME=/home/wangshuo/java/jdk1.8.0_231 export JRE_HOME=/home/wangshuo/java/jdk1.8.0_231/jre # ----------------------------------------------------------------------------- # Set JAVA_HOME or JRE_HOME if not already set, ensure any provided settings # are valid and consistent with the selected start-up options and set up the # endorsed directory. # ----------------------------------------------------------------------------- ","description":"","tags":["Tomcat","Java"],"title":"指定 tomcat 使用的 JDK","uri":"/posts/java/tomcat-set-jdk/"},{"categories":null,"content":"错误-Your password does not satisfy the current policy requirements 出错原因 由于 MySQL 数据库对密码的验证策略较为严格造成。\n解决方法 查看 MySQL 密码策略 1 SHOW VARIABLES LIKE 'validate_password%'; 修改验证强度等级 将 validate_password_policy 设置为 LOW，则只验证密码长度\n1 set global validate_password_policy=LOW; 修改密码长度验证 可将 validate_password_length 设置为 4，最小值为 4\n1 set global validate_password_length=4; 密码策略参数说明 validate_password_length 固定密码的总长度 validate_password_dictionary_file 指定密码验证的文件路径 validate_password_mixed_case_count 整个密码中至少要包含大/小写字母的总个数 validate_password_number_count 整个密码中至少要包含阿拉伯数字的个数 validate_password_policy 指定密码的强度验证等级，默认为 MEDIUM 关于 validate_password_policy 的取值：\n0/LOW：只验证长度； 1/MEDIUM：验证长度、数字、大小写、特殊字符； 2/STRONG：验证长度、数字、大小写、特殊字符、字典文件； validate_password_special_char_count 整个密码中至少要包含特殊字符的个数； 参考文档 ERROR 1819 (HY000): Your password does not satisfy the current policy requirements\n","description":"","tags":["MySQL"],"title":"MySQL 密码策略","uri":"/posts/database/mysql-password-satisfy/"},{"categories":null,"content":"No Caching mode page found 错误原因 使用 UltraISO 只做的启动盘安装 CentOS7 时，提示 No Caching mode page found, 稍后会一直弹出信息，这是因为 CentOS 找不到镜像位置造成的\n解决办法 在如下界面按 Tab，调出命令行\n将\n1 vmlinuz initrd=initrd.img inst.stage2=hd:LABEL=CentOS\\x207\\x20x86_64 quiet 修改为\n1 vmlinuz initrd=initrd.img linux dd quiet 按 Enter 查看 U 盘信息\n重启电脑 将\n1 vmlinuz initrd=initrd.img inst.stage2=hd:LABEL=CentOS\\x207\\x20x86_64 quiet 修改为\n1 2 3 4 5 6 7 # /dev/sdb4 为安装盘的盘符 vmlinuz initrd=initrd.img inst.stage2=hd:/dev/sdb4 quiet 或 #由于系统位数限制，将 LABEL=CentOS\\x207\\x20x8 之后的数据截断了，相应删除即可 vmlinuz initrd=initrd.img inst.stage2=hd:LABEL=CentOS\\x207\\x20x8 quiet Enter\n","description":"","tags":["Linux","Exception"],"title":"No Caching mode page found","uri":"/posts/linux/linux-no-caching-mode-page-found/"},{"categories":null,"content":"SSH 无法连接 问题描述 新安装的 Fedora 系统，无法使用 Xshell 工具连接。\n点击连接后返回如下提示 1 2 3 4 5 6 7 8 9 10 11 Connecting to 10.1.7.95:22... Connection established. To escape to local shell, press 'Ctrl+Alt+]'. Connection closing...Socket close. Connection closed by foreign host. Disconnected from remote host(10.1.7.95) at 15:04:57. Type `help' to learn how to use Xshell prompt. [D:\\~]$ 问题原因 可能是 sshd 服务没有开启\n解决办法 启动 sshd 服务\n1 systemctl start sshd 无法使用 root 用户登录 问题原因 可能 ssh 配置文件中禁止了 root 用户远程登录\n解决办法 修改 /etc/ssh/sshd.conf 文件，修改为下面配置\n1 PermitRootLogin yes 重启 sshd 服务\n1 systemctl reload sshd ","description":"","tags":["Linux","Fedora","SSH"],"title":"SSH 无法连接","uri":"/posts/linux/fedora/ssh-connection-close/"},{"categories":null,"content":"阿里云镜像站\n","description":"","tags":["Linux"],"title":"修改 yum 仓库位置","uri":"/posts/linux/yum-mirror/"},{"categories":null,"content":"Nginx 负载均衡 跨多个应用实例的负载均衡技术，可以优化资源利用率，最大化吞吐量，减少延迟，并确保容错配置。\n可以使用 Nginx 作为非常有效的 HTTP 负载均衡器，将流量分发给几个应用程序服务器，提高 web 服务器的性能，及可伸缩性，可扩展性。\nNginx 支持的负载均衡方法 轮询：对应用程序的请求以循环的方式发布 最少连接：将连接分配给活跃连接数最少的服务器 ip 哈希：基于客户机的 IP 地址进行哈希运算，来确定将请求分配给哪个服务器 配置负载均衡 在 nginx.conf 中配置相关信息\n轮询方式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 http { # 定义一组均运行了相同应用的服务器，组名称为 myapp1 upstream myapp1 { # 使用域名方式或 IP:port server srv1.example.com:; server srv2.example.com; server 192.168.12.25:3349; } server { listen 80; location / { # 此处使用了组名称 proxy_pass http://myapp1; } } } Nginx 的负载均衡包含对 HTTP、HTTPS、FastCGI、uwsgi、SCGI、memcached and gRPC 的反向代理。\n最少连接的负载平衡 该分配方式对应用程序实例更公平些，同时请求需要更长的时间来完成。nginx 将新的请求分配给不太繁忙的服务器。\n1 2 3 4 5 6 7 upstream myapp1 { # 使用最少连接的负载平衡 least_conn; server srv1.example.com; server srv2.example.com; server srv3.example.com; } ip-hash 负载平衡 ip-hash 负载平衡，会将客户端和服务器绑定，即，一个客户端的请求始终会被同一个服务器处理，除非该服务器不可用。\n1 2 3 4 5 6 upstream myapp1 { ip_hash; server srv1.example.com; server srv2.example.com; server srv3.example.com; } 加权的负载平衡 在上面例子中，没有配置权重，意味着所有的服务器具有相同的权重。\n使用 weight 在设置权重\n1 2 3 4 5 upstream myapp1 { server srv1.example.com weight=3; server srv2.example.com; server srv3.example.com; } 如果有 5 个请求，3 个会分配到 srv1，1 个分配给 srv2，1 个分配给 srv3。\n也可以使用在最少连接和 ip-hash 负载均衡\n健康检查 nginx 默认实现健康检查，如果一个服务器请求出错，nginx 将会标记这个错误的服务器，并且避免将之后的请求分配到该服务器\nmax_fails 参数定义请求出错几次将该服务器标记为错误，默认值为 1，如果设置为 0，健康检查将会对该服务器失效。fail_timeout 定义多长时间解除服务器失败的标记。\n参考文档 官方文档 Using nginx as HTTP load balancer\n使用 Nginx 实现负载均衡\n","description":"","tags":["Nginx"],"title":"Nginx 负载均衡","uri":"/posts/nginx/nginx-loadbalance/"},{"categories":null,"content":"Nginx 新手入门 Nginx 简介 Nginx 有一个主进程和几个工作进程，主进程负责读取配置和维护工作进程。工作进程对请求作出实际的处理。Nginx 通过基本事件模块及操作系统来高效的对工作进程进行任务的分配。所有的工作进程都是在配置文件中定义的，这些配置文件可能在一个固定的位置，也可能是根据可用的 CPU 内核数自动调整的。\nNginx 和其模块的工作方式是在配置文件中确定的。配置文件的默认名称是 nginx.conf，存放位置在 /usr/local/nginx/conf 或 /etc/nginx 或 /usr/local/etc/nginx。\n启动，停止及重载配置 通过可执行文件启动 nginx，启动后可通过以下命令来控制 nginx\n1 nginx -s signal 其中 signal 可被下列参数替换\nstop：立即停止 quit：优雅的停止 reload：重新加载配置文件 reopen：重启日志文件 当执行 reload 命令后，如果执行成功，主进程启动新的工作进程，并要求旧的工作进程自动结束。否则，主进程会回滚改变并使旧的配置继续运行，旧的工作进程会接收到停止的命令，将当前所有正在处理的请求完成后自动停止这些工作进程。\nsignal 也能在 Unix 工具的帮助下发送到 nginx 进程，例如 kill 命令。nginx 的主进程 PID 默认是记录在 nginx.pid 文件中的，位置在 /usr/localnginx/logs 或 /var/run 目录下。执行如下命令，优雅的退出 nginx。\n1 kill -s QUIT PID 配置文件 nginx 的模块和控制指令都是在配置文件中定义的。指令分为简单指令和指令快。简单指令是格式为\n1 key val; 块指令的格式为\n1 2 3 4 name { key1 val1; key2 val2; } 如果块指令被()包围，则他被称为上下文\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 ( events { key1 val1; } http { key2 val2; server { key3 val3; } } ) 指令放在除配置文件以外的任何地方，都被认为是主上下文。events 和 http 命令在主上下文，server 在 http 中，location 在 server中。\n通过 nginx 服务访问静态内容 创建两个目录 /data/www（里面放 html 页面），/data/images（里面放一些图片）。这时就需要在 http 块 的 server 块 中添加两个 location 块。通常，server 块中包含多个 location 块，他们通过监听的端口和服务名称区分，一旦 nginx 决定哪个服务解决请求，他会检验 location 中定义 URI\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 配置文件中需要包含该标签，不然会报错 events { } http { server { # 这里指定了使用 \"/\" 前缀与请求的 URI 进行比对 location / { # root 后是本地的文件路径 # 查找文件时，会将前缀/拼接到该文件路径后方，/data/www/ root /data/www; } location /images/ { # /data/images/ root /data; } } } 如果请求匹配，那么该 URI 会被添加 root 指令指定的路径下。匹配会优先匹配长的前缀，如果多个前缀均可以匹配，会使用最长的前缀。\n重启 nginx，默认监听 80 端口的请求。如果请求以 /images/ 开头，例如 http://localhost/images/example.png，nginx 会返回 /data/images/example.png，如果文件不存在，返回 404：如果请求不以 /images/ 开头，将会映射到 /data/www 目录，例如 http://localhost/some/example.html，将会返回 /data/www/some/example.html。\n如果一些事情没有按照预期的方式发生，可以查看 access.log 和 error.log 文件，位于 /usr/local/nginx/logs 或 /var/log/nginx 目录下。\n建立一个简单的代理服务 将 nginx 作为代理服务器是一个频繁的情形，就是说服务器将请求发送到代理服务器，然后检索相应它，并将相应发送给客户端。\n配置一个基本的代理服务器，服务请求通过代理服务器请求一个图片，然后代理服务器将本地的图片响应给客户端。在这个例子中，两个服务将会定义在各自的 nginx 实例中。\n创建一个被代理的服务 重新解压一份新的 nginx，在 nginx.conf 中使用如下配置，并在 /data/up1 文件夹中创建一个 example.json，内容随意。\n1 2 3 4 5 6 7 8 9 10 11 12 13 events { } http { server { listen 8080; root /data/up1; location / { } } } 这会创建一个普通的服务，监听 8080 端口，并将所有的请求映射到本地的 /data/up1 目录。此时 root 指令是在 server 的上下文中，如果使用 location 块来相应请求，并且其内部没有指定 root 指令，那么会使用上下文中的 root 指令来作为它的 root 指令\n创建代理服务器 重新解压一份新的 nginx，在 nginx.conf 中使用如下配置，并在 /data/images 创建一个 example.png\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 events { } http { server { location / { proxy_pass http://localhost:8080/; } location ~\\.(gif|jpg|png)$ { root /data/images; } } } 指定代理服务器的协议，服务名和端口作为 proxy_pass 指令的参数\n第二个 location 块使用了正则表达式，此时会匹配所有以 .gif，.jpg 或 .png 结尾的 URI。正则表达式需要有一个 ~ 符号在前面，符合的请求会被映射到 /data/images 目录，而其他的请求都会被映射到上面的代理服务器。\n当 nginx 选择了一个 location 块去服务请求，它第一次会检查详细的 location 指令，记住其中最长的那个前缀，然后再去匹配正则表达式，如果正则匹配成功，就使用匹配成功的，否则，使用之前记录的最长的那个前缀\n测试访问 此时被代理的服务器端口为 8080，代理服务器的端口为 80，通过访问代理服务器 http://localhost:80/example.json 或 http://localhost:80/example.png 进行测试。\n建立一个 FastCGI 代理 可以使用 Nginx 将请求路由到一个 FastCGI（Fast Common Gateway Interface）服务器，最基本的配置方式为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 http{ server { location / { # 被代理的服务器协议+名称+端口 fastcgi_pass localhost:9000; # 设置通过 FaseCGI 服务器的参数 fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param QUERY_STRING $query_string; } location ~\\.(gif|jpg|png)$ { root /data/images; } } } 以上除了符合改正则 ~\\.(gif|jpg|png)$ 的请求会被映射到 /data/images 目录下，其余的请求都会被代理服务器路由到 FastCGI 服务器。\n参考文档 官方文档 Beginner’s Guide\n","description":"","tags":["Nginx"],"title":"Nginx 新手入门","uri":"/posts/nginx/nginx-getting-started/"},{"categories":null,"content":"微服务概述与 Spring Cloud 微服务是什么 微服务提出者：Martin Fowler 就目前而言，对于微服务业界并没有一个统一的，标准的定义（While there is no precise definition of this architectural style） 软件架构的发展 单机版：ALL IN ONE\nicu.intelli.service.商品/交易/积分/订单/库存...\n所有模块/服务都在一个 war 包中\n分布式：专业的事情交给专业的人做\n各个模块/服务独立出来，各自形成微小的进程，尽量降低耦合度，拥有自己独立的数据库。\n独立部署\n微服务架构：\n从技术纬度理解 微服务化的核心就是将传统的一站式应用，根据业务拆分成一个一个的微服务，彻底地去耦合，每一个微服务提供单个业务功能的服务，一个服务做一件事，从技术角度看就是一种小而独立的处理过程，类似进程概念，能够自行单独启动或销毁，拥有自己独立的数据库。\n微服务与微服务架构 微服务 强调的是服务的大小，它关注的是某一个点，是具体解决某一问题/提供落地对应服务的一个服务应用，强调的是一个个的个体，每个个体完成一个具体的任务或功能。\n微服务架构 强调的是整体，使用哪种方式将一个个的微服务组装起来，对外构成一个整体。\n通常而言，微服务架构是一种架构模式或者说是一种架构风格，它提倡将单一应用程序划分成一组小的服务，每个服务运行在其独立的进程中，服务之间互相协调，互相配合，为用户提供最终价值。服务之间采用轻量级的通信机制互相沟通（dubbo 通过 RPC 调用，SpringCloud 通过 RESTful API 调用）。每个服务都围绕具体的业务进行构建，并且能够被独立地部署到生产环境，类生产环境等。另外，应尽量避免统一的，集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言，工具对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的语言来编写服务，也可以使用不同的数据存储。\n微服务优缺点 优点 每个服务足够内聚，足够小，代码容易理解，这样能聚集一个指定的业务功能或业务需求 开发简单，开发效率提高，一个服务可能就是专一的只干一件事。 微服务能够被小团队单独开发，2-5 人即可 微服务是松耦合的，有功能意义的服务，无论在开发阶段和部署阶段都是独立的 微服务能够使用不同的语言开发 易于和第三方集成，允许容易且灵活的方式集成自动部署，通过持续集成工具（如 Jenkins、Hudson、bamboo） 易于被一个开发人员理解，修改和维护，小团队能更关注自己的工作成果。无需通过合作才能体现价值。 允许利用融合最新技术 微服务只是业务逻辑代码，不会和 HTML、CSS 或其他页面组件混合 每个微服务都有自己的存储能力，可以拥有自己的数据库，也可以使用公共的数据库 2 种开发模式 前后端分离 后端给前端 H5 工程师按照约定提供 Rest 地址 + 输入参数格式和报文约定 + 输出参数\n$.post(rest, jsonParameter, callBack)\n全栈工程师 H5 + javaEE + ...\n缺点 开发人员要处理分布式系统的复杂性 多服务运维难度，随着服务的增加运维压力也增大 系统部署依赖 服务间通信成本 数据一致性 系统集成测试 性能监控 …… 微服务技术栈有哪些 微服务技术栈：多种落地技术的集合体\n微服务条目 落地技术 服务开发 SpringBoot，Spring，SpringMVC 服务配置与管理 Archaius，Diamond 服务注册与发现 Eureka，Consul，Zookeeper 等 服务调用 Rest，RPC，gRPC 服务熔断器 Hystrix，Envoy，Sentinel 等 负载均衡 Ribbon，Nginx 等 服务接口调用（客户端调用服务的简化工具） Feign 消息队列 Kafka，RabbitMQ，ActiveMQ 等 服务配置中心管理 SpringCloudConfig，Chef 等 服务路由（API 网关） Zuul 等 服务监控 Zabbix，Nagios，Metrics，Spectator 等 全链路追踪 Zipkin，Brave，Dapper 等 服务部署 Docker，OpenStack，Kubernetes 等 数据流操作开发包 SpringCloud Stream（封装与 Redis，Rabbit，Kafka 等发送接收消息） 事件消息总线 Spring Cloud Bus …… …… 为什么选择 SpringCloud 作为微服务架构 选择依据 整体解决方案和框架成熟度 社区热度 可维护性 学习曲线 当前各大 IT 公司的微服务架构有哪些 阿里：Dubbo（2012 年起不再维护，2017 年 8 月启动维护）/HSF 京东：JSF 新浪微博：Motan 当当网：DubboX（公司被买了） ……：…… Dubbo 和 SpringCloud 生态较好\n各个微服务框架对比 功能点/服务框架 Netglix/Spring Cloud Motan gRPC（Google） Thrift（Facebook） Dubbo（Alibaba）/DubboX（dangdang） 功能定位 完整的微服务架构 RPC 框架，但整合了 ZK 或 Consul，实现集群环境的基本服务注册/发现 RPC 框架 RPC 框架 服务框架 支持 Rest 是，Ribbon 支持多种可插拔序列化选择 否 否 否 否 支持 RPC 否 是（Hession2） 是 是 是 支持多语言 是（Rest 形式） 否 是 是 是 服务注册/发现 是（Eureka），Eureka 服务注册表，Karyon 服务端框架支持服务自注册和健康检查 是（zookeeper/consul） 否 否 是 负载均衡 是（服务端 Zuul + 客户端 Ribbon） Zuul 服务：动态路由器，云端负载均衡。Eureka：针对中间层服务器 是（客户端） 否 否 是（客户端） 配置服务 Archaius，Spring cloud Config Server 集中配置 是（zookeeper 提供） 否 否 否 服务调用链监控 是（Zuul） Zuul 提供边缘服务，API 网关 否 否 否 否 高可用/容器 是（服务端 Hystrix + 客户端 Ribbon） 是（客户端） 否 否 是（客户端） 典型应用案例 Netflix Sina Google Facebook - 社区活跃程度 高 一般 高 一般 2017 年 8 月开始维护 学习难度 中等 低 高 高 低 文档丰富 高 一般 一般 一般 高 其他 Spring Cloud Bus 为我们应用程序带来了更多管理端点 支持降级 Netflix 内部在开发继承 gRPC IDL 定义 实践的公司比较多 SpringCloud 是什么 是什么 分布式微服务架构下的一站式解决方案，是各个微服务架构落地技术的集合体，俗称微服务全家桶\nSpringCloud，基于 SpringBoot 提供了一套微服务解决方案，包括注册与发现，配置中心，全链路监控，服务网关，负载均衡，熔断器等组件，除了基于 NetFlix 的开源组件做高度抽象封装之外，还有一些选型中立的开源组件。\nSpringCloud 利用 Spring Boot 的开发便利性巧妙地简化了分布式系统基础设施的开发，SpringCloud 为开发人员提供了快速构建分布式系统的一些工具，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用 Spring Boot 的开发风格做到一键启动和部署。\nSpring Cloud 并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过 Spring Boot 风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。\nSpringCloud 和 SpringBoot 关系 SpringBoot 关注微观，就是一个一个的微服务；SpringCloud 关注宏观，是微服务的全家桶。 SpringBoot 可以单独使用，SpringCloud 依赖于 SpringBoot SpringBoot 专注于快速方便的开发单个微服务个体，SpringCloud 关注全局的服务治理框架。\nDubbo 与 SpringCloud 的对比 最大区别：SpringCloud 抛弃了 Dubbo 的 RPC 通信，采用基于 HTTP 的 REST 方式。\nREST 方式牺牲了服务调用性能，但也避免了原生 RPC 带来的问题。REST 比 RPC 更灵活，服务提供方和调用方的依赖只靠一纸契约，不存在代码级别的强依赖，这在强调快速演化的微服务环境下显得更为合适。\n品牌机与组装机的区别\n社区支持与更新力度\nDubbo：http://github.com/dubbo\nSpringCloud：https://github.com/spring-cloud\n总结\nDubbo 的定位始终是一款 RPC 框架，而 SpringCloud 是微服务框架的一站式解决方案 由于 RPC 协议，注册中心元数据不匹配等问题，在面临微服务框架选型时 Dubbo 与 SpringCloud 只能二选一 Dubbo 之后会积极寻求适配到 SpringCloud 生态 能干嘛 参照技术纬度\n去哪下 SpringCloud 官网\n参考文档\nSpring Cloud Netflix 中文文档 参考手册 中文版 Spring Cloud Dalston 中文文档 参考手册 中文版 springcloud 中国社区 springcloud 中文网 怎么玩 参照技术纬度\n国内使用情况 阿里云等\n","description":"","tags":["Spring Cloud","Microserver","Java"],"title":"微服务概述与 Spring Cloud","uri":"/posts/java/microserver-and-spring-cloud/"},{"categories":null,"content":"分布式配置中心 Nacos 系列目录\n配置中心：把关于应用的配置，集中的放在一个地点。\nnacos 可以做配置中心\n使用配置中心的好处 分离的多环境配置：简化应用的配置过程，比如，同一个应用部署到不同的环境（test，dev，prod）使用不同的配置。 可以更灵活的管理权限 安全性高：将密码等信息部署在相对安全的地方 使用 nacos 做配置中心 添加配置文件 bootstrap.properties 1 2 3 4 5 6 7 8 # 指定使用哪个配置文件 # 此处指定的是名称为 nacos-config-example 的配置文件，对应上图中的 Data ID # Group 默认是 DEFAULT_GROUP spring.application.name=nacos-config-example # 当前服务的端口 server.port=18083 # nacos 服务的地址和端口 spring.cloud.nacos.config.server-addr=127.0.0.1:8848 POM 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-nacos-config\u003c/artifactId\u003e \u003cversion\u003e0.9.0.RELEASE\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-dependencies\u003c/artifactId\u003e \u003cversion\u003eGreenwich.SR1\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e NacosConfigExampleApplication 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @SpringBootApplication public class NacosConfigExampleApplication { public static void main(String[] args) { SpringApplication.run(NacosConfigExampleApplication.class, args); } } @RestController @RefreshScope class EchoController { @Value(\"${user.name:unknown}\") private String userName; @RequestMapping(value = \"/\") public String echo() { return userName; } } 使用 nacos 作为配置中心的其他技巧 使用 yaml 格式文件作为配置文件 修改 bootstrap.properties，添加 spring.cloud.nacos.config.file-extension=yaml\n1 2 3 4 5 6 7 8 9 10 11 # 指定使用哪个配置文件 # 此处指定的是名称为 nacos-config-example 的配置文件，对应上图中的 Data ID # Group 默认是 DEFAULT_GROUP spring.application.name=nacos-config-example # 当前服务的端口 server.port=18083 # nacos 服务的地址和端口 spring.cloud.nacos.config.server-addr=127.0.0.1:8848 # 指定读取的配置文件格式 spring.cloud.nacos.config.file-extension=yaml 在 nacos 控制台修改配置文件，不需要重启应用即可实现配置的动态更新。\nprofile 的使用 在 nacos 中创建配置文件 nacos-config-example-{profile}\n例如 nacos-config-example-develop.yaml application-product.properties\n修改 bootstrap.properties 添加 spring.profiles.active=粒度，并修改 spring.application.name 和 spring.cloud.nacos.config.file-extension 的值\n1 2 3 spring.application.name=nacos-config-example spring.cloud.nacos.config.file-extension=yaml spring.profiles.active=develop namespace 的使用 在 nacos 中创建新的 namespace 在新的 namespace 中创建配置文件 修改 bootstrapt.properties 添加 spring.cloud.nacos.config.namespace=Namespace ID\n1 2 # 例 spring.cloud.nacos.config.namespace=74ce8dac-3b1f-43e1-82ad-645f9c7ff741 ","description":"","tags":["Nacos","Java"],"title":"Nacos 分布式配置中心","uri":"/posts/java/nacos-distribut-configuration-center/"},{"categories":null,"content":"Nacos 服务注册与发现 Nacos 系列目录\n服务注册 服务实例将自身服务注册到注册中心，包括服务所在 IP 和 Port，服务版本以及访问协议等。\n类比为增强版的 DNS\n服务发现 应用实例通过注册中心，获取到注册到其中的服务实例的信息，通过这些信息去请求它们提供的服务。\n为什么需要服务注册和发现 在微服务中，由于自动扩缩，故障与升级，整组服务实例会动态变更\n安装启动 nacos nacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。\nnocas 包含一个监听的 API，以及一个控制台\n控制台访问地址：http://localhost:8848/nacos/ username：nacos password：nacos\nnacos 注册与发现示例代码 github 地址：https://github.com/szihai/Nacos-discovery-demo\n服务端 ProviderApplication.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @SpringBootApplication @EnableDiscoveryClient public class ProviderApplication { public static void main(String[] args) { SpringApplication.run(ProviderApplication.class, args); } } @RestController class EchoController { @RequestMapping(value = \"/echo/{string}\", method = RequestMethod.GET) public String echo(@PathVariable String string) { return string; } } @EnableDiscoveryClient：让服务中心（nacos）来扫描，并将其加入到注册中心中，是 Spring Cloud 的 Annotation\napplication.properties 1 2 3 4 5 6 7 8 # 服务的名字 spring.application.name=service-provider # 服务发布端口 server.port=8081 # 把 nocas 的服务地址和端口号告诉该应用程序 spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848 # 暴露这些 endpoint management.endpoints.web.exposure.include=* 启动 provider 后，在 nacos 上即可发现该服务\nPOM 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-actuator\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-nacos-discovery\u003c/artifactId\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-dependencies\u003c/artifactId\u003e \u003cversion\u003eGreenwich.SR1\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-alibaba-dependencies\u003c/artifactId\u003e \u003cversion\u003e0.9.0.RELEASE\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e Actuator 端点 监控和管理服务 /info，/health http://localhost:8081/actuator/nacos-discovery application.properties\n1 2 # 暴露这些 endpoint management.endpoints.web.exposure.include=* 以及 POM 中引入的一些依赖，需要了解 Spring Cloud\n详情需要了解 Spring Boot 的端点相关\n消费端 POM 文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-nacos-discovery\u003c/artifactId\u003e \u003cversion\u003e0.9.0.RELEASE\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-openfeign\u003c/artifactId\u003e \u003cversion\u003e2.1.0.RELEASE\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-dependencies\u003c/artifactId\u003e \u003cversion\u003eGreenwich.SR1\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e 比服务端多了个 spring-cloud-starter-openfeign，需要手动引入\napplication.properties 1 2 3 4 5 6 # 服务名称 spring.application.name=service-consumer # 服务端口 server.port=18082 # nacos 地址和端口 spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848 ConsumerApplication nacos 支持 REST Template 和 Feign client\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 @SpringBootApplication @EnableDiscoveryClient @EnableFeignClients public class ConsumerApplication { @LoadBalanced @Bean public RestTemplate restTemplate() { return new RestTemplate(); } public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); } } @FeignClient(name = \"service-provider\") interface EchoService { @RequestMapping(value = \"/echo/{str}\", method = RequestMethod.GET) String echo(@PathVariable(\"str\") String str); } @RestController class TestController { @Autowired private RestTemplate restTemplate; @Autowired private EchoService echoService; @RequestMapping(value = \"/echo-rest/{str}\", method = RequestMethod.GET) public String rest(@PathVariable String str) { return restTemplate.getForObject(\"http://service-provider/echo/\" + str, String.class); } @RequestMapping(value = \"/echo-feign/{str}\", method = RequestMethod.GET) public String feign(@PathVariable String str) { return echoService.echo(str); } } ","description":"","tags":["Nacos","Java"],"title":"Nacos 服务注册与发现","uri":"/posts/java/nacos-service-registry-and-discovery/"},{"categories":null,"content":"Nacos 服务注册中心 Nacos 系列目录\nNacos 简介 一个更易于构建云原生应用的动态服务发现，配置管理和服务管理平台\n动态配置服务：对接入 nacos 的客户端进行配置的动态配置，业内具有相同功能的有 Apollo、confD 服务发现与管理：服务的注册和发现，以及流量的管理调度等。 动态 DNS 服务：提供无侵入的 DNS 协议来支持异构系统的接入和访问。 Nacos 注册中心简介 Nacos 注册中心是 Nacos 中负责服务注册，服务发现，健康检查等功能的组件\n服务注册与发现 支持使用 Java，Go，NodeJs 等客户端进行服务的注册与发现 支持 Dubbo 服务框架，Spring Cloud Alibaba 服务框架 支持使用 DNS 协议进行服务的发现 健康检查 支持服务端发送 TCP，HTTP，MySQL 请求进行服务健康状态的探测 支持客户端心跳上报 1 的健康状态更新 访问策略 支持基于权重的负载均衡策略 支持保护阈值，解决服务雪崩问题 支持服务上下线 支持基于机房等环境信息设置访问策略 Nacos 作为注册中心的优势（对比 Eureka，Zookeeper) Nacos Zookeeper Eureka 优点 一致性协议 CP + AP CP AP 可以选择使用哪种方式。如果写入数据的成功由单条请求保证，使用 CP 一致性优先保证数据的一致性，提升服务的可用性；如果单次请求不是很重要，可以通过之后的数据补偿机制上报数据，使用 AP 优先保证服务的可用性，保证数据的一致性。 访问协议 HTTP/DNS TCP HTTP 健康检查 TCP/HTTP/MySQL/上报心跳/用户扩展 Keep Alive 上报心跳 访问策略 服务端访问策略 + 客户端访问策略 客户端访问策略 客户端访问策略 客户端访问策略：将服务的所有实例下发到客户端，在客户端或借助第三方组件进行服务的筛选；服务端访问策略：在 nacos 控制台或使用 API 对服务配置特定的访问策略，在通过接口进行服务实例查询时，在 nacos 服务端进行服务实例的过滤，不需要修改客户端并可在运行时动态调整，更灵活。 多地域数据中心 支持 不支持 不支持 nacos 支持单节点/集群/同城双机房/同城多机房/扩地域多数据中心部署 读写 TPS 万级 万级 千级 服务容量 百万级 十万级 万级 Nacos 部署 Nacos 单机部署 下载 Nacos 安装包\n解压安装包\n启动单机模式\n1 sh bin/startup.sh -m standalone 控制台访问\n1 地址：127.0.0.1:8848/nacos/index.html，默认账号密码：nacos/nacos Nacos 集群部署 配置 Nacos 集群地址列表文件 conf/cluster.conf\n添加 nacos 集群中所有节点的地址\n1 2 3 4 # ip:port 10.10.109.214:8848 11.16.128.34:8849 11.16.128.36:8848 配置 MySQL 数据库\nnacos 使用了 5.1.34 版本的 MySQL 连接器，因此需要使用5.6.5 以上 或 **5.7.***版本的 MySQL，可以查看 nacos 源码 的 pom 文件检查 mysql 连接器版本\n初始化 MySQL 数据库\nSQL 语句源文件\napplication.properties 配置\n修改端口号，并添加数据库的配置\n1 2 3 4 5 6 7 8 # 数据库实例数量 db.num=1 # 第一个数据库实例 db.url.0=jdbc:mysql://127.0.0.1:3307/nacos_config?characterEncoding=utf8 # 数据库用户名 db.user=root # 数据库密码 db.password=root 启动服务，可通过控制台查看信息\nNacos 注册中心使用场景 在 Spring Cloud 中使用 Nacos 作为注册中心 官方文档\n示例代码：https://github.com/nacos-group/nacos-examples/tree/master/nacos-spring-cloud-example/nacos-spring-cloud-discovery-example\n添加 Maven 依赖 Provider 端和 Consumer 端均需要添加\n\u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-nacos-discovery\u003c/artifactId\u003e \u003cversion\u003e${latest.version}\u003c/version\u003e \u003c/dependency\u003e Spring Cloud Version Spring Cloud Alibaba Version Nacos Version Spring Cloud Greenwich 0.9.0RELEASE 1.0.0 Spring Cloud Finchley 0.2.2RELEASE 1.0.0 Spring Cloud Edgware 0.1.2RELEASE 1.0.0 配置 Provider 端 在 application.properties 中配置 NacosServer 地址\n1 2 3 server.port=8070 spring.application.name=service-provider spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848 通过 Spring Cloud 原生注解 @EnableDiscoveryClient 开启服务注册发现功能：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @SpringBootApplication @EnableDiscoveryClient public class NacosProviderApplication { public static void main(String[] args) { SpringApplication.run(NacosProviderApplication.class, args); } @RestController class EchoController { @RequestMapping(value = \"/echo/{string}\") public String echo(@PathVariable String string) { return \"Hello Nacos Discovery \" + string; } } } 配置 Consumer 端 在 application.properties 中配置 NacosServer 地址：\n1 2 3 server.port=8080 spring.application.name=service-consumer spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848 通过 Spring Cloud 原生注解 @EnableDiscoveryClient 开启服务注册发现功能\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @SpringBootApplication @EnableDiscoveryClient public class NacosConsumerApplication { @LoadBalanced @Bean public RestTemplate restTemplate() { return new RestTemplate(); } public static void main(String[] args) { SpringApplication.run(NacosConsumerApplication.class, args); } @RestController public class TestController { @Autowired private RestTemplate restTemplate; @RequestMapping(value = \"/echo/{str}\", method = RequestMethod.GET) public String echo(@PathVariable String str) { return restTemplate.getForObject(\"http://service-provider/echo/\" + str, String.class); } } } 通过客户端接口调用服务端接口 通过访问客户端接口 http://127.0.0.1:8080/echo/2019\n返回 Hello Nacos Discovery 2019\n在 Dubbo 中使用 Nacos 作为注册中心 官方文档\n引入 Maven 依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u003c!-- Dubbo 客户端 --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e \u003cartifactId\u003edubbo\u003c/artifactId\u003e \u003cversion\u003e${latest version}\u003c/version\u003e \u003c/dependency\u003e \u003c!--与 nacos-client 结合，调用 nacos-client 进行服务的注册与发现--\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e \u003cartifactId\u003edubbo-registry-nacos\u003c/artifactId\u003e \u003cversion\u003e${latest version}\u003c/version\u003e \u003c/dependency\u003e \u003c!--真正与 nocas 服务端进行通讯的--\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.nacos\u003c/groupId\u003e \u003cartifactId\u003enacos-client\u003c/artifactId\u003e \u003cversion\u003e${latest version}\u003c/version\u003e \u003c/dependency\u003e 配置 Provider 端 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://dubbo.apache.org/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.3.xsd http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd\"\u003e \u003c!-- 提供方应用信息，用于计算依赖关系 --\u003e \u003cdubbo:application name=\"dubbo-provider-xml-demo\"/\u003e \u003c!-- 暴露的服务，将会注册到 Nacos 上 --\u003e \u003cdubbo:service interface=\"com.alibaba.dubbo.demo.service.DemoService\" ref=\"demoServiceLocal\" version=\"1.0.0\"/\u003e \u003c!-- 暴露的端口 --\u003e \u003cdubbo:protocol name=\"dubbo\" port=\"20881\"/\u003e \u003c!-- 使用 Nacos 注册中心 --\u003e \u003cdubbo:registry address=\"nacos://127.0.0.1:8848\" /\u003e \u003c/beans\u003e 配置 Consumer 端 略，参照 官方文档\n在阿里云上使用 Nacos 注册中心 参考视频\nNacos 基本实现原理 Nacos 注册中心数据模型 数据隔离模型：nacos 支持 4 层，保证不同的用户或相同的用户在不同的场景中，数据不会冲突 服务数据模型：分为 3 层，IP 和端口存储在实例数据中，服务和集群中存储特定配置，进行整个的服务管理. Nacos 注册中心逻辑模块 用户接口模块（User Interface）：权限校验，参数校验，数据转换等 主存模块（Main Memory of Services）：存储注册中心所有的数据，所有的查询均从该处获取数据 推送模块（Push Service）：管理所有的订阅端，以及推送的触发，聚合，去除等工作 健康检查模块（Health Check Module）：包含服务端探测和客户端上报两种方式 访问策略模块（Selector Module）：根据服务配置的特定访问策略，对下发的实例进行过滤，支持基于标签的访问策略 集群管理模块（Cluster Module）：对 nacos-service 集群列表进行管理，维持一个可以联通的 nocas 集群 一致性和持久化模块（Consistency and Persistency）：对 nacos 中的数据进行持久化存储，以及 SQL 间的同步保证整个集群的数据置信。 Nacos 注册中心 Distro 协议 ","description":"","tags":["Nacos","Java"],"title":"Nacos 服务注册中心","uri":"/posts/java/nacos-service-registry-center/"},{"categories":null,"content":"Nacos 系列目录 Nacos 服务注册与发现 Nacos 分布式配置中心 Nacos 服务注册中心 ","description":"","tags":["Nacos","Java"],"title":"Nacos 系列目录","uri":"/posts/java/nacos-alibaba-table/"},{"categories":null,"content":"Sentinel 服务熔断 Sentinel：阿里巴巴开源的面向分布式服务架构的轻量级流量控制组件\nGitHub：https://github.com/alibaba/Sentinel\nSentinel 介绍 背景 微服务中，其中一个服务不可用，拖垮其他服务，进而拖垮更多服务，造成服务雪崩。\n核心特性 限流：限定 QPS 的阈值，保护服务不对突然而来的流量打垮 流量整型：流量是随机的，不均匀的，不可预测的，需要将流量调整成匀速的，或缓慢增加的 熔断降级：保证调用方自己不被远程不稳定的服务拖垮，及时熔断不稳定的连接，避免级联失败造成雪崩 系统自适应保护：结合系统的总 CPU 使用率、load、实时 QPS 等保护整个系统的不被打垮，并充分利用系统资源 多样化的流量控制场景 从衡量标准，调用关系等多维度进行限流，也支持热点参数级别，集群纬度（v1.4.0 版本后）级别的限流\n基于 TCP、BBR 算法的系统自适应能力，保证系统吞吐量最大化并保持系统的稳定性\n开源生态 流控降级组件对比 使用场景 启动控制台 Spring Cloud Web 应用接入 Spring Cloud Gateway 网关接入 Dubbo 服务接入 手动埋点 阿里云应用高可用服务 AHAS 视频地址 https://edu.aliyun.com/lesson_1943_16990?spm=5176.8764728.0.0.7d3679bfnaWU7Y#_16990\n","description":"","tags":["Sentinel","Java"],"title":"Sentinel 服务熔断","uri":"/posts/java/sentinel-server-fuse/"},{"categories":null,"content":"The IDE is running low on memory and this might affect performance. Please consider increasing available heap. 报错原因 IDEA 设置的堆内存过小，需要修改 IDEA 的堆内存大小\n解决方法 修改 IDEA 安装目录的 bin 目录下的 idea64.exe.vmoptions 配置文件，将堆内存设置为 2G（自定义）\n1 -Xmx2048m 如果依旧出错，在 IDEA 页面点击 Help→ Change Memory Settings, Change Memory Settings 也可能在 Diagnostic 中\n此处可以看到 IDEA 使用的配置文件位置，可以通过输入框直接修改\n参考文档 【IDEA】The IDE is running low on memory and this might affect performance. Please consider increasing\n","description":"","tags":["IDEA","Exception","Java"],"title":"The IDE is running low on memory and this might affect performance. Please consider increasing available heap.","uri":"/posts/java/idea-low-memory/"},{"categories":null,"content":"数据库设计 为了有效的存储，和高效的运行。\n优良的设计 糟糕的设计 减少数据冗余 存在大量数据冗余 避免数据维护异常 存在数据插入，更新，删除异常 节约存储空间 浪费大量存储空间 高效的访问 访问数据低效 数据库设计步骤 需求分析 → 逻辑设计 → 物理设计 → 维护优化\n需求分析 为什么要进行数据分析？ 了解系统中所要存储的数据\n了解数据的存储特点\n例如数据的时效性，对有时效性的数据需要定期清理等\n了解数据的生命周期\n日志记录不适合存储到数据库，增长量大，非核心数据，需要首先制定清理规则\n要搞清楚的一些问题 实体及实体之间的关系（1 对 1，1 对多，多对多） 实体包含的属性有什么？ 哪些属性或属性的组合可以唯一标识一个实体 实例演示 以一个小型电子商务网站为例，包含几个核心模块：用户模块，商品模块，订单模块，购物车模块，供应商模块。\n用户模块 用于记录注册用户信息\n包含属性：用户名，密码，电话，邮箱，身份证号，地址，姓名，昵称…… 可选唯一标识属性：用户名，身份证，电话 存储特点：随系统上线时间逐渐增加，需要永久存储，不需要删除和归档（归档：将不常用的数据迁移到另一个数据库表或磁盘中），需要提前考虑分库分表的问题 商品模块 用于记录网站中所销售的商品信息\n包含属性：商品编码，商品名称，商品描述，商品描述，商品类，供应商名称，重量，有效期，价格…… 可选唯一标识属性：（商品名称，供应商名称），商品编码 存储特点：对于下线商品可以归档存储（如果供应商不在对某一商品提供供应，但是该商品可能在订单表中使用，所以不能删除该产品，可以将这些下线商品移动到另一个库表中，使得当前库表的查询等高效） 订单模块 用于用户订购商品的信息\n包含属性：订单号，用户姓名，用户电话，收货地址，商品编号，商品名称，数量，价格，订单状态，支付类型，订单类型…… 可选唯一标识属性：订单号 存储特点：永久存储（分表，分库存储） 购物车模块 用于保存用户购物时选购的商品\n包含属性：用户名，商品编号，商品名称，商品价格，商品描述，商品分类，加入时间，商品数量…… 可选唯一标识属性：（用户名，商品编号，加入时间），购物车编号 存储特点：不用永久存储（设置归档，清理规则） 供应商模块 用于保存所销售商品的供应商信息\n包含属性：供应商编号，供应商名称，联系人，电话，营业执照号，地址，法人…… 可选唯一标识属性：供应商编号，营业执照号 存储特点：永久存储 对应关系 逻辑设计 将需求转化为数据库的逻辑模型 通过 ER 图（Entity Relationship Diagram）的形式对逻辑模型进行展示 同所选用的具体 DBMS（DataBase Manager System）无关 名词解释 关系：一个关系对应通常所说的一张表\n元组：表中的一行即为一个元组\n属性：表中的一列即为一个属性\n候选码：表中的某个属性组，可以唯一确定一个元组\n主码：一个关系有多个候选码，选定其中一个为主码\n域：属性的取值范围\n分量：元组中的属性值\nER 图例说明 实例 ER 图 菱形（关系级），可以将多对多的关系转换成 1 对多的关系，例如选购关系 在椭圆（属性）下添加下划线，表示该属性是一个主码\n设计范式概要 常见的数据库设计范式\n第一范式 第二范式 第三范式 BC 范式 其他范式\n第四范式 第五范式 数据操作异常及数据冗余 第一范式（1NF） 定义：数据库表中的所有字段都是单一属性，不可再分的，这个单一属性是由基本的数据类型所构成的，如整数，浮点数，字符串等 换句话说：第一范式要求数据库中的表都是二维表\n第二范式（2NF） 定义：数据库的表中不存在非关键字段对任一候选关键字段的部分函数依赖。部分函数依赖是指存在着组合关键字的某一关键字决定非关键字的情况\n换句话说：所有单关键字段的表都符合第二范式\n存在的问题\n插入异常 如果该表中不包含饮料一厂提供的产品，则无法在插入饮料一厂产品时，获取到饮料一厂的信息 删除异常 如果把饮料一厂提供的产品信息删除掉，则在该表中找不到任何关于饮料一厂的信息 更新异常 如果饮料一厂提供了多种商品，在更新饮料一厂的电话时，会更新多条数据 数据冗余 如果饮料一厂提供了多个商品，则会有多条饮料一厂的电话，造成数据冗余 解决方法\n第三范式（3NF） 定义：第三范式是在第二范式的基础之上定义的，如果数据表中不存在非关键字段对任一候选关键字段的传递函数依赖则符合第三范式。\n存在的问题\n插入异常 如果酒水饮料没有任何商品，则在插入新酒水饮料数据时，查询不到酒水饮料的分类描述等信息 删除异常 如果删除了酒水饮料下的所有产品，则查询不到酒水饮料的任何信息 更新异常 更新酒水饮料的分类描述时，会更新多条分类描述 数据冗余 如果有多个酒水饮料，则会有多条相同的分类，分类描述信息。 解决方法\nBoyce.Codd 范式（BCNF） 定义：在第三范式的基础上，数据库表中如果不存在任何字段对任一候选关键字段的传递函数依赖则符合 BC 范式。\n也就是说：如果是复合关键字，则复合关键字之间也不能存在函数依赖关系\n存在的问题\n插入异常 如果饮料二厂没有任何商品，则在插入饮料二厂提供的商品数据时，查询不到饮料二厂的各种信息 删除异常 如果删除了饮料二厂的所有商品，则查询不到饮料二厂的任何信息 更新异常 如果饮料一厂有多个供应商联系人，在更新时，会更新出错 数据冗余 如果有多个商品都是饮料一厂的同一个供应商联系人，则会造成数据冗余 解决方法\n物理设计 选择合适的数据库管理系统。\n定义数据库，表及字段的命名规范。\n根据所选的 DBMS 系统选择合适的字段类型。\n反范式化设计。\nMySQL 常用的存储引擎 存储引擎 事物 锁粒度 主要应用 忌用 备注 MyISAM（5.5 之前默认） 不支持 支持并发插入的表级锁 读多写少 写操作频繁 读取快 MRG_MYISAM 不支持 支持并发插入的表级锁 分段归档，数据仓库 全局查找过多的场景 将多个结构相同的 MyISAM 表合并成一个表处理，类似于视图，分区的功能 Innodb（5.5 之后默认） 支持 支持 MVCC 的行级锁 事务处理 无 MVCC：Multi-Version Concurrency Control 多版本并发控制 Archive 不支持 行级锁 只支持 insert，select 需要随机读取，更新，删除 适合日志记录，存储数据占用空间较小 Ndb cluster 支持 行级锁 高可用性 大部分应用 MySQL 集群时使用，大部分数据放到内存中，数据量较大不适合 表及字段的命名规则 可读性原则\n使用大写和小写来格式化的库对象名以获得良好的可读性。\n例如：使用 cust_address 而不是 custaddress 来提高可读性。（注意 DBMS 系统对表名的大小写敏感性）\n表意性原则\n对象的名字应该能够描述他所标识的对象。\n例如：对于表，表的名称应该能够体现表中存储的数据内容；对于存储过程，存储过程名称应该能够体现存储过程的功能。\n长名原则\n尽可能少使用或不使用缩写\n适用于数据库名之外的任一对象。\n字段类型的选择原则 在对数据进行比较（查询条件，JOIN 条件及排序）操作时，同样的数据，字符串处理往往比数字处理慢。 在数据库中，数据处理是以页为单位的，列的长度越小，利于性能提升。 MySQL 数据类型占用空间 TimeStamp 使用 Int 来存储，最多存储到 2037 年\n具体的选择方式 只存储年可以使用 Year 类型\n其他注意事项 如何选择主键 避免使用外键约束 降低数据导入的效率 增加维护成本 虽然不建议使用外键约束，但是相关联的列上一定要建立索引 避免使用触发器 降低数据导入的效率 可能会出现意想不到的数据异常 使业务逻辑变复杂 关于预留字段 无法准确的知道预留字段类型 无法准确的知道预留字段中所存储的内容 后期维护预留字段所要的成本，同增加一个字段所需要的成本是相同的 严禁使用预留字段 反范式化 符合范式化的设计 查询订单信息\n1 2 3 4 5 6 7 8 SELECT b.用户名, b.电话, b.地址, a.订单 ID, SUM(c.商品价格 * c.商品数量) as 订单价格 FROM 订单表 a JOIN 用户表 b ON a.用户 ID = b.用户 ID JOIN 订单商品表 c ON c.订单 ID = b.订单 ID GROUP BY b.用户名, b.电话, b.地址, a.订单 ID; 反范式化的设计 查询订单信息\n1 2 3 4 5 6 SELECT b.用户名, b.电话, b.地址, a.订单 ID, c.商品名称, c.过期时间, c.商品数量, c.商品价格 FROM 订单表 a JOIN 用户表 b ON a.用户 ID = b.用户 ID JOIN 订单商品表 c ON c.订单 ID = b.订单 ID; 反范式化的好处 减少表的关联数量 增加数据的读取效率 反范式化一定要适度 维护优化 维护数据字典 使用第三方工具对数据字典进行维护\n利用数据本身的备注字段来维护数据字典\n以 MySQL 为例\n1 2 3 4 5 CREATE TABLE customer( cust_id INT A 标签，例如 spring-boot javaUTO_INCREMENT NOT NULL COMMENT '自增 ID', cust_name VARCHAR(10) NOT NULL COMMENT '客户姓名', PRIMARY KEY (cust_id) ) COMMENT '客户表' 导出数据字典\n1 2 3 4 5 6 7 8 9 10 SELECT a.table_name, b.TABLE_COMMENT, a.COLUMN_NAME, a.COLUMN_TYPE, a.COLUMN_COMMENT FROM information_schema.COLUMNS a JOIN information_schema.TABLES b ON a.table_schema = b.table_schema AND a.table_name = b.table_name WHERE a.table_name = 'customer'; MySQL 的元数据信息均存储在了 information_schema 数据库下的表中\n维护索引 如何选择合适的列建立索引? 出现在 WHERE 从句，GROUP BY 从句，ORDER BY 从句中的列 可选择性高的列要放在索引的前面 索引中不要包括太长的数据类型 注意事项 索引并不是越多越好，过多的索引不但会降低写的效率，而且会降低读的效率 定期维护索引碎片 在 SQL 语句中不要使用强制索引关键字 维护表结构 注意事项 使用在线变更表结构的工具 MySQL5.5 之前会锁表，可以使用 pt-online-schema-change 工具，会将源数据库表中的数据赋值到临时表，然后对临时表进行修改，注意原表中不能包含触发器，因为该工具会对表添加三个触发器（删除，插入，更新），MySQL 一个表中只能含有一个同类触发器 MySQL5.6 之后本身支持在线表结构的变更 同时对数据字典进行维护 控制表的宽度和大小 数据库中适合的操作 批量操作 禁止使用 SELECT * 这样的查询 控制使用用户自定义函数 不要使用数据库中的全文索引 在适当的时候对表进行水平拆分或垂直拆分 表的垂直拆分 为了控制表的宽度可以进行表的垂直拆分\n经常一起查询的列放在一起 text，blob 等大字段拆分到附加表中 表的水平拆分 为了控制表的大小可以进行表的水平拆分\n通过主键 HASH 的方式拆分\n参考视频 数据库设计那些事\n","description":"","tags":["Database"],"title":"数据库设计","uri":"/posts/database/database-design/"},{"categories":null,"content":"下载 Windows10 镜像文件 下载官方下载工具 下载工具 下载 ISO 镜像 打开下载的 MediaCreationToolxxxx.exe 文件，点击接受 选择为另一台电脑创建安装介质(U 盘、DVD 或 ISO 文件) 根据需要选择版本，取消为这台电脑使用推荐的选项即可手动选择 选择 ISO 文件，点击下一步选择保存位置，等待下载完成，期间可以做其他的工作。 ","description":"","tags":["Windows"],"title":"下载 Windows10 镜像文件","uri":"/posts/windows/windows10-download/"},{"categories":null,"content":"CentOS7 安装 Redis 下载 Redis Redis 官网\n安装 gcc 和 make 因为 redis 是用 c 编写的，所以首先安装 gcc 和 make\nyum install gcc-c++ yum install make 解压安装 Redis 创建 redis 目录，在该目录下解压 redis-x.x.x.tar.gz，切换到 redis-x.x.x 目录，使用 make 命令进行编译\n安装 redis 移动到 redis-x.x.x/src 目录下，使用下面命令安装，通过 PREFIX 指定将编译得到的文件存放到哪\n1 make install PREFIX=../../ 安装成功在 redis 目录下出现 bin 文件夹，该文件夹中包含 redis-server，redis-cli等可执行程序\n将 redis.conf 从 redis-x.x.x 文件夹中移动到 bin 目下，删除不需要的目录和文件\n相关命令 设置 redis 后台启动，修改 redis.conf\ndaemonize yes 启动 redis\n1 2 3 ./redis-server \u003c配置文件\u003e ./redis-server ./redis.conf redis-cli 的使用\n1 2 3 4 redis-cli -h host -p port -a password 例如 redis-cli -h 127.0.0.1 -p 6379 ","description":"","tags":["Redis","CentOS"],"title":"CentOS7 安装 Redis","uri":"/posts/database/redis-install-in-centos7/"},{"categories":null,"content":"java.Net.UnknownHostException 异常处理方法 出错原因 在 CentOS7 中运行项目时，出现如下图错误\n因为 CentOS7 根据 /etc/hosts 配置文件查找主机名，而此时设置的 hostname 没有对应到本机 ip, Java 的 InetAddress.getLocalHost() 方法通过本地方法（native）来获取本地主机名，因为本地配置的问题，导致 Java 程序报错。\n解决方法 使用 hostname 查看本机主机名\n如果 hostname 不是本机的网卡 ip, 则证明可能有问题，需要在 /etc/hosts 配置文件中添加下列信息\n1 2 3 # \u003cIP 地址\u003e \u003chostname1\u003e \u003chostname2\u003e # 例如 127.0.0.1 localhost localhost.admin 相关操作命令 修改本机 hostname\n1 hostname \u003cnew hostname\u003e 参考文档 java.Net.UnknownHostException 异常处理方法\n","description":"","tags":["Exception","Java"],"title":"java.Net.UnknownHostException 异常处理方法","uri":"/posts/java/unknown-host-exception/"},{"categories":null,"content":"MySQL 在 Linux 上区分大小写 错误提示 找不到 database.TABLE 这个表\n查找原因 查看 lower_case_table_names 属性\n1 show variables like 'lower%'; 0 代表区分大小写，1 代表不区分大小写\n注意\n在 linux 系统，默认设置如下\n数据库名与表名是严格区分大小写的 列明与列的别名在所有情况下均是忽略大小写的 变量名也是严格区分大小写的 在 windows 系统，默认设置如下\n均不区分大小写 解决办法 使用 root 用户登录，编辑 /etc/my.cnf 文件，在 [mysqld] 下加入如下代码\n1 lower_case_table_names=1 重新启动数据库\n1 systemctl restart mysqld mysql 参考文档 MySQL 填坑系列--Linux 平台下 MySQL 区分大小写问题\n","description":"","tags":["MySQL"],"title":"MySQL 在 Linux 上区分大小写","uri":"/posts/database/mysql-case-in-linux/"},{"categories":null,"content":"PowerDesigner16.5 导入 MySQL 数据 下载 MySQL 的 ODBC 连接工具 MySQL ODBC 官方下载\n注：需要检验 PowerDisigner 使用的 ODBC 数据源是 32 位还是 64 位，具体操作如下\n以管理员身份运行 PowerDesigner16.5 新建一个空白项目 如下图所示，则下载安装 32 位的 ODBC 导入 MySQL 数据 安装完成 ODBC 后，重新以管理员身份运行新的 PowerDesigner\n依次点击 File → Reverse Engineer → Database\n输入 Model Name 并选择 DBMS，Model Name 和项目名称相同即可，DBMS 此处选择 MySQL5.0\n选择 Using a data source:，如下图依次点击，最后选择 系统数据源(只用于当前机器)(S)\n注 : 如果不是以管理员身份运行的 PowerDesigner，此选项不可选\n下一步后选择 MySQL ODBC 5.3 Unicode Driver，依次点击完成\n依次输入 数据源名称，IP 地址和端口号，用户和密码，使用的数据库，数据源名称自定义，可以与项目名称相同，使用的数据库是否选择都没有问题。\n依次点击确定后，到达如下页面后，选择刚才新建的数据库，点击 Connect\n首先，选择**\u003cAll users\u003e**，点击如下图标，取消对数据库中所有数据库所有数据表的全部选中\n然后，选择需要使用的数据库，点击如下图标，选中所用数据库中的所有表，此处可按需求选择\n点击 OK 后，该数据库中的信息自动加载到当前工作空间，如下图所示\n","description":"","tags":["PowerDesigner"],"title":"PowerDesigner16.5 导入 MySQL 数据","uri":"/posts/powerdesigner/powerdesigner16.5-import-mysql/"},{"categories":null,"content":"运行 vue 项目 下载安装 node.js node.js 官方下载地址\nnode.js 是 JavaScript 的一个运行环境，类似于 Java 的 JVM\nnpm 是 Node.js 的包管理工具（package manager）\n测试安装结果 以管理员身份运行 cmd，输入 node -v, 出现版本号，即证明安装成功\nnpm 是集成在 node 中，可以使用 npm -v 查看版本\n安装 cnpm 或修改 npm 仓库位置 安装 cnpm cnpm 是淘宝团队做的国内镜像，由于 npm 的服务器位于国外，速度较慢，因此可以使用 cnpm\n以管理员身份运行 cmd，输入\n1 npm install -g cnpm --registry=http://registry.npm.taobao.org 修改 npm 仓库位置 搜索 修改 npm 镜像\n启动项目 以管理员身份运行 cmd\n在项目目录下使用 cnpm install 或 npm install（速度较慢）安装依赖包，会生成 node_modules 文件夹\n安装完成后使用 npm run dev 命令启动项目\n","description":"","tags":["VUE"],"title":"运行 vue 项目","uri":"/posts/vue/vue-run/"},{"categories":null,"content":"MongoDB 常用命令 连接 MongoDB mongodb://[username:password@]host1[:port1][,host2[:port2],...[,hostN[:portN]]][/[database][?options]]\n查看所有数据库列表 show dbs\n查看当前使用的数据库 db\n切换数据库 use 数据库名\n创建数据库 use 数据库名\n删除数据库 db.dropDatabase()\n创建集合 db.createCollection(name[, options])\n查看所有集合 show collections或show tables\n删除集合 db.集合名.drop()\n操作集合中的文档 插入文档 基本命令：db.集合名.insert(BSON 文档)，如果集合不存在会自动创建\ndb.col.insert({title: 'MongoDB 教程', description: 'MongoDB 是一个 Nosql 数据库', by: '菜鸟教程', url: 'http://www.runoob.com', tags: ['mongodb', 'database', 'NoSQL'], likes: 100 }) 定义为变量后插入\n\u003edocument=({title: 'MongoDB 教程', description: 'MongoDB 是一个 Nosql 数据库', by: '菜鸟教程', url: 'http://www.runoob.com', tags: ['mongodb', 'database', 'NoSQL'], likes: 100 }) \u003edb.col.insert(document) 使用 db.集合名.save(document) 方式插入，如果不指定 _id 字段，save() 和 insert() 类似，如果指定 _id 字段，save() 方法会更新该 _id 的数据\n更新文档 使用 update() 方法和 save() 方法来更新集合中的文档。\nupdate() 方法 update() 方法用于更新已存在的文档。语法格式\ndb.collection.update( \u003cquery\u003e, \u003cupdate\u003e, { upsert: \u003cboolean\u003e, multi: \u003cboolean\u003e, writeConcern: \u003cdocument\u003e } ) 参数说明\nquery：update 的查询条件，类似 sql update 查询内 where 后面的 update：update 的对象和一些更新的操作符（如$，$inc...等）可以理解为 sql update 内 set 后面的 upsert：可选，如果不存在 update 的记录，是否插入 objNew，默认 false，不插入 multi：可选，只更新找到的第一条记录，如果为 true，则把按条件查出来的多条记录全部更新，默认为 false writeConcern：可选，抛出异常的级别 实例\n将 col 集合中 title 为 MongoDB 教程的文档的 title 修改为 MongoDB\ndb.col.update({\"title\":\"MongoDB 教程\"},{$set:{\"title\":\"MongoDB\"}) 查看修改结果\ndb.col.find().pretty() 以上方式只会更新第一条发现的文档，如要修改多条相同的文档，需要设置 multi 为 true\ndb.col.update({\"title\":\"MongoDB 教程\"},{$set:{\"title\":\"MongoDB\"}},{multi:true}) save() 方法 save() 方法通过传入的文档来替换已有文档，语法格式\ndb.collection.save( \u003cdocument\u003e, { writeConcern: \u003cdocument\u003e } ) 参数说明\ndocument：文档数据 writeConcern：可选，抛出的异常的级别 实例\n替换 _id 为 5dd50fc604e9adcbffb78e38 的文档数据\ndb.col.save({ \"_id\" : ObjectId(\"5dd50fc604e9adcbffb78e38\"), \"title\" : \"MongoDB\", \"description\" : \"MongoDB 是一个 Nosql 数据库\", \"by\" : \"Runoob\", \"url\" : \"http://www.runoob.com\", \"tags\" : [ \"mongodb\", \"NoSQL\" ], \"likes\" : 110 }) 查看结果\ndb.col.pretty() 删除文档 语法\ndb.collection.remove( \u003cquery\u003e, \u003cjustOne\u003e ) 2.6 版本后\ndb.collection.remove( \u003cquery\u003e, { justOne: \u003cboolean\u003e, writeConcern: \u003cdocument\u003e } ) 参数说明\nquery：可选，删除的文档的条件。 justOne：可选，如果设为 true 或 1，则只删除一个文档，如果不设置该参数，或使用默认值 false，则删除所有匹配条件的文档。 writeConcern：可选，抛出异常的级别。 实例\n删除所有 title 为 MongoDB 教程的文档\ndb.col.remove({\"title\" : \"MongoDB 教程\"}) 只删除第一条找到的 title 为 MongoDB 教程的文档\ndb.col.remove({\"title\" : \"MongoDB 教程\"}, true) 删除所有文档，（类似于 sql 的 truncate）\ndb.col.remove({}) 查询文档 语法\ndb.collection.find(query, projection) 参数说明\nquery：可选，使用查询操作符指定查询条件 projection：可选，使用投影操作符指定返回的键。 使用易读的方式来查询数据，可以使用 pretty() 方法，以格式化的方式显示所有文档\ndb.collection.find().pretty() 只返回一个文档\ndb.collection.findOne() 只返回 title 字段\ndb.collection.find({}, {\"title\":1, \"_id\":0}) 注：默认会显示 _id 字段，1 代表显示，0 代表不显示\n条件操作符 MongoDB 与 RDBMS WHERE 语句比较 操作 格式 范例 RDBMS 中的类似语句 等于 {\u003ckey\u003e : \u003cvalue\u003e} db.col.find({\"by\" : \"菜鸟\"}) where by = \"菜鸟\" 小于 {\u003ckey\u003e : {$lt : \u003cvalue\u003e}} db.col.find({\"likes\" : {$lt : 50}}) where likes \u003c 50 小于等于 {\u003ckey\u003e : {$lte : \u003cvalue\u003e}} db.col.find({\"likes\" : {$lq : 50}}) where likes \u003c= 50 大于 {\u003ckey\u003e : {$gt : \u003cvalue\u003e}} db.col.find({\"likes\" : {$gt : 50}}) where likes \u003e 50 大于等于 {\u003ckey\u003e : {$gte : 50} db.col.find({\"likes\" : {$gte : 50}}) where likes \u003e= 50 不等于 {key : {$ne : \u003cvalue\u003e}} db.col.find({\"likes\" : {$ne : 50}}) where likes \u003c\u003e 50 MongoDB AND 条件 find() 方法可以传入多个键，每个键以逗号隔开，常规 AND 语法\ndb.col.find({key1 : value1, key2 : value2}) 实例\n通过 by 和 title 查询\ndb.col.find({\"by\" : \"菜鸟教程\", \"title\" : \"MongoDB 教程\"}) MongoDB OR 条件 使用 $or关键字，语法格式\ndb.col.find( { $or:[ {key1 : value1}, {key2 : value2} ] } ) MongoDB AND 和 OR 联合使用 db.col.find({key1:value1, key2:value2}, $or:[{key3:value3}, {key4:value4}]) MongoDB 使用 \u003e 和 \u003c 查询 db.col.find({\"likes\": {$gt:50, $lt:100}}) MongoDB 中的 $type 操作符 $type 操作符是基于 BSON 类型来检索集合中匹配的数据类型，并返回结果 MongoDB 中可以使用的类型如下\n类型 数字 备注 Double 1 String 2 Object 3 Array 4 Binary data 5 Undefined 6 已废弃 Object id 7 Boolean 8 Date 9 Null 10 Regular Expression 11 JavaScript 13 Symbol 14 JavaScript(with scope) 15 32-bit integer 16 Timestamp 17 64-bit integer 18 Min key 255 Query with -1 Max key 127 实例\n获取 col 集合中 title 为 String 类型的文档\ndb.col.find({\"title\" : {$type : 2}}) 或 db.col.find({\"title\" : {$type : \"string\"}) 分页操作 Limit() 方法 使用 limit() 方法读取指定数量的数据\n语法\ndb.COLLECTION_NAME.find().limit(NUMBER) 注：如果没有指定 limit() 方法的参数，则显示所有数据\nSkip() 方法 使用 skip() 方法跳过指定数量的数据\n语法\ndb.COLLECTION_NAME.find().limit(NUMBER).skip(NUMBER) 注：skip() 方法默认参数为 0\n排序操作 使用 sort() 方法进行排序，1 为升序排列，-1 为降序排列，语法\ndb.COLLECTION_NAME.find().sort({key:1}) 同时包含 limit()，skip()，sort() 时，执行顺序是 sort() → skip() → limit()\nTODO 参考文档 MongoDB 教程\n","description":"","tags":["MongoDB"],"title":"MongoDB 常用命令","uri":"/posts/database/mongodb-command/"},{"categories":null,"content":"MongoDB 使用 show dbs 报错 使用 rs.slaveOk() 命令解决\n","description":"","tags":["MongoDB"],"title":"MongoDB 使用 show dbs 报错","uri":"/posts/database/mongodb-show-dbs/"},{"categories":null,"content":"Windows 安装绿色版 MongoDB 下载 MongoDB.zip MongoDB 官方下载地址 MongoDB 官方安装教程 解压 使用的 MongoDB 版本为 mongodb-win32-x86_64-2012plus-4.2.1.zip\n解压后得到\n创建存放数据和日志的文件夹和文件 在 bin 的同级目录下创建 data 和 log 文件夹 在 data 文件夹中创建 db 空文件夹 在 log 文件夹下创建 mongo.log 空文件 注：文件路径在何处创建都无所谓，关键在于 mongo.config 的配置。\n创建 mongo.config 配置文件 在 bin 的同级目录创建 mongo.config 文件，注意修改 dbpath 和 logpath 为正确的位置\n1 2 3 4 5 # 数据库文件的存放位置 dbpath=D:\\Program Files (x86)\\MongoDB\\mongodb-win32-x86_64-2012plus-4.2.1\\data\\db # 日志文件存放的路径 logpath=D:\\Program Files (x86)\\MongoDB\\mongodb-win32-x86_64-2012plus-4.2.1\\log\\mongo.log 其他配置说明\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 # 数据库文件的存放位置 dbpath=D:\\Program Files (x86)\\MongoDB\\mongodb-win32-x86_64-2012plus-4.2.1\\data\\db # 日志文件存放的路径 logpath=D:\\Program Files (x86)\\MongoDB\\mongodb-win32-x86_64-2012plus-4.2.1\\log\\mongo.log # 是否追加方式写入日志，默认 True logappend=true # 设置绑定 ip bind_ip=127.0.0.1 # 设置端口 port=27017 # 是否以守护进程方式运行，默认 false #fork=true #这个选项可以过滤掉一些无用的日志信息，若需要调试使用请设置为 false quiet=false # 启用日志文件，默认启用 journal=true # 启用定期记录 CPU 利用率和 I/O 等待，默认 false #cpu=true # 是否以安全认证方式运行，默认是不认证的非安全方式 #noauth=true #auth=true # 详细记录输出，默认 false #verbose=true #用于开发驱动程序时验证客户端请求 #objcheck=true # # 启用数据库配额管理，默认 false #quota=true # 设置 oplog 日志记录等级，默认 0 # 0=off (default) # 1=W # 2=R # 3=both # 7=W+some reads #oplog=0 # 是否打开动态调试项，默认 false #nocursors=true # 忽略查询提示，默认 false #nohints=true # 禁用 http 界面，默认为 localhost：28017 #nohttpinterface=true # 关闭服务器端脚本，这将极大的限制功能，默认 false #noscripting=true # 关闭扫描表，任何查询将会是扫描失败 #notablescan=true # 关闭数据文件预分配 #noprealloc=true # 为新数据库指定.ns 文件的大小，单位:MB # nssize=\u003csize\u003e # 用于 Mongo 监控服务器的 Accout token。 #mms-token=\u003ctoken\u003e # Mongo 监控服务器的服务器名称。 #mms-name=\u003cserver-name\u003e # Mongo 监控服务器的 Ping 间隔时间，即心跳 #mms-interval=\u003cseconds\u003e # Replication Options # 设置主从复制参数 #slave=true # 设置从节点 #source=master.example.com # 指定从节点的主节点 # Slave only: 指定要复制的单个数据库 #only=master.example.com # or #master=true # 设置主节点 #source=slave.example.com # 设置副本集的名字，所有的实例指定相同的名字属于一个副本集 replSet=name #pairwith=\u003cserver:port\u003e # 仲裁服务器地址 #arbiter=\u003cserver:port\u003e # 默认为 false，用于从实例设置。是否自动重新同步 #autoresync=true # 指定的复制操作日志（OPLOG）的最大大小 #oplogSize=\u003cMB\u003e # 限制复制操作的内存使用 #opIdMem=\u003cbytes\u003e # 设置 ssl 认证 # Enable SSL on normal ports #sslOnNormalPorts=true # SSL Key file and password #sslPEMKeyFile=/etc/ssl/mongodb.pem #sslPEMKeyPassword=pass # path to a key file storing authentication info for connections # between replica set members #指定存储身份验证信息的密钥文件的路径 #keyFile=/path/to/keyfile 安装并启动服务 配置好环境变量（略）或在 bin 目录下以管理员身份运行 cmd\n安装 mongod 服务\n1 2 mongod --config \"[配置文件路径]\" --serviceName \"[服务名]\" mongod --config \"D:\\Program Files (x86)\\MongoDB\\mongodb-win32-x86_64-2012plus-4.2.1\\mongo.config\" --serviceName MongoDB --install 启动服务\n1 net start [服务名] 参考文档 Windows 安装 MongoDB .zip 绿色版\n","description":"","tags":["MongoDB"],"title":"Windows 安装绿色版 MongoDB","uri":"/posts/database/mongodb-install-in-windows/"},{"categories":null,"content":"Windows 安装绿色版 MySQL 下载压缩包 MySQL 绿色版官方下载地址\n解压后得到\n新建 my.ini 配置文件 在 bin 文件夹的同级目录新建一个 my.ini 文件，一定要修改 basedir 和 datadir 为正确的位置，否则之后的服务会启动失败\n8.0.17 或 5.7.27 版本的 my.ini\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 [mysqld] # 设置端口 port=3306 # 设置 mysql 的安装目录 basedir=\"D:\\\\Program Files (x86)\\\\MySQL\\\\mysql-8.0.17-winx64\" # 设置 mysql 数据库的数据的存放目录 datadir=\"D:\\\\Program Files (x86)\\\\MySQL\\\\mysql-8.0.17-winx64\\\\data\" # 允许最大连接数 max_connections=200 # 允许连接失败的次数。这是为了防止有人从该主机试图攻击数据库系统 max_connect_errors=10 # 服务端使用的字符集默认为 UTF8 character-set-server=utf8mb4 # 创建新表时将使用的默认存储引擎 default-storage-engine=INNODB # 默认使用 mysql_native_password 插件认证 default_authentication_plugin=mysql_native_password # 5.7.27 需要添加下面这个 explicit_defaults_for_timestamp=true [mysql] # 设置 mysql 客户端默认字符集 default-character-set=utf8mb4 [client] # 设置 mysql 客户端连接服务端时默认使用的端口 port=3306 default-character-set=utf8mb4 5.6.45 版本的 my.ini\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 [mysql] # 设置 mysql 客户端默认字符集 default-character-set=utf8 [client] # 设置 mysql 客户端连接服务端时默认使用的端口 port=3306 default-character-set=utf8 [mysqld] # 设置端口 port=3306 # 设置 mysql 的安装目录 basedir=\"D:\\\\Program Files (x86)\\\\MySQL\\\\mysql-5.6.45-winx64\" # 设置 mysql 数据库的数据的存放目录 datadir=\"D:\\\\Program Files (x86)\\\\MySQL\\\\mysql-5.6.45-winx64\\\\data\" # 允许最大连接数 max_connections=200 # 允许连接失败的次数。这是为了防止有人从该主机试图攻击数据库系统 max_connect_errors=10 # 服务端使用的字符集默认为 UTF8 character-set-server=utf8 # 创建新表时将使用的默认存储引擎 default-storage-engine=INNODB # 默认使用 mysql_native_password 插件认证 default_authentication_plugin=mysql_native_password sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES 安装并配置启动 MySQL 服务 MySQL 官方说明\n法 1（8.0.17 和 5.7.27 版本适用） 设置好环境变量（略）或移动到 bin 目录下，以管理员身份运行 cmd 窗口\n安装 mysqld 服务\n服务名可选，默认为 mysql\n1 mysqld install [服务名] 初始化 MySQL\n1 mysqld --initialize --console 此时会打印出系统随机生成的密码，注意保存，在第一次登录时需要使用\n启动 MySQL 服务\n1 net start [服务名] 修改密码\n1 2 3 mysql -uroot -p 初始密码; ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'new password'; 其他相关命令\n1 2 3 4 # 停止服务 net stop [服务名] # 移除 mysql 服务 mysqld --remove [服务名] 法 2（5.5.62 版本适用） 安装 mysqld 服务\n服务名可选，默认为 mysql\n1 mysqld install [服务名] 启动 MySQL 服务\n1 net start [服务名] 初始化密码\n1 mysqladmin -u root password 密码 ","description":"","tags":["MySQL"],"title":"Windows 安装绿色版 MySQL","uri":"/posts/database/mysql-install-in-windows/"},{"categories":null,"content":"Windows 开机自动挂载挂载盘 创建批处理文件 新建文本文档，将格式修改为 .bat，得到 nfs_auto.bat\n1 mount \\\\172.168.13.119\\home X: 创建计划任务 在 Windows 的管理工具中，打开任务计划程序\n选择 操作 → 创建任务\n选择常规，设置任务计划名称，选择不管用户是否登录都要运行、使用最高权限运行(I)\n选择触发器 → 新建，弹出编辑触发器，开始任务选择登录时，高级设置中选择已启用，单击确定。 选择操作 → 新建，弹出新建操作，操作选择启动程序，程序或脚本选择 nfs_auto.bat 文件，单击确定 选择条件，网络选择任何连接。 7.选择设置，选择如果请求后任务还在运行，强行将其停止(F)、请勿启动新实例。\n单击确定，保存退出 常见问题 任务计划程序无法应用你的更改。用户账户未知、密码错误或用户账户没有修改此任务的权限。 解决方法\n可选择常规，选择只在用户登录时运行(R) 可能的原因包括不允许空密码，登录时间限制，或强制的策略限制 解决方法\n按 Win+R 输入 gpedit.msc 打开本地组策略编辑器 找到账户：使用空密码的本地账户只允许进行控制台登录 双击，将其禁用 参考文档 Windows 系统实现自动挂载 NAS 解决：登录失败，用户账号限制。可能的原因包括不允许空密码，登录时间限制，或强制的策略限制 ","description":"","tags":["Windows"],"title":"Windows 配置自动启动批处理任务","uri":"/posts/windows/windows-auto-mount/"},{"categories":null,"content":"Windows10 安装 Docker https://www.runoob.com/docker/windows-docker-install.html\n阿里云 dockertoolbox http://mirrors.aliyun.com/docker-toolbox/windows/docker-toolbox/\n","description":"","tags":["Docker"],"title":"Windows10 安装 Docker","uri":"/posts/docker/windows-install-docker/"},{"categories":null,"content":"Windows10 移动 Docker 关闭 Hyper-V 虚拟化 如果启动过 Docker 需要先关闭 Hyper-V，防止 Docker 镜像文件被系统占用\n停止 Docker 服务 停止 Docker Desktop Service(com.docker.service)\n移动文件 C:\\Program File\\Docker 移动到另一个地方，例如 D:\\Program File（x86）\\Docker\n修改注册表 打开注册表\nWin+R\n1 regedit 修改注册表值\n\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\com.docker.service 的 ImagePath 值为新路径下 com.docker.service 的路径，例如：D:\\Program File（x86）\\Docker\\com.docker.service 启动服务 启动 Docker Desktop Service 服务\n","description":"","tags":["Docker"],"title":"Windows10 移动 Docker","uri":"/posts/docker/windows-move-docker/"},{"categories":null,"content":"Java 使用 cmd 调用进程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 import java.io.BufferedReader; import java.io.BufferedWriter; import java.io.File; import java.io.FileWriter; import java.io.IOException; import java.io.InputStreamReader; import java.util.Calendar; import java.util.Date; import java.util.GregorianCalendar; import java.util.Timer; import java.util.TimerTask; public class ProcCmd { private String charsetName = \"UTF-8\"; private String logFilePath = \"D:/logs\"; private Long timeout = (long) (1000 * 60 * 3); private boolean isSuccess = true; private static class Worker extends Thread { private final Process process; private Integer exit; private Worker(Process process) { this.process = process; } public void run() { try { exit = process.waitFor(); } catch (InterruptedException ignore) { return; } } } public boolean execByTimeout(String commandstr) { System.out.println(\"开始时间：\" + new Date()); Runtime runtime = Runtime.getRuntime(); Process process = null; try { process = runtime.exec(commandstr); outputLog(process, false, false); Worker worker = new Worker(process); worker.start(); worker.join(this.timeout); System.out.println(\"worker.exit =====\" + worker.exit); if (worker.exit != null) { if (isSuccess) { writeComLog(\"Process out :执行成功...\"); } else { writeComLog(\"Process out :执行过程中有错误发生...\"); } return isSuccess; } else { writeComLog(\"Process err :执行超时：\" + commandstr); // 超时 return false; } } catch (IOException e) { e.printStackTrace(); } catch (InterruptedException e) { e.printStackTrace(); } finally { if (process != null) { /*\ttry { Thread.sleep(3000L); } catch (InterruptedException e) { e.printStackTrace(); }*/ System.out.println(\"结束时间：\" + new Date()); process.destroy(); } } return false; } public boolean exec(String commandstr) { Process process = null; try { process = Runtime.getRuntime().exec(commandstr); outputLog(process, true, true); // 阻塞线程，等待命令执行完毕 process.waitFor(); return true; } catch (Exception e) { e.printStackTrace(); return false; } finally { if (process != null) { process.destroy(); } } } /** * 记录日志内容 */ @SuppressWarnings(\"static-access\") public synchronized void writeComLog(String str) { Calendar c = GregorianCalendar.getInstance(); logFilePath = logFilePath +\"/\"+ \"databackup-\"+c.get(c.YEAR)+ fillZero(1+c.get(c.MONTH)+\"\", 2) + \".log\"; String datetime = null; try { datetime = \"\" + c.get(c.YEAR) + \"-\" + fillZero(1 + c.get(c.MONTH) + \"\", 2) + \"-\" + fillZero(\"\" + c.get(c.DAY_OF_MONTH), 2) + \" \" + fillZero(\"\" + c.get(c.HOUR), 2) + \":\" + fillZero(\"\" + c.get(c.MINUTE), 2) + \":\" + fillZero(\"\" + c.get(c.SECOND), 2); str = \"[\" + datetime + \"] \" + str; System.out.println(str); //写日志 writeLog(str); } catch (Exception e) { System.out.println(\"Error\"); } } private void outputLog(final Process pr, boolean printOutput, boolean printError) { if (printOutput) { new Timer().schedule(new TimerTask() { @Override public void run() { BufferedReader br_in = null; try { br_in = new BufferedReader(new InputStreamReader(pr.getInputStream(), charsetName)); String buff = null; String lastBuff = null; while ((buff = br_in.readLine()) != null) { if (buff != null \u0026\u0026 !buff.equals(lastBuff)) { lastBuff = buff; writeComLog(\"Process out :\" + buff); } try { Thread.sleep(100); } catch (Exception e) { } } br_in.close(); } catch (IOException ioe) { System.out.println(\"Exception caught printing process output.\"); ioe.printStackTrace(); } finally { try { br_in.close(); } catch (Exception ex) { ex.printStackTrace(); } } } }, 100); } if (printError) { new Timer().schedule(new TimerTask() { @Override public void run() { BufferedReader br_err = null; try { br_err = new BufferedReader(new InputStreamReader(pr.getErrorStream(), charsetName)); String buff = null; String lastBuff = null; while ((buff = br_err.readLine()) != null) { if (buff != null \u0026\u0026 !buff.equals(lastBuff)) { lastBuff = buff; writeComLog(\"Process err :\" + buff); isSuccess = false; } try { Thread.sleep(100); } catch (Exception e) { } } br_err.close(); } catch (IOException ioe) { System.out.println(\"Exception caught printing process error.\"); ioe.printStackTrace(); } finally { try { br_err.close(); } catch (Exception ex) { ex.printStackTrace(); } } } }, 100); } } private void writeLog(String str) { if (logFilePath == null) { return; } BufferedWriter bufOut = null; try { File f = new File(logFilePath); if (f.exists() == true) { bufOut = new BufferedWriter(new FileWriter(f, true)); } else { bufOut = new BufferedWriter(new FileWriter(f)); } bufOut.write(str + \"\\n\"); } catch (Exception e) { e.printStackTrace(); } finally { if (bufOut != null) { try { bufOut.close(); } catch (IOException e) { e.printStackTrace(); } } } } public static void writeLog(String logPath, String str) { if (logPath == null) { return; } BufferedWriter bufOut = null; try { File f = new File(logPath); if (f.exists() == true) { bufOut = new BufferedWriter(new FileWriter(f, true)); } else { bufOut = new BufferedWriter(new FileWriter(f)); } bufOut.write(str + \"\\n\"); } catch (Exception e) { e.printStackTrace(); } finally { if (bufOut != null) { try { bufOut.close(); } catch (IOException e) { e.printStackTrace(); } } } } /*右对齐左补零*/ static String fillZero(String str, int len) { int tmp = str.length(); int t; String str1 = str; if (tmp \u003e= len) return str1; t = len - tmp; for (int i = 0; i \u003c t; i++) str1 = \"0\" + str1; return str1; } public String getLogFilePath() { return logFilePath; } public void setLogFilePath(String logFilePath) { this.logFilePath = logFilePath; } public String getCharsetName() { return charsetName; } public void setCharsetName(String charsetName) { this.charsetName = charsetName; } public Long getTimeout() { return timeout; } public void setTimeout(Long timeout) { this.timeout = timeout; } } ","description":"","tags":["Java"],"title":"Java 执行 cmd 命令","uri":"/posts/java/java-process/"},{"categories":null,"content":"Linux 内存 buff/cache 占用过多 free 命令说明 使用 free 命令可以查看系统内存使用情况\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 Usage: free [options] Options: -b, --bytes show output in bytes -k, --kilo show output in kilobytes -m, --mega show output in megabytes -g, --giga show output in gigabytes --tera show output in terabytes --peta show output in petabytes -h, --human show human-readable output --si use powers of 1000 not 1024 -l, --lohi show detailed low and high memory statistics -t, --total show total for RAM + swap -s N, --seconds N repeat printing every N seconds -c N, --count N repeat printing N times, then exit -w, --wide wide output --help display this help and exit -V, --version output version information and exit For more details see free(1). buff/cache 说明 什么是 buff/cache buffer 和 cache 是两个在计算机技术中被用滥的名词，放在不通语境下会有不同的意义。在 Linux 的内存管理中，这里的 buffer 指 Linux 内存的：Buffer cache。这里的 cache 指 Linux 内存中的：Page cache。翻译成中文可以叫做缓冲区缓存和页面缓存。在历史上，它们一个（buffer）被用来当成对 io 设备写的缓存，而另一个（cache）被用来当作对 io 设备的读缓存，这里的 io 设备，主要指的是块设备文件和文件系统上的普通文件。但是现在，它们的意义已经不一样了。在当前的内核中，page cache 顾名思义就是针对内存页的缓存，说白了就是，如果有内存是以 page 进行分配管理的，都可以使用 page cache 作为其缓存来管理使用。当然，不是所有的内存都是以页（page）进行管理的，也有很多是针对块（block）进行管理的，这部分内存使用如果要用到 cache 功能，则都集中到 buffer cache 中来使用。（从这个角度出发，是不是 buffer cache 改名叫做 block cache 更好？）然而，也不是所有块（block）都有固定长度，系统上块的长度主要是根据所使用的块设备决定的，而页长度在 X86 上无论是 32 位还是 64 位都是 4k。\n什么是 page cache Page cache 主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有 read/write 操作的时候。如果你仔细想想的话，作为可以映射文件到内存的系统调用：mmap 是不是很自然的也应该用到 page cache？在当前的系统实现里，page cache 也被作为其它文件类型的缓存设备来用，所以事实上 page cache 也负责了大部分的块设备文件的缓存工作。\n什么是 buffer cache Buffer cache 则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。这意味着某些对块的操作会使用 buffer cache 进行缓存，比如我们在格式化文件系统的时候。一般情况下两个缓存系统是一起配合使用的，比如当我们对一个文件进行写操作的时候，page cache 的内容会被改变，而 buffer cache 则可以用来将 page 标记为不同的缓冲区，并记录是哪一个缓冲区被修改了。这样，内核在后续执行脏数据的回写（writeback）时，就不用将整个 page 写回，而只需要写回修改的部分即可\n如何回收 cache Linux 内核会在内存将要耗尽的时候，触发内存回收的工作，以便释放出内存给急需内存的进程使用。一般情况下，这个操作中主要的内存释放都来自于对 buffer/cache 的释放。尤其是被使用更多的 cache 空间。既然它主要用来做缓存，只是在内存够用的时候加快进程对文件的读写速度，那么在内存压力较大的情况下，当然有必要清空释放 cache，作为 free 空间分给相关进程使用。所以一般情况下，我们认为 buffer/cache 空间可以被释放，这个理解是正确的。\n但是这种清缓存的工作也并不是没有成本。理解 cache 是干什么的就可以明白清缓存必须保证 cache 中的数据跟对应文件中的数据一致，才能对 cache 进行释放。所以伴随着 cache 清除的行为的，一般都是系统 IO 飙高。因为内核要对比 cache 中的数据和对应硬盘文件上的数据是否一致，如果不一致需要写回，之后才能回收\n手动回收 cache\n1 2 # 查看当前清理缓存的级别 cat /proc/sys/vm/drop_caches echo 1 \u003e /proc/sys/vm/drop_caches : 表示清除 pagecache。 echo 2 \u003e /proc/sys/vm/drop_caches：表示清除回收 slab 分配器中的对象（包括目录项缓存和 inode 缓存）。slab 分配器是内核中管理内存的一种机制，其中很多缓存数据实现都是用的 pagecache。 echo 3 \u003e /proc/sys/vm/drop_caches：表示清除 pagecache 和 slab 分配器中的缓存对象。 参考文档 解决 Linux buffer/cache 内存占用过高的办法\n","description":"","tags":["Linux"],"title":"Linux 内存 buff/cache 占用过多","uri":"/posts/linux/linux-clean-buff-cache/"},{"categories":null,"content":"CentOS修改文件或目录权限 类型 root用户 组用户 当前用户 -（文件） rwx() rwx rwx d（目录） rwx rwx rwx rwx 从左到右分别为 1、2、4\nchmod 753\nroot用户权限 组用户权限 当前用户权限 7=1+2+4 5=1+0+4 6=1+2+0 r + w + x r + x r + w ","description":"","tags":["Linux","CentOS"],"title":"CentOS 修改文件或目录权限","uri":"/posts/linux/centos/centos7-dir-permission/"},{"categories":null,"content":"firewalld firewalld 基本概念 firewalld 和 iptables-service iptables 命令是用来在用户空间操作内核中 Netfilter 的工具；\nfirewalld 和 iptables-service 最终都是使用 iptables 命令来操作 Netfilter 的服务；\n操作 iptables-service 的方式是使用配置文件和 service iptables ... 命令；操作 firewalld 使用 firewall-cmd 命令即可。\nfirewalld 和 iptables-service 服务同时只能使用一个。\nfirewalld 的好处 动态防火墙：在修改了防火墙规则后，firewalld 只会对变更的部分进行修改；而 iptables-service 会先清空所有旧的规则，再重新加载所有规则（静态防火墙） firewalld 引入 zone 和 service 的概念用来简化对包的管理 区域（Zone）和服务（Service） firewalld 定义了区域（zone）和服务（service）的概念，每个区域都预先定义了一系列的规则，这些规则可以是对某个服务进行设置的（iptables-service 不支持对服务进行设置）；一个网络连接/网络接口/资源只能属于一个区域，一个区域里可以有多个网络连接/网络接口/资源。\n预定义区域和配置文件 预定义的区域\n预定义的区域存储在 /usr/lib/firewalld/zones/ 目录，如果对预定义的区域进行修改后，会将修改后的文件复制到 /etc/firewalld/zones/ 目录\nblock（限制）：任何接收的网络连接都被 IPv4 的 icmp-host-prohibited 信息和 IPv6 的 icmp6-adm-prohibited 信息所拒绝。 dmz（非军事区）：用于您的非军事区内的电脑，此区域内可公开访问，可以有限地进入您的内部网络，仅仅接收经过选择的连接。 drop（丢弃）：任何接收的网络数据包都被丢弃，没有任何回复。仅能有发送出去的网络连接。 external（外部）：特别是为路由器启用了伪装功能的外部网。您不能信任来自网络的其他计算，不能相信它们不会对您的计算机造成危害，只能接收经过选择的连接。 home（家庭）：用于家庭网络。您可以基本信任网络内的其他计算机不会危害您的计算机。仅仅接收经过选择的连接。 internal（内部）：用于内部网络。您可以基本上信任网络内的其他计算机不会威胁您的计算机。仅仅接受经过选择的连接。 public（公共）：在公共区域内使用，不能相信网络内的其他计算机不会对您的计算机造成危害，只能接收经过选取的连接。 trusted（信任）：可接受所有的网络连接。 work（工作）：用于工作区。您可以基本相信网络内的其他电脑不会危害您的电脑。仅仅接收经过选择的连接。 通常，默认使用 public 区域。\n区域配置文件格式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003c!-- version 可选，用于表示 zone 的版本 --\u003e \u003c!-- target 可选，接收/拒绝/丢弃没有匹配任何规则的包。默认值为 default，default 类似于 REJECT，但是它会允许 ICMP 包 --\u003e \u003czone version=\"string\" target=\"ACCEPT|%%REJECT%%|DROP\"\u003e \u003c!-- 可选，简短的描述信息 --\u003e \u003cshort\u003eshort description\u003c/short\u003e \u003c!-- 可选，详细的描述信息 --\u003e \u003cdescription\u003edescription\u003c/description\u003e \u003c!-- 可多次使用的可选项。与该 zone 绑定的网络接口名称，如果使用 NetworkManager 管理网络接口，则不需要配置该标签 --\u003e \u003cinterface name=\"string\"/\u003e \u003c!-- 可多次使用的可选项。与该 zone 绑定的源地址/地址端、MAC 地址、ipset，该 zone 中的规则只对该源生效。所有的属性都是可选项。--\u003e \u003csource address=\"ipv4-or-ipv6-address[/mask]\" mac=\"MAC\" ipset=\"ipset\"/\u003e \u003c!-- 可多次使用的可选项。允许（ACCEPT）源访问的目标服务名称 --\u003e \u003cservice name=\"ssh\"/\u003e \u003c!-- 可多次使用的可选项。port 属性是必填的，protocol 属性时可选的，值可以为 tcp/udp。允许（ACCEPT）源访问的目标端口和协议 --\u003e \u003cport port=\"portid[-portid]\" protocol=\"tcp|udp\"/\u003e \u003c!-- 可多次使用的可选项。值可以为 /etc/protocols 中的任意协议。允许（ACCEPT）源访问的目标协议 --\u003e \u003cprotocol value=\"string\"/\u003e \u003c!-- 可多次使用的可选项。阻止（REJECT）源使用指定的 icmp 类型访问目标。如果一个都不配置则允许所有 icmp 请求 --\u003e \u003cicmp-block name=\"string\"/\u003e \u003c!-- 可选。反转 icmp-block 标签中的配置，即添加该标签后，允许（ACCEPT）源使用 icmp-block 中配置的 icmp 类型访问目标。如果没有配置 icmp-block，只添加了 icmp-block-inversion，则拒绝所有 icmp 请求 --\u003e \u003cicmp-block-inversion/\u003e \u003c!-- 可选。在接口和源之间启用数据包转发 --\u003e \u003cforward/\u003e \u003c!-- 可选，不适用 IPv6。启用地址伪装。如果要启用伪装，则应在绑定了外部接口的 zone 中启用它 --\u003e \u003cmasquerade/\u003e \u003c!-- 可多次使用的可选项，只支持 IPv4。把通过 protocol 协议发送给到 port 的请求转发到 to-addr 的 to-port 端口 --\u003e \u003c!-- port 和 protocol 属性为必填 --\u003e \u003c!-- to-port 和 to-addr 属性为选填。to-port 为目的地端口，如果省略，则默认值与 port 相同。to-addr 是目的地的 IPv4 地址 --\u003e \u003cforward-port port=\"portid[-portid]\" protocol=\"tcp|udp\" to-port=\"portid[-portid]\" to-addr=\"ipv4-address\"/\u003e \u003c!-- 可多次使用的可选项，port 和 protocol 属性都是必填的。该 zone 中的规则只对该源端口和协议生效 --\u003e \u003csource-port port=\"portid[-portid]\" protocol=\"tcp|udp\"/\u003e \u003c!-- 可多次使用的可选项，可以包含更丰富的语法规则。详情参考：firewalld.richlanguage(5) --\u003e \u003crule\u003e\u003c/rule\u003e \u003c/zone\u003e 修改完 service 的配置文件后，需要使用 firewall-cmd --reload 重载配置。\n预定义服务和配置文件 预定义的服务\n在 /usr/lib/firewalld/services/ 目录中保存着预定义的服务，不建议对该目录下的文件进行修改；可以将其复制到 /etc/firewalld/services/ 目录后，在该目录下进行修改；如果需要添加服务，也可以在后者中新建，服务文件名的格式为：service-name.xml\n服务配置文件格式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003c!-- version 可选，用于表示 service 的版本 --\u003e \u003cservice version=\"string\"\u003e \u003c!-- 可选，简短的描述信息 --\u003e \u003cshort\u003eshort description\u003c/short\u003e \u003c!-- 可选，详细的描述信息 --\u003e \u003cdescription\u003edescription\u003c/description\u003e \u003c!-- 可选，该服务的端口和协议信息，通常配置服务，配置的都是该标签，该标签可以使用多次 --\u003e \u003c!-- port 属性是必填的，用来配置端口，protocol 属性值只能是 tcp 或 udp --\u003e \u003c!-- 旧版本的 firewalld 中，port 属性也是可选的，如果不配置 port 属性，该标签与 protocol 标签相同，protocol 可以配置 /etc/protocols 中的任意协议 --\u003e \u003cport port=\"portid[-portid]\" protocol=\"tcp|udp\"/\u003e \u003c!-- 可选，只配置协议信息，值可以为 /etc/protocols 中的任意协议，该标签可以使用多次 --\u003e \u003cprotocol value=\"string\"/\u003e \u003c!-- 可选，请求源的端口和协议信息，port 和 protocol 属性都是必填的，该标签可以使用多次 --\u003e \u003csource-port port=\"string\" protocol=\"tcp|udp\" /\u003e \u003c!-- 可选，配置 Netfilter 的 helper，该标签可以使用多次 --\u003e \u003cmodule name=\"helper\"/\u003e \u003c!-- 可选，目标地址，即该服务只对目标地址的请求生效，可以使用掩码 --\u003e \u003cdestination ipv4=\"address[/mask]\" ipv6=\"address[/mask]\"/\u003e \u003c/service\u003e 修改完 service 的配置文件后，需要使用 firewall-cmd --reload 重载配置。\n常用命令 详细的命令说明可参考 man firewall-cmd\n防火墙状态相关 查看防火墙版本\n1 firewall-cmd --version 查看防火墙状态\n1 2 3 systemctl status firewalld 或 firewall-cmd --state 刷新防火墙配置\n1 2 3 firewall-cmd --reload 或 systemctl reload firewalld 开启防火墙\n1 systemctl start firewalld 关闭防火墙\n1 systemctl stop firewalld 重启防火墙\n1 systemctl restart firewalld 设置为开机自启\n1 systemctl enable firewalld 取消开机自启\n1 systemctl disable firewalld 持久化选项 在 firewall-cmd 后添加 --permanent 选项，可以设置持久化保存到 firewalld 的配置文件中。没有持久化的配置在防火墙重启，或重新加载配置，或服务器重启后会失效。执行完带持久话操作的命令后需要执行 firewalld-cmd reload 重新加载防火墙配置使其生效。\n查询/设置区域（Zone）状态的命令 查询默认的区域\n1 firewall-cmd --get-default-zone 设置默认区域\n1 firewall-cmd --set-default-zone=zone [--permanent] 查询所有可用的区域信息\n1 firewall-cmd [--permanent] --list-all-zones 查询指定区域的信息\n1 firewall-cmd [--permanent] --info-zone=zone 查询已激活的区域及其绑定的网络接口和资源信息\n1 firewall-cmd --get-active-zone 查询预定义的区域\n1 firewall-cmd [--permanent] --get-zones 查询支持的 icmp 类型\n1 firewall-cmd [--permanent] --get-icmptypes 查询与指定网络接口绑定的区域\n1 firewall-cmd [--permanent] --get-zone-of-interface=interface 查询与指定资源/MAC/ipset 绑定的区域\n1 firewall-cmd [--permanent] --get-zone-of-source=source[/mask]|MAC|ipset:ipset 添加新的区域\n1 2 3 firewall-cmd --permanent --new-zone=zone # 从文件中加载一个新的区域 firewall-cmd --permanent --new-zone-from-file=filename [--name=zone] 删除区域\n1 firewall-cmd --permanent --delete-zone=zone 加载区域的默认设置\n1 firewall-cmd --permanent --load-zone-defaults=zone 查询区域的配置文件路径\n1 firewall-cmd --permanent --path-zone=zone 查询/调整区域（Zone）配置的命令 本节中的选项仅影响一个特定区域，如果与 --zone=zone 选项一起使用则会影响指定区域，否则影响默认区域。查询和调整的是 zone 配置文件中的标签属性，标签的说明可参考 区域配置文件格式\n查看区域下所有添加或启用的配置信息\n1 firewall-cmd [--permanent] [--zone=zone] --list-all 查看/修改区域的目标信息（zone.target）\n1 2 3 firewall-cmd --permanent [--zone=zone] --get-target # 可选值有：default、ACCEPT、DROP、REJECT firewall-cmd --permanent [--zone=zone] --set-target=default|ACCEPT|DROP|REJECT 查看/修改区域的简短描述信息（zone.short）\n1 2 firewall-cmd --permanent [--zone=zone] --get-short firewall-cmd --permanent [--zone=zone] --set-short=description 查看/修改区域的描述信息（zone.description）\n1 2 firewall-cmd --permanent [--zone=zone] --get-description firewall-cmd --permanent [--zone=zone] --set-description=description 查看/添加/修改/删除区域绑定的网络端口（zone.interfaces）\n1 2 3 4 5 6 7 8 # --timeout 设置当前规则的失效时间，例如：60s/20m/1h。不能和 --permanent 同时使用 firewall-cmd [--permanent] [--zone=zone] --list-interfaces firewall-cmd [--permanent] [--zone=zone] --add-interface=interface # 将已于其他区域绑定的网络接口绑定到指定的区域，如果不指定区域则绑定到默认区域。如果不存在该源，则效果与 --add-source　相同 firewall-cmd [--permanent] [--zone=zone] --change-interface=interface firewall-cmd [--permanent] [--zone=zone] --remove-interface=interface # 查询区域是否绑定了这个网络端口，已绑定返回 0，否则返回 1 firewall-cmd [--permanent] [--zone=zone] --query-interface=interface 查看/添加/修改/删除区域绑定的资源（zone.source）\n1 2 3 4 5 6 7 8 9 # --timeout 设置当前规则的失效时间，例如：60s/20m/1h。不能和 --permanent 同时使用 firewall-cmd [--permanent] [--zone=zone] --list-sources firewall-cmd [--permanent] [--zone=zone] --add-source=source[/mask]|MAC|ipset:ipset # 将已于其他区域绑定的源绑定到指定的区域，如果不指定区域则绑定到默认区域。如果不存在该源，则效果与 --add-source　相同 firewall-cmd [--zone=zone] --change-source=source[/mask]|MAC|ipset:ipset # 删除已存在的源 firewall-cmd [--permanent] --remove-source=source[/mask]|MAC|ipset:ipset # 查询区域是否绑定了这个源，已绑定返回 0，否则返回 1 firewall-cmd [--permanent] --query-source=source[/mask]|MAC|ipset:ipset 查看/添加/删除区域允许的服务（zone.service)\n1 2 3 4 5 6 firewall-cmd [--permanent] [--zone=zone] --list-services # --timeout 设置当前规则的失效时间，例如：60s/20m/1h。不能和 --permanent 同时使用 firewall-cmd [--permanent] [--zone=zone] --add-service=service [--timeout=timeval] firewall-cmd [--permanent] [--zone=zone] --remove-service=service # 查询区域中是否包含该服务，包含返回 0，否则返回 1 firewall-cmd [--permanent] [--zone=zone] --query-service=service 查看/添加/删除区域允许的端口（zone.port）\n1 2 3 4 5 6 firewall-cmd [--permanent] [--zone=zone] --list-ports # --timeout 设置当前规则的失效时间，例如：60s/20m/1h。不能和 --permanent 同时使用 firewall-cmd [--permanent] [--zone=zone] --add-port=portid[-portid]/protocol [--timeout=timeval] firewall-cmd [--permanent] [--zone=zone] --remove-port=portid[-portid]/protocol # 查询区域中是否包含该端口，包含返回 0，否则返回 1 firewall-cmd [--permanent] [--zone=zone] --query-port=portid[-portid]/protocol 查看/添加/删除区域允许的协议（zone.protocols）\n1 2 3 4 5 6 firewall-cmd [--permanent] [--zone=zone] --list-protocols # --timeout 设置当前规则的失效时间，例如：60s/20m/1h。不能和 --permanent 同时使用 firewall-cmd [--permanent] [--zone=zone] --add-protocol=protocol [--timeout=timeval] firewall-cmd [--permanent] [--zone=zone] --remove-protocol=protocol # 查询区域中是否包含该协议，包含返回 0，否则返回 1 firewall-cmd [--permanent] [--zone=zone] --query-protocol=protocol 查看/添加/删除区域中的 zone.icmp-block\n1 2 3 4 5 6 firewall-cmd [--permanent] [--zone=zone] --list-icmp-blocks # --timeout 设置当前规则的失效时间，例如：60s/20m/1h。不能和 --permanent 同时使用 firewall-cmd [--permanent] [--zone=zone] --add-icmp-block=icmptype [--timeout=timeval] firewall-cmd [--permanent] [--zone=zone] --remove-icmp-block=icmptype # 查询区域中是否包含该 icmp-block，包含返回 0，否则返回 1 firewall-cmd [--permanent] [--zone=zone] --query-icmp-block=icmptype 启用/禁用/查询区域中的反转 icmp-block（zone.icmp-block-inversion）\n1 2 3 4 5 # --timeout 设置当前规则的失效时间，例如：60s/20m/1h。不能和 --permanent 同时使用 firewall-cmd [--permanent] [--zone=zone] --add-icmp-block-inversion firewall-cmd [--permanent] [--zone=zone] --remove-icmp-block-inversion # 查询区域中是否启用反转，启用返回 0，否则返回 1 firewall-cmd [--permanent] [--zone=zone] --query-icmp-block-inversion 启用/禁用/查询区域内转发（zone.forward）\n1 2 3 4 5 # --timeout 设置当前规则的失效时间，例如：60s/20m/1h。不能和 --permanent 同时使用 firewall-cmd [--permanent] [--zone=zone] --add-forward firewall-cmd [--permanent] [--zone=zone] --remove-forward # 查询区域中是否启用转发，启用返回 0，否则返回 1 firewall-cmd [--permanent] [--zone=zone] --query-forward 启用/禁用/查询区域中的地址伪装（zone.masquerade）\n不适用 Ipv6。Ipv6 需要使用 rich language\n1 2 3 4 5 # --timeout 设置当前规则的失效时间，例如：60s/20m/1h。不能和 --permanent 同时使用 firewall-cmd [--permanent] [--zone=zone] --add-masquerade [--timeout=timeval] firewall-cmd [--permanent] [--zone=zone] --remove-masquerade # 查询区域中是否包含该 icmp-block，包含返回 0，否则返回 1 firewall-cmd [--permanent] [--zone=zone] --query-masquerade 查看/添加/删除区域中的转发端口（zone.forward-port）\n只支持 IPv4 的转发端口。如需对 IPv6 的进行操作，请使用 rich language\n1 2 3 4 5 6 firewall-cmd [--permanent] [--zone=zone] --list-forward-ports # --timeout 设置当前规则的失效时间，例如：60s/20m/1h。不能和 --permanent 同时使用 firewall-cmd [--permanent] [--zone=zone] --add-forward-port=port=portid[-portid]:proto=protocol[:toport=portid[-portid]][:toaddr=address[/mask]] [--timeout=timeval] firewall-cmd [--permanent] [--zone=zone] --remove-icmp-block=icmptype # 查询区域中是否包含该转发端口，包含返回 0，否则返回 1 firewall-cmd [--permanent] [--zone=zone] --query-forward-port=port=portid[-portid]:proto=protocol[:toport=portid[-portid]][:toaddr=address[/mask]] 查看/添加/删除区域限制的源端口信息（zone.source-port）\n1 2 3 4 5 6 firewall-cmd [--permanent] [--zone=zone] --list-source-ports # --timeout 设置当前规则的失效时间，例如：60s/20m/1h。不能和 --permanent 同时使用 firewall-cmd [--permanent] [--zone=zone] --add-source-port=portid[-portid]/protocol [--timeout=timeval] firewall-cmd [--permanent] [--zone=zone] --remove-source-port=portid[-portid]/protocol # 查询区域中是否包含该源端口，包含返回 0，否则返回 1 firewall-cmd [--permanent] [--zone=zone] --query-source-port=portid[-portid]/protocol 添加/删除/查询区域中的富规则（zone.rule）\n对于某些不支持 Ipv6 标签的操作，可以在这里提供支持。详情参考：firewalld.richlanguage(5)\n1 2 3 4 5 6 firewall-cmd [--permanent] [--zone=zone] --list-rich-rules # --timeout 设置当前规则的失效时间，例如：60s/20m/1h。不能和 --permanent 同时使用 firewall-cmd [--permanent] [--zone=zone] --add-rich-rule='rule' [--timeout=timeval] firewall-cmd [--permanent] [--zone=zone] --remove-rich-rule='rule' # 查询区域中是否包含该源端口，包含返回 0，否则返回 1 firewall-cmd [--permanent] [--zone=zone] --query-rich-rule='rule' 查询/修改服务（Service）状态的命令 查询预定义的服务\n1 firewall-cmd [--permanent] --get-services 查看服务的信息\n1 firewall-cmd [--permanent] --info-service=service 新建服务\n1 2 3 4 # 服务名可以包含字母、数字、_、- firewall-cmd --permanent --new-service=service # 从文件中加载服务信息 firewall-cmd --permanent --new-service-from-file=filename [--name=service] 删除服务\n1 firewall-cmd --permanent --delete-service=service 加载服务的默认设置\n1 firewall-cmd --permanent --load-service-defaults=service 查看服务的配置文件路径\n1 firewall-cmd --permanent --path-service=service 查询/调整服务（Service）配置的命令 查询和调整的是 service 配置文件中的标签属性，标签的说明可参考 服务配置文件格式\n查看/修改简短的描述（service.short）\n1 2 firewall-cmd --permanent --service=service --get-short firewall-cmd --permanent --service=service --set-short=description 查看/修改描述（service.description）\n1 2 firewall-cmd --permanent --service=service --get-description firewall-cmd --permanent --service=service --set-description=description 查看/添加/删除服务的端口（service.port）\n1 2 3 4 5 6 # 获取服务中添加的所有端口信息 firewall-cmd --permanent --service=service --get-ports # 查询服务中是否包含指定的端口 firewall-cmd --permanent --service=service --query-port=portid[-portid]/protocol firewall-cmd --permanent --service=service --add-port=portid[-portid]/protocol firewall-cmd --permanent --service=service --remove-port=portid[-portid]/protocol 查看/添加/删除服务的协议（service.protocol）\n1 2 3 4 firewall-cmd --permanent --service=service --get-protocols firewall-cmd --permanent --service=service --query-protocol=protocol firewall-cmd --permanent --service=service --add-protocol=protocol firewall-cmd --permanent --service=service --remove-protocol=protocol 查看/添加/删除服务的源端口（service.source-port）\n1 2 3 4 firewall-cmd --permanent --service=service --get-source-ports firewall-cmd --permanent --service=service --query-source-port=portid[-portid]/protocol firewall-cmd --permanent --service=service --add-source-port=portid[-portid]/protocol firewall-cmd --permanent --service=service --remove-source-port=portid[-portid]/protocol 查看/添加/删除服务模块中的 helper（service.module）\n1 2 3 4 firewall-cmd --permanent --service=service --get-service-helpers firewall-cmd --permanent --service=service --add-helper=helper firewall-cmd --permanent --service=service --remove-helper=helper firewall-cmd --permanent --service=service --query-helper=helper 查看/添加/删除服务的目的地（service.destination）\n1 2 3 4 firewall-cmd --permanent --service=service --get-destinations firewall-cmd --permanent --service=service --query-destination=ipv:address[/mask] firewall-cmd --permanent --service=service --set-destination=ipv:address[/mask] firewall-cmd --permanent --service=service --remove-destination=ipv 查看/添加/删除服务的引入\n1 2 3 4 firewall-cmd --permanent --service=service --get-includes firewall-cmd --permanent --service=service --query-include=service firewall-cmd --permanent --service=service --add-include=service firewall-cmd --permanent --service=service --remove-include=service 常用命令案例 开放指定端口\n1 2 3 firewall-cmd --permanent --add-port=8080/tcp # 按范围开放端口 firewall-cmd --permanent --add-port=8000-8003/tcp 在当前 zone 中允许 wireguard 服务\n1 2 3 4 5 firewall-cmd --permanent --get-services firewall-cmd --permanent --list-services firewall-cmd --permanent --add-service=wireguard firewall-cmd --reload firewall-cmd --list-all 设置/删除只允许指定 IP 段的机器访问 6379 端口\n1 2 firewall-cmd --add-rich-rule=\"rule family=\"ipv4\" source address=\"192.168.1.0/24\" port protocol=\"tcp\" port=\"6379\" accept\" --permanent firewall-cmd --remove-rich-rule=\"rule family=\"ipv4\" source address=\"192.168.1.0/24\" port protocol=\"tcp\" port=\"6379\" accept\" --permanent 参考文档\nUSING FIREWALLS\nfirewalld\nman firewall-cmd\n","description":"","tags":["Linux"],"title":"firewalld","uri":"/posts/linux/firewalld/"},{"categories":null,"content":"NFS 需要开启的端口 nfs tcp 2049 这个很明显到处都是 sunrpc tcp 111 这个很明显到处都是 sunrpc udp 111 其中这个很难发现，仔细排查才看到 acp-proto udp 4046 其中仔细看 udp 的会找到 参考文档 NFS 挂载的时候需要开通那几个端口的访问权限。\n","description":"","tags":["Linux","NFS"],"title":"NFS 需要开启的端口","uri":"/posts/linux/linux-nfs-port/"},{"categories":null,"content":"Ubuntu 配置 Java 环境 下载 JDK\n从 Oracle 下载 JDK\n解压\n1 tar -zxvf jdk1.8.0_202.tar.gz 向 ~/.profile（仅对当前用户生效）或 /etc/profile（对所有用户生效）文件中添加如下代码\n1 2 3 4 # java environment JAVA_HOME=/path/to/jdk1.8.0_202 PATH=$JAVA_HOME/bin:$PATH export JAVA_HOME PATH JDK1.4（包含）之前还需要配置 CLASSPATH\n1 2 3 4 5 # java environment JAVA_HOME=/path/to/jdk1.8.0_202 PATH=$JAVA_HOME/bin:$PATH CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export JAVA_HOME PATH CLASSPATH 刷新配置\n执行 source ~/.profile 或 source /etc/profile\n","description":"","tags":["Linux","Ubuntu"],"title":"Ubuntu 配置 Java 环境","uri":"/posts/linux/ubuntu/ubuntu-install-java/"},{"categories":null,"content":"Win10 挂载 linux 盘 CentOS 安装 rpcbind 和 nfs-utils 1 yum install rpcbind nfs-utils 说明：\nNFS 是一个 RPC 服务，启动任何一个 RPC 服务都需要做好端口映射，该工作是由 rpcbind 负责的。因此，需要在启动 NFS 之前启动 rpcbind。\nnfs-utils 是 nfs 的主程序，提供 rpc.nfsd 和 rpc.mountd 两个服务以及其他文档文件等，\n启动服务 1 2 systemctl start rpcbind # 启动 rpc 服务 systemctl start nfs nfs-secure # 启动 nfs 服务和 nfs 安全传输服务 放行服务和端口 配置防火墙放行 nfs 服务\n1 firewall-cmd --zone=public --add-service=nfs --permanent 修改挂载监听端口\n1 2 vim /etc/sysconfig/nfs 取消 MOUNTD_PORT=892 的注释，则需要开放的端口为 892 开放端口\n1 2 3 4 5 6 # 放行 rpc 端口 firewall-cmd --zone=public --add-port=111/tcp --permanent firewall-cmd --zone=public --add-port=111/udp --permanent # 放行 nfs 端口 firewall-cmd --zone=public --add-port=892/tcp --permanent firewall-cmd --zone=public --add-port=892/udp --permanent 重新加载防火墙\n1 firewall-cmd --reload 注意\n可以对指定 IP 开放服务和端口\n配置挂载目录和客户端权限 1 2 3 4 # 创建共享文件夹 mkdir /shard # 编辑配置文件 vim /etc/exports 添加格式\n共享目录路径 允许访问的客户端（权限参数）允许访问的客户端（权限参数）\n1 2 3 4 /shard *(rw) # 任意主机都有读写权限 /public 192.168.125.31(rw,sync,no_root_squash) # 192.168.125.31 主机具有读写权限，并且使用 root 用户登录时，具有 root 权限 /public 192.168.0.0/24(rw,sync,no_root_squash) /public 192.168.0.0/24(rw,sync,no_root_squash) *(ro) 更新配置\n1 2 3 systemctl reload nfs 或 exportfs -a NFS 主要配置文件\n主要配置文件：/etc/exports\n这是 NFS 的主要配置文件了。该文件是空白的，有的系统可能不存在这个文件，主要手动建立。NFS 的配置一般只在这个文件中配置即可。\n分享资源的登录档：/var/lib/nfs/*tab\n在 NFS 服务器的登录文件都放置到 /var/lib/nfs/ 目录里面，在该目录下有两个比较重要的登录档，一个是 etab，主要记录了 NFS 所分享出来的目录的完整权限设定值；另一个 xtab 则记录曾经链接到此 NFS 服务器的相关客户端数据。\nNFS 系统配置文件：/etc/sysconfig/nfs，可以指定 NFS 的端口等信息\nNFS 主要指令\nNFS 文件系统维护指令：/usr/sbin/exportfs\n这个是维护 NFS 分享资源的指令，可以利用这个指令重新分享 /etc/exports 变更的目录资源、将 NFS Server 分享的目录卸除或重新分享。\n客户端查询服务器分享资源的指令：/usr/sbin/showmount\n这是另一个重要的 NFS 指令。exportfs 是用在 NFS Server 端，而 showmount 则主要用在 Client 端。showmount 可以用来察看 NFS 分享出来的目录资源。\n/etc/exports 参数说明\n参数 作用 ro 只读 rw 读写 root_squash 当 NFS 客户端以 root 用户访问时，映射为 NFS 服务器的匿名用户 no_root_squash 当 NFS 客户端以 root 用户访问时，映射为 NFS 服务器的 root 用户 all_squash 无论 NFS 客户端使用什么账户访问，均映射为 NFS 服务器的匿名用户 sync 同时将数据写入到内存与硬盘中，保证不丢失数据 async 优先将数据保存到内存，然后再写入磁盘；效率更高，但可能丢失数据 开启 Windows 客户端上的 NFS（Network File System）网络文件系统 开启 NFS\n控制面板 → 打开或关闭 windows 功能 → 勾选NFS及其子节点 → 立即重启计算机\n验证结果\ncmd输入 mount -h\n如遇权限问题，修改 Windows 客户端用户 UID 和 GID Win+R 输入 regedit 进入注册表编辑器 → HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\ClientForNFS\\CurrentVersion\\Default 下新建两个 DWORD(32)位值，添加 AnonymousUid 和 AnonymousGid，值均为 0，\n说明\n因为 CentOS7 中 root 用户的 uid=0，gid=0，可以使用 id 用户名 查看用户 id 信息，如 id root，如果是其他用户应该可以修改为对应的 id，\n挂载NFS cmd输入 mount \\\\\\\\NFS的IP地址或者主机名\\nfs目录名 挂载点 用法：mount [-o options] [-u:username] [-p:\u003cpassword | *\u003e] \u003c\\computername\\sharename\u003e \u003cdevicename | *\u003e\n1 mount -u:username -p:password \\\\192.168.121.128\\mynfs x: 取消挂载 cmd输入 umount 挂载点\n1 umount x: 参考文档 如何在Windows上挂载Linux系统分区 NFS服务器搭建与配置 ","description":"","tags":["Windows","Linux"],"title":"Win10 挂载 linux 盘","uri":"/posts/windows/windows-mount-linux/"},{"categories":null,"content":"远程访问 MySQL 旧版本 添加指定 IP 访问 GRANT ALL ON *.* TO 用户名@'IP 地址' IDENTIFIED BY '密码';\n1 2 3 use mysql; GRANT ALL ON *.* to root@'10.60.160.12' IDENTIFIED BY 'root'; FLUSH PRIVILEGES; 添加指定 IP 段访问 GRANT ALL ON *.* TO 用户名@'[xxx.xxx.xxx](http://xxx.xxx.xxx/).%' IDENTIFIED BY '密码';\n1 2 3 use mysql; GRANT ALL ON *.* to root@'10.60.160.%' IDENTIFIED BY 'root'; FLUSH PRIVILEGES; 添加任意 IP 访问 GRANT ALL ON *.* TO 用户名@'%' IDENTIFIED BY '密码';\n1 2 3 use mysql; GRANT ALL ON *.* TO root@'%' IDENTIFIED BY 'root'; FLUSH PRIVILEGES; 新版本 新版本的 MySQL 将创建用户和赋予权限分开了，因此使用上方命令会报错:\nYou have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'IDENTIFIED BY 'root'' at line 1\n需要使用如下命令:\n创建用户 CREATE USER '用户名'@'访问主机' IDENTIFIED BY '密码';\n1 CREATE USER 'root'@'%' IDENTIFIED BY 'root'; 赋予权限 GRANT 权限列表 ON 数据库 TO '用户名'@'访问主机';\n1 GRANT ALL ON *.* TO 'root'@'%'; 撤销权限 REVOKE 权限列表 ON 数据库 FROM '用户名'@'访问主机';\n1 REVOKE ALL ON *.* FROM 'root'@'%'; 删除用户 DROP USER '用户名'@'访问主机';\n1 DROP USER root@'%'; 参考资料 mysql 数据库添加某个 IP 访问\n","description":"","tags":["MySQL"],"title":"远程访问 MySQL","uri":"/posts/database/mysql-remote-access/"},{"categories":null,"content":"远程访问 Redis 允许所有机器连接 redis，注解掉所有 bind，并将 protected-mode 属性设置为 no。\n配置文件中的 bind 属性说明 默认情况\n未指定 bind（或者 bind 0.0.0.0），redis 将监听本服务器上所有可用网络接口地址。\n网络接口地址即计算机上每个网卡对应的 IP 地址，每一个网卡都有一个 IP 地址\n只允许本机访问\n使用 bind 127.0.0.1，127.0.0.1 是一个回环地址（Local Loopback），只有本地才能访问本机的回环地址\n指定网卡 IP，其他机器通过该网卡访问\n使用 bind xxx.xxx.xxx.xxx 监听一个网络接口，或者使用 bind xxx.xxx.xxx.xxx xxx.xxx.xxx.xxx 监听多个网络接口，则其他计算机可以通过绑定的网络接口访问\n原文\n1 2 3 4 5 6 7 8 9 10 11 12 # By default, if no \"bind\" configuration directive is specified, Redis listens # for connections from all the network interfaces available on the server. # It is possible to listen to just one or multiple selected interfaces using # the \"bind\" configuration directive, followed by one or more IP addresses. # ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the # internet, binding to all the interfaces is dangerous and will expose the # instance to everybody on the internet. So by default we uncomment the # following bind directive, that will force Redis to listen only into # the IPv4 loopback interface address (this means Redis will be able to # accept connections only from clients running into the same computer it # is running). protected-mode 属性说明 作用: 只有本机可以访问 redis\n必须满足三个条件，protected-mode 才生效，否则，其将处于关闭状态\nprotected-mode 属性为 yes 没有 bind 指令 没有设置密码 原文\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Protected mode is a layer of security protection, in order to avoid that # Redis instances left open on the internet are accessed and exploited. # # When protected mode is on and if: # # 1) The server is not binding explicitly to a set of addresses using the # \"bind\" directive. # 2) No password is configured. # # The server only accepts connections from clients connecting from the # IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain # sockets. # # By default protected mode is enabled. You should disable it only if # you are sure you want clients from other hosts to connect to Redis # even if no authentication is configured, nor a specific set of interfaces # are explicitly listed using the \"bind\" directive. 限制只有指定的主机可以连接到 redis 只能通过防火墙来控制\n参考链接 Redis 的 bind 的误区\n","description":"","tags":["Redis"],"title":"远程访问 Redis","uri":"/posts/database/redis-remote-access/"},{"categories":null,"content":"CentOS7 安装 GNOME 图形化界面 安装图形化页面包 1 yum groupinstall \"GNOME Desktop\" \"Graphical Administration Tools\" 启动图形化页面/默认图形化启动 启动图形化页面\n1 startx 注意 init 5 命令会要求创建新用户，startx 直接使用当前用户登录\n设置默认图形化启动\n1 ln -sf /lib/systemd/system/runlevel5.target /etc/systemd/system/default.target 参考文档 centos7 安装图形化界面\n","description":"","tags":["Linux","CentOS"],"title":"CentOS7 安装 GNOME 图形化界面","uri":"/posts/linux/centos/centos7-gnome/"},{"categories":null,"content":"There are unfinished transactions remaining 原因 由于强制结束 yum 过，所以存在未完成的 yum 事物，建议运行 yum-complete-transaction 命令清除\n解决方法 安装 yum-complete-transaction\n1 yum -y install yum-utils 清除 yum 缓存\n1 yum clearall 清除未完成事物\n1 yum-complete-transaction --cleanup-only 参考文档 There are unfinished transactions remaining 解决方法\n","description":"","tags":["Linux"],"title":"yum 安装 There are unfinished transactions remaining","uri":"/posts/linux/there-are-unfinished-transactions-remaining/"},{"categories":null,"content":"CentOS7 设置静态 IP 和 DNS 解析 寻找网卡对应的配置文件 1 cd /etc/sysconfig/network-scripts/ ifcfg-xxx(xxx 为网卡名称)\n修改对应网卡参数 1 vim ifcfg-xxx 参数说明 默认参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 TYPE=\"Ethernet\" # 网络类型 PROXY_METHOD=\"none\" # 代理方式 BROWSER_ONLY=\"no\" # 只是浏览器 BOOTPROTO=\"dhcp\" # 网卡引导协议，dhcp 自动获取 IP 地址,static 使用静态 IP 地址 DEFROUTE=\"yes\" # default route 是否设置为默认路由 IPV4_FAILURE_FATAL=\"no\" # 是否开启 IPV4 致命错误检测，如果 ipv4 配置失败会禁用设备 IPV6INIT=\"yes\" # IPV6 是否自动初始化 IPV6_AUTOCONF=\"yes\" # IPV6 是否自动配置 IPV6_DEFROUTE=\"yes\" # IPV6 是否可以为默认路由 IPV6_FAILURE_FATAL=\"no\" # 是否开启 IPV6 致命错误检测，如果 IPV6 配置失败会禁用设备 IPV6_ADDR_GEN_MODE=\"stable-privacy\" # IPV6 地址生成模型 NAME=\"ens33\" # 网卡物理设备名称 UUID=\"5e1647e0-5c6e-467d-ab2f-4fdc6e810422\" # 通用唯一识别码，每一个网卡都会有，不能重复，否两台 linux 只有一台网卡可用 DEVICE=\"ens33\" # 网卡设备名称，必须和 NAME 值一样 ONBOOT=\"yes\" #是否开启自动启动网络连接 其他参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 NM_CONTROLLED=\"yes\" # 是否可以由 Network Manager 托管 HWADDR=\"\" # MAC 地址 PREFIX=24 # 子网掩码 24 位 IPADDR=\"\" # IP 地址 NETMASK=\"\" # 子网掩码 GATEWAY=\"\" # 设置网关 DNS1=\"\" # 首选 DNS DNS2=\"\" # 次要 DNS DNS3=\"\" # 第三个 DNS，最多设置三个 DNS BROADCAST= # 广播 BRIDGE= # 设置桥接网卡 USERCTL=\"no\" # 是否允许非 root 用户控制该设备 MASTER=\"bond1\" # 指定主名称 SLAVE # 指定该接口是一个接合界面的组件 NETWORK # 网络地址 ARPCHECK=\"yes\" # 检测 PEERDNS # 是否允许 DHCP 获取的 DNS 覆盖本地的 DNS PEEROUTES # 是否从 DHCP 获取用于定义接口的默认网关的信息的路由表条目 重启网卡服务 1 systemctl restart network.service 参考文档 centOS7ifcfg-eth0 配置详解 CentOS7 配置网卡为静态 IP，如果你还学不会那真的没有办法了！ ","description":"","tags":["Linux","CentOS"],"title":"CentOS7 设置静态 IP 和 DNS 解析","uri":"/posts/linux/centos/centos7-static-ip-dns/"},{"categories":null,"content":"修改 npm 镜像 国内优秀 npm 镜像 淘宝 npm 镜像 搜索地址：http://npm.taobao.org/ registry 地址：http://registry.npm.taobao.org/ cnpmjs 镜像 搜索地址：http://cnpmjs.org/ registry 地址：http://r.cnpmjs.org/ 使用方式 临时使用 1 npm --registry https://registry.npm.taobao.org install express 持久使用 1 2 3 4 5 6 npm config set registry https://registry.npm.taobao.org // 配置后可通过下面方式来验证是否成功 npm config get registry // 或 npm info express 使用 cnpm 1 2 3 4 npm install -g cnpm --registry=https://registry.npm.taobao.org // 使用 cnpm install expresstall express 参考文档 https://blog.csdn.net/p358278505/article/details/78094542\n","description":"","tags":["NodeJS"],"title":"修改 npm 镜像","uri":"/posts/nodejs/npm-change-mirror/"},{"categories":null,"content":"CentOS7 安装和卸载 Docker 使用 yum 命令安装 Docker 准备环境 卸载旧版本\n1 sudo yum remove docker docker-client docker-client-lastest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine 安装社区版 建立仓库 安装必须包\n1 sudo yum install -y yum-utils device-mapper-persistent-data lvm2 设置稳定的仓库(stable repository)\n1 sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 可选项：使用 nightly 或者 test 仓库\n使用 nightly 仓库\n1 sudo yum-config-manager --enable docker-ce-nightly 使用 test 仓库\n1 sudo yum-config-manager --enable docker-ce-test 取消使用 nightly 或 test 库\n1 sudo yum-config-manager --disable docker-ce-nightly 安装 Docker 引擎(Engine) 安装最新版本\n1 sudo yum install docker-ce docker-ce-cli containerd.io **注意事项：**使用 yum install 或 yum update 不指定版本，会安装/更新为最新的版本\n安装特定版本\n查看所有版本\n1 2 3 4 5 6 sudo yum list docker-ce --shouduplicates | sort -r docker-ce.x86_64 3:18.09.1-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.0-3.el7 docker-ce-stable docker-ce.x86_64 18.06.1.ce-3.el7 docker-ce-stable docker-ce.x86_64 18.06.0.ce-3.el7 docker-ce-stable 安装特定版本\n1 2 3 4 sudo yum install docker-ce-\u003cVERSION_STRING\u003e docker-ce-cli-\u003cVERSION_STRING\u003e containerd.io 例： sudo yum install docker-ce-18.06.0 docker-ce-cli-18.06.0 containerd.io 开启服务\n1 sudo systemctl start docker 验证 1 sudo docker run hello-world 使用 rpm 包安装 Docker 安装 Docker 下载安装包 下载地址：https://download.docker.com/linux/centos/7/x86_64/stable/Packages/\n如需下载 nightly 或 test 版，只需将下载路径中的 stable 修改为 nightly 或 test\n安装 1 sudo yum install /path/to/package.rpm 启动 1 sudo systemctl start docker 验证 1 sudo docker run hello-world 卸载 Docker 卸载 Docker 包 1 sudo yum remove docker-ce 移除镜像，容器以及数据 1 sudo rm -rm /var/lib/docker 删除所有手动编写的配置文件 参考文档 docker 官方文档\n","description":"","tags":["Docker","CentOS"],"title":"CentOS7 安装和卸载 Docker","uri":"/posts/docker/docker-install-on-centos/"},{"categories":null,"content":"Docker 设置阿里云镜像地址 获取阿里云容器镜像服务地址 登录阿里云容器镜像服务：容器镜像服务 点击镜像加速器，得到加速器地址 修改 daemon 配置文件 修改 /etc/docker/daemon.json，如果没有就新建，将如下内容写入\n1 2 3 { \"registry-mirrors\": [\"https://xxx.mirror.aliyuncs.com\"] } 重启 daemon 1 systemctl daemon-reload 重启 Docker 1 systemctl restart docker 测试 1 docker info ","description":"","tags":["Docker"],"title":"Docker 设置阿里云镜像地址","uri":"/posts/docker/docker-mirrors/"},{"categories":null,"content":"Docker 用集装箱装运（Containerizing）一个应用 描述 Create and test individual containers for each component of your application by first creating Docker images. Assemble your containers and supporting infrastructure into a complete application, expressed either as a Docker stack file or in Kubernetes YAML. Test, share and deploy your complete containerized application. 建立 拉取示例代码 1 2 git clone -b v1 https://github.com/docker-training/node-bulletin-board cd node-bulletin-board/bulletin-board-app 编写 Dockerfile 1 2 3 4 5 6 7 8 FROM node:6.11.5 WORKDIR /usr/src/app COPY package.json . RUN npm install COPY . . CMD [ \"npm\", \"start\" ] 说明\nFROM\n指定程序使用的基础镜像，必须为第一个命令\nWORKDIR\n指定文件中后续的指令执行时所在的目录\nCOPY\n将主机上的文件拷贝到镜像中\nRUN\n在镜像中执行的命令\n参考文档\nDockerfile 文件详解 官方说明 构建和测试镜像 构建一个新镜像 1 docker image build -t bulletinboard:1.0 . 基于该镜像启动一个容器 1 docker container run --publish 8000:8080 --detach --name bb bulletinboard:1.0 说明\n--publish 8000:8080\n指定入方向端口为 8000，出方向端口为 8080，并且，防火墙规则默认禁止网路访问该容器\n--detach\n要求 Docker 后台运行该容器\n--name\n指定一个容器名称，在之后的操作中可以引用该名称\n**注意：**在启动容器的时候我们不需要输入其他任何的指定，因为在 Dockerfile 的 CMD 中我们已经指定了需要执行的命令，Docker 会自动去执行那些命令。\n测试 使用浏览器访问 localhost:8000\n删除容器 1 docker container rm --force bb ","description":"","tags":["Docker"],"title":"ocker 用集装箱装运（Containerizing）一个应用","uri":"/posts/docker/docker-containerizing-app/"},{"categories":null,"content":"Windows 安装 Redis Redis 临时服务 windows 下 redis 下载地址 https://github.com/MicrosoftArchive/redis/releases\n启动 redis 服务 cmd 运行\n1 redis-server.exe redis.windows.conf 客户端调用 cmd 运行\n1 redis-cli.exe -h 127.0.0.1 -p 6379 自定义 Redis 服务/启动多个 Redis 复制一份 redis 到另一个目录 修改 redis.windows.conf 将 port 6379 修改为 port 6380 等，指定端口号\n安装服务 1 redis-server.exe --service-install redis.windows.conf --service-name redis6380 --loglevel verbose 启动服务 1 redis-server.exe --service-start --service-name redis6380 停止服务 1 redis-server.exe --serviec-stop --service-name redis6380 卸载服务 1 redis-server.exe --service-uninstall --service-name redis6380 工具地址 Redis Desktop 参考博文 【Redis】windows 下 redis 服务的安装 ","description":"","tags":["Redis"],"title":"Windows 安装 Redis","uri":"/posts/database/redis-install-in-windows/"},{"categories":null,"content":"错误-MySQL server has gone away 出现原因: 使用 Navicat 导入大 sql 文件时，报 MySQL server has gone away 错误。由于 max_allowed_packet 的值过小。该值的作用是限制 MySQL 服务接收到的包的大小。\n解决方法 cmd 登录到 mysql 输入 show global variables like 'max_allowed_packet'; 查看 max_allowed_packet 的大小 输入 set global max_allowed_packet=4194304; 修改 max_allowed_packet 的大小 注意事项 需要在 root 用户权限下才可以修改成功 命令行中的修改只对当前有效，重启 MySQL 服务后恢复默认值，可以在配置文件中添加 max_allowed_packet=4M 来达到永久有效的目的 max_allowed_packet 的大小必须为 1024 的整数倍 ","description":"","tags":["Exception","MySQL"],"title":"MySQL server has gone away","uri":"/posts/database/mysql-server-has-gone-away/"},{"categories":null,"content":"Cannot start compilation: the output path is not specified for module \"...\" Specify the output path 原因 项目中此时没有指定 class 文件生成的路径，若单纯指定 module 的 output 路径会导致后续出现无法找到类的 Error。\n解决方法 打开 project structure → project，在右侧 project compiler output 目标路径文件夹，通常是\"\\Workspace Intelij\\project_name\\out\" 打开（project structure →）module，在 paths 栏中选择 Inherit project compiler output path 确定 ","description":"","tags":["IDEA","Exception","Java"],"title":"Cannot start compilation: the output path is not specified for module \"...\" Specify the output path","uri":"/posts/java/idea-cannot-start-compilation/"},{"categories":null,"content":"IDEA 中 maven 的使用 重新向工作空间导入仓库中的 jar 包 法 1：右键单击项目 → Maven → Reimport 法 2：先点击右侧 Maven 弹出窗口，点击 Reimport All Maven Projects 图标 下载 jar 包的源文件（Sources）和文档（Documentation） 法 1：右键单击项目 → Maven → Download Sources/Download Documentation/Download Sources and Documentation 法 2：先点击右侧 Maven 弹出窗口，点击 Download Sources and/or Documentation 重新下载未下载完成的 jar 包到本地仓库 点击右侧 Maven 弹出窗口 点击 Execute Maven Goal 在弹出窗口中输入 mvn -U idea:idea 点击 Execute 查看工作空间导入的 jar 包状态 点击菜单栏 File → Project Structure...【Ctrl+Alt+Shift+s】 点击 Libraries 即可查看当前工作空间的 jar 包状态 使用 tomcat7 插件运行项目 点击右侧 Maven 弹出窗口 单击需要运行的项目弹出选项 Lifecycle\u0026Plugins\u0026Dependencies 单击 Plugins 单击 tomcat7 右键单击 tomcat7:run 选择 Run 项目名或 Debug 项目名即可 ","description":"","tags":["IDEA","Java"],"title":"IDEA 中 maven 的使用","uri":"/posts/java/idea-maven/"},{"categories":null,"content":"Git 入门 CentOS 安装 git 1 yum install git 安装完成后，设置该计算机上 git 仓库的用户名和邮箱\n1 2 git config --global user.name \"Your Name\" git config --global user.email \"email@example.com\" --global：表示这台机器上所有 Git 仓库都会使用这个配置 使用 git init 把当前目录变成 Git 可以管理的仓库\n1 git init 版本控制 使用 git log 查看所有提交，或加上 --pretty=oneline 查看简略版\n1 2 git log git log --pretty=oneline 使用 git reset 回退版本，HEAD^ 代表上一版本，上上版本就是 HEAD^^，或者使用 HEAD~100 代表往上 100 个版本\n1 2 3 git reset --hard HEAD^ git reset --hard HEAD^^ git reset --hard HEAD~100 使用 git reflog 查看每一次命令\n1 git reflog 使用 git reset --hard 版本号 回退到指定版本\n1 git reset --hard 3s4d2s 使用 git status 查看状态\n1 git status 使用 git add \u003cfile\u003e ... 添加到暂存区\n1 2 git add file1.txt git add file2.txt file3.txt 使用 git commit 将暂存区的文件全部提交到版本库\n1 git commit -m \"message\" 使用 git checkout -- \u003cfile\u003e ... 丢弃工作区的更改\n1 git checkout -- readme.txt 自修改后还没有被放到暂存区，撤销修改就回到和版本库一模一样的状态； 已经添加到暂存区后，又做了修改，撤销修改就回到添加到暂存区后的状态。 使用 git reset HEAD \u003cfile\u003e 撤销暂存区的修改，重新放回工作区\n1 git reset HEAD readme.txt 之后可以使用 git checkout -- \u003cfile\u003e 撤销工作区的修改。\n如果将修改提交到了版本库，使用版本回退即可。\n1 git reset --hard HEAD^等/版本号 使用 git rm \u003cfile\u003e ... 删除版本库的文件\n1 git rm test.txt 删除后可以使用 commit 提交一下更改，并使用 rm 命令删除本地文件\n1 2 git commit -m \"remove test.txt\" rm test.txt 如果误删了工作区的文件，可以使用 git checkout 从版本库还原\n1 git checkout -- test.txt 远程版本库(使用 GitHub) 在用户目录下创建 ssh key 秘钥，成功后，会出现一个 .ssh 的文件夹，里面包含私钥 id_rsa 和公钥 id_rsa.pub。\n1 ssh-keygen -t rsa -C \"youremail@example.com\" 在 GitHub 中添加 SSH Key\nAccount → Settings → SSH and GPG keys → New SSH key，Title 任意，将公钥粘贴到 Key 中。 在 GitHub 中创建新的仓库\n＋ → New repository，填写 Repository name，其他可以默认 根据提示将本地仓库与该 GitHub 远程仓库关联\n1 git remote add origin git@github.com:swang-harbin/learngit.git 将本地仓库的文件推到 GitHub 远程仓库\n1 git push -u origin master -u 代表将本地仓库的 master 分支与 GitHub 远程仓库的 master 分支进行关联，以后推送或拉取可以简化命令。 只要本地做了提交，就可以把本地 master 分支的最新修改推送至 GitHub 仓库\n1 git push origin master 从 GitHub 服务器克隆仓库到本地仓库\n1 git clone git@github.com:swang-harbin/gitskills.git 分支管理 创建 dev 分支\n1 git branch dev 切换分支\n1 git checkout dev 创建 dev 分支，并切换到 dev\n1 git checkout -b dev 查看分支\n1 git branch 将 dev 分支合并到 master 分支，merge 是将指定分支合并到当前分支\n1 git merge dev 删除 dev 分支\n1 git branch -d dev 在两个不同分支上都对同一文件进行了修改，会产生冲突。删除文件中的\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003c ========== \u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e，并修改为所需内容，重新 add、commit 即可解决冲突，并将两分支合并到当前分支。可以查看图形化的 log 日志\n1 git log --graph --pretty=oneline --abbrev-commit 合并分支时，Git 默认使用 Fast forward 模式，在这种模式下，删除分支后，会丢掉被合并分支的信息。可以在合并时通过 --no-ff 禁用这种模式，合并后的历史有分支，能看出来曾经做过合并。\n1 git merge --no-ff -m \"merge with no-ff\" dev Bug 分支，当前正在 dev 分支上工作，但是需要去解决一个 master 分支上的 bug，但是 dev 分支上的代码没有开发完，不能提交，可以先将 dev 分支上当前的状态储藏起来。\n1 git stash 解决完 bug 之后，可以切换到 dev 分支，查看之前储藏的纪录\n1 git stash list 恢复工作现场\n1 2 git stash apply git stash drop 或\n1 git stash pop 第一种 apply 恢复后，不会删除 stash，需要使用 drop 删除 第二种恢复 stash 后会自动将 stash 删除 恢复到指定 stash，例如 stash@{0}\n1 git stash apply stash@{0} 强制删除一个没有被合并的分支\n1 git branch -D feature-vulcan 多人协作 查看远程库信息\n1 git remote -v -v 代表显示详细信息，可以不添加 推送分支，把该分支上的本地提交推送到远程库，推送时需要指定本地分支，例如 master\n1 git push origin master 抓取分支，新用户从远程库克隆后，默认只能看到本地的 master 分支，如需抓取远程其他分支，例如 dev\n1 git checkout -b dev origin/dev 通常，多人协作的工作模式 首先，可以试图推送自己的修改\n1 git push origin \u003cbranch-name\u003e 如果推送失败，则因为远程分支比你的本地更新，需要先用 git pull 试图合并；\n1 git pull 如果合并有冲突，则解决冲突，并在本地提交；\n没有冲突或者解决掉冲突后，再推送就能成功！\n1 git push origin \u003cbranch-name\u003e 如果 git pull 提示 no tracking information，则说明本地分支和远程分支的链接关系没有创建，用命令\n1 git branch --set-upstream-to=origin/\u003cbranch-name\u003e \u003cbranch-name\u003e 变基操作 1 git rebase 标签管理 首先，切换到需要打标签的分支上\n1 git checkout master 然后，使用 git tag \u003cname\u003e 默认在最新提交的 commit 上打标签\n1 git tag v1.0 使用 git tag 查看所有标签\n1 git tag 在历史提交上打标签 git tag \u003ctagName\u003e \u003ccommitId\u003e\n1 git tag v0.9 fd32da 创建带说明的标签 git tag -a \u003ctagName\u003e -m \u003cmessage\u003e \u003ccommitId\u003e\n1 git tag -a v0.1 -m \"version 0.1 released\" 1094adb 删除标签 git tag -d \u003ctagName\u003e\n1 git tag -d v0.1 推送某个标签到远程 git push origin \u003ctagName\u003e\n1 git push origin v1.0 推送全部未推送的本地标签\n1 git push origin --tags 删除远程标签\n先删除本地标签\n1 git tag -d v0.9 再删除远程标签 git push origon :refs/tags/\u003ctagName\u003e\n1 git push origon :refs/tags/v0.9 关联多个远程库 解除与某一远程库的关联 git remote rm \u003crepositoryName\u003e\n1 git remote rm origin 关联 GitHub\n1 git remote add github git@github.com:swang-harbin/learngit.git 关联码云\n1 git remote add gitee fit@gitee.com:swang-harbin/learngit.git 自定义 Git 让 Git 显示颜色\n1 git config --global color.ui true 忽略特殊文件 GitHub 提供的忽略文件模板：链接\n忽略文件的原则\n忽略操作系统自动生成的文件，比如缩略图等 忽略变异生成的中间文件、可执行文件等，也就是如果一个文件是通过另一个文件自动生成的，那自动生成的文件就没必要放进版本库，比如 Java 编译产生的.class 文件 忽略你自己的带有敏感信息的配置文件，比如存放口令的配置文件 强制添加被 .gitignore 忽略的文件\n1 git add -f \u003cfile\u003e 检查 .gitignore\n1 git check-ignore -v \u003cfile\u003e 配置别名 1 git config --global alias.st status --global 只针对当前用户起作用，如果不加只针对当前仓库起作用。仓库的配置文件在 .git/config 中，用户的在用户主目录下的 .gitconfig 文件中。\n搭建 Git 服务器 安装 Git：\n1 sudo yum install git 创建一个 git 用户，用来运行 git 服务：\n1 sudo adduser git 创建证书登录：\n收集所有需要登录的用户的公钥，就是他们自己的 id_rsa.pub 文件，把所有公钥导入到 /home/git/.ssh/authorized_keys 文件里，一行一个。\n初始化 Git 仓库：先选定一个目录作为 Git 仓库，假定是 /srv/sample.git，在 /srv 目录下输入命令：\n1 sudo git init --bare sample.git Git 就会创建一个裸仓库，裸仓库没有工作区，因为服务器上的 Git 仓库纯粹是为了共享，所以不让用户直接登录到服务器上去改工作区，并且服务器上的 Git 仓库通常都以 .git 结尾。然后，把 owner 改为 git：\n1 sudo chown -R git:git sample.git 禁用 shell 登录 出于安全考虑，第二步创建的 git 用户不允许登录 shell，这可以通过编辑 /etc/passwd 文件完成。找到类似下面的一行：\n1 git:x:1001:1001:,,,:/home/git:/bin/bash 改为：\n1 git:x:1001:1001:,,,:/home/git:/usr/bin/git-shell 这样，git 用户可以正常通过 ssh 使用 git，但无法登录 shell，因为我们为 git 用户指定的 git-shell 每次一登录就自动退出。\n克隆远程仓库：\n1 git clone git@server:/srv/sample.git 方便管理公钥：用Gitosis 控制权限：用Gitolite\n","description":"","tags":["Git"],"title":"Git 入门","uri":"/posts/git/git-introduction/"},{"categories":null,"content":"Eclipse 使用 git 提交项目 Team → Fetch from UpStream：从 git 服务器将代码拉取到本地服务器 Team → Pull：将本地服务器的代码拉取到工作空间 Team → Commit：将工作空间中的代码提交到本地服务器，这里要选择需要提交的文件，将 Unstaged Changes 中需要提交的代码 添加到 Staged Changes 中然后点击 Commit Team → Push Branch \"xxxxx\"：将本地服务器的代码提交到 git 服务器 ","description":"","tags":["Eclipse","Java"],"title":"Eclipse 使用 git 提交项目","uri":"/posts/java/eclipse-git/"},{"categories":null,"content":"马士兵：学习流程 算法 设计模式（坦克一期项目） 多线程与高并发（进程内高并发）【不断更新】 JVM 入门到精通【不断更新】 从网络到分布式（集群内高并发） Redis Zookeeper Nginx LVS 网络 MySQL 调优 网游后端（Netty 应用） Spring 源码，Netty 源码 网约车 基础：Spring Cloud 亿级流量多级缓存平台 ","description":"","tags":null,"title":"马士兵：学习流程","uri":"/posts/msb/msb-study-process/"}]
